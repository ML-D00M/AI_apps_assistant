{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import JSONLoader\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your LlamaIndex documentation JSON file\n",
    "file_path = './llamaindex_docs/test_llamaindex.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the metadata extraction function\n",
    "def metadata_func(record: dict, metadata: dict) -> dict:\n",
    "    # Assuming each record in your JSON has a 'title' field you want to include in the metadata\n",
    "    metadata[\"filename\"] = record.get(\"filename\")\n",
    "    metadata[\"filepath\"] = record.get(\"filepath\")\n",
    "    metadata[\"url\"] = record.get(\"url\")\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the JSONLoader with appropriate parameters\n",
    "loader = JSONLoader(\n",
    "    file_path=file_path,\n",
    "    jq_schema='.[]',  # Adjust this based on your actual JSON structure\n",
    "    content_key=\"content\",  # Key where the actual content is stored\n",
    "    metadata_func=metadata_func  # Function to extract additional metadata from each record\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='# GPT Builder Demo\\n\\n<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/agent_builder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\\n\\nInspired by GPTs interface, presented at OpenAI Dev Day 2023. Construct an agent with natural language.\\n\\nHere you can build your own agent...with another agent!\\n\\n\\n```python\\nfrom llama_index.tools import BaseTool, FunctionTool\\n```\\n\\n\\n```python\\nfrom llama_index.agent import OpenAIAgent\\nfrom llama_index.prompts import PromptTemplate\\nfrom llama_index.llms import ChatMessage, OpenAI\\nfrom llama_index import ServiceContext\\n```\\n\\n\\n```python\\nllm = OpenAI(model=\"gpt-4\")\\nservice_context = ServiceContext.from_defaults(llm=llm)\\n```\\n\\n## Define Candidate Tools\\n\\nWe also define a tool retriever to retrieve candidate tools.\\n\\nIn this setting we define tools as different Wikipedia pages.\\n\\n\\n```python\\nfrom llama_index import SimpleDirectoryReader\\n```\\n\\n\\n```python\\nwiki_titles = [\"Toronto\", \"Seattle\", \"Chicago\", \"Boston\", \"Houston\"]\\n```\\n\\n\\n```python\\nfrom pathlib import Path\\n\\nimport requests\\n\\nfor title in wiki_titles:\\n    response = requests.get(\\n        \"https://en.wikipedia.org/w/api.php\",\\n        params={\\n            \"action\": \"query\",\\n            \"format\": \"json\",\\n            \"titles\": title,\\n            \"prop\": \"extracts\",\\n            # \\'exintro\\': True,\\n            \"explaintext\": True,\\n        },\\n    ).json()\\n    page = next(iter(response[\"query\"][\"pages\"].values()))\\n    wiki_text = page[\"extract\"]\\n\\n    data_path = Path(\"data\")\\n    if not data_path.exists():\\n        Path.mkdir(data_path)\\n\\n    with open(data_path / f\"{title}.txt\", \"w\") as fp:\\n        fp.write(wiki_text)\\n```\\n\\n\\n```python\\n# Load all wiki documents\\ncity_docs = {}\\nfor wiki_title in wiki_titles:\\n    city_docs[wiki_title] = SimpleDirectoryReader(\\n        input_files=[f\"data/{wiki_title}.txt\"]\\n    ).load_data()\\n```\\n\\n### Build Query Tool for Each Document\\n\\n\\n```python\\nfrom llama_index.agent import OpenAIAgent\\nfrom llama_index.tools import QueryEngineTool, ToolMetadata\\n\\n# Build tool dictionary\\ntool_dict = {}\\n\\nfor wiki_title in wiki_titles:\\n    # build vector index\\n    vector_index = VectorStoreIndex.from_documents(\\n        city_docs[wiki_title], service_context=service_context\\n    )\\n    # define query engines\\n    vector_query_engine = vector_index.as_query_engine()\\n\\n    # define tools\\n    vector_tool = QueryEngineTool(\\n        query_engine=vector_query_engine,\\n        metadata=ToolMetadata(\\n            name=wiki_title,\\n            description=(\"Useful for questions related to\" f\" {wiki_title}\"),\\n        ),\\n    )\\n    tool_dict[wiki_title] = vector_tool\\n```\\n\\n### Define Tool Retriever\\n\\n\\n```python\\n# define an \"object\" index and retriever over these tools\\nfrom llama_index import VectorStoreIndex\\nfrom llama_index.objects import ObjectIndex, SimpleToolNodeMapping\\n\\ntool_mapping = SimpleToolNodeMapping.from_objects(list(tool_dict.values()))\\ntool_index = ObjectIndex.from_objects(\\n    list(tool_dict.values()),\\n    tool_mapping,\\n    VectorStoreIndex,\\n)\\ntool_retriever = tool_index.as_retriever(similarity_top_k=1)\\n```\\n\\n### Load Data\\n\\nHere we load wikipedia pages from different cities.\\n\\n## Define Meta-Tools for GPT Builder\\n\\n\\n```python\\nfrom llama_index.prompts import ChatPromptTemplate\\nfrom typing import List\\n\\nGEN_SYS_PROMPT_STR = \"\"\"\\\\\\nTask information is given below. \\n\\nGiven the task, please generate a system prompt for an OpenAI-powered bot to solve this task: \\n{task} \\\\\\n\"\"\"\\n\\ngen_sys_prompt_messages = [\\n    ChatMessage(\\n        role=\"system\",\\n        content=\"You are helping to build a system prompt for another bot.\",\\n    ),\\n    ChatMessage(role=\"user\", content=GEN_SYS_PROMPT_STR),\\n]\\n\\nGEN_SYS_PROMPT_TMPL = ChatPromptTemplate(gen_sys_prompt_messages)\\n\\n\\nagent_cache = {}\\n\\n\\ndef create_system_prompt(task: str):\\n    \"\"\"Create system prompt for another agent given an input task.\"\"\"\\n    llm = OpenAI(llm=\"gpt-4\")\\n    fmt_messages = GEN_SYS_PROMPT_TMPL.format_messages(task=task)\\n    response = llm.chat(fmt_messages)\\n    return response.message.content\\n\\n\\ndef get_tools(task: str):\\n    \"\"\"Get the set of relevant tools to use given an input task.\"\"\"\\n    subset_tools = tool_retriever.retrieve(task)\\n    return [t.metadata.name for t in subset_tools]\\n\\n\\ndef create_agent(system_prompt: str, tool_names: List[str]):\\n    \"\"\"Create an agent given a system prompt and an input set of tools.\"\"\"\\n    llm = OpenAI(model=\"gpt-4\")\\n    try:\\n        # get the list of tools\\n        input_tools = [tool_dict[tn] for tn in tool_names]\\n\\n        agent = OpenAIAgent.from_tools(input_tools, llm=llm, verbose=True)\\n        agent_cache[\"agent\"] = agent\\n        return_msg = \"Agent created successfully.\"\\n    except Exception as e:\\n        return_msg = f\"An error occurred when building an agent. Here is the error: {repr(e)}\"\\n    return return_msg\\n```\\n\\n\\n```python\\nsystem_prompt_tool = FunctionTool.from_defaults(fn=create_system_prompt)\\nget_tools_tool = FunctionTool.from_defaults(fn=get_tools)\\ncreate_agent_tool = FunctionTool.from_defaults(fn=create_agent)\\n```\\n\\n\\n```python\\nGPT_BUILDER_SYS_STR = \"\"\"\\\\\\nYou are helping to construct an agent given a user-specified task. You should generally use the tools in this order to build the agent.\\n\\n1) Create system prompt tool: to create the system prompt for the agent.\\n2) Get tools tool: to fetch the candidate set of tools to use.\\n3) Create agent tool: to create the final agent.\\n\"\"\"\\n\\nprefix_msgs = [ChatMessage(role=\"system\", content=GPT_BUILDER_SYS_STR)]\\n\\n\\nbuilder_agent = OpenAIAgent.from_tools(\\n    tools=[system_prompt_tool, get_tools_tool, create_agent_tool],\\n    llm=llm,\\n    prefix_messages=prefix_msgs,\\n    verbose=True,\\n)\\n```\\n\\n\\n```python\\nbuilder_agent.query(\"Build an agent that can tell me about Toronto.\")\\n```\\n\\n    === Calling Function ===\\n    Calling function: create_system_prompt with args: {\\n      \"task\": \"tell me about Toronto\"\\n    }\\n    Got output: System Prompt: \\n    \\n    \"Sure, I can provide you with information about Toronto. Toronto is the capital city of the province of Ontario, Canada. It is the largest city in Canada and one of the most multicultural cities in the world. Known for its diverse population, vibrant arts scene, and thriving business community, Toronto offers a wide range of attractions and experiences.\\n    \\n    Toronto is home to iconic landmarks such as the CN Tower, which offers breathtaking views of the city, and the Royal Ontario Museum, which houses an extensive collection of art, culture, and natural history. The city also boasts beautiful waterfront areas, including the Harbourfront Centre and the Toronto Islands, where visitors can enjoy outdoor activities and scenic views.\\n    \\n    In terms of culture, Toronto hosts numerous festivals throughout the year, including the Toronto International Film Festival, Caribana, and Nuit Blanche. The city is also known for its world-class dining scene, offering a diverse range of cuisines from around the globe.\\n    \\n    Toronto is a major economic hub, with a strong presence in industries such as finance, technology, and healthcare. It is home to the Toronto Stock Exchange and several multinational corporations. The city\\'s robust public transportation system, including the TTC subway and streetcar network, makes it easy to navigate and explore.\\n    \\n    Whether you\\'re interested in exploring its cultural attractions, enjoying its culinary delights, or experiencing its vibrant nightlife, Toronto has something to offer for everyone. How can I assist you further in discovering more about Toronto?\"\\n    ========================\\n    === Calling Function ===\\n    Calling function: get_tools with args: {\\n      \"task\": \"tell me about Toronto\"\\n    }\\n    Got output: [\\'Toronto\\']\\n    ========================\\n    === Calling Function ===\\n    Calling function: create_agent with args: {\\n      \"system_prompt\": \"Sure, I can provide you with information about Toronto. Toronto is the capital city of the province of Ontario, Canada. It is the largest city in Canada and one of the most multicultural cities in the world. Known for its diverse population, vibrant arts scene, and thriving business community, Toronto offers a wide range of attractions and experiences.\\\\n\\\\nToronto is home to iconic landmarks such as the CN Tower, which offers breathtaking views of the city, and the Royal Ontario Museum, which houses an extensive collection of art, culture, and natural history. The city also boasts beautiful waterfront areas, including the Harbourfront Centre and the Toronto Islands, where visitors can enjoy outdoor activities and scenic views.\\\\n\\\\nIn terms of culture, Toronto hosts numerous festivals throughout the year, including the Toronto International Film Festival, Caribana, and Nuit Blanche. The city is also known for its world-class dining scene, offering a diverse range of cuisines from around the globe.\\\\n\\\\nToronto is a major economic hub, with a strong presence in industries such as finance, technology, and healthcare. It is home to the Toronto Stock Exchange and several multinational corporations. The city\\'s robust public transportation system, including the TTC subway and streetcar network, makes it easy to navigate and explore.\\\\n\\\\nWhether you\\'re interested in exploring its cultural attractions, enjoying its culinary delights, or experiencing its vibrant nightlife, Toronto has something to offer for everyone. How can I assist you further in discovering more about Toronto?\",\\n      \"tool_names\": [\"Toronto\"]\\n    }\\n    Got output: Agent created successfully.\\n    ========================\\n    \\n\\n\\n\\n\\n    Response(response=\\'The agent has been successfully created. It can provide detailed information about Toronto, including its landmarks, culture, economy, and transportation.\\', source_nodes=[], metadata=None)\\n\\n\\n\\n\\n```python\\ncity_agent = agent_cache[\"agent\"]\\n```\\n\\n\\n```python\\nresponse = city_agent.query(\"Tell me about the parks in Toronto\")\\nprint(str(response))\\n```\\n\\n    === Calling Function ===\\n    Calling function: Toronto with args: {\\n      \"input\": \"parks in Toronto\"\\n    }\\n    Got output: Toronto has a wide variety of public parks and spaces. Some of the downtown parks include Allan Gardens, Christie Pits, Grange Park, Little Norway Park, Moss Park, Queen\\'s Park, Riverdale Park and Trinity Bellwoods Park. There are also two large parks on the waterfront south of downtown: Tommy Thompson Park and the Toronto Islands. Other large parks managed by the city in the outer areas include High Park, Humber Bay Park, Centennial Park, Downsview Park, Guild Park and Gardens, Sunnybrook Park and Morningside Park. Toronto also has parts of Rouge National Urban Park, the largest urban park in North America, which is managed by Parks Canada.\\n    ========================\\n    Toronto is home to a variety of parks, offering a mix of natural beauty, recreational activities, and cultural experiences. Here are some of the notable parks in Toronto:\\n    \\n    1. **Allan Gardens**: Located downtown, this park features a conservatory with six greenhouses showcasing rare botanical plants.\\n    \\n    2. **Christie Pits**: Known for its outdoor pool and artificial ice rink, this park is a popular spot for sports and leisure.\\n    \\n    3. **Grange Park**: This park is located in the heart of the city and offers a playground, a splash pad, and a dog off-leash area.\\n    \\n    4. **Little Norway Park**: Overlooking the waterfront, this park features a playground, a wading pool, and a baseball diamond.\\n    \\n    5. **Moss Park**: This downtown park has a large sports field, a playground, and a splash pad.\\n    \\n    6. **Queen\\'s Park**: This urban park is home to the Ontario Legislative Building and several monuments.\\n    \\n    7. **Riverdale Park**: Offering panoramic views of downtown Toronto, this park has sports fields, a swimming pool, and a large off-leash dog area.\\n    \\n    8. **Trinity Bellwoods Park**: This popular park features a variety of recreational facilities, including sports fields, a wading pool, and a children\\'s playground.\\n    \\n    9. **Tommy Thompson Park**: Located on the waterfront, this park is a popular spot for bird watching and nature walks.\\n    \\n    10. **Toronto Islands**: This group of small islands offers beaches, picnic areas, and canoe rentals.\\n    \\n    11. **High Park**: Toronto\\'s largest public park, featuring hiking trails, sports facilities, a beautiful lakefront, a dog park, a zoo, and several playgrounds.\\n    \\n    12. **Humber Bay Park**: This waterfront park offers stunning views of the Toronto skyline, a butterfly habitat, and a network of trails.\\n    \\n    13. **Centennial Park**: One of Toronto\\'s busiest parks, featuring a conservatory, a ski hill, a golf centre, and a multipurpose sports field.\\n    \\n    14. **Downsview Park**: Once a military base, now a dynamic urban park with sports fields, a pond, and a forested area.\\n    \\n    15. **Guild Park and Gardens**: Known for its collection of salvaged architectural pieces, this park offers a unique blend of nature and culture.\\n    \\n    16. **Sunnybrook Park**: This park offers a variety of sports fields, horse stables, and a dog off-leash area.\\n    \\n    17. **Morningside Park**: One of Toronto\\'s largest parks, featuring picnic areas, walking trails, and a creek.\\n    \\n    18. **Rouge National Urban Park**: Managed by Parks Canada, this is the largest urban park in North America, offering a mix of wilderness, farmland, and historical sites.\\n    \\n', metadata={'source': '/mnt/c/Users/User/Documents/AI_ML/career_ai_engineer/Projects/ai_apps_assistant/llamaindex_docs/test_llamaindex.json', 'seq_num': 1, 'filename': 'agent_builder.ipynb', 'filepath': 'docs/examples/agent/agent_builder.ipynb', 'url': 'https://github.com/run-llama/llama_index/blob/3823389e3f91cab47b72e2cc2814826db9f98e32/docs/examples/agent/agent_builder.ipynb'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/Chatbot_SEC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\\n\\n# 💬🤖 How to Build a Chatbot\\n\\nLlamaIndex serves as a bridge between your data and Language Learning Models (LLMs), providing a toolkit that enables you to establish a query interface around your data for a variety of tasks, such as question-answering and summarization.\\n\\nIn this tutorial, we\\'ll walk you through building a context-augmented chatbot using a [Data Agent](https://gpt-index.readthedocs.io/en/stable/core_modules/agent_modules/agents/root.html). This agent, powered by LLMs, is capable of intelligently executing tasks over your data. The end result is a chatbot agent equipped with a robust set of data interface tools provided by LlamaIndex to answer queries about your data.\\n\\n**Note**: This tutorial builds upon initial work on creating a query interface over SEC 10-K filings - [check it out here](https://medium.com/@jerryjliu98/how-unstructured-and-llamaindex-can-help-bring-the-power-of-llms-to-your-own-data-3657d063e30d).\\n\\n### Context\\n\\nIn this guide, we’ll build a \"10-K Chatbot\" that uses raw UBER 10-K HTML filings from Dropbox. Users can interact with the chatbot to ask questions related to the 10-K filings.\\n\\n### Preparation\\n\\n\\n```python\\nimport os\\nimport openai\\n\\nos.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\\nopenai.api_key = os.environ[\"OPENAI_API_KEY\"]\\n\\nimport nest_asyncio\\n\\nnest_asyncio.apply()\\n```\\n\\n\\n```python\\n# set text wrapping\\nfrom IPython.display import HTML, display\\n\\n\\ndef set_css():\\n    display(\\n        HTML(\\n            \"\"\"\\n  <style>\\n    pre {\\n        white-space: pre-wrap;\\n    }\\n  </style>\\n  \"\"\"\\n        )\\n    )\\n\\n\\nget_ipython().events.register(\"pre_run_cell\", set_css)\\n```\\n\\n### Ingest Data\\n\\nLet\\'s first download the raw 10-k files, from 2019-2022.\\n\\n\\n```python\\n# NOTE: the code examples assume you\\'re operating within a Jupyter notebook.\\n# download files\\n!mkdir data\\n!wget \"https://www.dropbox.com/s/948jr9cfs7fgj99/UBER.zip?dl=1\" -O data/UBER.zip\\n!unzip data/UBER.zip -d data\\n```\\n\\n\\n\\n<style>\\n  pre {\\n      white-space: pre-wrap;\\n  }\\n</style>\\n\\n\\n\\n    --2023-09-22 11:13:42--  https://www.dropbox.com/s/948jr9cfs7fgj99/UBER.zip?dl=1\\n    Resolving www.dropbox.com (www.dropbox.com)... 2620:100:601f:18::a27d:912, 162.125.5.18\\n    Connecting to www.dropbox.com (www.dropbox.com)|2620:100:601f:18::a27d:912|:443... connected.\\n    HTTP request sent, awaiting response... 302 Found\\n    Location: /s/dl/948jr9cfs7fgj99/UBER.zip [following]\\n    --2023-09-22 11:13:43--  https://www.dropbox.com/s/dl/948jr9cfs7fgj99/UBER.zip\\n    Reusing existing connection to [www.dropbox.com]:443.\\n    HTTP request sent, awaiting response... 302 Found\\n    Location: https://uc5e96fc71f5bcad342d7ef5261b.dl.dropboxusercontent.com/cd/0/get/CEMPMHdxNS2yZDvMeO8IVhjAHBo1ExUFCUxxR3rUUAuuAn2VBlNyyyzCCERRU4Uj9cVyRgHADCluk4Kqqe1NWdxiC1Uh1u85EJEPIlVuW1gK9-KC3EcD0tD7u21w14I6d80gfspvvfKJCFzc15556zTV/file?dl=1# [following]\\n    --2023-09-22 11:13:43--  https://uc5e96fc71f5bcad342d7ef5261b.dl.dropboxusercontent.com/cd/0/get/CEMPMHdxNS2yZDvMeO8IVhjAHBo1ExUFCUxxR3rUUAuuAn2VBlNyyyzCCERRU4Uj9cVyRgHADCluk4Kqqe1NWdxiC1Uh1u85EJEPIlVuW1gK9-KC3EcD0tD7u21w14I6d80gfspvvfKJCFzc15556zTV/file?dl=1\\n    Resolving uc5e96fc71f5bcad342d7ef5261b.dl.dropboxusercontent.com (uc5e96fc71f5bcad342d7ef5261b.dl.dropboxusercontent.com)... 2620:100:601f:15::a27d:90f, 162.125.5.15\\n    Connecting to uc5e96fc71f5bcad342d7ef5261b.dl.dropboxusercontent.com (uc5e96fc71f5bcad342d7ef5261b.dl.dropboxusercontent.com)|2620:100:601f:15::a27d:90f|:443... connected.\\n    HTTP request sent, awaiting response... 200 OK\\n    Length: 1820227 (1,7M) [application/binary]\\n    Saving to: ‘data/UBER.zip’\\n    \\n    data/UBER.zip       100%[===================>]   1,74M  3,12MB/s    in 0,6s    \\n    \\n    2023-09-22 11:13:45 (3,12 MB/s) - ‘data/UBER.zip’ saved [1820227/1820227]\\n    \\n    Archive:  data/UBER.zip\\n       creating: data/UBER/\\n      inflating: data/UBER/UBER_2021.html  \\n      inflating: data/__MACOSX/UBER/._UBER_2021.html  \\n      inflating: data/UBER/UBER_2020.html  \\n      inflating: data/__MACOSX/UBER/._UBER_2020.html  \\n      inflating: data/UBER/UBER_2019.html  \\n      inflating: data/__MACOSX/UBER/._UBER_2019.html  \\n      inflating: data/UBER/UBER_2022.html  \\n      inflating: data/__MACOSX/UBER/._UBER_2022.html  \\n    \\n\\nTo parse the HTML files into formatted text, we use the [Unstructured](https://github.com/Unstructured-IO/unstructured) library. Thanks to [LlamaHub](https://llamahub.ai/), we can directly integrate with Unstructured, allowing conversion of any text into a Document format that LlamaIndex can ingest.\\n\\nFirst we install the necessary packages:\\n\\n\\n```python\\n!pip install llama-hub unstructured\\n```\\n\\n\\n\\n<style>\\n  pre {\\n      white-space: pre-wrap;\\n  }\\n</style>\\n\\n\\n\\n    Collecting llama-hub\\n      Obtaining dependency information for llama-hub from https://files.pythonhosted.org/packages/3f/af/3bc30c2b7ca1bdd7a193f67443539f6667a6b77dd62e54f2c5c8464ad4cb/llama_hub-0.0.31-py3-none-any.whl.metadata\\n      Downloading llama_hub-0.0.31-py3-none-any.whl.metadata (8.8 kB)\\n    Requirement already satisfied: unstructured in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (0.10.15)\\n    Collecting atlassian-python-api (from llama-hub)\\n      Obtaining dependency information for atlassian-python-api from https://files.pythonhosted.org/packages/ca/ed/3577ccec639736c8e4660423be68cf1a4a7040bf543b3144793760792949/atlassian_python_api-3.41.2-py3-none-any.whl.metadata\\n      Downloading atlassian_python_api-3.41.2-py3-none-any.whl.metadata (8.7 kB)\\n    Collecting html2text (from llama-hub)\\n      Downloading html2text-2020.1.16-py3-none-any.whl (32 kB)\\n    Requirement already satisfied: llama-index>=0.6.9 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from llama-hub) (0.8.29.post1)\\n    Requirement already satisfied: psutil in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from llama-hub) (5.9.5)\\n    Collecting retrying (from llama-hub)\\n      Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\\n    Requirement already satisfied: chardet in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from unstructured) (5.2.0)\\n    Requirement already satisfied: filetype in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from unstructured) (1.2.0)\\n    Requirement already satisfied: python-magic in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from unstructured) (0.4.27)\\n    Requirement already satisfied: lxml in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from unstructured) (4.9.3)\\n    Requirement already satisfied: nltk in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from unstructured) (3.8.1)\\n    Requirement already satisfied: tabulate in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from unstructured) (0.9.0)\\n    Requirement already satisfied: requests in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from unstructured) (2.31.0)\\n    Requirement already satisfied: beautifulsoup4 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from unstructured) (4.12.2)\\n    Requirement already satisfied: emoji in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from unstructured) (2.8.0)\\n    Requirement already satisfied: dataclasses-json in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from unstructured) (0.5.14)\\n    Requirement already satisfied: tiktoken in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from llama-index>=0.6.9->llama-hub) (0.5.1)\\n    Requirement already satisfied: langchain>=0.0.293 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from llama-index>=0.6.9->llama-hub) (0.0.295)\\n    Requirement already satisfied: sqlalchemy>=2.0.15 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from llama-index>=0.6.9->llama-hub) (2.0.21)\\n    Requirement already satisfied: numpy in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from llama-index>=0.6.9->llama-hub) (1.26.0)\\n    Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from llama-index>=0.6.9->llama-hub) (8.2.3)\\n    Requirement already satisfied: openai>=0.26.4 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from llama-index>=0.6.9->llama-hub) (0.28.0)\\n    Requirement already satisfied: pandas in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from llama-index>=0.6.9->llama-hub) (2.1.0)\\n    Requirement already satisfied: urllib3<2 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from llama-index>=0.6.9->llama-hub) (1.26.16)\\n    Requirement already satisfied: fsspec>=2023.5.0 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from llama-index>=0.6.9->llama-hub) (2023.9.1)\\n    Requirement already satisfied: typing-inspect>=0.8.0 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from llama-index>=0.6.9->llama-hub) (0.9.0)\\n    Requirement already satisfied: typing-extensions>=4.5.0 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from llama-index>=0.6.9->llama-hub) (4.8.0)\\n    Requirement already satisfied: nest-asyncio in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from llama-index>=0.6.9->llama-hub) (1.5.8)\\n    Collecting deprecated (from atlassian-python-api->llama-hub)\\n      Obtaining dependency information for deprecated from https://files.pythonhosted.org/packages/20/8d/778b7d51b981a96554f29136cd59ca7880bf58094338085bcf2a979a0e6a/Deprecated-1.2.14-py2.py3-none-any.whl.metadata\\n      Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\\n    Requirement already satisfied: six in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from atlassian-python-api->llama-hub) (1.16.0)\\n    Requirement already satisfied: oauthlib in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from atlassian-python-api->llama-hub) (3.2.2)\\n    Requirement already satisfied: requests-oauthlib in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from atlassian-python-api->llama-hub) (1.3.1)\\n    Requirement already satisfied: soupsieve>1.2 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from beautifulsoup4->unstructured) (2.5)\\n    Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from dataclasses-json->unstructured) (3.20.1)\\n    Requirement already satisfied: click in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from nltk->unstructured) (8.1.7)\\n    Requirement already satisfied: joblib in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from nltk->unstructured) (1.3.2)\\n    Requirement already satisfied: regex>=2021.8.3 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from nltk->unstructured) (2023.8.8)\\n    Requirement already satisfied: tqdm in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from nltk->unstructured) (4.66.1)\\n    Requirement already satisfied: charset-normalizer<4,>=2 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from requests->unstructured) (3.2.0)\\n    Requirement already satisfied: idna<4,>=2.5 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from requests->unstructured) (3.4)\\n    Requirement already satisfied: certifi>=2017.4.17 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from requests->unstructured) (2023.7.22)\\n    Requirement already satisfied: PyYAML>=5.3 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from langchain>=0.0.293->llama-index>=0.6.9->llama-hub) (6.0.1)\\n    Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from langchain>=0.0.293->llama-index>=0.6.9->llama-hub) (3.8.5)\\n    Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from langchain>=0.0.293->llama-index>=0.6.9->llama-hub) (4.0.3)\\n    Requirement already satisfied: langsmith<0.1.0,>=0.0.38 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from langchain>=0.0.293->llama-index>=0.6.9->llama-hub) (0.0.38)\\n    Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from langchain>=0.0.293->llama-index>=0.6.9->llama-hub) (2.8.6)\\n    Requirement already satisfied: pydantic<3,>=1 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from langchain>=0.0.293->llama-index>=0.6.9->llama-hub) (1.10.12)\\n    Requirement already satisfied: packaging>=17.0 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured) (23.1)\\n    Requirement already satisfied: greenlet!=0.4.17 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from sqlalchemy>=2.0.15->llama-index>=0.6.9->llama-hub) (2.0.2)\\n    Requirement already satisfied: mypy-extensions>=0.3.0 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index>=0.6.9->llama-hub) (1.0.0)\\n    Requirement already satisfied: wrapt<2,>=1.10 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from deprecated->atlassian-python-api->llama-hub) (1.15.0)\\n    Requirement already satisfied: python-dateutil>=2.8.2 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from pandas->llama-index>=0.6.9->llama-hub) (2.8.2)\\n    Requirement already satisfied: pytz>=2020.1 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from pandas->llama-index>=0.6.9->llama-hub) (2023.3.post1)\\n    Requirement already satisfied: tzdata>=2022.1 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from pandas->llama-index>=0.6.9->llama-hub) (2023.3)\\n    Requirement already satisfied: attrs>=17.3.0 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.293->llama-index>=0.6.9->llama-hub) (23.1.0)\\n    Requirement already satisfied: multidict<7.0,>=4.5 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.293->llama-index>=0.6.9->llama-hub) (6.0.4)\\n    Requirement already satisfied: yarl<2.0,>=1.0 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.293->llama-index>=0.6.9->llama-hub) (1.9.2)\\n    Requirement already satisfied: frozenlist>=1.1.1 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.293->llama-index>=0.6.9->llama-hub) (1.4.0)\\n    Requirement already satisfied: aiosignal>=1.1.2 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.293->llama-index>=0.6.9->llama-hub) (1.3.1)\\n    Downloading llama_hub-0.0.31-py3-none-any.whl (9.8 MB)\\n    \\x1b[2K   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m9.8/9.8 MB\\x1b[0m \\x1b[31m16.4 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m00:01\\x1b[0m00:01\\x1b[0m\\n    \\x1b[?25hDownloading atlassian_python_api-3.41.2-py3-none-any.whl (167 kB)\\n    \\x1b[2K   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m167.2/167.2 kB\\x1b[0m \\x1b[31m20.8 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m\\n    \\x1b[?25hDownloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\\n    Installing collected packages: retrying, html2text, deprecated, atlassian-python-api, llama-hub\\n    Successfully installed atlassian-python-api-3.41.2 deprecated-1.2.14 html2text-2020.1.16 llama-hub-0.0.31 retrying-1.3.4\\n    \\n\\nThen we can use the `UnstructuredReader` to parse the HTML files into a list of `Document` objects.\\n\\n\\n```python\\nfrom llama_hub.file.unstructured.base import UnstructuredReader\\nfrom pathlib import Path\\n\\nyears = [2022, 2021, 2020, 2019]\\n\\nloader = UnstructuredReader()\\ndoc_set = {}\\nall_docs = []\\nfor year in years:\\n    year_docs = loader.load_data(\\n        file=Path(f\"./data/UBER/UBER_{year}.html\"), split_documents=False\\n    )\\n    # insert year metadata into each year\\n    for d in year_docs:\\n        d.metadata = {\"year\": year}\\n    doc_set[year] = year_docs\\n    all_docs.extend(year_docs)\\n```\\n\\n\\n\\n<style>\\n  pre {\\n      white-space: pre-wrap;\\n  }\\n</style>\\n\\n\\n\\n    [nltk_data] Downloading package punkt to /home/jtorres/nltk_data...\\n    [nltk_data]   Package punkt is already up-to-date!\\n    [nltk_data] Downloading package averaged_perceptron_tagger to\\n    [nltk_data]     /home/jtorres/nltk_data...\\n    [nltk_data]   Package averaged_perceptron_tagger is already up-to-\\n    [nltk_data]       date!\\n    \\n\\n### Setting up Vector Indices for each year\\n\\nWe first setup a vector index for each year. Each vector index allows us\\nto ask questions about the 10-K filing of a given year.\\n\\nWe build each index and save it to disk.\\n\\n\\n```python\\n# initialize simple vector indices\\n# NOTE: don\\'t run this cell if the indices are already loaded!\\nfrom llama_index import VectorStoreIndex, ServiceContext, StorageContext\\n\\nindex_set = {}\\nservice_context = ServiceContext.from_defaults(chunk_size=512)\\nfor year in years:\\n    storage_context = StorageContext.from_defaults()\\n    cur_index = VectorStoreIndex.from_documents(\\n        doc_set[year],\\n        service_context=service_context,\\n        storage_context=storage_context,\\n    )\\n    index_set[year] = cur_index\\n    storage_context.persist(persist_dir=f\"./storage/{year}\")\\n```\\n\\n\\n\\n<style>\\n  pre {\\n      white-space: pre-wrap;\\n  }\\n</style>\\n\\n\\n\\nTo load an index from disk, do the following\\n\\n\\n```python\\n# Load indices from disk\\nfrom llama_index import load_index_from_storage\\n\\nindex_set = {}\\nfor year in years:\\n    storage_context = StorageContext.from_defaults(\\n        persist_dir=f\"./storage/{year}\"\\n    )\\n    cur_index = load_index_from_storage(\\n        storage_context, service_context=service_context\\n    )\\n    index_set[year] = cur_index\\n```\\n\\n\\n\\n<style>\\n  pre {\\n      white-space: pre-wrap;\\n  }\\n</style>\\n\\n\\n\\n### Setting up a Sub Question Query Engine to Synthesize Answers Across 10-K Filings\\n\\nSince we have access to documents of 4 years, we may not only want to ask questions regarding the 10-K document of a given year, but ask questions that require analysis over all 10-K filings.\\n\\nTo address this, we can use a [Sub Question Query Engine](https://gpt-index.readthedocs.io/en/stable/examples/query_engine/sub_question_query_engine.html). It decomposes a query into subqueries, each answered by an individual vector index, and synthesizes the results to answer the overall query.\\n\\nLlamaIndex provides some wrappers around indices (and query engines) so that they can be used by query engines and agents. First we define a `QueryEngineTool` for each vector index.\\nEach tool has a name and a description; these are what the LLM agent sees to decide which tool to choose.\\n\\n\\n```python\\nfrom llama_index.tools import QueryEngineTool, ToolMetadata\\n\\nindividual_query_engine_tools = [\\n    QueryEngineTool(\\n        query_engine=index_set[year].as_query_engine(),\\n        metadata=ToolMetadata(\\n            name=f\"vector_index_{year}\",\\n            description=(\\n                \"useful for when you want to answer queries about the\"\\n                f\" {year} SEC 10-K for Uber\"\\n            ),\\n        ),\\n    )\\n    for year in years\\n]\\n```\\n\\n\\n\\n<style>\\n  pre {\\n      white-space: pre-wrap;\\n  }\\n</style>\\n\\n\\n\\nNow we can create the Sub Question Query Engine, which will allow us to synthesize answers across the 10-K filings. We pass in the `individual_query_engine_tools` we defined above, as well as a `service_context` that will be used to run the subqueries.\\n\\n\\n```python\\nfrom llama_index.query_engine import SubQuestionQueryEngine\\n\\nquery_engine = SubQuestionQueryEngine.from_defaults(\\n    query_engine_tools=individual_query_engine_tools,\\n    service_context=service_context,\\n)\\n```\\n\\n\\n\\n<style>\\n  pre {\\n      white-space: pre-wrap;\\n  }\\n</style>\\n\\n\\n\\n### Setting up the Chatbot Agent\\n\\nWe use a LlamaIndex Data Agent to setup the outer chatbot agent, which has access to a set of Tools. Specifically, we will use an OpenAIAgent, that takes advantage of OpenAI API function calling. We want to use the separate Tools we defined previously for each index (corresponding to a given year), as well as a tool for the sub question query engine we defined above.\\n\\nFirst we define a `QueryEngineTool` for the sub question query engine:\\n\\n\\n```python\\nquery_engine_tool = QueryEngineTool(\\n    query_engine=query_engine,\\n    metadata=ToolMetadata(\\n        name=\"sub_question_query_engine\",\\n        description=(\\n            \"useful for when you want to answer queries that require analyzing\"\\n            \" multiple SEC 10-K documents for Uber\"\\n        ),\\n    ),\\n)\\n```\\n\\n\\n\\n<style>\\n  pre {\\n      white-space: pre-wrap;\\n  }\\n</style>\\n\\n\\n\\nThen, we combine the Tools we defined above into a single list of tools for the agent:\\n\\n\\n```python\\ntools = individual_query_engine_tools + [query_engine_tool]\\n```\\n\\n\\n\\n<style>\\n  pre {\\n      white-space: pre-wrap;\\n  }\\n</style>\\n\\n\\n\\nFinally, we call `OpenAIAgent.from_tools` to create the agent, passing in the list of tools we defined above.\\n\\n\\n```python\\nfrom llama_index.agent import OpenAIAgent\\n\\nagent = OpenAIAgent.from_tools(tools, verbose=True)\\n```\\n\\n\\n\\n<style>\\n  pre {\\n      white-space: pre-wrap;\\n  }\\n</style>\\n\\n\\n\\n### Testing the Agent\\n\\nWe can now test the agent with various queries.\\n\\nIf we test it with a simple \"hello\" query, the agent does not use any Tools.\\n\\n\\n```python\\nresponse = agent.chat(\"hi, i am bob\")\\nprint(str(response))\\n```\\n\\n\\n\\n<style>\\n  pre {\\n      white-space: pre-wrap;\\n  }\\n</style>\\n\\n\\n\\n    Hello Bob! How can I assist you today?\\n    \\n\\nIf we test it with a query regarding the 10-k of a given year, the agent will use\\nthe relevant vector index Tool.\\n\\n\\n```python\\nresponse = agent.chat(\\n    \"What were some of the biggest risk factors in 2020 for Uber?\"\\n)\\nprint(str(response))\\n```\\n\\n\\n\\n<style>\\n  pre {\\n      white-space: pre-wrap;\\n  }\\n</style>\\n\\n\\n\\n    === Calling Function ===\\n    Calling function: vector_index_2020 with args: {\\n      \"input\": \"biggest risk factors\"\\n    }\\n    Got output: The biggest risk factors mentioned in the context are:\\n    1. The adverse impact of the COVID-19 pandemic and actions taken to mitigate it on the business.\\n    2. The potential reclassification of drivers as employees, workers, or quasi-employees instead of independent contractors.\\n    3. Intense competition in the mobility, delivery, and logistics industries, with low barriers to entry and well-capitalized competitors.\\n    4. The need to lower fares or service fees and offer driver incentives and consumer discounts to remain competitive.\\n    5. Significant losses incurred and the uncertainty of achieving profitability.\\n    6. The risk of not attracting or maintaining a critical mass of platform users.\\n    7. Operational, compliance, and cultural challenges related to the workplace culture and forward-leaning approach.\\n    8. The potential negative impact of international investments and the challenges of conducting business in foreign countries, including operational and compliance challenges, localization requirements, restrictive laws and regulations, competition from local companies, social acceptance, technological compatibility, improper business practices, legal uncertainty, difficulties in managing international operations, currency exchange rate fluctuations, and regulations governing local currencies.\\n    ========================\\n    In 2020, some of the biggest risk factors for Uber were:\\n    \\n    1. The adverse impact of the COVID-19 pandemic and the measures taken to mitigate it on the business.\\n    2. The potential reclassification of drivers as employees, workers, or quasi-employees instead of independent contractors.\\n    3. Intense competition in the mobility, delivery, and logistics industries, with low barriers to entry and well-capitalized competitors.\\n    4. The need to lower fares or service fees and offer driver incentives and consumer discounts to remain competitive.\\n    5. Significant losses incurred and uncertainty about achieving profitability.\\n    6. The risk of not attracting or maintaining a critical mass of platform users.\\n    7. Operational, compliance, and cultural challenges related to the workplace culture and forward-leaning approach.\\n    8. The potential negative impact of international investments and the challenges of conducting business in foreign countries, including operational and compliance challenges, localization requirements, restrictive laws and regulations, competition from local companies, social acceptance, technological compatibility, improper business practices, legal uncertainty, difficulties in managing international operations, currency exchange rate fluctuations, and regulations governing local currencies.\\n    \\n    These risk factors highlight the challenges and uncertainties faced by Uber in 2020.\\n    \\n\\nFinally, if we test it with a query to compare/contrast risk factors across years, the agent will use the Sub Question Query Engine Tool.\\n\\n\\n```python\\ncross_query_str = (\\n    \"Compare/contrast the risk factors described in the Uber 10-K across\"\\n    \" years. Give answer in bullet points.\"\\n)\\n\\nresponse = agent.chat(cross_query_str)\\nprint(str(response))\\n```\\n\\n\\n\\n<style>\\n  pre {\\n      white-space: pre-wrap;\\n  }\\n</style>\\n\\n\\n\\n    === Calling Function ===\\n    Calling function: sub_question_query_engine with args: {\\n      \"input\": \"Compare/contrast the risk factors described in the Uber 10-K across years\"\\n    }\\n    Generated 4 sub questions.\\n    \\x1b[36;1m\\x1b[1;3m[vector_index_2022] Q: What are the risk factors described in the 2022 SEC 10-K for Uber?\\n    \\x1b[0m\\x1b[33;1m\\x1b[1;3m[vector_index_2021] Q: What are the risk factors described in the 2021 SEC 10-K for Uber?\\n    \\x1b[0m\\x1b[38;5;200m\\x1b[1;3m[vector_index_2020] Q: What are the risk factors described in the 2020 SEC 10-K for Uber?\\n    \\x1b[0m\\x1b[32;1m\\x1b[1;3m[vector_index_2019] Q: What are the risk factors described in the 2019 SEC 10-K for Uber?\\n    \\x1b[0m\\x1b[36;1m\\x1b[1;3m[vector_index_2022] A: The risk factors described in the 2022 SEC 10-K for Uber include the potential adverse effect on their business if drivers were classified as employees instead of independent contractors, the highly competitive nature of the mobility, delivery, and logistics industries, the need to lower fares or service fees to remain competitive in certain markets, the company\\'s history of significant losses and the expectation of increased operating expenses in the future, and the potential impact on their platform if they are unable to attract or maintain a critical mass of drivers, consumers, merchants, shippers, and carriers.\\n    \\x1b[0m\\x1b[32;1m\\x1b[1;3m[vector_index_2019] A: The risk factors described in the 2019 SEC 10-K for Uber include the loss of their license to operate in London, the complexity of their business and operating model due to regulatory uncertainties, the potential for additional regulations for their other products in the Other Bets segment, the evolving laws and regulations regarding the development and deployment of autonomous vehicles, and the increasing number of data protection and privacy laws around the world. Additionally, there are legal proceedings, litigation, claims, and government investigations that Uber is involved in, including those related to the classification of drivers and compliance with applicable laws, which could impose a significant burden on the company.\\n    \\x1b[0m\\x1b[33;1m\\x1b[1;3m[vector_index_2021] A: The risk factors described in the 2021 SEC 10-K for Uber include the adverse impact of the COVID-19 pandemic and actions taken to mitigate it on their business, the potential reclassification of drivers as employees instead of independent contractors, intense competition in the mobility, delivery, and logistics industries, the need to lower fares and offer incentives to remain competitive, significant losses incurred and the expectation of increased operating expenses, the importance of attracting and maintaining a critical mass of drivers, consumers, merchants, shippers, and carriers, and the uncertainty surrounding the impact of COVID-19 on their business and financial position. Additionally, the classification of drivers is being challenged in courts and by government agencies, which could have legal and financial implications for the company.\\n    \\x1b[0m\\x1b[38;5;200m\\x1b[1;3m[vector_index_2020] A: The risk factors described in the 2020 SEC 10-K for Uber include the adverse impact of the COVID-19 pandemic on their business, the potential reclassification of drivers as employees instead of independent contractors, intense competition in the mobility, delivery, and logistics industries, the need to lower fares and offer incentives to remain competitive, significant losses and the uncertainty of achieving profitability, the importance of attracting and maintaining a critical mass of platform users, operational and compliance challenges, inquiries and investigations from government agencies, risks related to data security breaches, the need to introduce new or upgraded products and features, and the need to invest in the development of new offerings to retain and attract users.\\n    \\x1b[0mGot output: The risk factors described in the Uber 10-K reports across the years include the potential reclassification of drivers as employees instead of independent contractors, intense competition in the mobility, delivery, and logistics industries, the need to lower fares and offer incentives to remain competitive, significant losses incurred and the expectation of increased operating expenses, the importance of attracting and maintaining a critical mass of drivers, consumers, merchants, shippers, and carriers, and the impact of the COVID-19 pandemic on their business. Additionally, there are legal and regulatory uncertainties, such as the evolving laws and regulations regarding autonomous vehicles, data protection and privacy laws, and the potential for additional regulations for their other products. The reports also mention the operational and compliance challenges, inquiries and investigations from government agencies, and the risks associated with data security breaches. It is worth noting that specific risk factors may vary from year to year based on the prevailing circumstances and developments in the industry and regulatory environment.\\n    ========================\\n    Here are the key points comparing and contrasting the risk factors described in the Uber 10-K reports across years:\\n    \\n    2022:\\n    - Potential reclassification of drivers as employees instead of independent contractors.\\n    - Intense competition in the mobility, delivery, and logistics industries.\\n    - Need to lower fares and offer incentives to remain competitive.\\n    - Significant losses incurred and expectation of increased operating expenses.\\n    - Importance of attracting and maintaining a critical mass of drivers, consumers, merchants, shippers, and carriers.\\n    - Impact of the COVID-19 pandemic on their business.\\n    - Legal and regulatory uncertainties, including evolving laws and regulations regarding autonomous vehicles and data protection and privacy laws.\\n    - Operational and compliance challenges.\\n    - Inquiries and investigations from government agencies.\\n    - Risks associated with data security breaches.\\n    \\n    2021:\\n    - Similar risk factors as in 2022, including potential reclassification of drivers, intense competition, need to lower fares, significant losses, and the impact of the COVID-19 pandemic.\\n    - Emphasis on the importance of maintaining a critical mass of drivers, consumers, merchants, shippers, and carriers.\\n    - Mention of legal and regulatory uncertainties, such as evolving laws and regulations regarding autonomous vehicles and data protection and privacy laws.\\n    - Operational and compliance challenges.\\n    - Inquiries and investigations from government agencies.\\n    - Risks associated with data security breaches.\\n    \\n    2020:\\n    - Similar risk factors as in 2021, including potential reclassification of drivers, intense competition, need to lower fares, significant losses, and the impact of the COVID-19 pandemic.\\n    - Emphasis on the importance of maintaining a critical mass of drivers, consumers, merchants, shippers, and carriers.\\n    - Mention of legal and regulatory uncertainties, such as evolving laws and regulations regarding autonomous vehicles and data protection and privacy laws.\\n    - Operational and compliance challenges.\\n    - Inquiries and investigations from government agencies.\\n    - Risks associated with data security breaches.\\n    \\n    2019:\\n    - Similar risk factors as in 2020, including potential reclassification of drivers, intense competition, need to lower fares, significant losses, and the impact of the COVID-19 pandemic.\\n    - Emphasis on the importance of maintaining a critical mass of drivers, consumers, merchants, shippers, and carriers.\\n    - Mention of legal and regulatory uncertainties, such as evolving laws and regulations regarding autonomous vehicles and data protection and privacy laws.\\n    - Operational and compliance challenges.\\n    - Inquiries and investigations from government agencies.\\n    - Risks associated with data security breaches.\\n    \\n    Please note that these are just the key points, and there may be additional risk factors mentioned in each year\\'s 10-K report.\\n    \\n\\n### Setting up the Chatbot Loop\\n\\nNow that we have the chatbot setup, it only takes a few more steps to setup a basic interactive loop to chat with our SEC-augmented chatbot!\\n\\n\\n```python\\nagent = OpenAIAgent.from_tools(tools)  # verbose=False by default\\n\\nwhile True:\\n    text_input = input(\"User: \")\\n    if text_input == \"exit\":\\n        break\\n    response = agent.chat(text_input)\\n    print(f\"Agent: {response}\")\\n\\n# User: What were some of the legal proceedings against Uber in 2022?\\n```\\n\\n\\n\\n<style>\\n  pre {\\n      white-space: pre-wrap;\\n  }\\n</style>\\n\\n\\n\\n    Agent: In 2022, Uber is facing several legal proceedings. Here are some of them:\\n    \\n    1. California: The state Attorney General and city attorneys filed a complaint against Uber and Lyft, alleging that drivers are misclassified as independent contractors. A preliminary injunction was issued but stayed pending appeal. The Court of Appeal affirmed the lower court\\'s ruling, and Uber filed a petition for review with the California Supreme Court. However, the Supreme Court declined the petition for review. The lawsuit is ongoing, focusing on claims by the California Attorney General for periods prior to the enactment of Proposition 22.\\n    \\n    2. Massachusetts: The Attorney General of Massachusetts filed a complaint against Uber, alleging that drivers are employees entitled to wage and labor law protections. Uber\\'s motion to dismiss the complaint was denied, and a summary judgment motion is pending.\\n    \\n    3. New York: Uber is facing allegations of misclassification and employment violations by the state Attorney General. The resolution of this matter is uncertain.\\n    \\n    4. Switzerland: Several administrative bodies in Switzerland have issued rulings classifying Uber drivers as employees for social security or labor purposes. Uber is challenging these rulings before the Social Security and Administrative Tribunals.\\n    \\n    These are some of the legal proceedings against Uber in 2022. The outcomes and potential losses in these cases are uncertain.\\n    \\n', metadata={'source': '/mnt/c/Users/User/Documents/AI_ML/career_ai_engineer/Projects/ai_apps_assistant/llamaindex_docs/test_llamaindex.json', 'seq_num': 2, 'filename': 'building_a_chatbot.md', 'filepath': 'docs/understanding/putting_it_all_together/chatbots/building_a_chatbot.md', 'url': 'https://github.com/run-llama/llama_index/blob/3823389e3f91cab47b72e2cc2814826db9f98e32/docs/understanding/putting_it_all_together/chatbots/building_a_chatbot.md'}),\n",
      " Document(page_content='# Building a Custom Agent\\n\\nIn this cookbook we show you how to build a custom agent using LlamaIndex.\\n\\nThe easiest way to build a custom agent is to simply subclass `CustomSimpleAgentWorker` and implement a few required functions. You have complete flexibility in defining the agent step-wise logic.\\n\\nThis lets you add arbitrarily complex reasoning logic on top of your RAG pipeline.\\n\\nWe show you how to build a simple agent that adds a retry layer on top of a RouterQueryEngine, allowing it to retry queries until the task is complete. We build this on top of both a SQL tool and a vector index query tool. Even if the tool makes an error or only answers part of the question, the agent can continue retrying the question until the task is complete.\\n\\n## Setup the Custom Agent\\n\\nHere we setup the custom agent.\\n\\n### Refresher\\n\\nAn agent in LlamaIndex consists of both an agent runner + agent worker. An agent runner is an orchestrator that stores state like memory, whereas an agent worker controls the step-wise execution of a Task. Agent runners include sequential, parallel execution. More details can be found in our [lower level API guide](https://docs.llamaindex.ai/en/latest/module_guides/deploying/agents/agent_runner.html).\\n\\nMost core agent logic (e.g. ReAct, function calling loops), can be executed in the agent worker. Therefore we\\'ve made it easy to subclass an agent worker, letting you plug it into any agent runner.\\n\\n### Creating a Custom Agent Worker Subclass\\n\\nAs mentioned above we subclass `CustomSimpleAgentWorker`. This is a class that already sets up some scaffolding for you. This includes being able to take in tools, callbacks, LLM, and also ensures that the state/steps are properly formatted. In the meantime you mostly have to implement the following functions:\\n\\n- `_initialize_state`\\n- `_run_step`\\n- `_finalize_task`\\n\\nSome additional notes:\\n- You can implement `_arun_step` as well if you want to support async chat in the agent.\\n- You can choose to override `__init__` as long as you pass all remaining args, kwargs to `super()`\\n- `CustomSimpleAgentWorker` is implemented as a Pydantic `BaseModel` meaning that you can define your own custom properties as well.\\n\\nHere are the full set of base properties on each `CustomSimpleAgentWorker` (that you need to/can pass in when constructing your custom agent):\\n- `tools: Sequence[BaseTool]`\\n- `tool_retriever: Optional[ObjectRetriever[BaseTool]]`\\n- `llm: LLM`\\n- `callback_manager: CallbackManager`\\n- `verbose: bool`\\n\\nNote that `tools` and `tool_retriever` are mutually exclusive, you can only pass in one or the either (e.g. define a static list of tools or define a callable function that returns relevant tools given a user message). You can call `get_tools(message: str)` to return relevant tools given a message.\\n\\nAll of these properties are accessible via `self` when defining your custom agent.\\n\\n\\n```python\\nfrom llama_index.agent import CustomSimpleAgentWorker, Task, AgentChatResponse\\nfrom typing import Dict, Any, List, Tuple\\nfrom llama_index.tools import BaseTool, QueryEngineTool\\nfrom llama_index.program import LLMTextCompletionProgram\\nfrom llama_index.output_parsers import PydanticOutputParser\\nfrom llama_index.query_engine import RouterQueryEngine\\nfrom llama_index.prompts import ChatPromptTemplate, PromptTemplate\\nfrom llama_index.selectors import PydanticSingleSelector\\nfrom pydantic import Field, BaseModel\\n```\\n\\nHere we define some helper variables and methods. E.g. the prompt template to use to detect errors as well as the response format in Pydantic.\\n\\n\\n```python\\nfrom llama_index.llms import ChatMessage, MessageRole\\n\\nDEFAULT_PROMPT_STR = \"\"\"\\nGiven previous question/response pairs, please determine if an error has occurred in the response, and suggest \\\\\\n    a modified question that will not trigger the error.\\n\\nExamples of modified questions:\\n- The question itself is modified to elicit a non-erroneous response\\n- The question is augmented with context that will help the downstream system better answer the question.\\n- The question is augmented with examples of negative responses, or other negative questions.\\n\\nAn error means that either an exception has triggered, or the response is completely irrelevant to the question.\\n\\nPlease return the evaluation of the response in the following JSON format.\\n\\n\"\"\"\\n\\n\\ndef get_chat_prompt_template(\\n    system_prompt: str, current_reasoning: Tuple[str, str]\\n) -> ChatPromptTemplate:\\n    system_msg = ChatMessage(role=MessageRole.SYSTEM, content=system_prompt)\\n    messages = [system_msg]\\n    for raw_msg in current_reasoning:\\n        if raw_msg[0] == \"user\":\\n            messages.append(\\n                ChatMessage(role=MessageRole.USER, content=raw_msg[1])\\n            )\\n        else:\\n            messages.append(\\n                ChatMessage(role=MessageRole.ASSISTANT, content=raw_msg[1])\\n            )\\n    return ChatPromptTemplate(message_templates=messages)\\n\\n\\nclass ResponseEval(BaseModel):\\n    \"\"\"Evaluation of whether the response has an error.\"\"\"\\n\\n    has_error: bool = Field(\\n        ..., description=\"Whether the response has an error.\"\\n    )\\n    new_question: str = Field(..., description=\"The suggested new question.\")\\n    explanation: str = Field(\\n        ...,\\n        description=(\\n            \"The explanation for the error as well as for the new question.\"\\n            \"Can include the direct stack trace as well.\"\\n        ),\\n    )\\n```\\n\\n\\n```python\\nfrom pydantic import PrivateAttr\\n\\n\\nclass RetryAgentWorker(CustomSimpleAgentWorker):\\n    \"\"\"Agent worker that adds a retry layer on top of a router.\\n\\n    Continues iterating until there\\'s no errors / task is done.\\n\\n    \"\"\"\\n\\n    prompt_str: str = Field(default=DEFAULT_PROMPT_STR)\\n    max_iterations: int = Field(default=10)\\n\\n    _router_query_engine: RouterQueryEngine = PrivateAttr()\\n\\n    def __init__(self, tools: List[BaseTool], **kwargs: Any) -> None:\\n        \"\"\"Init params.\"\"\"\\n        # validate that all tools are query engine tools\\n        for tool in tools:\\n            if not isinstance(tool, QueryEngineTool):\\n                raise ValueError(\\n                    f\"Tool {tool.metadata.name} is not a query engine tool.\"\\n                )\\n        self._router_query_engine = RouterQueryEngine(\\n            selector=PydanticSingleSelector.from_defaults(),\\n            query_engine_tools=tools,\\n            verbose=kwargs.get(\"verbose\", False),\\n        )\\n        super().__init__(\\n            tools=tools,\\n            **kwargs,\\n        )\\n\\n    def _initialize_state(self, task: Task, **kwargs: Any) -> Dict[str, Any]:\\n        \"\"\"Initialize state.\"\"\"\\n        return {\"count\": 0, \"current_reasoning\": []}\\n\\n    def _run_step(\\n        self, state: Dict[str, Any], task: Task\\n    ) -> Tuple[AgentChatResponse, bool]:\\n        \"\"\"Run step.\\n\\n        Returns:\\n            Tuple of (agent_response, is_done)\\n\\n        \"\"\"\\n        if \"new_input\" not in state:\\n            new_input = task.input\\n        else:\\n            new_input = state[\"new_input\"]\\n\\n        # first run router query engine\\n        response = self._router_query_engine.query(new_input)\\n\\n        # append to current reasoning\\n        state[\"current_reasoning\"].extend(\\n            [(\"user\", new_input), (\"assistant\", str(response))]\\n        )\\n\\n        # Then, check for errors\\n        # dynamically create pydantic program for structured output extraction based on template\\n        chat_prompt_tmpl = get_chat_prompt_template(\\n            self.prompt_str, state[\"current_reasoning\"]\\n        )\\n        llm_program = LLMTextCompletionProgram.from_defaults(\\n            output_parser=PydanticOutputParser(output_cls=ResponseEval),\\n            prompt=chat_prompt_tmpl,\\n            llm=self.llm,\\n        )\\n        # run program, look at the result\\n        response_eval = llm_program(\\n            query_str=new_input, response_str=str(response)\\n        )\\n        if not response_eval.has_error:\\n            is_done = True\\n        else:\\n            is_done = False\\n        state[\"new_input\"] = response_eval.new_question\\n\\n        if self.verbose:\\n            print(f\"> Question: {new_input}\")\\n            print(f\"> Response: {response}\")\\n            print(f\"> Response eval: {response_eval.dict()}\")\\n\\n        # return response\\n        return AgentChatResponse(response=str(response)), is_done\\n\\n    def _finalize_task(self, state: Dict[str, Any], **kwargs) -> None:\\n        \"\"\"Finalize task.\"\"\"\\n        # nothing to finalize here\\n        # this is usually if you want to modify any sort of\\n        # internal state beyond what is set in `_initialize_state`\\n        pass\\n```\\n\\n## Setup Data and Tools\\n\\nWe setup both a SQL Tool as well as vector index tools for each city.\\n\\n\\n```python\\nfrom llama_index.tools.query_engine import QueryEngineTool\\n```\\n\\n### Setup SQL DB + Tool\\n\\n\\n```python\\nfrom sqlalchemy import (\\n    create_engine,\\n    MetaData,\\n    Table,\\n    Column,\\n    String,\\n    Integer,\\n    select,\\n    column,\\n)\\nfrom llama_index import SQLDatabase\\n\\nengine = create_engine(\"sqlite:///:memory:\", future=True)\\nmetadata_obj = MetaData()\\n# create city SQL table\\ntable_name = \"city_stats\"\\ncity_stats_table = Table(\\n    table_name,\\n    metadata_obj,\\n    Column(\"city_name\", String(16), primary_key=True),\\n    Column(\"population\", Integer),\\n    Column(\"country\", String(16), nullable=False),\\n)\\n\\nmetadata_obj.create_all(engine)\\n```\\n\\n\\n```python\\nfrom sqlalchemy import insert\\n\\nrows = [\\n    {\"city_name\": \"Toronto\", \"population\": 2930000, \"country\": \"Canada\"},\\n    {\"city_name\": \"Tokyo\", \"population\": 13960000, \"country\": \"Japan\"},\\n    {\"city_name\": \"Berlin\", \"population\": 3645000, \"country\": \"Germany\"},\\n]\\nfor row in rows:\\n    stmt = insert(city_stats_table).values(**row)\\n    with engine.begin() as connection:\\n        cursor = connection.execute(stmt)\\n```\\n\\n\\n```python\\nfrom llama_index.indices.struct_store.sql_query import NLSQLTableQueryEngine\\n\\nsql_database = SQLDatabase(engine, include_tables=[\"city_stats\"])\\nsql_query_engine = NLSQLTableQueryEngine(\\n    sql_database=sql_database, tables=[\"city_stats\"], verbose=True\\n)\\nsql_tool = QueryEngineTool.from_defaults(\\n    query_engine=sql_query_engine,\\n    description=(\\n        \"Useful for translating a natural language query into a SQL query over\"\\n        \" a table containing: city_stats, containing the population/country of\"\\n        \" each city\"\\n    ),\\n)\\n```\\n\\n### Setup Vector Tools\\n\\n\\n```python\\nfrom llama_index.readers import WikipediaReader\\nfrom llama_index import VectorStoreIndex\\n```\\n\\n\\n```python\\ncities = [\"Toronto\", \"Berlin\", \"Tokyo\"]\\nwiki_docs = WikipediaReader().load_data(pages=cities)\\n```\\n\\n\\n```python\\n# build a separate vector index per city\\n# You could also choose to define a single vector index across all docs, and annotate each chunk by metadata\\nvector_tools = []\\nfor city, wiki_doc in zip(cities, wiki_docs):\\n    vector_index = VectorStoreIndex.from_documents([wiki_doc])\\n    vector_query_engine = vector_index.as_query_engine()\\n    vector_tool = QueryEngineTool.from_defaults(\\n        query_engine=vector_query_engine,\\n        description=f\"Useful for answering semantic questions about {city}\",\\n    )\\n    vector_tools.append(vector_tool)\\n```\\n\\n## Build Custom Agent\\n\\n\\n```python\\nfrom llama_index.agent import AgentRunner\\nfrom llama_index.llms import OpenAI\\n```\\n\\n\\n```python\\nllm = OpenAI(model=\"gpt-4\")\\ncallback_manager = llm.callback_manager\\n\\nquery_engine_tools = [sql_tool] + vector_tools\\nagent_worker = RetryAgentWorker.from_tools(\\n    query_engine_tools,\\n    llm=llm,\\n    verbose=True,\\n    callback_manager=callback_manager,\\n)\\nagent = AgentRunner(agent_worker, callback_manager=callback_manager)\\n```\\n\\n## Try Out Some Queries\\n\\n\\n```python\\nresponse = agent.chat(\"Which countries are each city from?\")\\nprint(str(response))\\n```\\n\\n    \\x1b[1;3;38;5;200mSelecting query engine 0: The choice is about translating a natural language query into a SQL query over a table containing city_stats, which likely includes information about the country of each city..\\n    \\x1b[0m> Table desc str: Table \\'city_stats\\' has columns: city_name (VARCHAR(16)), population (INTEGER), country (VARCHAR(16)), and foreign keys: .\\n    > Predicted SQL query: SELECT city_name, country FROM city_stats\\n    > Question: Which countries are each city from?\\n    > Response: The city of Toronto is from Canada, Tokyo is from Japan, and Berlin is from Germany.\\n    > Response eval: {\\'has_error\\': True, \\'new_question\\': \\'Which country is each of the following cities from: Toronto, Tokyo, Berlin?\\', \\'explanation\\': \\'The original question was too vague as it did not specify which cities the question was referring to. The new question provides specific cities for which the country of origin is being asked.\\'}\\n    \\x1b[1;3;38;5;200mSelecting query engine 0: This choice is relevant because it mentions a table containing city_stats, which likely includes information about the country of each city..\\n    \\x1b[0m> Table desc str: Table \\'city_stats\\' has columns: city_name (VARCHAR(16)), population (INTEGER), country (VARCHAR(16)), and foreign keys: .\\n    > Predicted SQL query: SELECT city_name, country\\n    FROM city_stats\\n    WHERE city_name IN (\\'Toronto\\', \\'Tokyo\\', \\'Berlin\\')\\n    > Question: Which country is each of the following cities from: Toronto, Tokyo, Berlin?\\n    > Response: Toronto is from Canada, Tokyo is from Japan, and Berlin is from Germany.\\n    > Response eval: {\\'has_error\\': False, \\'new_question\\': \\'\\', \\'explanation\\': \\'\\'}\\n    Toronto is from Canada, Tokyo is from Japan, and Berlin is from Germany.\\n    \\n\\n\\n```python\\nresponse = agent.chat(\\n    \"What are the top modes of transporation fo the city with the higehest population?\"\\n)\\nprint(str(response))\\n```\\n\\n    \\x1b[1;3;38;5;200mSelecting query engine 0: The question is asking about the top modes of transportation for the city with the highest population. Choice (1) is the most relevant because it mentions a table containing city_stats, which likely includes information about the population of each city..\\n    \\x1b[0m> Table desc str: Table \\'city_stats\\' has columns: city_name (VARCHAR(16)), population (INTEGER), country (VARCHAR(16)), and foreign keys: .\\n    > Predicted SQL query: SELECT city_name, population, mode_of_transportation\\n    FROM city_stats\\n    WHERE population = (SELECT MAX(population) FROM city_stats)\\n    ORDER BY mode_of_transportation ASC\\n    LIMIT 5;\\n    > Question: What are the top modes of transporation fo the city with the higehest population?\\n    > Response: I\\'m sorry, but there was an error in retrieving the information. Please try again later.\\n    > Response eval: {\\'has_error\\': True, \\'new_question\\': \\'What are the top modes of transportation for the city with the highest population?\\', \\'explanation\\': \\'The original question had spelling errors which might have caused the system to not understand the question correctly. The corrected question should now be clear and understandable for the system.\\'}\\n    \\x1b[1;3;38;5;200mSelecting query engine 0: The first choice is the most relevant because it mentions translating a natural language query into a SQL query over a table containing city_stats, which likely includes information about the population of each city..\\n    \\x1b[0m> Table desc str: Table \\'city_stats\\' has columns: city_name (VARCHAR(16)), population (INTEGER), country (VARCHAR(16)), and foreign keys: .\\n    > Predicted SQL query: SELECT city_name, population, country\\n    FROM city_stats\\n    WHERE population = (SELECT MAX(population) FROM city_stats)\\n    > Question: What are the top modes of transportation for the city with the highest population?\\n    > Response: The city with the highest population is Tokyo, Japan with a population of 13,960,000.\\n    > Response eval: {\\'has_error\\': True, \\'new_question\\': \\'What are the top modes of transportation for Tokyo, Japan?\\', \\'explanation\\': \\'The assistant failed to answer the original question correctly. The response was about the city with the highest population, but it did not mention anything about the top modes of transportation in that city. The new question directly asks about the top modes of transportation in Tokyo, Japan, which is the city with the highest population.\\'}\\n    \\x1b[1;3;38;5;200mSelecting query engine 3: The question specifically asks about Tokyo, and choice (4) is about answering semantic questions about Tokyo..\\n    \\x1b[0m> Question: What are the top modes of transportation for Tokyo, Japan?\\n    > Response: The top modes of transportation for Tokyo, Japan are trains and subways, which are considered clean and efficient. Tokyo has an extensive network of electric train lines and over 900 train stations. Buses, monorails, and trams also play a secondary role in the public transportation system. Additionally, expressways connect Tokyo to other points in the Greater Tokyo Area and beyond. Taxis and long-distance ferries are also available for transportation within the city and to the surrounding islands.\\n    > Response eval: {\\'has_error\\': True, \\'new_question\\': \\'What are the top modes of transportation for Tokyo, Japan?\\', \\'explanation\\': \\'The original question was not answered correctly because the assistant did not provide information on the top modes of transportation for the city with the highest population. The new question directly asks for the top modes of transportation for Tokyo, Japan, which is the city with the highest population.\\'}\\n    \\x1b[1;3;38;5;200mSelecting query engine 3: Tokyo is mentioned in choice 4.\\n    \\x1b[0m> Question: What are the top modes of transportation for Tokyo, Japan?\\n    > Response: The top modes of transportation for Tokyo, Japan are trains and subways, which are considered clean and efficient. Tokyo has an extensive network of electric train lines and over 900 train stations. Buses, monorails, and trams also play a secondary role in public transportation within the city. Additionally, Tokyo has two major airports, Narita International Airport and Haneda Airport, which offer domestic and international flights. Expressways and taxis are also available for transportation within the city.\\n    > Response eval: {\\'has_error\\': True, \\'new_question\\': \\'What are the top modes of transportation for Tokyo, Japan?\\', \\'explanation\\': \\'The response is erroneous because it does not answer the question asked. The question asks for the top modes of transportation in the city with the highest population, but the response only provides the population of the city. The new question directly asks for the top modes of transportation in Tokyo, Japan, which is the city with the highest population.\\'}\\n    \\x1b[1;3;38;5;200mSelecting query engine 3: The question specifically asks about Tokyo, and choice 4 is about answering semantic questions about Tokyo..\\n    \\x1b[0m> Question: What are the top modes of transportation for Tokyo, Japan?\\n    > Response: The top modes of transportation for Tokyo, Japan are trains and subways, which are considered clean and efficient. Tokyo has an extensive network of electric train lines and over 900 train stations. Buses, monorails, and trams also play a secondary role in public transportation within the city. Additionally, Tokyo has two major airports, Narita International Airport and Haneda Airport, which offer domestic and international flights. Expressways and taxis are also available for transportation within the city.\\n    > Response eval: {\\'has_error\\': False, \\'new_question\\': \\'\\', \\'explanation\\': \\'\\'}\\n    The top modes of transportation for Tokyo, Japan are trains and subways, which are considered clean and efficient. Tokyo has an extensive network of electric train lines and over 900 train stations. Buses, monorails, and trams also play a secondary role in public transportation within the city. Additionally, Tokyo has two major airports, Narita International Airport and Haneda Airport, which offer domestic and international flights. Expressways and taxis are also available for transportation within the city.\\n    \\n\\n\\n```python\\nprint(str(response))\\n```\\n\\n    The top modes of transportation for Tokyo, Japan are trains and subways, which are considered clean and efficient. Tokyo has an extensive network of electric train lines and over 900 train stations. Buses, monorails, and trams also play a secondary role in public transportation within the city. Additionally, Tokyo has two major airports, Narita International Airport and Haneda Airport, which offer domestic and international flights. Expressways and taxis are also available for transportation within the city.\\n    \\n\\n\\n```python\\nresponse = agent.chat(\"What are the sports teams of each city in Asia?\")\\nprint(str(response))\\n```\\n\\n    \\x1b[1;3;38;5;200mSelecting query engine 3: The question is asking about sports teams in Asia, and Tokyo is located in Asia..\\n    \\x1b[0m> Question: What are the sports teams of each city in Asia?\\n    > Response: I\\'m sorry, but the context information does not provide a comprehensive list of sports teams in each city in Asia. It only mentions some sports teams in Tokyo, Japan. To get a complete list of sports teams in each city in Asia, you would need to consult a reliable source or conduct further research.\\n    > Response eval: {\\'has_error\\': True, \\'new_question\\': \\'What are some popular sports teams in Tokyo, Japan?\\', \\'explanation\\': \\'The original question is too broad and requires extensive data that the system may not possess. The new question is more specific and focuses on a single city, making it more likely to receive a correct and comprehensive answer.\\'}\\n    \\x1b[1;3;38;5;200mSelecting query engine 3: The question specifically asks about Tokyo, and choice 4 is about answering semantic questions about Tokyo..\\n    \\x1b[0m> Question: What are some popular sports teams in Tokyo, Japan?\\n    > Response: Some popular sports teams in Tokyo, Japan include the Yomiuri Giants and Tokyo Yakult Swallows in baseball, F.C. Tokyo and Tokyo Verdy 1969 in soccer, and Hitachi SunRockers, Toyota Alvark Tokyo, and Tokyo Excellence in basketball. Tokyo is also known for its sumo wrestling tournaments held at the Ryōgoku Kokugikan sumo arena.\\n    > Response eval: {\\'has_error\\': False, \\'new_question\\': \\'\\', \\'explanation\\': \\'\\'}\\n    Some popular sports teams in Tokyo, Japan include the Yomiuri Giants and Tokyo Yakult Swallows in baseball, F.C. Tokyo and Tokyo Verdy 1969 in soccer, and Hitachi SunRockers, Toyota Alvark Tokyo, and Tokyo Excellence in basketball. Tokyo is also known for its sumo wrestling tournaments held at the Ryōgoku Kokugikan sumo arena.\\n    \\n', metadata={'source': '/mnt/c/Users/User/Documents/AI_ML/career_ai_engineer/Projects/ai_apps_assistant/llamaindex_docs/test_llamaindex.json', 'seq_num': 3, 'filename': 'custom_agent.ipynb', 'filepath': 'docs/examples/agent/custom_agent.ipynb', 'url': 'https://github.com/run-llama/llama_index/blob/3823389e3f91cab47b72e2cc2814826db9f98e32/docs/examples/agent/custom_agent.ipynb'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/multi_document_agents-v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\\n\\n# Multi-Document Agents (V1)\\n\\nIn this guide, you learn towards setting up a multi-document agent over the LlamaIndex documentation.\\n\\nThis is an extension of V0 multi-document agents with the additional features:\\n- Reranking during document (tool) retrieval\\n- Query planning tool that the agent can use to plan \\n\\n\\nWe do this with the following architecture:\\n\\n- setup a \"document agent\" over each Document: each doc agent can do QA/summarization within its doc\\n- setup a top-level agent over this set of document agents. Do tool retrieval and then do CoT over the set of tools to answer a question.\\n\\nIf you\\'re opening this Notebook on colab, you will probably need to install LlamaIndex 🦙.\\n\\n\\n```python\\n!pip install llama-index\\n```\\n\\n\\n```python\\n%load_ext autoreload\\n%autoreload 2\\n```\\n\\n## Setup and Download Data\\n\\nIn this section, we\\'ll load in the LlamaIndex documentation.\\n\\n\\n```python\\ndomain = \"docs.llamaindex.ai\"\\ndocs_url = \"https://docs.llamaindex.ai/en/latest/\"\\n!wget -e robots=off --recursive --no-clobber --page-requisites --html-extension --convert-links --restrict-file-names=windows --domains {domain} --no-parent {docs_url}\\n```\\n\\n\\n```python\\nfrom llama_hub.file.unstructured.base import UnstructuredReader\\nfrom pathlib import Path\\nfrom llama_index.llms import OpenAI\\nfrom llama_index import ServiceContext\\n```\\n\\n\\n```python\\nreader = UnstructuredReader()\\n```\\n\\n    [nltk_data] Downloading package punkt to /Users/jerryliu/nltk_data...\\n    [nltk_data]   Package punkt is already up-to-date!\\n    [nltk_data] Downloading package averaged_perceptron_tagger to\\n    [nltk_data]     /Users/jerryliu/nltk_data...\\n    [nltk_data]   Package averaged_perceptron_tagger is already up-to-\\n    [nltk_data]       date!\\n    \\n\\n\\n```python\\nall_files_gen = Path(\"./docs.llamaindex.ai/\").rglob(\"*\")\\nall_files = [f.resolve() for f in all_files_gen]\\n```\\n\\n\\n```python\\nall_html_files = [f for f in all_files if f.suffix.lower() == \".html\"]\\n```\\n\\n\\n```python\\nlen(all_html_files)\\n```\\n\\n\\n\\n\\n    418\\n\\n\\n\\n\\n```python\\nfrom llama_index import Document\\n\\n# TODO: set to higher value if you want more docs\\ndoc_limit = 100\\n\\ndocs = []\\nfor idx, f in enumerate(all_html_files):\\n    if idx > doc_limit:\\n        break\\n    print(f\"Idx {idx}/{len(all_html_files)}\")\\n    loaded_docs = reader.load_data(file=f, split_documents=True)\\n    # Hardcoded Index. Everything before this is ToC for all pages\\n    start_idx = 72\\n    loaded_doc = Document(\\n        text=\"\\\\n\\\\n\".join([d.get_content() for d in loaded_docs[72:]]),\\n        metadata={\"path\": str(f)},\\n    )\\n    print(loaded_doc.metadata[\"path\"])\\n    docs.append(loaded_doc)\\n```\\n\\nDefine LLM + Service Context + Callback Manager\\n\\n\\n```python\\nllm = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\\nservice_context = ServiceContext.from_defaults(llm=llm)\\n```\\n\\n## Building Multi-Document Agents\\n\\nIn this section we show you how to construct the multi-document agent. We first build a document agent for each document, and then define the top-level parent agent with an object index.\\n\\n\\n```python\\nfrom llama_index import VectorStoreIndex, SummaryIndex\\n```\\n\\n\\n```python\\nimport nest_asyncio\\n\\nnest_asyncio.apply()\\n```\\n\\n### Build Document Agent for each Document\\n\\nIn this section we define \"document agents\" for each document.\\n\\nWe define both a vector index (for semantic search) and summary index (for summarization) for each document. The two query engines are then converted into tools that are passed to an OpenAI function calling agent.\\n\\nThis document agent can dynamically choose to perform semantic search or summarization within a given document.\\n\\nWe create a separate document agent for each city.\\n\\n\\n```python\\nfrom llama_index.agent import OpenAIAgent\\nfrom llama_index import load_index_from_storage, StorageContext\\nfrom llama_index.tools import QueryEngineTool, ToolMetadata\\nfrom llama_index.node_parser import SentenceSplitter\\nimport os\\nfrom tqdm.notebook import tqdm\\nimport pickle\\n\\n\\nasync def build_agent_per_doc(nodes, file_base):\\n    print(file_base)\\n\\n    vi_out_path = f\"./data/llamaindex_docs/{file_base}\"\\n    summary_out_path = f\"./data/llamaindex_docs/{file_base}_summary.pkl\"\\n    if not os.path.exists(vi_out_path):\\n        Path(\"./data/llamaindex_docs/\").mkdir(parents=True, exist_ok=True)\\n        # build vector index\\n        vector_index = VectorStoreIndex(nodes, service_context=service_context)\\n        vector_index.storage_context.persist(persist_dir=vi_out_path)\\n    else:\\n        vector_index = load_index_from_storage(\\n            StorageContext.from_defaults(persist_dir=vi_out_path),\\n            service_context=service_context,\\n        )\\n\\n    # build summary index\\n    summary_index = SummaryIndex(nodes, service_context=service_context)\\n\\n    # define query engines\\n    vector_query_engine = vector_index.as_query_engine()\\n    summary_query_engine = summary_index.as_query_engine(\\n        response_mode=\"tree_summarize\"\\n    )\\n\\n    # extract a summary\\n    if not os.path.exists(summary_out_path):\\n        Path(summary_out_path).parent.mkdir(parents=True, exist_ok=True)\\n        summary = str(\\n            await summary_query_engine.aquery(\\n                \"Extract a concise 1-2 line summary of this document\"\\n            )\\n        )\\n        pickle.dump(summary, open(summary_out_path, \"wb\"))\\n    else:\\n        summary = pickle.load(open(summary_out_path, \"rb\"))\\n\\n    # define tools\\n    query_engine_tools = [\\n        QueryEngineTool(\\n            query_engine=vector_query_engine,\\n            metadata=ToolMetadata(\\n                name=f\"vector_tool_{file_base}\",\\n                description=f\"Useful for questions related to specific facts\",\\n            ),\\n        ),\\n        QueryEngineTool(\\n            query_engine=summary_query_engine,\\n            metadata=ToolMetadata(\\n                name=f\"summary_tool_{file_base}\",\\n                description=f\"Useful for summarization questions\",\\n            ),\\n        ),\\n    ]\\n\\n    # build agent\\n    function_llm = OpenAI(model=\"gpt-4\")\\n    agent = OpenAIAgent.from_tools(\\n        query_engine_tools,\\n        llm=function_llm,\\n        verbose=True,\\n        system_prompt=f\"\"\"\\\\\\nYou are a specialized agent designed to answer queries about the `{file_base}.html` part of the LlamaIndex docs.\\nYou must ALWAYS use at least one of the tools provided when answering a question; do NOT rely on prior knowledge.\\\\\\n\"\"\",\\n    )\\n\\n    return agent, summary\\n\\n\\nasync def build_agents(docs):\\n    node_parser = SentenceSplitter()\\n\\n    # Build agents dictionary\\n    agents_dict = {}\\n    extra_info_dict = {}\\n\\n    # # this is for the baseline\\n    # all_nodes = []\\n\\n    for idx, doc in enumerate(tqdm(docs)):\\n        nodes = node_parser.get_nodes_from_documents([doc])\\n        # all_nodes.extend(nodes)\\n\\n        # ID will be base + parent\\n        file_path = Path(doc.metadata[\"path\"])\\n        file_base = str(file_path.parent.stem) + \"_\" + str(file_path.stem)\\n        agent, summary = await build_agent_per_doc(nodes, file_base)\\n\\n        agents_dict[file_base] = agent\\n        extra_info_dict[file_base] = {\"summary\": summary, \"nodes\": nodes}\\n\\n    return agents_dict, extra_info_dict\\n```\\n\\n\\n```python\\nagents_dict, extra_info_dict = await build_agents(docs)\\n```\\n\\n### Build Retriever-Enabled OpenAI Agent\\n\\nWe build a top-level agent that can orchestrate across the different document agents to answer any user query.\\n\\nThis `RetrieverOpenAIAgent` performs tool retrieval before tool use (unlike a default agent that tries to put all tools in the prompt).\\n\\n**Improvements from V0**: We make the following improvements compared to the \"base\" version in V0.\\n\\n- Adding in reranking: we use Cohere reranker to better filter the candidate set of documents.\\n- Adding in a query planning tool: we add an explicit query planning tool that\\'s dynamically created based on the set of retrieved tools.\\n\\n\\n\\n```python\\n# define tool for each document agent\\nall_tools = []\\nfor file_base, agent in agents_dict.items():\\n    summary = extra_info_dict[file_base][\"summary\"]\\n    doc_tool = QueryEngineTool(\\n        query_engine=agent,\\n        metadata=ToolMetadata(\\n            name=f\"tool_{file_base}\",\\n            description=summary,\\n        ),\\n    )\\n    all_tools.append(doc_tool)\\n```\\n\\n\\n```python\\nprint(all_tools[0].metadata)\\n```\\n\\n    ToolMetadata(description=\\'LlamaIndex is a data framework that allows LLM applications to ingest, structure, and access private or domain-specific data by providing tools such as data connectors, data indexes, engines, data agents, and application integrations. It is designed for beginners, advanced users, and everyone in between, and offers both high-level and lower-level APIs for customization. LlamaIndex can be installed using pip and has detailed documentation and tutorials available. It is available on GitHub and PyPi, and there is also a Typescript package available. The LlamaIndex community can be joined on Twitter and Discord.\\', name=\\'tool_latest_index\\', fn_schema=<class \\'llama_index.tools.types.DefaultToolFnSchema\\'>)\\n    \\n\\n\\n```python\\n# define an \"object\" index and retriever over these tools\\nfrom llama_index import VectorStoreIndex\\nfrom llama_index.objects import (\\n    ObjectIndex,\\n    SimpleToolNodeMapping,\\n    ObjectRetriever,\\n)\\nfrom llama_index.retrievers import BaseRetriever\\nfrom llama_index.postprocessor import CohereRerank\\nfrom llama_index.tools import QueryPlanTool\\nfrom llama_index.query_engine import SubQuestionQueryEngine\\nfrom llama_index.llms import OpenAI\\n\\nllm = OpenAI(model_name=\"gpt-4-0613\")\\n\\ntool_mapping = SimpleToolNodeMapping.from_objects(all_tools)\\nobj_index = ObjectIndex.from_objects(\\n    all_tools,\\n    tool_mapping,\\n    VectorStoreIndex,\\n)\\nvector_node_retriever = obj_index.as_node_retriever(similarity_top_k=10)\\n\\n\\n# define a custom retriever with reranking\\nclass CustomRetriever(BaseRetriever):\\n    def __init__(self, vector_retriever, postprocessor=None):\\n        self._vector_retriever = vector_retriever\\n        self._postprocessor = postprocessor or CohereRerank(top_n=5)\\n        super().__init__()\\n\\n    def _retrieve(self, query_bundle):\\n        retrieved_nodes = self._vector_retriever.retrieve(query_bundle)\\n        filtered_nodes = self._postprocessor.postprocess_nodes(\\n            retrieved_nodes, query_bundle=query_bundle\\n        )\\n\\n        return filtered_nodes\\n\\n\\n# define a custom object retriever that adds in a query planning tool\\nclass CustomObjectRetriever(ObjectRetriever):\\n    def __init__(self, retriever, object_node_mapping, all_tools, llm=None):\\n        self._retriever = retriever\\n        self._object_node_mapping = object_node_mapping\\n        self._llm = llm or OpenAI(\"gpt-4-0613\")\\n\\n    def retrieve(self, query_bundle):\\n        nodes = self._retriever.retrieve(query_bundle)\\n        tools = [self._object_node_mapping.from_node(n.node) for n in nodes]\\n\\n        sub_question_sc = ServiceContext.from_defaults(llm=self._llm)\\n        sub_question_engine = SubQuestionQueryEngine.from_defaults(\\n            query_engine_tools=tools, service_context=sub_question_sc\\n        )\\n        sub_question_description = f\"\"\"\\\\\\nUseful for any queries that involve comparing multiple documents. ALWAYS use this tool for comparison queries - make sure to call this \\\\\\ntool with the original query. Do NOT use the other tools for any queries involving multiple documents.\\n\"\"\"\\n        sub_question_tool = QueryEngineTool(\\n            query_engine=sub_question_engine,\\n            metadata=ToolMetadata(\\n                name=\"compare_tool\", description=sub_question_description\\n            ),\\n        )\\n\\n        return tools + [sub_question_tool]\\n```\\n\\n\\n```python\\ncustom_node_retriever = CustomRetriever(vector_node_retriever)\\n\\n# wrap it with ObjectRetriever to return objects\\ncustom_obj_retriever = CustomObjectRetriever(\\n    custom_node_retriever, tool_mapping, all_tools, llm=llm\\n)\\n```\\n\\n\\n```python\\ntmps = custom_obj_retriever.retrieve(\"hello\")\\nprint(len(tmps))\\n```\\n\\n    6\\n    \\n\\n\\n```python\\nfrom llama_index.agent import FnRetrieverOpenAIAgent, ReActAgent\\n\\ntop_agent = FnRetrieverOpenAIAgent.from_retriever(\\n    custom_obj_retriever,\\n    system_prompt=\"\"\" \\\\\\nYou are an agent designed to answer queries about the documentation.\\nPlease always use the tools provided to answer a question. Do not rely on prior knowledge.\\\\\\n\\n\"\"\",\\n    llm=llm,\\n    verbose=True,\\n)\\n\\n# top_agent = ReActAgent.from_tools(\\n#     tool_retriever=custom_obj_retriever,\\n#     system_prompt=\"\"\" \\\\\\n# You are an agent designed to answer queries about the documentation.\\n# Please always use the tools provided to answer a question. Do not rely on prior knowledge.\\\\\\n\\n# \"\"\",\\n#     llm=llm,\\n#     verbose=True,\\n# )\\n```\\n\\n### Define Baseline Vector Store Index\\n\\nAs a point of comparison, we define a \"naive\" RAG pipeline which dumps all docs into a single vector index collection.\\n\\nWe set the top_k = 4\\n\\n\\n```python\\nall_nodes = [\\n    n for extra_info in extra_info_dict.values() for n in extra_info[\"nodes\"]\\n]\\n```\\n\\n\\n```python\\nbase_index = VectorStoreIndex(all_nodes)\\nbase_query_engine = base_index.as_query_engine(similarity_top_k=4)\\n```\\n\\n## Running Example Queries\\n\\nLet\\'s run some example queries, ranging from QA / summaries over a single document to QA / summarization over multiple documents.\\n\\n\\n```python\\nresponse = top_agent.query(\\n    \"Tell me about the different types of evaluation in LlamaIndex\"\\n)\\n```\\n\\n    === Calling Function ===\\n    Calling function: tool_api_reference_evaluation with args: {\\n      \"input\": \"types of evaluation\"\\n    }\\n    === Calling Function ===\\n    Calling function: vector_tool_api_reference_evaluation with args: {\\n      \"input\": \"types of evaluation\"\\n    }\\n    Got output: The types of evaluation can include correctness evaluation, faithfulness evaluation, guideline evaluation, hit rate evaluation, MRR (Mean Reciprocal Rank) evaluation, pairwise comparison evaluation, relevancy evaluation, and response evaluation.\\n    ========================\\n    Got output: The types of evaluation mentioned in the `api_reference_evaluation.html` part of the LlamaIndex docs include:\\n    \\n    1. Correctness Evaluation\\n    2. Faithfulness Evaluation\\n    3. Guideline Evaluation\\n    4. Hit Rate Evaluation\\n    5. MRR (Mean Reciprocal Rank) Evaluation\\n    6. Pairwise Comparison Evaluation\\n    7. Relevancy Evaluation\\n    8. Response Evaluation\\n    ========================\\n    \\n\\n\\n```python\\nprint(response)\\n```\\n\\n    There are several types of evaluation in LlamaIndex:\\n    \\n    1. Correctness Evaluation: This type of evaluation measures the accuracy of the retrieval results. It checks if the retrieved documents are correct and relevant to the query.\\n    \\n    2. Faithfulness Evaluation: Faithfulness evaluation measures how faithfully the retrieved documents represent the original data. It checks if the retrieved documents accurately reflect the information in the original documents.\\n    \\n    3. Guideline Evaluation: Guideline evaluation involves comparing the retrieval results against a set of guidelines or ground truth. It checks if the retrieval results align with the expected or desired outcomes.\\n    \\n    4. Hit Rate Evaluation: Hit rate evaluation measures the percentage of queries that return at least one relevant document. It is a binary evaluation metric that indicates the effectiveness of the retrieval system in finding relevant documents.\\n    \\n    5. MRR (Mean Reciprocal Rank) Evaluation: MRR evaluation measures the average rank of the first relevant document in the retrieval results. It provides a single value that represents the effectiveness of the retrieval system in ranking relevant documents.\\n    \\n    6. Pairwise Comparison Evaluation: Pairwise comparison evaluation involves comparing the retrieval results of different systems or algorithms. It helps determine which system performs better in terms of retrieval accuracy and relevance.\\n    \\n    7. Relevancy Evaluation: Relevancy evaluation measures the relevance of the retrieved documents to the query. It can be done using various metrics such as precision, recall, and F1 score.\\n    \\n    8. Response Evaluation: Response evaluation measures the quality of the response generated by the retrieval system. It checks if the response is informative, accurate, and helpful to the user.\\n    \\n    These evaluation types help assess the performance and effectiveness of the retrieval system in LlamaIndex.\\n    \\n\\n\\n```python\\n# baseline\\nresponse = base_query_engine.query(\\n    \"Tell me about the different types of evaluation in LlamaIndex\"\\n)\\nprint(str(response))\\n```\\n\\n    LlamaIndex utilizes various types of evaluation methods to assess its performance and effectiveness. These evaluation methods include RelevancyEvaluator, RetrieverEvaluator, SemanticSimilarityEvaluator, PairwiseComparisonEvaluator, CorrectnessEvaluator, FaithfulnessEvaluator, and GuidelineEvaluator. Each of these evaluators serves a specific purpose in evaluating different aspects of the LlamaIndex system.\\n    \\n\\n\\n```python\\nresponse = top_agent.query(\\n    \"Compare the content in the contributions page vs. index page.\"\\n)\\n```\\n\\n    === Calling Function ===\\n    Calling function: compare_tool with args: {\\n      \"input\": \"content in the contributions page vs. index page\"\\n    }\\n    Generated 2 sub questions.\\n    \\x1b[1;3;38;2;237;90;200m[tool_development_contributing] Q: What is the content of the contributions page?\\n    \\x1b[0m\\x1b[1;3;38;2;90;149;237m[tool_latest_index] Q: What is the content of the index page?\\n    \\x1b[0m=== Calling Function ===\\n    Calling function: summary_tool_development_contributing with args: {\\n      \"input\": \"development_contributing.html\"\\n    }\\n    === Calling Function ===\\n    Calling function: vector_tool_latest_index with args: {\\n      \"input\": \"content of the index page\"\\n    }\\n    Got output: The development_contributing.html file provides information on how to contribute to LlamaIndex. It includes guidelines on what to work on, such as extending core modules, fixing bugs, adding usage examples, adding experimental features, and improving code quality and documentation. The file also provides details on each module, including data loaders, node parsers, text splitters, document/index/KV stores, managed index, vector stores, retrievers, query engines, query transforms, token usage optimizers, node postprocessors, and output parsers. Additionally, the file includes a development guideline section that covers environment setup, validating changes, formatting/linting, testing, creating example notebooks, and creating a pull request.\\n    ========================\\n    Got output: The content of the index page provides information about LlamaIndex, a data framework for LLM applications. It explains why LlamaIndex is useful for augmenting LLM models with private or domain-specific data that may be distributed across different applications and data stores. LlamaIndex offers tools such as data connectors, data indexes, engines, and data agents to ingest, structure, and access data. It is designed for beginners as well as advanced users who can customize and extend its modules. The page also provides installation instructions, tutorials, and links to the LlamaIndex ecosystem and associated projects.\\n    ========================\\n    \\x1b[1;3;38;2;90;149;237m[tool_latest_index] A: The content of the `latest_index.html` page provides comprehensive information about LlamaIndex, a data framework for LLM applications. It explains the utility of LlamaIndex in augmenting LLM models with private or domain-specific data that may be distributed across different applications and data stores. \\n    \\n    The page details the tools offered by LlamaIndex, such as data connectors, data indexes, engines, and data agents, which are used to ingest, structure, and access data. It is designed to cater to both beginners and advanced users, with the flexibility to customize and extend its modules.\\n    \\n    Additionally, the page provides installation instructions and tutorials for users. It also includes links to the LlamaIndex ecosystem and associated projects for further exploration and understanding.\\n    \\x1b[0m\\x1b[1;3;38;2;237;90;200m[tool_development_contributing] A: The `development_contributing.html` page of the LlamaIndex docs provides comprehensive information on how to contribute to the project. It includes guidelines on the areas to focus on, such as extending core modules, fixing bugs, adding usage examples, adding experimental features, and improving code quality and documentation.\\n    \\n    The page also provides detailed information on each module, including data loaders, node parsers, text splitters, document/index/KV stores, managed index, vector stores, retrievers, query engines, query transforms, token usage optimizers, node postprocessors, and output parsers.\\n    \\n    In addition, there is a development guideline section that covers various aspects of the development process, including environment setup, validating changes, formatting/linting, testing, creating example notebooks, and creating a pull request.\\n    \\x1b[0mGot output: The content in the contributions page of the LlamaIndex documentation provides comprehensive information on how to contribute to the project, including guidelines on areas to focus on and detailed information on each module. It also covers various aspects of the development process. \\n    \\n    On the other hand, the content in the index page of the LlamaIndex documentation provides comprehensive information about LlamaIndex itself, explaining its utility in augmenting LLM models with private or domain-specific data. It details the tools offered by LlamaIndex and provides installation instructions, tutorials, and links to the LlamaIndex ecosystem and associated projects.\\n    ========================\\n    \\n\\n\\n```python\\nprint(response)\\n```\\n\\n    The contributions page of the LlamaIndex documentation provides guidelines for contributing to LlamaIndex, including extending core modules, fixing bugs, adding usage examples, adding experimental features, and improving code quality and documentation. It also includes information on the environment setup, validating changes, formatting and linting, testing, creating example notebooks, and creating a pull request.\\n    \\n    On the other hand, the index page of the LlamaIndex documentation provides information about LlamaIndex itself. It explains that LlamaIndex is a data framework that allows LLM applications to ingest, structure, and access private or domain-specific data. It provides tools such as data connectors, data indexes, engines, data agents, and application integrations. The index page also mentions that LlamaIndex is designed for beginners, advanced users, and everyone in between, and offers both high-level and lower-level APIs for customization. It provides installation instructions, links to the GitHub and PyPi repositories, and information about the LlamaIndex community on Twitter and Discord.\\n    \\n    In summary, the contributions page focuses on contributing to LlamaIndex, while the index page provides an overview of LlamaIndex and its features.\\n    \\n\\n\\n```python\\nresponse = top_agent.query(\\n    \"Can you compare the tree index and list index at a very high-level?\"\\n)\\n```\\n\\n\\n```python\\nprint(str(response))\\n```\\n\\n    At a high level, the Tree Index and List Index are two different types of indexes used in the system. \\n    \\n    The Tree Index is a tree-structured index that is built specifically for each query. It allows for the construction of a query-specific tree from leaf nodes to return a response. The Tree Index is designed to provide a more optimized and efficient way of retrieving nodes based on a query.\\n    \\n    On the other hand, the List Index is a keyword table index that supports operations such as inserting and deleting documents, retrieving nodes based on a query, and refreshing the index with updated documents. The List Index is a simpler index that uses a keyword table approach for retrieval.\\n    \\n    Both indexes have their own advantages and use cases. The choice between them depends on the specific requirements and constraints of the system.\\n    \\n', metadata={'source': '/mnt/c/Users/User/Documents/AI_ML/career_ai_engineer/Projects/ai_apps_assistant/llamaindex_docs/test_llamaindex.json', 'seq_num': 4, 'filename': 'README.md', 'filepath': 'llama-index-packs/llama-index-packs-multi-document-agents/README.md', 'url': 'https://github.com/run-llama/llama_index/blob/3823389e3f91cab47b72e2cc2814826db9f98e32/llama-index-packs/llama-index-packs-multi-document-agents/README.md'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/multi_document_agents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\\n\\n# Multi-Document Agents\\n\\nIn this guide, you learn towards setting up an agent that can effectively answer different types of questions over a larger set of documents.\\n\\nThese questions include the following\\n\\n- QA over a specific doc\\n- QA comparing different docs\\n- Summaries over a specific doc\\n- Comparing summaries between different docs\\n\\nWe do this with the following architecture:\\n\\n- setup a \"document agent\" over each Document: each doc agent can do QA/summarization within its doc\\n- setup a top-level agent over this set of document agents. Do tool retrieval and then do CoT over the set of tools to answer a question.\\n\\n## Setup and Download Data\\n\\nIn this section, we\\'ll define imports and then download Wikipedia articles about different cities. Each article is stored separately.\\n\\nWe load in 18 cities - this is not quite at the level of \"hundreds\" of documents but its still large enough to warrant some top-level document retrieval!\\n\\nIf you\\'re opening this Notebook on colab, you will probably need to install LlamaIndex 🦙.\\n\\n\\n```python\\n!pip install llama-index\\n```\\n\\n\\n```python\\nfrom llama_index import (\\n    VectorStoreIndex,\\n    SummaryIndex,\\n    SimpleKeywordTableIndex,\\n    SimpleDirectoryReader,\\n    ServiceContext,\\n)\\nfrom llama_index.schema import IndexNode\\nfrom llama_index.tools import QueryEngineTool, ToolMetadata\\nfrom llama_index.llms import OpenAI\\n```\\n\\n\\n```python\\nwiki_titles = [\\n    \"Toronto\",\\n    \"Seattle\",\\n    \"Chicago\",\\n    \"Boston\",\\n    \"Houston\",\\n    \"Tokyo\",\\n    \"Berlin\",\\n    \"Lisbon\",\\n    \"Paris\",\\n    \"London\",\\n    \"Atlanta\",\\n    \"Munich\",\\n    \"Shanghai\",\\n    \"Beijing\",\\n    \"Copenhagen\",\\n    \"Moscow\",\\n    \"Cairo\",\\n    \"Karachi\",\\n]\\n```\\n\\n\\n```python\\nfrom pathlib import Path\\n\\nimport requests\\n\\nfor title in wiki_titles:\\n    response = requests.get(\\n        \"https://en.wikipedia.org/w/api.php\",\\n        params={\\n            \"action\": \"query\",\\n            \"format\": \"json\",\\n            \"titles\": title,\\n            \"prop\": \"extracts\",\\n            # \\'exintro\\': True,\\n            \"explaintext\": True,\\n        },\\n    ).json()\\n    page = next(iter(response[\"query\"][\"pages\"].values()))\\n    wiki_text = page[\"extract\"]\\n\\n    data_path = Path(\"data\")\\n    if not data_path.exists():\\n        Path.mkdir(data_path)\\n\\n    with open(data_path / f\"{title}.txt\", \"w\") as fp:\\n        fp.write(wiki_text)\\n```\\n\\n\\n```python\\n# Load all wiki documents\\ncity_docs = {}\\nfor wiki_title in wiki_titles:\\n    city_docs[wiki_title] = SimpleDirectoryReader(\\n        input_files=[f\"data/{wiki_title}.txt\"]\\n    ).load_data()\\n```\\n\\nDefine LLM + Service Context + Callback Manager\\n\\n\\n```python\\nllm = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\\nservice_context = ServiceContext.from_defaults(llm=llm)\\n```\\n\\n## Building Multi-Document Agents\\n\\nIn this section we show you how to construct the multi-document agent. We first build a document agent for each document, and then define the top-level parent agent with an object index.\\n\\n### Build Document Agent for each Document\\n\\nIn this section we define \"document agents\" for each document.\\n\\nWe define both a vector index (for semantic search) and summary index (for summarization) for each document. The two query engines are then converted into tools that are passed to an OpenAI function calling agent.\\n\\nThis document agent can dynamically choose to perform semantic search or summarization within a given document.\\n\\nWe create a separate document agent for each city.\\n\\n\\n```python\\nfrom llama_index.agent import OpenAIAgent\\nfrom llama_index import load_index_from_storage, StorageContext\\nfrom llama_index.node_parser import SentenceSplitter\\nimport os\\n\\nnode_parser = SentenceSplitter()\\n\\n# Build agents dictionary\\nagents = {}\\nquery_engines = {}\\n\\n# this is for the baseline\\nall_nodes = []\\n\\nfor idx, wiki_title in enumerate(wiki_titles):\\n    nodes = node_parser.get_nodes_from_documents(city_docs[wiki_title])\\n    all_nodes.extend(nodes)\\n\\n    if not os.path.exists(f\"./data/{wiki_title}\"):\\n        # build vector index\\n        vector_index = VectorStoreIndex(nodes, service_context=service_context)\\n        vector_index.storage_context.persist(\\n            persist_dir=f\"./data/{wiki_title}\"\\n        )\\n    else:\\n        vector_index = load_index_from_storage(\\n            StorageContext.from_defaults(persist_dir=f\"./data/{wiki_title}\"),\\n            service_context=service_context,\\n        )\\n\\n    # build summary index\\n    summary_index = SummaryIndex(nodes, service_context=service_context)\\n    # define query engines\\n    vector_query_engine = vector_index.as_query_engine()\\n    summary_query_engine = summary_index.as_query_engine()\\n\\n    # define tools\\n    query_engine_tools = [\\n        QueryEngineTool(\\n            query_engine=vector_query_engine,\\n            metadata=ToolMetadata(\\n                name=\"vector_tool\",\\n                description=(\\n                    \"Useful for questions related to specific aspects of\"\\n                    f\" {wiki_title} (e.g. the history, arts and culture,\"\\n                    \" sports, demographics, or more).\"\\n                ),\\n            ),\\n        ),\\n        QueryEngineTool(\\n            query_engine=summary_query_engine,\\n            metadata=ToolMetadata(\\n                name=\"summary_tool\",\\n                description=(\\n                    \"Useful for any requests that require a holistic summary\"\\n                    f\" of EVERYTHING about {wiki_title}. For questions about\"\\n                    \" more specific sections, please use the vector_tool.\"\\n                ),\\n            ),\\n        ),\\n    ]\\n\\n    # build agent\\n    function_llm = OpenAI(model=\"gpt-4\")\\n    agent = OpenAIAgent.from_tools(\\n        query_engine_tools,\\n        llm=function_llm,\\n        verbose=True,\\n        system_prompt=f\"\"\"\\\\\\nYou are a specialized agent designed to answer queries about {wiki_title}.\\nYou must ALWAYS use at least one of the tools provided when answering a question; do NOT rely on prior knowledge.\\\\\\n\"\"\",\\n    )\\n\\n    agents[wiki_title] = agent\\n    query_engines[wiki_title] = vector_index.as_query_engine(\\n        similarity_top_k=2\\n    )\\n```\\n\\n### Build Retriever-Enabled OpenAI Agent\\n\\nWe build a top-level agent that can orchestrate across the different document agents to answer any user query.\\n\\nThis agent takes in all document agents as tools. This specific agent `RetrieverOpenAIAgent` performs tool retrieval before tool use (unlike a default agent that tries to put all tools in the prompt).\\n\\nHere we use a top-k retriever, but we encourage you to customize the tool retriever method!\\n\\n\\n\\n```python\\n# define tool for each document agent\\nall_tools = []\\nfor wiki_title in wiki_titles:\\n    wiki_summary = (\\n        f\"This content contains Wikipedia articles about {wiki_title}. Use\"\\n        f\" this tool if you want to answer any questions about {wiki_title}.\\\\n\"\\n    )\\n    doc_tool = QueryEngineTool(\\n        query_engine=agents[wiki_title],\\n        metadata=ToolMetadata(\\n            name=f\"tool_{wiki_title}\",\\n            description=wiki_summary,\\n        ),\\n    )\\n    all_tools.append(doc_tool)\\n```\\n\\n\\n```python\\n# define an \"object\" index and retriever over these tools\\nfrom llama_index import VectorStoreIndex\\nfrom llama_index.objects import ObjectIndex, SimpleToolNodeMapping\\n\\ntool_mapping = SimpleToolNodeMapping.from_objects(all_tools)\\nobj_index = ObjectIndex.from_objects(\\n    all_tools,\\n    tool_mapping,\\n    VectorStoreIndex,\\n)\\n```\\n\\n\\n```python\\nfrom llama_index.agent import FnRetrieverOpenAIAgent\\n\\ntop_agent = FnRetrieverOpenAIAgent.from_retriever(\\n    obj_index.as_retriever(similarity_top_k=3),\\n    system_prompt=\"\"\" \\\\\\nYou are an agent designed to answer queries about a set of given cities.\\nPlease always use the tools provided to answer a question. Do not rely on prior knowledge.\\\\\\n\\n\"\"\",\\n    verbose=True,\\n)\\n```\\n\\n### Define Baseline Vector Store Index\\n\\nAs a point of comparison, we define a \"naive\" RAG pipeline which dumps all docs into a single vector index collection.\\n\\nWe set the top_k = 4\\n\\n\\n```python\\nbase_index = VectorStoreIndex(all_nodes)\\nbase_query_engine = base_index.as_query_engine(similarity_top_k=4)\\n```\\n\\n## Running Example Queries\\n\\nLet\\'s run some example queries, ranging from QA / summaries over a single document to QA / summarization over multiple documents.\\n\\n\\n```python\\n# should use Boston agent -> vector tool\\nresponse = top_agent.query(\"Tell me about the arts and culture in Boston\")\\n```\\n\\n    === Calling Function ===\\n    Calling function: tool_Boston with args: {\\n      \"input\": \"arts and culture\"\\n    }\\n    === Calling Function ===\\n    Calling function: vector_tool with args: {\\n      \"input\": \"arts and culture\"\\n    }\\n    Got output: Boston is known for its vibrant arts and culture scene. The city is home to a number of performing arts organizations, including the Boston Ballet, Boston Lyric Opera Company, Opera Boston, Boston Baroque, and the Handel and Haydn Society. There are also several theaters in or near the Theater District, such as the Cutler Majestic Theatre, Citi Performing Arts Center, the Colonial Theater, and the Orpheum Theatre. Boston is a center for contemporary classical music, with groups like the Boston Modern Orchestra Project and Boston Musica Viva. The city also hosts major annual events, such as First Night, the Boston Early Music Festival, and the Boston Arts Festival. In addition, Boston has several art museums and galleries, including the Museum of Fine Arts, the Isabella Stewart Gardner Museum, and the Institute of Contemporary Art.\\n    ========================\\n    Got output: Boston is renowned for its vibrant arts and culture scene. It is home to numerous performing arts organizations, including the Boston Ballet, Boston Lyric Opera Company, Opera Boston, Boston Baroque, and the Handel and Haydn Society. The city\\'s Theater District houses several theaters, such as the Cutler Majestic Theatre, Citi Performing Arts Center, the Colonial Theater, and the Orpheum Theatre.\\n    \\n    Boston is also a hub for contemporary classical music, with groups like the Boston Modern Orchestra Project and Boston Musica Viva. The city hosts major annual events, such as First Night, the Boston Early Music Festival, and the Boston Arts Festival, which contribute to its cultural richness.\\n    \\n    In terms of visual arts, Boston boasts several art museums and galleries. The Museum of Fine Arts, the Isabella Stewart Gardner Museum, and the Institute of Contemporary Art are among the most notable. These institutions offer a wide range of art collections, from ancient to contemporary, attracting art enthusiasts from around the world.\\n    ========================\\n    \\n\\n\\n```python\\nprint(response)\\n```\\n\\n    Boston has a rich arts and culture scene, with a variety of performing arts organizations and venues. The city is home to renowned institutions such as the Boston Ballet, Boston Lyric Opera Company, Opera Boston, Boston Baroque, and the Handel and Haydn Society. The Theater District in Boston is a hub for theatrical performances, with theaters like the Cutler Majestic Theatre, Citi Performing Arts Center, Colonial Theater, and Orpheum Theatre.\\n    \\n    In addition to performing arts, Boston also has a thriving contemporary classical music scene, with groups like the Boston Modern Orchestra Project and Boston Musica Viva. The city hosts several annual events that celebrate the arts, including First Night, the Boston Early Music Festival, and the Boston Arts Festival.\\n    \\n    Boston is also known for its visual arts scene, with a number of art museums and galleries. The Museum of Fine Arts, the Isabella Stewart Gardner Museum, and the Institute of Contemporary Art are among the notable institutions in the city. These museums offer a diverse range of art collections, spanning from ancient to contemporary art, and attract art enthusiasts from around the world.\\n    \\n\\n\\n```python\\n# baseline\\nresponse = base_query_engine.query(\\n    \"Tell me about the arts and culture in Boston\"\\n)\\nprint(str(response))\\n```\\n\\n    Boston has a rich arts and culture scene. The city is home to a variety of performing arts organizations, such as the Boston Ballet, Boston Lyric Opera Company, Opera Boston, Boston Baroque, and the Handel and Haydn Society. Additionally, there are numerous contemporary classical music groups associated with the city\\'s conservatories and universities, like the Boston Modern Orchestra Project and Boston Musica Viva. The Theater District in Boston is a hub for theater, with notable venues including the Cutler Majestic Theatre, Citi Performing Arts Center, the Colonial Theater, and the Orpheum Theatre. Boston also hosts several significant annual events, including First Night, the Boston Early Music Festival, the Boston Arts Festival, and the Boston gay pride parade and festival. The city is renowned for its historic sites connected to the American Revolution, as well as its art museums and galleries, such as the Museum of Fine Arts, Isabella Stewart Gardner Museum, and the Institute of Contemporary Art.\\n    \\n\\n\\n```python\\n# should use Houston agent -> vector tool\\nresponse = top_agent.query(\\n    \"Give me a summary of all the positive aspects of Houston\"\\n)\\n```\\n\\n    === Calling Function ===\\n    Calling function: tool_Houston with args: {\\n      \"input\": \"positive aspects\"\\n    }\\n    === Calling Function ===\\n    Calling function: summary_tool with args: {\\n      \"input\": \"positive aspects\"\\n    }\\n    Got output: Houston has many positive aspects that make it an attractive place to live and visit. The city\\'s diverse population, with people from different ethnic and religious backgrounds, adds to its cultural richness and inclusiveness. Additionally, Houston is home to the Texas Medical Center, which is the largest concentration of healthcare and research institutions in the world. The presence of NASA\\'s Johnson Space Center also highlights Houston\\'s importance in the fields of medicine and space exploration. The city\\'s strong economy, supported by industries such as energy, manufacturing, aeronautics, and transportation, provides numerous economic opportunities for residents and visitors alike. Furthermore, Houston has a thriving visual and performing arts scene, including a theater district and a variety of museums and galleries. Overall, Houston\\'s diverse community, cultural attractions, and economic prospects make it an exceptionally appealing city.\\n    ========================\\n    Got output: Houston has numerous positive aspects that make it a desirable place to live and visit. Some of these include:\\n    \\n    1. **Diversity**: Houston is known for its diverse population, with people from different ethnic and religious backgrounds. This diversity adds to the city\\'s cultural richness and inclusiveness.\\n    \\n    2. **Healthcare and Research Institutions**: The city is home to the Texas Medical Center, the largest concentration of healthcare and research institutions in the world. This makes Houston a hub for medical innovation and healthcare services.\\n    \\n    3. **Space Exploration**: Houston is also known for NASA\\'s Johnson Space Center, highlighting the city\\'s significant role in space exploration.\\n    \\n    4. **Strong Economy**: Houston\\'s economy is robust and diverse, supported by industries such as energy, manufacturing, aeronautics, and transportation. This provides numerous economic opportunities for its residents.\\n    \\n    5. **Arts and Culture**: The city has a thriving visual and performing arts scene, with a theater district and a variety of museums and galleries. This makes Houston a vibrant place for art lovers and creatives.\\n    \\n    Overall, these aspects contribute to making Houston an appealing and dynamic city.\\n    ========================\\n    \\n\\n\\n```python\\nprint(response)\\n```\\n\\n    Houston has numerous positive aspects that make it a desirable place to live and visit. Some of these include:\\n    \\n    1. Diversity: Houston is known for its diverse population, with people from different ethnic and religious backgrounds. This diversity adds to the city\\'s cultural richness and inclusiveness.\\n    \\n    2. Healthcare and Research Institutions: The city is home to the Texas Medical Center, the largest concentration of healthcare and research institutions in the world. This makes Houston a hub for medical innovation and healthcare services.\\n    \\n    3. Space Exploration: Houston is also known for NASA\\'s Johnson Space Center, highlighting the city\\'s significant role in space exploration.\\n    \\n    4. Strong Economy: Houston\\'s economy is robust and diverse, supported by industries such as energy, manufacturing, aeronautics, and transportation. This provides numerous economic opportunities for its residents.\\n    \\n    5. Arts and Culture: The city has a thriving visual and performing arts scene, with a theater district and a variety of museums and galleries. This makes Houston a vibrant place for art lovers and creatives.\\n    \\n    Overall, these aspects contribute to making Houston an appealing and dynamic city.\\n    \\n\\n\\n```python\\n# baseline\\nresponse = base_query_engine.query(\\n    \"Give me a summary of all the positive aspects of Houston\"\\n)\\nprint(str(response))\\n```\\n\\n    Houston has several positive aspects that contribute to its reputation as a thriving city. It is home to a diverse and growing international community, with a large number of foreign banks and consular offices representing 92 countries. The city has received numerous accolades, including being ranked as one of the best cities for employment, college graduates, and homebuyers. Houston has a strong economy, with a broad industrial base in sectors such as energy, manufacturing, aeronautics, and healthcare. It is also a major center for the oil and gas industry and has the second-most Fortune 500 headquarters in the United States. The city\\'s cultural scene is vibrant, with a variety of annual events celebrating different cultures, as well as a reputation for diverse and excellent food. Houston is known for its world-class museums and performing arts scene. Additionally, the city has made significant investments in renewable energy sources like wind and solar. Overall, Houston offers a high quality of life, reasonable living costs, and abundant employment opportunities.\\n    \\n\\n\\n```python\\n# baseline: the response doesn\\'t quite match the sources...\\nresponse.source_nodes[1].get_content()\\n```\\n\\n\\n```python\\nresponse = top_agent.query(\\n    \"Tell the demographics of Houston, and then compare that with the\"\\n    \" demographics of Chicago\"\\n)\\n```\\n\\n    === Calling Function ===\\n    Calling function: tool_Houston with args: {\\n      \"input\": \"demographics\"\\n    }\\n    === Calling Function ===\\n    Calling function: vector_tool with args: {\\n      \"input\": \"demographics\"\\n    }\\n    Got output: Houston is a majority-minority city with a diverse population. According to the U.S. Census Bureau, in 2019, non-Hispanic whites made up 23.3% of the population, Hispanics and Latino Americans 45.8%, Blacks or African Americans 22.4%, and Asian Americans 6.5%. The largest Hispanic or Latino American ethnic group in the city is Mexican Americans, followed by Puerto Ricans and Cuban Americans. Houston is also home to the largest African American community west of the Mississippi River. Additionally, Houston has a growing Muslim population, with Muslims estimated to make up 1.2% of the city\\'s population. The city is known for its LGBT community and is home to one of the largest pride parades in the United States. The Hindu, Sikh, and Buddhist communities are also growing in Houston. Overall, Houston is considered one of the most ethnically and culturally diverse metropolitan areas in the country.\\n    ========================\\n    Got output: Houston is a majority-minority city with a diverse population. According to the U.S. Census Bureau, in 2019, non-Hispanic whites made up 23.3% of the population, Hispanics and Latino Americans 45.8%, Blacks or African Americans 22.4%, and Asian Americans 6.5%. The largest Hispanic or Latino American ethnic group in the city is Mexican Americans, followed by Puerto Ricans and Cuban Americans. \\n    \\n    Houston is also home to the largest African American community west of the Mississippi River. Additionally, Houston has a growing Muslim population, with Muslims estimated to make up 1.2% of the city\\'s population. The city is known for its LGBT community and is home to one of the largest pride parades in the United States. The Hindu, Sikh, and Buddhist communities are also growing in Houston. \\n    \\n    Overall, Houston is considered one of the most ethnically and culturally diverse metropolitan areas in the country.\\n    ========================\\n    === Calling Function ===\\n    Calling function: tool_Chicago with args: {\\n      \"input\": \"demographics\"\\n    }\\n    === Calling Function ===\\n    Calling function: vector_tool with args: {\\n      \"input\": \"demographics\"\\n    }\\n    Got output: Chicago has a diverse demographic makeup. It experienced rapid population growth during its early years, becoming one of the fastest-growing cities in the world. Waves of immigrants from various European countries, as well as African Americans from the American South, contributed to the city\\'s population growth. Over time, Chicago\\'s population has fluctuated, with a decline in the latter half of the 20th century followed by a rise in recent years. As of the latest census estimates, the largest racial or ethnic groups in Chicago are non-Hispanic White, Black, and Hispanic. Additionally, Chicago has a significant LGBT population and is known for its cultural diversity.\\n    ========================\\n    Got output: Chicago is known for its diverse demographic makeup. The city experienced rapid population growth during its early years, with immigrants from various European countries and African Americans from the American South contributing significantly to this growth. Over time, the population has fluctuated, with a decline in the latter half of the 20th century followed by a rise in recent years. \\n    \\n    As per the latest census estimates, the largest racial or ethnic groups in Chicago are non-Hispanic White, Black, and Hispanic. The city also has a significant LGBT population and is celebrated for its cultural diversity.\\n    ========================\\n    \\n\\n\\n```python\\nprint(response)\\n```\\n\\n    Houston has a diverse population with a demographic makeup that includes non-Hispanic whites (23.3%), Hispanics and Latino Americans (45.8%), Blacks or African Americans (22.4%), and Asian Americans (6.5%). The largest Hispanic or Latino American ethnic group in Houston is Mexican Americans. Houston is also home to the largest African American community west of the Mississippi River and has a growing Muslim population.\\n    \\n    On the other hand, Chicago is also known for its diverse demographics. The city has a significant non-Hispanic White population, along with a substantial Black population and Hispanic population. Chicago is celebrated for its cultural diversity and has a significant LGBT population.\\n    \\n    Both Houston and Chicago have diverse populations, with a mix of different racial and ethnic groups contributing to their vibrant communities.\\n    \\n\\n\\n```python\\n# baseline\\nresponse = base_query_engine.query(\\n    \"Tell the demographics of Houston, and then compare that with the\"\\n    \" demographics of Chicago\"\\n)\\nprint(str(response))\\n```\\n\\n    Houston is the most populous city in Texas and the fourth-most populous city in the United States. It has a population of 2,304,580 as of the 2020 U.S. census. The city is known for its diversity, with a significant proportion of minorities. In 2019, non-Hispanic whites made up 23.3% of the population, Hispanics and Latino Americans 45.8%, Blacks or African Americans 22.4%, and Asian Americans 6.5%. The largest Hispanic or Latino American ethnic group in Houston is Mexican Americans, comprising 31.6% of the population.\\n    \\n    In comparison, Chicago is the third-most populous city in the United States. According to the 2020 U.S. census, Chicago has a population of 2,746,388. The demographics of Chicago are different from Houston, with non-Hispanic whites making up 32.7% of the population, Hispanics and Latino Americans 29.9%, Blacks or African Americans 29.8%, and Asian Americans 7.6%. The largest Hispanic or Latino American ethnic group in Chicago is Mexican Americans, comprising 21.6% of the population.\\n    \\n    Overall, both Houston and Chicago have diverse populations, but the specific demographic composition differs between the two cities.\\n    \\n\\n\\n```python\\n# baseline: the response tells you nothing about Chicago...\\nresponse.source_nodes[3].get_content()\\n```\\n\\n\\n```python\\nresponse = top_agent.query(\\n    \"Tell me the differences between Shanghai and Beijing in terms of history\"\\n    \" and current economy\"\\n)\\n```\\n\\n    === Calling Function ===\\n    Calling function: tool_Shanghai with args: {\\n      \"input\": \"history\"\\n    }\\n    === Calling Function ===\\n    Calling function: vector_tool with args: {\\n      \"input\": \"history\"\\n    }\\n    Got output: Shanghai has a rich history that dates back to ancient times. However, in the context provided, the history of Shanghai is mainly discussed in relation to its modern development. After the war, Shanghai\\'s economy experienced significant growth, with increased agricultural and industrial output. The city\\'s administrative divisions were rearranged, and it became a center for radical leftism during the 1950s and 1960s. The Cultural Revolution had a severe impact on Shanghai\\'s society, but the city maintained economic production with a positive growth rate. Shanghai also played a significant role in China\\'s Third Front campaign and has been a major contributor of tax revenue to the central government. Economic reforms were initiated in Shanghai in 1990, leading to the development of the Pudong district and its classification as an Alpha+ city.\\n    ========================\\n    Got output: Shanghai\\'s history is rich and complex, dating back to ancient times. However, its modern development is particularly noteworthy. After the war, Shanghai experienced significant economic growth, with a boost in both agricultural and industrial output. The city\\'s administrative divisions were restructured, and it became a hub for radical leftism during the 1950s and 1960s.\\n    \\n    The Cultural Revolution had a profound impact on Shanghai\\'s society, but despite this, the city managed to maintain economic production with a positive growth rate. Shanghai also played a significant role in China\\'s Third Front campaign and has been a major contributor of tax revenue to the central government.\\n    \\n    In 1990, economic reforms were initiated in Shanghai, leading to the development of the Pudong district. This has helped Shanghai to be classified as an Alpha+ city, indicating its influence on the global economic stage.\\n    ========================\\n    === Calling Function ===\\n    Calling function: tool_Beijing with args: {\\n      \"input\": \"history\"\\n    }\\n    === Calling Function ===\\n    Calling function: vector_tool with args: {\\n      \"input\": \"history\"\\n    }\\n    Got output: Beijing has a rich history that spans several dynasties. It was the capital of the Ming dynasty, during which the city took its current shape and many of its major attractions, such as the Forbidden City and the Temple of Heaven, were constructed. The Qing dynasty succeeded the Ming dynasty and made Beijing its sole capital. During this time, the Imperial residence and the general layout of the city remained largely unchanged. However, the city faced challenges during the Second Opium War and the Boxer Rebellion, resulting in the looting and destruction of important structures. In the early 20th century, Beijing saw the signing of a peace agreement between the Eight-Nation Alliance and the Chinese government, which led to the restoration of Qing dynasty rule. However, the dynasty eventually collapsed in 1911.\\n    ========================\\n    Got output: Beijing has a rich and complex history that spans several dynasties. It served as the capital during the Ming dynasty, during which the city took its current shape and many of its major attractions, such as the Forbidden City and the Temple of Heaven, were constructed. The Qing dynasty succeeded the Ming dynasty and made Beijing its sole capital. During this time, the Imperial residence and the general layout of the city remained largely unchanged.\\n    \\n    However, the city faced significant challenges during the Second Opium War and the Boxer Rebellion, which resulted in the looting and destruction of important structures. In the early 20th century, Beijing saw the signing of a peace agreement between the Eight-Nation Alliance and the Chinese government, leading to the restoration of Qing dynasty rule. However, the dynasty eventually collapsed in 1911. Despite these tumultuous events, Beijing has managed to preserve its historical heritage while also evolving into a modern metropolis.\\n    ========================\\n    === Calling Function ===\\n    Calling function: tool_Shanghai with args: {\\n      \"input\": \"current economy\"\\n    }\\n    === Calling Function ===\\n    Calling function: vector_tool with args: {\\n      \"input\": \"current economy\"\\n    }\\n    Got output: The current economy of Shanghai is strong and thriving. It is a global center for finance and innovation, and a national center for commerce, trade, and transportation. The city has a diverse economy, with its six largest industries comprising about half of its GDP. Shanghai has experienced rapid development and has been one of the fastest-developing cities in the world. It has recorded double-digit GDP growth in almost every year between 1992 and 2008. As of 2021, Shanghai had a GDP of CN¥4.46 trillion ($1.106 trillion in PPP), making it one of the wealthiest cities in China. It is also the most expensive city in mainland China to live in. Shanghai is a major player in the global financial industry, ranking first in Asia and third globally in the Global Financial Centres Index. It is home to the Shanghai Stock Exchange, the largest stock exchange in China and the fourth-largest in the world. The city has attracted significant foreign investment and has been a hub for the technology industry and startups. Overall, the current economy of Shanghai is robust and continues to grow.\\n    ========================\\n    Got output: The current economy of Shanghai is robust and thriving. It is a global center for finance and innovation, and a national center for commerce, trade, and transportation. The city has a diverse economy, with its six largest industries comprising about half of its GDP. \\n    \\n    Shanghai has experienced rapid development and has been one of the fastest-developing cities in the world. It has recorded double-digit GDP growth in almost every year between 1992 and 2008. As of 2021, Shanghai had a GDP of CN¥4.46 trillion ($1.106 trillion in PPP), making it one of the wealthiest cities in China. \\n    \\n    Shanghai is also the most expensive city in mainland China to live in. It is a major player in the global financial industry, ranking first in Asia and third globally in the Global Financial Centres Index. The city is home to the Shanghai Stock Exchange, the largest stock exchange in China and the fourth-largest in the world. \\n    \\n    The city has attracted significant foreign investment and has been a hub for the technology industry and startups. Overall, the current economy of Shanghai is robust and continues to grow.\\n    ========================\\n    === Calling Function ===\\n    Calling function: tool_Beijing with args: {\\n      \"input\": \"current economy\"\\n    }\\n    === Calling Function ===\\n    Calling function: vector_tool with args: {\\n      \"input\": \"current economy\"\\n    }\\n    Got output: The current economy of Beijing is dominated by the tertiary sector, which includes services such as professional services, wholesale and retail, information technology, commercial real estate, scientific research, and residential real estate. This sector generated 83.8% of the city\\'s output in 2022. The secondary sector, which includes manufacturing and construction, accounted for 15.8% of output, while the primary sector, which includes agriculture and mining, contributed only 0.26%. The city has also identified six high-end economic output zones that are driving local economic growth, including Zhongguancun, Beijing Financial Street, Beijing Central Business District (CBD), Beijing Economic and Technological Development Area (Yizhuang), Beijing Airport Economic Zone, and Beijing Olympic Center Zone. These zones are home to various industries and sectors, such as technology companies, financial institutions, office buildings, industrial parks, and entertainment and sports centers.\\n    ========================\\n    Got output: The current economy of Beijing is primarily driven by the tertiary sector, which includes services such as professional services, wholesale and retail, information technology, commercial real estate, scientific research, and residential real estate. This sector generated 83.8% of the city\\'s output in 2022. The secondary sector, which includes manufacturing and construction, accounted for 15.8% of output, while the primary sector, which includes agriculture and mining, contributed only 0.26%.\\n    \\n    Beijing has also identified six high-end economic output zones that are driving local economic growth. These include Zhongguancun, Beijing Financial Street, Beijing Central Business District (CBD), Beijing Economic and Technological Development Area (Yizhuang), Beijing Airport Economic Zone, and Beijing Olympic Center Zone. These zones are home to various industries and sectors, such as technology companies, financial institutions, office buildings, industrial parks, and entertainment and sports centers.\\n    ========================\\n    \\n\\n\\n```python\\nprint(str(response))\\n```\\n\\n    In terms of history, both Shanghai and Beijing have rich and complex pasts. Shanghai\\'s history dates back to ancient times, but its modern development is particularly noteworthy. It experienced significant economic growth after the war and played a major role in China\\'s economic reforms. Beijing, on the other hand, has a history that spans several dynasties and served as the capital during the Ming and Qing dynasties. It has preserved its historical heritage while evolving into a modern metropolis.\\n    \\n    In terms of current economy, Shanghai is a global center for finance and innovation. It has a diverse economy and has experienced rapid development, with a high GDP and significant foreign investment. It is a major player in the global financial industry and is home to the Shanghai Stock Exchange. Beijing\\'s economy is primarily driven by the tertiary sector, with a focus on services such as professional services, information technology, and commercial real estate. It has identified high-end economic output zones that are driving local economic growth.\\n    \\n    Overall, both cities have thriving economies, but Shanghai has a stronger focus on finance and global influence, while Beijing has a diverse economy with a focus on services and high-end economic zones.\\n    \\n\\n\\n```python\\n# baseline\\nresponse = base_query_engine.query(\\n    \"Tell me the differences between Shanghai and Beijing in terms of history\"\\n    \" and current economy\"\\n)\\nprint(str(response))\\n```\\n\\n    Shanghai and Beijing have distinct differences in terms of history and current economy. Historically, Shanghai was the largest and most prosperous city in East Asia during the 1930s, while Beijing served as the capital of the Republic of China and later the People\\'s Republic of China. Shanghai experienced significant growth and redevelopment in the 1990s, while Beijing expanded its urban area and underwent rapid development in the last two decades.\\n    \\n    In terms of the current economy, Shanghai is considered the \"showpiece\" of China\\'s booming economy. It is a global center for finance and innovation, with a strong focus on industries such as retail, finance, IT, real estate, machine manufacturing, and automotive manufacturing. Shanghai is also home to the world\\'s busiest container port, the Port of Shanghai. The city has a high GDP and is classified as an Alpha+ city by the Globalization and World Cities Research Network.\\n    \\n    On the other hand, Beijing is a global financial center and ranks third globally in the Global Financial Centres Index. It is also a hub for the Chinese and global technology industry, with a large startup ecosystem. Beijing has a strong presence in industries such as finance, technology, and pharmaceuticals. The city is home to the headquarters of large state banks and insurance companies, as well as the country\\'s financial regulatory agencies.\\n    \\n    Overall, while both Shanghai and Beijing are important economic centers in China, Shanghai has a stronger focus on industries such as finance, retail, and manufacturing, while Beijing has a strong presence in finance, technology, and pharmaceuticals.\\n    \\n', metadata={'source': '/mnt/c/Users/User/Documents/AI_ML/career_ai_engineer/Projects/ai_apps_assistant/llamaindex_docs/test_llamaindex.json', 'seq_num': 5, 'filename': 'multi_document_agents.ipynb', 'filepath': 'docs/examples/agent/multi_document_agents.ipynb', 'url': 'https://github.com/run-llama/llama_index/blob/3823389e3f91cab47b72e2cc2814826db9f98e32/docs/examples/agent/multi_document_agents.ipynb'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/openai_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\\n\\n# Build your own OpenAI Agent\\n\\nWith the [new OpenAI API](https://openai.com/blog/function-calling-and-other-api-updates) that supports function calling, it\\'s never been easier to build your own agent!\\n\\nIn this notebook tutorial, we showcase how to write your own OpenAI agent in **under 50 lines of code**! It is minimal, yet feature complete (with ability to carry on a conversation and use tools).\\n\\n## Initial Setup \\n\\nLet\\'s start by importing some simple building blocks.  \\n\\nThe main thing we need is:\\n1. the OpenAI API (using our own `llama_index` LLM class)\\n2. a place to keep conversation history \\n3. a definition for tools that our agent can use.\\n\\nIf you\\'re opening this Notebook on colab, you will probably need to install LlamaIndex 🦙.\\n\\n\\n\\n```python\\n!pip install llama-index\\n```\\n\\n\\n```python\\nimport json\\nfrom typing import Sequence, List\\n\\nfrom llama_index.llms import OpenAI, ChatMessage\\nfrom llama_index.tools import BaseTool, FunctionTool\\n\\nimport nest_asyncio\\n\\nnest_asyncio.apply()\\n```\\n\\nLet\\'s define some very simple calculator tools for our agent.\\n\\n\\n```python\\ndef multiply(a: int, b: int) -> int:\\n    \"\"\"Multiple two integers and returns the result integer\"\"\"\\n    return a * b\\n\\n\\nmultiply_tool = FunctionTool.from_defaults(fn=multiply)\\n```\\n\\n\\n```python\\ndef add(a: int, b: int) -> int:\\n    \"\"\"Add two integers and returns the result integer\"\"\"\\n    return a + b\\n\\n\\nadd_tool = FunctionTool.from_defaults(fn=add)\\n```\\n\\n## Agent Definition\\n\\nNow, we define our agent that\\'s capable of holding a conversation and calling tools in **under 50 lines of code**.\\n\\nThe meat of the agent logic is in the `chat` method. At a high-level, there are 3 steps:\\n1. Call OpenAI to decide which tool (if any) to call and with what arguments.\\n2. Call the tool with the arguments to obtain an output\\n3. Call OpenAI to synthesize a response from the conversation context and the tool output.\\n\\nThe `reset` method simply resets the conversation context, so we can start another conversation.\\n\\n\\n```python\\nclass YourOpenAIAgent:\\n    def __init__(\\n        self,\\n        tools: Sequence[BaseTool] = [],\\n        llm: OpenAI = OpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\"),\\n        chat_history: List[ChatMessage] = [],\\n    ) -> None:\\n        self._llm = llm\\n        self._tools = {tool.metadata.name: tool for tool in tools}\\n        self._chat_history = chat_history\\n\\n    def reset(self) -> None:\\n        self._chat_history = []\\n\\n    def chat(self, message: str) -> str:\\n        chat_history = self._chat_history\\n        chat_history.append(ChatMessage(role=\"user\", content=message))\\n        tools = [\\n            tool.metadata.to_openai_tool() for _, tool in self._tools.items()\\n        ]\\n\\n        ai_message = self._llm.chat(chat_history, tools=tools).message\\n        additional_kwargs = ai_message.additional_kwargs\\n        chat_history.append(ai_message)\\n\\n        tool_calls = ai_message.additional_kwargs.get(\"tool_calls\", None)\\n        # parallel function calling is now supported\\n        if tool_calls is not None:\\n            for tool_call in tool_calls:\\n                function_message = self._call_function(tool_call)\\n                chat_history.append(function_message)\\n                ai_message = self._llm.chat(chat_history).message\\n                chat_history.append(ai_message)\\n\\n        return ai_message.content\\n\\n    def _call_function(self, tool_call: dict) -> ChatMessage:\\n        id_ = tool_call[\"id\"]\\n        function_call = tool_call[\"function\"]\\n        tool = self._tools[function_call[\"name\"]]\\n        output = tool(**json.loads(function_call[\"arguments\"]))\\n        return ChatMessage(\\n            name=function_call[\"name\"],\\n            content=str(output),\\n            role=\"tool\",\\n            additional_kwargs={\\n                \"tool_call_id\": id_,\\n                \"name\": function_call[\"name\"],\\n            },\\n        )\\n```\\n\\n## Let\\'s Try It Out!\\n\\n\\n```python\\nagent = YourOpenAIAgent(tools=[multiply_tool, add_tool])\\n```\\n\\n\\n```python\\nagent.chat(\"Hi\")\\n```\\n\\n\\n\\n\\n    \\'Hello! How can I assist you today?\\'\\n\\n\\n\\n\\n```python\\nagent.chat(\"What is 2123 * 215123\")\\n```\\n\\n\\n\\n\\n    \\'The product of 2123 multiplied by 215123 is 456,706,129.\\'\\n\\n\\n\\n## Our (Slightly Better) `OpenAIAgent` Implementation \\n\\nWe provide a (slightly better) `OpenAIAgent` implementation in LlamaIndex, which you can directly use as follows.  \\n\\nIn comparison to the simplified version above:\\n* it implements the `BaseChatEngine` and `BaseQueryEngine` interface, so you can more seamlessly use it in the LlamaIndex framework. \\n* it supports multiple function calls per conversation turn\\n* it supports streaming\\n* it supports async endpoints\\n* it supports callback and tracing\\n\\n\\n```python\\nfrom llama_index.agent import OpenAIAgent\\nfrom llama_index.llms import OpenAI\\n```\\n\\n\\n```python\\nllm = OpenAI(model=\"gpt-3.5-turbo-0613\")\\nagent = OpenAIAgent.from_tools(\\n    [multiply_tool, add_tool], llm=llm, verbose=True\\n)\\n```\\n\\n### Chat\\n\\n\\n```python\\nresponse = agent.chat(\"What is (121 * 3) + 42?\")\\nprint(str(response))\\n```\\n\\n    STARTING TURN 1\\n    ---------------\\n    \\n    === Calling Function ===\\n    Calling function: multiply with args: {\\n      \"a\": 121,\\n      \"b\": 3\\n    }\\n    Got output: 363\\n    ========================\\n    \\n    STARTING TURN 2\\n    ---------------\\n    \\n    === Calling Function ===\\n    Calling function: add with args: {\\n      \"a\": 363,\\n      \"b\": 42\\n    }\\n    Got output: 405\\n    ========================\\n    \\n    STARTING TURN 3\\n    ---------------\\n    \\n    (121 * 3) + 42 is equal to 405.\\n    \\n\\n\\n```python\\n# inspect sources\\nprint(response.sources)\\n```\\n\\n    [ToolOutput(content=\\'363\\', tool_name=\\'multiply\\', raw_input={\\'args\\': (), \\'kwargs\\': {\\'a\\': 121, \\'b\\': 3}}, raw_output=363), ToolOutput(content=\\'405\\', tool_name=\\'add\\', raw_input={\\'args\\': (), \\'kwargs\\': {\\'a\\': 363, \\'b\\': 42}}, raw_output=405)]\\n    \\n\\n### Async Chat\\n\\n\\n```python\\nresponse = await agent.achat(\"What is 121 * 3?\")\\nprint(str(response))\\n```\\n\\n    STARTING TURN 1\\n    ---------------\\n    \\n    === Calling Function ===\\n    Calling function: multiply with args: {\\n      \"a\": 121,\\n      \"b\": 3\\n    }\\n    Got output: 363\\n    ========================\\n    \\n    STARTING TURN 2\\n    ---------------\\n    \\n    121 multiplied by 3 is equal to 363.\\n    \\n\\n### Streaming Chat\\nHere, every LLM response is returned as a generator. You can stream every incremental step, or only the last response.\\n\\n\\n```python\\nresponse = agent.stream_chat(\\n    \"What is 121 * 2? Once you have the answer, use that number to write a\"\\n    \" story about a group of mice.\"\\n)\\n\\nresponse_gen = response.response_gen\\n\\nfor token in response_gen:\\n    print(token, end=\"\")\\n```\\n\\n    STARTING TURN 1\\n    ---------------\\n    \\n    === Calling Function ===\\n    Calling function: multiply with args: {\\n      \"a\": 121,\\n      \"b\": 2\\n    }\\n    Got output: 242\\n    ========================\\n    \\n    STARTING TURN 2\\n    ---------------\\n    \\n    121 multiplied by 2 is equal to 242.\\n    \\n    Once upon a time, in a small village, there was a group of mice who lived in a cozy little burrow. The mice were known for their intelligence and resourcefulness. They had built a tight-knit community and worked together to overcome any challenges they faced.\\n    \\n    One sunny day, as the mice were going about their daily activities, they stumbled upon a bountiful field of ripe corn. The field was filled with tall stalks of golden corn, swaying gently in the breeze. The mice couldn\\'t believe their luck! They knew they had to gather as much corn as possible to sustain themselves through the upcoming winter.\\n    \\n    With their tiny paws and sharp teeth, the mice began to harvest the corn. They worked tirelessly, carrying one ear of corn at a time back to their burrow. The mice were determined to make the most of this opportunity and ensure they had enough food for everyone.\\n    \\n    As the days turned into weeks, the mice\\'s hard work paid off. They had collected an impressive stash of corn, thanks to their diligent efforts and the abundance of the field. The mice celebrated their success, knowing that they had secured their survival for the winter.\\n    \\n    But the mice didn\\'t stop there. They realized that they had more corn than they needed just for themselves. They decided to share their abundance with the other animals in the village who were struggling to find food. The mice knew the importance of community and believed in helping others in need.\\n    \\n    Word spread quickly about the generous mice and their corn. Animals from all around the village came to the mice\\'s burrow, grateful for the assistance. The mice happily distributed the corn, ensuring that everyone had enough to eat.\\n    \\n    The mice\\'s act of kindness and their ability to multiply their resources had a profound impact on the village. The animals learned the value of working together and supporting one another. The mice became a symbol of unity and compassion, inspiring others to follow their example.\\n    \\n    And so, the mice\\'s story of multiplying their resources and spreading kindness became a legend in the village. The mice continued to thrive, not just because of their intelligence and resourcefulness, but also because of their big hearts and willingness to help others.\\n    \\n    The end.\\n\\n### Async Streaming Chat\\n\\n\\n```python\\nresponse = await agent.astream_chat(\\n    \"What is 121 + 8? Once you have the answer, use that number to write a\"\\n    \" story about a group of mice.\"\\n)\\n\\nresponse_gen = response.response_gen\\n\\nasync for token in response.async_response_gen():\\n    print(token, end=\"\")\\n```\\n\\n    STARTING TURN 1\\n    ---------------\\n    \\n    === Calling Function ===\\n    Calling function: add with args: {\\n      \"a\": 121,\\n      \"b\": 8\\n    }\\n    Got output: 129\\n    ========================\\n    \\n    STARTING TURN 2\\n    ---------------\\n    \\n    121 plus 8 is equal to 129.\\n    \\n    Once upon a time, in a peaceful meadow, there lived a group of mice. These mice were known for their bravery and adventurous spirit. They loved exploring the meadow and discovering new places.\\n    \\n    One sunny day, as the mice were scurrying through the tall grass, they stumbled upon a hidden treasure. It was a small, sparkling gemstone that radiated with a mesmerizing glow. The mice were amazed by its beauty and knew that it was something special.\\n    \\n    Excitedly, the mice decided to take the gemstone back to their burrow. They carefully carried it, taking turns to ensure its safety. As they reached their cozy home, they marveled at the gemstone\\'s brilliance. Little did they know, this gemstone held a magical power.\\n    \\n    As the mice gathered around the gemstone, a soft, enchanting light began to emanate from it. Suddenly, the mice felt a surge of energy and realized that they had been granted a special ability - the power to communicate with other animals.\\n    \\n    With their newfound power, the mice embarked on a mission to bring harmony and understanding among the creatures of the meadow. They started by reaching out to the birds, sharing their wisdom and learning about the secrets of the sky. The mice and birds formed a strong bond, exchanging stories and songs.\\n    \\n    Next, the mice approached the rabbits, teaching them about the importance of unity and cooperation. The rabbits, known for their agility, shared their knowledge of navigating the meadow and avoiding danger. Together, the mice and rabbits created a safe haven for all the animals.\\n    \\n    The mice\\'s journey continued as they connected with the squirrels, teaching them the value of saving and planning for the future. The squirrels, in return, shared their knowledge of gathering food and surviving the harsh winters. The meadow became a place of abundance and security for all its inhabitants.\\n    \\n    As the seasons changed, the mice\\'s influence spread throughout the meadow. Animals from all walks of life came together, forming a diverse and harmonious community. The mice\\'s ability to bring different species together was a testament to their leadership and compassion.\\n    \\n    The gemstone, a symbol of unity and understanding, remained at the center of the mice\\'s burrow. It served as a reminder of the power of collaboration and the importance of embracing diversity.\\n    \\n    And so, the mice\\'s story of adding their strengths and bringing animals together became a legend in the meadow. The mice continued to explore, learn, and spread their message of unity, leaving a lasting impact on the meadow and its inhabitants.\\n    \\n    The end.\\n\\n### Agent with Personality\\n\\nYou can specify a system prompt to give the agent additional instruction or personality.\\n\\n\\n```python\\nfrom llama_index.agent import OpenAIAgent\\nfrom llama_index.llms import OpenAI\\nfrom llama_index.prompts.system import SHAKESPEARE_WRITING_ASSISTANT\\n```\\n\\n\\n```python\\nllm = OpenAI(model=\"gpt-3.5-turbo-0613\")\\n\\nagent = OpenAIAgent.from_tools(\\n    [multiply_tool, add_tool],\\n    llm=llm,\\n    verbose=True,\\n    system_prompt=SHAKESPEARE_WRITING_ASSISTANT,\\n)\\n```\\n\\n\\n```python\\nresponse = agent.chat(\"Hi\")\\nprint(response)\\n```\\n\\n    STARTING TURN 1\\n    ---------------\\n    \\n    Greetings, fair traveler! How may I assist thee on this fine day?\\n    \\n\\n\\n```python\\nresponse = agent.chat(\"Tell me a story\")\\nprint(response)\\n```\\n\\n    STARTING TURN 1\\n    ---------------\\n    \\n    Of course, dear friend! Allow me to weave a tale for thee in the style of Shakespeare. \\n    \\n    Once upon a time, in a land far away, there lived a noble knight named Sir William. He was known throughout the kingdom for his bravery and chivalry. One fateful day, as Sir William rode through the enchanted forest, he stumbled upon a hidden glade.\\n    \\n    In the glade, he discovered a beautiful maiden named Lady Rosalind. She was fair of face and gentle of heart, and Sir William was instantly captivated by her beauty. They spent hours conversing, sharing stories, and laughing together.\\n    \\n    As the days turned into weeks, Sir William and Lady Rosalind\\'s bond grew stronger. They found solace in each other\\'s company and realized that they had fallen deeply in love. However, their love was not without obstacles.\\n    \\n    Lady Rosalind\\'s father, Lord Reginald, was a stern and overprotective man. He had already arranged a marriage for his daughter with a wealthy nobleman, Lord Percival. When Lady Rosalind confessed her love for Sir William, Lord Reginald was furious.\\n    \\n    Determined to be together, Sir William and Lady Rosalind devised a plan. They decided to elope under the cover of darkness, seeking refuge in a distant land where their love could flourish without hindrance. With heavy hearts, they bid farewell to their families and set off on their journey.\\n    \\n    Their path was treacherous, filled with perils and hardships. They faced raging storms, dangerous bandits, and even a fearsome dragon. But through it all, their love remained steadfast and unwavering.\\n    \\n    After many trials and tribulations, Sir William and Lady Rosalind finally reached their destination—a peaceful village nestled by the sea. They settled there, vowing to live a life of love and happiness.\\n    \\n    Years passed, and their love only grew stronger. They were blessed with children, who inherited their parents\\' noble qualities. Sir William and Lady Rosalind lived a long and fulfilling life, surrounded by the love of their family and the admiration of the villagers.\\n    \\n    And so, the tale of Sir William and Lady Rosalind serves as a reminder that true love can conquer all obstacles, even in the face of adversity. May their story inspire thee to follow thy heart and pursue love with unwavering determination.\\n    \\n', metadata={'source': '/mnt/c/Users/User/Documents/AI_ML/career_ai_engineer/Projects/ai_apps_assistant/llamaindex_docs/test_llamaindex.json', 'seq_num': 6, 'filename': 'openai_agent.ipynb', 'filepath': 'docs/examples/agent/openai_agent.ipynb', 'url': 'https://github.com/run-llama/llama_index/blob/3823389e3f91cab47b72e2cc2814826db9f98e32/docs/examples/agent/openai_agent.ipynb'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/openai_agent_context_retrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\\n\\n# Context-Augmented OpenAI Agent\\n\\nIn this tutorial, we show you how to use our `ContextRetrieverOpenAIAgent` implementation\\nto build an agent on top of OpenAI\\'s function API and store/index an arbitrary number of tools. Our indexing/retrieval modules help to remove the complexity of having too many functions to fit in the prompt.\\n\\n## Initial Setup \\n\\nHere we setup a ContextRetrieverOpenAIAgent. This agent will perform retrieval first before calling any tools. This can help ground the agent\\'s tool picking and answering capabilities in context.\\n\\nIf you\\'re opening this Notebook on colab, you will probably need to install LlamaIndex 🦙.\\n\\n\\n```python\\n!pip install llama-index\\n```\\n\\n\\n```python\\nimport json\\nfrom typing import Sequence\\n\\nfrom llama_index import (\\n    SimpleDirectoryReader,\\n    VectorStoreIndex,\\n    StorageContext,\\n    load_index_from_storage,\\n)\\nfrom llama_index.tools import QueryEngineTool, ToolMetadata\\n```\\n\\n\\n```python\\ntry:\\n    storage_context = StorageContext.from_defaults(\\n        persist_dir=\"./storage/march\"\\n    )\\n    march_index = load_index_from_storage(storage_context)\\n\\n    storage_context = StorageContext.from_defaults(\\n        persist_dir=\"./storage/june\"\\n    )\\n    june_index = load_index_from_storage(storage_context)\\n\\n    storage_context = StorageContext.from_defaults(\\n        persist_dir=\"./storage/sept\"\\n    )\\n    sept_index = load_index_from_storage(storage_context)\\n\\n    index_loaded = True\\nexcept:\\n    index_loaded = False\\n```\\n\\nDownload Data\\n\\n\\n```python\\n!mkdir -p \\'data/10q/\\'\\n!wget \\'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10q/uber_10q_march_2022.pdf\\' -O \\'data/10q/uber_10q_march_2022.pdf\\'\\n!wget \\'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10q/uber_10q_june_2022.pdf\\' -O \\'data/10q/uber_10q_june_2022.pdf\\'\\n!wget \\'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10q/uber_10q_sept_2022.pdf\\' -O \\'data/10q/uber_10q_sept_2022.pdf\\'\\n```\\n\\n\\n```python\\n# build indexes across the three data sources\\n\\nif not index_loaded:\\n    # load data\\n    march_docs = SimpleDirectoryReader(\\n        input_files=[\"./data/10q/uber_10q_march_2022.pdf\"]\\n    ).load_data()\\n    june_docs = SimpleDirectoryReader(\\n        input_files=[\"./data/10q/uber_10q_june_2022.pdf\"]\\n    ).load_data()\\n    sept_docs = SimpleDirectoryReader(\\n        input_files=[\"./data/10q/uber_10q_sept_2022.pdf\"]\\n    ).load_data()\\n\\n    # build index\\n    march_index = VectorStoreIndex.from_documents(march_docs)\\n    june_index = VectorStoreIndex.from_documents(june_docs)\\n    sept_index = VectorStoreIndex.from_documents(sept_docs)\\n\\n    # persist index\\n    march_index.storage_context.persist(persist_dir=\"./storage/march\")\\n    june_index.storage_context.persist(persist_dir=\"./storage/june\")\\n    sept_index.storage_context.persist(persist_dir=\"./storage/sept\")\\n```\\n\\n\\n```python\\nmarch_engine = march_index.as_query_engine(similarity_top_k=3)\\njune_engine = june_index.as_query_engine(similarity_top_k=3)\\nsept_engine = sept_index.as_query_engine(similarity_top_k=3)\\n```\\n\\n\\n```python\\nquery_engine_tools = [\\n    QueryEngineTool(\\n        query_engine=march_engine,\\n        metadata=ToolMetadata(\\n            name=\"uber_march_10q\",\\n            description=(\\n                \"Provides information about Uber 10Q filings for March 2022. \"\\n                \"Use a detailed plain text question as input to the tool.\"\\n            ),\\n        ),\\n    ),\\n    QueryEngineTool(\\n        query_engine=june_engine,\\n        metadata=ToolMetadata(\\n            name=\"uber_june_10q\",\\n            description=(\\n                \"Provides information about Uber financials for June 2021. \"\\n                \"Use a detailed plain text question as input to the tool.\"\\n            ),\\n        ),\\n    ),\\n    QueryEngineTool(\\n        query_engine=sept_engine,\\n        metadata=ToolMetadata(\\n            name=\"uber_sept_10q\",\\n            description=(\\n                \"Provides information about Uber financials for Sept 2021. \"\\n                \"Use a detailed plain text question as input to the tool.\"\\n            ),\\n        ),\\n    ),\\n]\\n```\\n\\n### Try Context-Augmented Agent\\n\\nHere we augment our agent with context in different settings:\\n- toy context: we define some abbreviations that map to financial terms (e.g. R=Revenue). We supply this as context to the agent\\n\\n\\n```python\\nfrom llama_index.schema import Document\\nfrom llama_index.agent import ContextRetrieverOpenAIAgent\\n```\\n\\n\\n```python\\n# toy index - stores a list of abbreviations\\ntexts = [\\n    \"Abbreviation: X = Revenue\",\\n    \"Abbreviation: YZ = Risk Factors\",\\n    \"Abbreviation: Z = Costs\",\\n]\\ndocs = [Document(text=t) for t in texts]\\ncontext_index = VectorStoreIndex.from_documents(docs)\\n```\\n\\n\\n```python\\ncontext_agent = ContextRetrieverOpenAIAgent.from_tools_and_retriever(\\n    query_engine_tools,\\n    context_index.as_retriever(similarity_top_k=1),\\n    verbose=True,\\n)\\n```\\n\\n\\n```python\\nresponse = context_agent.chat(\"What is the YZ of March 2022?\")\\n```\\n\\n    \\x1b[33;1m\\x1b[1;3mContext information is below.\\n    ---------------------\\n    Abbreviation: YZ = Risk Factors\\n    ---------------------\\n    Given the context information and not prior knowledge, either pick the corresponding tool or answer the function: What is the YZ of March 2022?\\n    \\n    \\x1b[0m=== Calling Function ===\\n    Calling function: uber_march_10q with args: {\\n      \"input\": \"Risk Factors\"\\n    }\\n    Got output: \\n    •The COVID-19 pandemic and the impact of actions to mitigate the pandemic have adversely affected and may continue to adversely affect parts of our business.\\n    •Our business would be adversely affected if Drivers were classified as employees, workers or quasi-employees instead of independent contractors.\\n    •The mobility, delivery, and logistics industries are highly competitive, with well-established and low-cost alternatives that have been available for decades, low barriers to entry, low switching costs, and well-capitalized competitors in nearly every major geographic region.\\n    •To remain competitive in certain markets, we have in the past lowered, and may continue to lower, fares or service fees, and we have in the past offered, and may continue to offer, significant Driver incentives and consumer discounts and promotions.\\n    •We have incurred significant losses since inception, including in the United States and other major markets. We expect our operating expenses to increase significantly in the foreseeable future, and we may not achieve or maintain profitability.\\n    •If we are unable to attract or maintain a critical mass of Drivers, consumers, merchants, shippers, and carriers, whether as a result of competition or other factors, our platform will become less appealing to platform users.\\n    •Maintaining and enhancing our brand and reputation is critical to our business prospects. We have previously received significant media coverage and negative publicity regarding our brand and reputation, and while we have taken significant steps to rehabilitate our brand and reputation, failure to maintain and enhance our brand and reputation could adversely affect our business.\\n    •The impact of economic conditions, including the resulting effect on discretionary consumer spending, may harm our business and operating results.\\n    •Increases in fuel, food, labor, energy, and other costs due to inflation and other factors could adversely affect our operating results.\\n    •If we experience security or privacy breaches or other unauthorized or improper access to, use of, disclosure of, alteration of or destruction of our proprietary or confidential data, employee data, or platform user data.\\n    •Cyberattacks, including computer malware, ransomware, viruses, spamming, and phishing attacks could harm our reputation, business, and operating results.\\n    •We are subject to climate change risks, including physical and transitional risks, and if we are unable to manage such risks, our business may be adversely impacted.\\n    •We have made climate related commitments that require us to invest significant effort, resources, and management time and circumstances may arise, including those beyond our control, that may require us to revise the contemplated timeframes for implementing these commitments.\\n    •We rely on third parties maintaining open marketplaces to distribute our platform and to provide the software we use in certain of our products and offerings. If such third parties interfere with the distribution of our products or offerings or with our use of such software, our business would be adversely affected.\\n    •We will require additional capital to support the growth of our business, and this capital might not be available on reasonable terms or at all.\\n    •If we are unable to successfully identify, acquire and integrate suitable businesses, our operating results and prospects could be harmed, and any businesses we acquire may not perform as expected or be effectively integrated.\\n    •We may continue to be blocked from or limited in providing or operating our products and offerings in certain jurisdictions, and may be required to modify our business model in those jurisdictions as a result.\\n    •Our business is subject to numerous legal and regulatory risks that could have an adverse impact on our business and future prospects.\\n    •Our business is subject to extensive government regulation and oversight relating to the provision of payment and financial services.\\n    •We face risks related to our collection, use, transfer, disclosure, and other processing of data, which could result in investigations, inquiries, litigation, fines, legislative and regulatory action, and negative press about our privacy and data protection practices.\\n    •If we are unable to protect our intellectual property, or if third parties are successful in claiming that we are misappropriating the intellectual property of others, we may incur significant expense and our business may be adversely affected.\\n    •The market price of our common stock has been, and may continue to be, volatile or may decline steeply or suddenly regardless of our operating performance, and we may not be able to meet investor or analyst expectations. You may not be able to resell your shares at or above the price you paid and may lose all or part of your investment.\\n    ========================\\n    \\n\\n\\n```python\\nprint(str(response))\\n```\\n\\n    The risk factors for Uber in March 2022 include:\\n    \\n    1. The adverse impact of the COVID-19 pandemic and actions taken to mitigate it on Uber\\'s business.\\n    2. The potential adverse effect on Uber\\'s business if drivers are classified as employees instead of independent contractors.\\n    3. Intense competition in the mobility, delivery, and logistics industries, with low-cost alternatives and well-capitalized competitors.\\n    4. The need to lower fares, offer driver incentives, and provide consumer discounts and promotions to remain competitive in certain markets.\\n    5. Uber\\'s history of significant losses and the expectation of increased operating expenses in the future, which may affect profitability.\\n    6. The importance of attracting and maintaining a critical mass of drivers, consumers, merchants, shippers, and carriers to keep the platform appealing.\\n    7. The significance of maintaining and enhancing Uber\\'s brand and reputation, as negative publicity could harm the business.\\n    8. The potential impact of economic conditions and discretionary consumer spending on Uber\\'s business.\\n    9. The adverse effect of increasing costs, such as fuel, food, labor, energy, and inflation, on Uber\\'s operating results.\\n    10. The risk of security or privacy breaches and unauthorized access to Uber\\'s proprietary or confidential data.\\n    11. The potential harm to Uber\\'s reputation, business, and operating results from cyberattacks.\\n    12. The impact of climate change risks, including physical and transitional risks, on Uber\\'s business.\\n    13. The commitment to climate-related initiatives that require significant effort, resources, and management time.\\n    14. The reliance on third parties for distributing Uber\\'s platform and providing software, with the risk of interference or limitations.\\n    15. The need for additional capital to support Uber\\'s business growth, with uncertainty about its availability on reasonable terms.\\n    16. The risks associated with identifying, acquiring, and integrating suitable businesses.\\n    17. The potential limitations and modifications to Uber\\'s business model in certain jurisdictions.\\n    18. The legal and regulatory risks that could adversely impact Uber\\'s business and future prospects.\\n    19. The extensive government regulation and oversight related to payment and financial services provided by Uber.\\n    20. The risks associated with data collection, use, transfer, disclosure, and processing, including investigations, litigation, and fines.\\n    21. The importance of protecting Uber\\'s intellectual property and the risk of claims of misappropriation.\\n    22. The volatility and potential decline in the market price of Uber\\'s common stock, which may not reflect operating performance.\\n    \\n    Please note that this is a summary of the risk factors mentioned in Uber\\'s March 2022 10Q filing. For more detailed information, please refer to the official filing.\\n    \\n\\n\\n```python\\ncontext_agent.chat(\"What is the X and Z in September 2022?\")\\n```\\n\\n### Use Uber 10-Q as context, use Calculator as Tool\\n\\n\\n```python\\nfrom llama_index.tools import BaseTool, FunctionTool\\n\\n\\ndef magic_formula(revenue: int, cost: int) -> int:\\n    \"\"\"Runs MAGIC_FORMULA on revenue and cost.\"\"\"\\n    return revenue - cost\\n\\n\\nmagic_tool = FunctionTool.from_defaults(fn=magic_formula, name=\"magic_formula\")\\n```\\n\\n\\n```python\\ncontext_agent = ContextRetrieverOpenAIAgent.from_tools_and_retriever(\\n    [magic_tool], sept_index.as_retriever(similarity_top_k=3), verbose=True\\n)\\n```\\n\\n\\n```python\\nresponse = context_agent.chat(\\n    \"Can you run MAGIC_FORMULA on Uber\\'s revenue and cost?\"\\n)\\n```\\n\\n    \\x1b[33;1m\\x1b[1;3mContext information is below.\\n    ---------------------\\n    Three Months Ended September 30, Nine Months Ended September 30,\\n    2021 2022 2021 2022\\n    Revenue 100 % 100 % 100 % 100 %\\n    Costs and expenses\\n    Cost of revenue, exclusive of depreciation and amortization shown separately\\n    below 50 % 62 % 53 % 62 %\\n    Operations and support 10 % 7 % 11 % 8 %\\n    Sales and marketing 24 % 14 % 30 % 16 %\\n    Research and development 10 % 9 % 13 % 9 %\\n    General and administrative 13 % 11 % 15 % 10 %\\n    Depreciation and amortization 4 % 3 % 6 % 3 %\\n    Total costs and expenses 112 % 106 % 128 % 107 %\\n    Loss from operations (12)% (6)% (28)% (7)%\\n    Interest expense (3)% (2)% (3)% (2)%\\n    Other income (expense), net (38)% (6)% 16 % (34)%\\n    Loss before income taxes and income (loss) from equity method\\n    investments (52)% (14)% (16)% (43)%\\n    Provision for (benefit from) income taxes (2)% 1 % (3)% — %\\n    Income (loss) from equity method investments — % — % — % — %\\n    Net loss including non-controlling interests (50)% (14)% (12)% (42)%\\n    Less: net income (loss) attributable to non-controlling interests,\\n    net of tax — % — % (1)% — %\\n    Net loss attributable to Uber Technologies, Inc. (50)% (14)% (12)% (42)%\\n     Totals of percentage of revenues may not foot due to rounding.\\n    The following discussion and analysis is for the three and nine months ended September 30, 2022 compared to same period in 2021.\\n    Revenue\\n    Three Months Ended September 30, Nine Months Ended September 30,\\n    (In millions, except per centages) 2021 2022 % Change 2021 2022 % Change\\n    Revenue $ 4,845 $ 8,343 72 %$ 11,677 $ 23,270 99 %\\n    Three Months Ended September 30, 2022 Compared with the Same Period in 2021\\n    Revenue increased $3.5 billion, or 72%, primarily attributable to an increase in Gross Bookings of 26%, or 32% on a constant currency basis. The increase in\\n    Gross Bookings was primarily driven by increases in Mobility Trip volumes as the business recovers from the impacts of COVID-19 and a $1.3 billion increase in\\n    Freight Gross Bookings resulting primarily from the acquisition of Transplace in the fourth quarter of 2021. Additionally, during the third quarter of 2022, we saw a\\n    $1.1 billion increase in Mobility revenue as a result of business model changes in the UK. We also saw a $164 million increase in Delivery revenue resulting from\\n    an increase in certain Courier payments and incentives that are recorded in cost of revenue, exclusive of depreciation and amortization, for certain markets where\\n    we are primarily responsible for Delivery services and pay Couriers for services provided.\\n    Nine Months Ended September 30, 2022 Compared with the Same Period in 2021\\n    Revenue increased $11.6 billion, or 99%, primarily attributable to an increase in Gross Bookings of 31%, or 36% on a constant currency basis. The increase in\\n    Gross Bookings was primarily driven by increases in Mobility Trip volumes as the business recovers from the impacts of COVID-19 and a $4.4 billion increase in\\n    Freight Gross Bookings resulting primarily from the acquisition of Transplace in the fourth quarter of 2021. Additionally, during the first nine months of 2022, we\\n    saw a $2.2 billion net increase in Mobility revenue as a result of business model changes in the UK and an accrual made for the resolution of historical claims in\\n    the UK relating to the classification of drivers. We also saw a $751 million increase in Delivery revenue resulting from an increase in certain Courier payments and\\n    incentives that are recorded in cost of revenue, exclusive of depreciation and amortization, for certain markets where we are primarily responsible for\\n    UBER TECHNOLOGIES, INC.\\n    CONDENSED CONSOLIDATED STATEMENTS OF OPERATIONS\\n    (In millions, except share amounts which are reflected in thousands, and per share amounts)\\n    (Unaudited)\\n    Three Months Ended September  30, Nine Months Ended September  30,\\n    2021 2022 2021 2022\\n    Revenue $ 4,845 $ 8,343 $ 11,677 $ 23,270 \\n    Costs and expenses\\n    Cost of revenue, exclusive of depreciation and amortization shown separately\\n    below 2,438 5,173 6,247 14,352 \\n    Operations and support 475 617 1,330 1,808 \\n    Sales and marketing 1,168 1,153 3,527 3,634 \\n    Research and development 493 760 1,496 2,051 \\n    General and administrative 625 908 1,705 2,391 \\n    Depreciation and amortization 218 227 656 724 \\n    Total costs and expenses 5,417 8,838 14,961 24,960 \\n    Loss from operations (572) (495) (3,284) (1,690)\\n    Interest expense (123) (146) (353) (414)\\n    Other income (expense), net (1,832) (535) 1,821 (7,796)\\n    Loss before income taxes and income (loss) from equity method investments (2,527) (1,176) (1,816) (9,900)\\n    Provision for (benefit from) income taxes (101) 58 (395) (97)\\n    Income (loss) from equity method investments (13) 30 (28) 65 \\n    Net loss including non-controlling interests (2,439) (1,204) (1,449) (9,738)\\n    Less: net income (loss) attributable to non-controlling interests, net of\\n    tax (15) 2 (61) (2)\\n    Net loss attributable to Uber Technologies, Inc. $ (2,424)$ (1,206)$ (1,388)$ (9,736)\\n    Net loss per share attributable to Uber Technologies, Inc. common\\n    stockholders:\\n    Basic $ (1.28)$ (0.61)$ (0.74)$ (4.96)\\n    Diluted $ (1.28)$ (0.61)$ (0.75)$ (4.97)\\n    Weighted-average shares used to compute net loss per share attributable to\\n    common stockholders:\\n    Basic 1,898,954 1,979,299 1,877,655 1,964,483 \\n    Diluted 1,898,954 1,979,299 1,878,997 1,968,228 \\n    The accompanying notes are an integral part of these condensed consolidated financial statements.\\n    5\\n    Components of Results of Operations\\n    Revenue\\n    We generate substantially all of our revenue from fees paid by Drivers and Merchants for use of our platform. We have concluded that we are an agent in these\\n    arrangements as we arrange for other parties to provide the service to the end-user. Under this model, revenue is net of Driver and Merchant earnings and Driver\\n    incentives. We act as an agent in these transactions by connecting consumers to Drivers and Merchants to facilitate a Trip, meal or grocery delivery service.\\n    During the first quarter of 2022, we modified our arrangements in certain markets and, as a result, concluded we are responsible for the provision of mobility\\n    services to end-users in those markets. We have determined that in these transactions, end-users are our customers and our sole performance obligation in the\\n    transaction is to provide transportation services to the end-user. We recognize revenue when a trip is complete. In these markets where we are responsible for\\n    mobility services, we present revenue from end-users on a gross basis, as we control the service provided by Drivers to end-users, while payments to Drivers in\\n    exchange for mobility services are recognized in cost of revenue, exclusive of depreciation and amortization.\\n    For additional discussion related to our revenue, see the section titled “Management’s Discussion and Analysis of Financial Condition and Results of\\n    Operations - Critical Accounting Estimates - Revenue Recognition,” “Note 1 - Description of Business and Summary of Significant Accounting Policies - Revenue\\n    Recognition,” and “Note 2 - Revenue” to our audited consolidated financial statements included in our Annual Report Form 10-K for the year ended December 31,\\n    2021 and Note 2 – Revenue in this Quarterly Report on Form 10-Q.\\n    Cost of Revenue, Exclusive of Depreciation and Amortization\\n    Cost of revenue, exclusive of depreciation and amortization, primarily consists of certain insurance costs related to our Mobility and Delivery offerings, credit\\n    card processing fees, bank fees, data center and networking expenses, mobile device and service costs, costs incurred with Carriers for Uber Freight transportation\\n    services, amounts related to fare chargebacks and other credit card losses as well as costs incurred for certain Mobility and Delivery transactions where we are\\n    primarily responsible for mobility or delivery services and pay Drivers and Couriers for services.\\n    We expect that cost of revenue, exclusive of depreciation and amortization, will fluctuate on an absolute dollar basis for the foreseeable future in line with Trip\\n    volume changes on the platform. As Trips increase or decrease, we expect related changes for insurance costs, credit card processing fees, hosting and co-located\\n    data center expenses, maps license fees, and other cost of revenue, exclusive of depreciation and amortization.\\n    Operations and Support\\n    Operations and support expenses primarily consist of compensation expenses, including stock-based compensation, for employees that support operations in\\n    cities, including the general managers, Driver operations, platform user support representatives and community managers. Also included is the cost of customer\\n    support, Driver background checks and the allocation of certain corporate costs.\\n    As our business recovers from the impacts of COVID-19 and Trip volume increases, we would expect operations and support expenses to increase on an\\n    absolute dollar basis for the foreseeable future, but decrease as a percentage of revenue as we become more efficient in supporting platform users.\\n    Sales and Marketing\\n    Sales and marketing expenses primarily consist of compensation costs, including stock-based compensation to sales and marketing employees, advertising\\n    costs, product marketing costs and discounts, loyalty programs, promotions, refunds, and credits provided to end-users who are not customers, and the allocation of\\n    certain corporate costs. We expense advertising and other promotional expenditures as incurred.\\n    As our business recovers from the impacts of COVID-19, we would anticipate sales and marketing expenses to increase on an absolute dollar basis for\\n    ---------------------\\n    Given the context information and not prior knowledge, either pick the corresponding tool or answer the function: Can you run MAGIC_FORMULA on Uber\\'s revenue and cost?\\n    \\n    \\x1b[0m=== Calling Function ===\\n    Calling function: magic_formula with args: {\\n      \"revenue\": 23270,\\n      \"cost\": 24960\\n    }\\n    Got output: -1690\\n    ========================\\n    \\n\\n\\n```python\\nprint(response)\\n```\\n\\n    The result of running MAGIC_FORMULA on Uber\\'s revenue and cost is -1690.\\n    \\n', metadata={'source': '/mnt/c/Users/User/Documents/AI_ML/career_ai_engineer/Projects/ai_apps_assistant/llamaindex_docs/test_llamaindex.json', 'seq_num': 7, 'filename': 'openai_agent_context_retrieval.ipynb', 'filepath': 'docs/examples/agent/openai_agent_context_retrieval.ipynb', 'url': 'https://github.com/run-llama/llama_index/blob/3823389e3f91cab47b72e2cc2814826db9f98e32/docs/examples/agent/openai_agent_context_retrieval.ipynb'}),\n",
      " Document(page_content='# Single-Turn Multi-Function Calling OpenAI Agents\\n\\n<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/openai_agent_parallel_function_calling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\\n\\nWith the latest OpenAI API (v. 1.1.0+), users can now execute multiple function calls within a single turn of `User` and `Agent` dialogue. We\\'ve updated our library to enable this new feature as well, and in this notebook we\\'ll show you how it all works!\\n\\nNOTE: OpenAI refers to this as \"Parallel\" function calling, but the current implementation doesn\\'t invoke parallel computations of the multiple function calls. So, it\\'s \"parallelizable\" function calling in terms of our current implementation.\\n\\n\\n```python\\nfrom llama_index.agent import OpenAIAgent\\nfrom llama_index.llms import OpenAI\\nfrom llama_index.tools import BaseTool, FunctionTool\\n```\\n\\n### Setup\\n\\nIf you\\'ve seen any of our previous notebooks on OpenAI Agents, then you\\'re already familiar with the cookbook recipe that we have to follow here. But if not, or if you fancy a refresher then all we need to do (at a high level) are the following steps:\\n\\n1. Define a set of tools (we\\'ll use `FunctionTool`) since Agents work with tools\\n2. Define the `LLM` for the Agent\\n3. Define a `OpenAIAgent`\\n\\n\\n```python\\ndef multiply(a: int, b: int) -> int:\\n    \"\"\"Multiple two integers and returns the result integer\"\"\"\\n    return a * b\\n\\n\\nmultiply_tool = FunctionTool.from_defaults(fn=multiply)\\n```\\n\\n\\n```python\\ndef add(a: int, b: int) -> int:\\n    \"\"\"Add two integers and returns the result integer\"\"\"\\n    return a + b\\n\\n\\nadd_tool = FunctionTool.from_defaults(fn=add)\\n```\\n\\n\\n```python\\nllm = OpenAI(model=\"gpt-3.5-turbo-1106\")\\nagent = OpenAIAgent.from_tools(\\n    [multiply_tool, add_tool], llm=llm, verbose=True\\n)\\n```\\n\\n### Sync mode\\n\\n\\n```python\\nresponse = agent.chat(\"What is (121 * 3) + 42?\")\\nprint(str(response))\\n```\\n\\n    STARTING TURN 1\\n    ---------------\\n    \\n    === Calling Function ===\\n    Calling function: multiply with args: {\"a\": 121, \"b\": 3}\\n    Got output: 363\\n    ========================\\n    \\n    === Calling Function ===\\n    Calling function: add with args: {\"a\": 363, \"b\": 42}\\n    Got output: 405\\n    ========================\\n    \\n    STARTING TURN 2\\n    ---------------\\n    \\n    The result of (121 * 3) + 42 is 405.\\n    \\n\\n\\n```python\\nresponse = agent.stream_chat(\"What is (121 * 3) + 42?\")\\n```\\n\\n    STARTING TURN 1\\n    ---------------\\n    \\n    === Calling Function ===\\n    Calling function: add with args: {\"a\":363,\"b\":42}\\n    Got output: 405\\n    ========================\\n    \\n    STARTING TURN 2\\n    ---------------\\n    \\n    \\n\\n### Async mode\\n\\n\\n```python\\nimport nest_asyncio\\n\\nnest_asyncio.apply()\\n```\\n\\n\\n```python\\nresponse = await agent.achat(\"What is (121 * 3) + 42?\")\\nprint(str(response))\\n```\\n\\n    STARTING TURN 1\\n    ---------------\\n    \\n    === Calling Function ===\\n    Calling function: add with args: {\"a\":363,\"b\":42}\\n    Got output: 405\\n    ========================\\n    \\n    STARTING TURN 2\\n    ---------------\\n    \\n    The result of (121 * 3) + 42 is 405.\\n    \\n\\n\\n```python\\nresponse = await agent.astream_chat(\"What is (121 * 3) + 42?\")\\n\\nresponse_gen = response.response_gen\\n\\nasync for token in response.async_response_gen():\\n    print(token, end=\"\")\\n```\\n\\n    STARTING TURN 1\\n    ---------------\\n    \\n    === Calling Function ===\\n    Calling function: multiply with args: {\"a\": 121, \"b\": 3}\\n    Got output: 363\\n    ========================\\n    \\n    === Calling Function ===\\n    Calling function: add with args: {\"a\": 363, \"b\": 42}\\n    Got output: 405\\n    ========================\\n    \\n    STARTING TURN 2\\n    ---------------\\n    \\n    The result of (121 * 3) + 42 is 405.\\n\\n### Example from OpenAI docs\\n\\nHere\\'s an example straight from the OpenAI [docs](https://platform.openai.com/docs/guides/function-calling/parallel-function-calling) on Parallel function calling. (Their example gets this done in 76 lines of code, whereas with the `llama_index` library you can get that down to about 18 lines.)\\n\\n\\n```python\\nimport json\\n\\n\\n# Example dummy function hard coded to return the same weather\\n# In production, this could be your backend API or an external API\\ndef get_current_weather(location, unit=\"fahrenheit\"):\\n    \"\"\"Get the current weather in a given location\"\"\"\\n    if \"tokyo\" in location.lower():\\n        return json.dumps(\\n            {\"location\": location, \"temperature\": \"10\", \"unit\": \"celsius\"}\\n        )\\n    elif \"san francisco\" in location.lower():\\n        return json.dumps(\\n            {\"location\": location, \"temperature\": \"72\", \"unit\": \"fahrenheit\"}\\n        )\\n    else:\\n        return json.dumps(\\n            {\"location\": location, \"temperature\": \"22\", \"unit\": \"celsius\"}\\n        )\\n\\n\\nweather_tool = FunctionTool.from_defaults(fn=get_current_weather)\\n```\\n\\n\\n```python\\nllm = OpenAI(model=\"gpt-3.5-turbo-1106\")\\nagent = OpenAIAgent.from_tools([weather_tool], llm=llm, verbose=True)\\nresponse = agent.chat(\\n    \"What\\'s the weather like in San Francisco, Tokyo, and Paris?\"\\n)\\n```\\n\\n    STARTING TURN 1\\n    ---------------\\n    \\n    === Calling Function ===\\n    Calling function: get_current_weather with args: {\"location\": \"San Francisco\", \"unit\": \"fahrenheit\"}\\n    Got output: {\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": \"fahrenheit\"}\\n    ========================\\n    \\n    === Calling Function ===\\n    Calling function: get_current_weather with args: {\"location\": \"Tokyo\", \"unit\": \"fahrenheit\"}\\n    Got output: {\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": \"celsius\"}\\n    ========================\\n    \\n    === Calling Function ===\\n    Calling function: get_current_weather with args: {\"location\": \"Paris\", \"unit\": \"fahrenheit\"}\\n    Got output: {\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": \"celsius\"}\\n    ========================\\n    \\n    STARTING TURN 2\\n    ---------------\\n    \\n    \\n\\nAll of the above function calls that the Agent has done above were in a single turn of dialogue between the `Assistant` and the `User`. What\\'s interesting is that an older version of GPT-3.5 is not quite advanced enough compared to is successor — it will do the above task in 3 separate turns. For the sake of demonstration, here it is below.\\n\\n\\n```python\\nllm = OpenAI(model=\"gpt-3.5-turbo-0613\")\\nagent = OpenAIAgent.from_tools([weather_tool], llm=llm, verbose=True)\\nresponse = agent.chat(\\n    \"What\\'s the weather like in San Francisco, Tokyo, and Paris?\"\\n)\\n```\\n\\n    STARTING TURN 1\\n    ---------------\\n    \\n    === Calling Function ===\\n    Calling function: get_current_weather with args: {\\n      \"location\": \"San Francisco\"\\n    }\\n    Got output: {\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": \"fahrenheit\"}\\n    ========================\\n    \\n    STARTING TURN 2\\n    ---------------\\n    \\n    === Calling Function ===\\n    Calling function: get_current_weather with args: {\\n      \"location\": \"Tokyo\"\\n    }\\n    Got output: {\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": \"celsius\"}\\n    ========================\\n    \\n    STARTING TURN 3\\n    ---------------\\n    \\n    === Calling Function ===\\n    Calling function: get_current_weather with args: {\\n      \"location\": \"Paris\"\\n    }\\n    Got output: {\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": \"celsius\"}\\n    ========================\\n    \\n    STARTING TURN 4\\n    ---------------\\n    \\n    \\n\\n## Conclusion\\n\\nAnd so, as you can see the `llama_index` library can handle multiple function calls (as well as a single function call) within a single turn of dialogue between the user and the OpenAI agent!\\n', metadata={'source': '/mnt/c/Users/User/Documents/AI_ML/career_ai_engineer/Projects/ai_apps_assistant/llamaindex_docs/test_llamaindex.json', 'seq_num': 8, 'filename': 'openai_agent_parallel_function_calling.ipynb', 'filepath': 'docs/examples/agent/openai_agent_parallel_function_calling.ipynb', 'url': 'https://github.com/run-llama/llama_index/blob/3823389e3f91cab47b72e2cc2814826db9f98e32/docs/examples/agent/openai_agent_parallel_function_calling.ipynb'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/openai_agent_query_cookbook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\\n\\n# OpenAI Agent + Query Engine Experimental Cookbook\\n\\n\\nIn this notebook, we try out the OpenAIAgent across a variety of query engine tools and datasets. We explore how OpenAIAgent can compare/replace existing workflows solved by our retrievers/query engines.\\n\\n- Auto retrieval \\n- Joint SQL and vector search\\n\\n## AutoRetrieval from a Vector Database\\n\\nOur existing \"auto-retrieval\" capabilities (in `VectorIndexAutoRetriever`) allow an LLM to infer the right query parameters for a vector database - including both the query string and metadata filter.\\n\\nSince the OpenAI Function API can infer function parameters, we explore its capabilities in performing auto-retrieval here.\\n\\nIf you\\'re opening this Notebook on colab, you will probably need to install LlamaIndex 🦙.\\n\\n\\n```python\\n!pip install llama-index\\n```\\n\\n\\n```python\\nimport pinecone\\nimport os\\n\\napi_key = os.environ[\"PINECONE_API_KEY\"]\\npinecone.init(api_key=api_key, environment=\"us-west4-gcp-free\")\\n```\\n\\n\\n```python\\nimport os\\nimport getpass\\n\\n# os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\\nimport openai\\n\\nopenai.api_key = \"sk-<your-key>\"\\n```\\n\\n\\n```python\\n# dimensions are for text-embedding-ada-002\\ntry:\\n    pinecone.create_index(\\n        \"quickstart-index\", dimension=1536, metric=\"euclidean\", pod_type=\"p1\"\\n    )\\nexcept Exception:\\n    # most likely index already exists\\n    pass\\n```\\n\\n\\n```python\\npinecone_index = pinecone.Index(\"quickstart-index\")\\n```\\n\\n\\n```python\\n# Optional: delete data in your pinecone index\\npinecone_index.delete(deleteAll=True, namespace=\"test\")\\n```\\n\\n\\n\\n\\n    {}\\n\\n\\n\\n\\n```python\\nfrom llama_index import VectorStoreIndex, StorageContext\\nfrom llama_index.vector_stores import PineconeVectorStore\\n```\\n\\n\\n```python\\nfrom llama_index.schema import TextNode\\n\\nnodes = [\\n    TextNode(\\n        text=(\\n            \"Michael Jordan is a retired professional basketball player,\"\\n            \" widely regarded as one of the greatest basketball players of all\"\\n            \" time.\"\\n        ),\\n        metadata={\\n            \"category\": \"Sports\",\\n            \"country\": \"United States\",\\n            \"gender\": \"male\",\\n            \"born\": 1963,\\n        },\\n    ),\\n    TextNode(\\n        text=(\\n            \"Angelina Jolie is an American actress, filmmaker, and\"\\n            \" humanitarian. She has received numerous awards for her acting\"\\n            \" and is known for her philanthropic work.\"\\n        ),\\n        metadata={\\n            \"category\": \"Entertainment\",\\n            \"country\": \"United States\",\\n            \"gender\": \"female\",\\n            \"born\": 1975,\\n        },\\n    ),\\n    TextNode(\\n        text=(\\n            \"Elon Musk is a business magnate, industrial designer, and\"\\n            \" engineer. He is the founder, CEO, and lead designer of SpaceX,\"\\n            \" Tesla, Inc., Neuralink, and The Boring Company.\"\\n        ),\\n        metadata={\\n            \"category\": \"Business\",\\n            \"country\": \"United States\",\\n            \"gender\": \"male\",\\n            \"born\": 1971,\\n        },\\n    ),\\n    TextNode(\\n        text=(\\n            \"Rihanna is a Barbadian singer, actress, and businesswoman. She\"\\n            \" has achieved significant success in the music industry and is\"\\n            \" known for her versatile musical style.\"\\n        ),\\n        metadata={\\n            \"category\": \"Music\",\\n            \"country\": \"Barbados\",\\n            \"gender\": \"female\",\\n            \"born\": 1988,\\n        },\\n    ),\\n    TextNode(\\n        text=(\\n            \"Cristiano Ronaldo is a Portuguese professional footballer who is\"\\n            \" considered one of the greatest football players of all time. He\"\\n            \" has won numerous awards and set multiple records during his\"\\n            \" career.\"\\n        ),\\n        metadata={\\n            \"category\": \"Sports\",\\n            \"country\": \"Portugal\",\\n            \"gender\": \"male\",\\n            \"born\": 1985,\\n        },\\n    ),\\n]\\n```\\n\\n\\n```python\\nvector_store = PineconeVectorStore(\\n    pinecone_index=pinecone_index, namespace=\"test\"\\n)\\nstorage_context = StorageContext.from_defaults(vector_store=vector_store)\\n```\\n\\n\\n```python\\nindex = VectorStoreIndex(nodes, storage_context=storage_context)\\n```\\n\\n    Upserted vectors: 100%|██████████| 5/5 [00:00<00:00,  5.79it/s]\\n    \\n\\n#### Define Function Tool\\n\\nHere we define the function interface, which is passed to OpenAI to perform auto-retrieval.\\n\\nWe were not able to get OpenAI to work with nested pydantic objects or tuples as arguments,\\nso we converted the metadata filter keys and values into lists for the function API to work with.\\n\\n\\n```python\\n# define function tool\\nfrom llama_index.tools import FunctionTool\\nfrom llama_index.vector_stores.types import (\\n    VectorStoreInfo,\\n    MetadataInfo,\\n    MetadataFilter,\\n    MetadataFilters,\\n    FilterCondition,\\n    FilterOperator,\\n)\\nfrom llama_index.retrievers import VectorIndexRetriever\\nfrom llama_index.query_engine import RetrieverQueryEngine\\n\\nfrom typing import List, Tuple, Any\\nfrom pydantic import BaseModel, Field\\n\\n# hardcode top k for now\\ntop_k = 3\\n\\n# define vector store info describing schema of vector store\\nvector_store_info = VectorStoreInfo(\\n    content_info=\"brief biography of celebrities\",\\n    metadata_info=[\\n        MetadataInfo(\\n            name=\"category\",\\n            type=\"str\",\\n            description=(\\n                \"Category of the celebrity, one of [Sports, Entertainment,\"\\n                \" Business, Music]\"\\n            ),\\n        ),\\n        MetadataInfo(\\n            name=\"country\",\\n            type=\"str\",\\n            description=(\\n                \"Country of the celebrity, one of [United States, Barbados,\"\\n                \" Portugal]\"\\n            ),\\n        ),\\n        MetadataInfo(\\n            name=\"gender\",\\n            type=\"str\",\\n            description=(\"Gender of the celebrity, one of [male, female]\"),\\n        ),\\n        MetadataInfo(\\n            name=\"born\",\\n            type=\"int\",\\n            description=(\"Born year of the celebrity, could be any integer\"),\\n        ),\\n    ],\\n)\\n```\\n\\n\\n```python\\n# define pydantic model for auto-retrieval function\\nclass AutoRetrieveModel(BaseModel):\\n    query: str = Field(..., description=\"natural language query string\")\\n    filter_key_list: List[str] = Field(\\n        ..., description=\"List of metadata filter field names\"\\n    )\\n    filter_value_list: List[Any] = Field(\\n        ...,\\n        description=(\\n            \"List of metadata filter field values (corresponding to names\"\\n            \" specified in filter_key_list)\"\\n        ),\\n    )\\n    filter_operator_list: List[str] = Field(\\n        ...,\\n        description=(\\n            \"Metadata filters conditions (could be one of <, <=, >, >=, ==, !=)\"\\n        ),\\n    )\\n    filter_condition: str = Field(\\n        ...,\\n        description=(\"Metadata filters condition values (could be AND or OR)\"),\\n    )\\n\\n\\ndescription = f\"\"\"\\\\\\nUse this tool to look up biographical information about celebrities.\\nThe vector database schema is given below:\\n{vector_store_info.json()}\\n\"\"\"\\n```\\n\\nDefine AutoRetrieve Functions\\n\\n\\n```python\\ndef auto_retrieve_fn(\\n    query: str,\\n    filter_key_list: List[str],\\n    filter_value_list: List[any],\\n    filter_operator_list: List[str],\\n    filter_condition: str,\\n):\\n    \"\"\"Auto retrieval function.\\n\\n    Performs auto-retrieval from a vector database, and then applies a set of filters.\\n\\n    \"\"\"\\n    query = query or \"Query\"\\n\\n    metadata_filters = [\\n        MetadataFilter(key=k, value=v, operator=op)\\n        for k, v, op in zip(\\n            filter_key_list, filter_value_list, filter_operator_list\\n        )\\n    ]\\n    retriever = VectorIndexRetriever(\\n        index,\\n        filters=MetadataFilters(\\n            filters=metadata_filters, condition=filter_condition\\n        ),\\n        top_k=top_k,\\n    )\\n    query_engine = RetrieverQueryEngine.from_args(retriever)\\n\\n    response = query_engine.query(query)\\n    return str(response)\\n\\n\\nauto_retrieve_tool = FunctionTool.from_defaults(\\n    fn=auto_retrieve_fn,\\n    name=\"celebrity_bios\",\\n    description=description,\\n    fn_schema=AutoRetrieveModel,\\n)\\n```\\n\\n#### Initialize Agent\\n\\n\\n```python\\nfrom llama_index.agent import OpenAIAgent\\nfrom llama_index.llms import OpenAI\\n\\nagent = OpenAIAgent.from_tools(\\n    [auto_retrieve_tool],\\n    llm=OpenAI(temperature=0, model=\"gpt-4-0613\"),\\n    verbose=True,\\n)\\n```\\n\\n\\n```python\\nresponse = agent.chat(\"Tell me about two celebrities from the United States. \")\\nprint(str(response))\\n```\\n\\n    STARTING TURN 1\\n    ---------------\\n    \\n    === Calling Function ===\\n    Calling function: celebrity_bios with args: {\\n    \"query\": \"celebrities from the United States\",\\n    \"filter_key_list\": [\"country\"],\\n    \"filter_value_list\": [\"United States\"],\\n    \"filter_operator_list\": [\"==\"],\\n    \"filter_condition\": \"and\"\\n    }\\n    Got output: Angelina Jolie and Michael Jordan are both celebrities from the United States.\\n    ========================\\n    \\n    STARTING TURN 2\\n    ---------------\\n    \\n    Here are two celebrities from the United States:\\n    \\n    1. **Angelina Jolie**: She is an American actress, filmmaker, and humanitarian. The recipient of numerous accolities, including an Academy Award and three Golden Globe Awards, she has been named Hollywood\\'s highest-paid actress multiple times.\\n    \\n    2. **Michael Jordan**: He is a former professional basketball player and the principal owner of the Charlotte Hornets of the National Basketball Association (NBA). He played 15 seasons in the NBA, winning six championships with the Chicago Bulls. He is considered one of the greatest players in the history of the NBA.\\n    \\n\\n\\n```python\\nresponse = agent.chat(\"Tell me about two celebrities born after 1980. \")\\nprint(str(response))\\n```\\n\\n    STARTING TURN 1\\n    ---------------\\n    \\n    === Calling Function ===\\n    Calling function: celebrity_bios with args: {\\n    \"query\": \"celebrities born after 1980\",\\n    \"filter_key_list\": [\"born\"],\\n    \"filter_value_list\": [1980],\\n    \"filter_operator_list\": [\">\"],\\n    \"filter_condition\": \"and\"\\n    }\\n    Got output: Rihanna and Cristiano Ronaldo are both celebrities who were born after 1980.\\n    ========================\\n    \\n    STARTING TURN 2\\n    ---------------\\n    \\n    Here are two celebrities who were born after 1980:\\n    \\n    1. **Rihanna**: She is a Barbadian singer, actress, and businesswoman. Born in Saint Michael and raised in Bridgetown, Barbados, Rihanna was discovered by American record producer Evan Rogers who invited her to the United States to record demo tapes. She rose to fame with her debut album \"Music of the Sun\" and its follow-up \"A Girl like Me\".\\n    \\n    2. **Cristiano Ronaldo**: He is a Portuguese professional footballer who plays as a forward for Serie A club Juventus and captains the Portugal\\n    \\n\\n\\n```python\\nresponse = agent.chat(\\n    \"Tell me about few celebrities under category business and born after 1950. \"\\n)\\nprint(str(response))\\n```\\n\\n    STARTING TURN 1\\n    ---------------\\n    \\n    === Calling Function ===\\n    Calling function: celebrity_bios with args: {\\n    \"query\": \"business celebrities born after 1950\",\\n    \"filter_key_list\": [\"category\", \"born\"],\\n    \"filter_value_list\": [\"Business\", 1950],\\n    \"filter_operator_list\": [\"==\", \">\"],\\n    \"filter_condition\": \"and\"\\n    }\\n    Got output: Elon Musk is a notable business celebrity who was born in 1971.\\n    ========================\\n    \\n    STARTING TURN 2\\n    ---------------\\n    \\n    Elon Musk is a business celebrity who was born after 1950. He is a business magnate and investor. He is the founder, CEO, CTO, and chief designer of SpaceX; early investor, CEO and product architect of Tesla, Inc.; founder of The\\n    \\n\\n## Joint Text-to-SQL and Semantic Search\\n\\nThis is currently handled by our `SQLAutoVectorQueryEngine`.\\n\\nLet\\'s try implementing this by giving our `OpenAIAgent` access to two query tools: SQL and Vector \\n\\n#### Load and Index Structured Data\\n\\nWe load sample structured datapoints into a SQL db and index it.\\n\\n\\n```python\\nfrom sqlalchemy import (\\n    create_engine,\\n    MetaData,\\n    Table,\\n    Column,\\n    String,\\n    Integer,\\n    select,\\n    column,\\n)\\nfrom llama_index import SQLDatabase, SQLStructStoreIndex\\n\\nengine = create_engine(\"sqlite:///:memory:\", future=True)\\nmetadata_obj = MetaData()\\n```\\n\\n\\n```python\\n# create city SQL table\\ntable_name = \"city_stats\"\\ncity_stats_table = Table(\\n    table_name,\\n    metadata_obj,\\n    Column(\"city_name\", String(16), primary_key=True),\\n    Column(\"population\", Integer),\\n    Column(\"country\", String(16), nullable=False),\\n)\\n\\nmetadata_obj.create_all(engine)\\n```\\n\\n\\n```python\\n# print tables\\nmetadata_obj.tables.keys()\\n```\\n\\n\\n\\n\\n    dict_keys([\\'city_stats\\'])\\n\\n\\n\\n\\n```python\\nfrom sqlalchemy import insert\\n\\nrows = [\\n    {\"city_name\": \"Toronto\", \"population\": 2930000, \"country\": \"Canada\"},\\n    {\"city_name\": \"Tokyo\", \"population\": 13960000, \"country\": \"Japan\"},\\n    {\"city_name\": \"Berlin\", \"population\": 3645000, \"country\": \"Germany\"},\\n]\\nfor row in rows:\\n    stmt = insert(city_stats_table).values(**row)\\n    with engine.begin() as connection:\\n        cursor = connection.execute(stmt)\\n```\\n\\n\\n```python\\nwith engine.connect() as connection:\\n    cursor = connection.exec_driver_sql(\"SELECT * FROM city_stats\")\\n    print(cursor.fetchall())\\n```\\n\\n    [(\\'Toronto\\', 2930000, \\'Canada\\'), (\\'Tokyo\\', 13960000, \\'Japan\\'), (\\'Berlin\\', 3645000, \\'Germany\\')]\\n    \\n\\n\\n```python\\nsql_database = SQLDatabase(engine, include_tables=[\"city_stats\"])\\n```\\n\\n\\n```python\\nfrom llama_index.indices.struct_store.sql_query import NLSQLTableQueryEngine\\n```\\n\\n\\n```python\\nquery_engine = NLSQLTableQueryEngine(\\n    sql_database=sql_database,\\n    tables=[\"city_stats\"],\\n)\\n```\\n\\n#### Load and Index Unstructured Data\\n\\nWe load unstructured data into a vector index backed by Pinecone\\n\\n\\n```python\\n# install wikipedia python package\\n!pip install wikipedia\\n```\\n\\n    Requirement already satisfied: wikipedia in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (1.4.0)\\n    Requirement already satisfied: requests<3.0.0,>=2.0.0 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from wikipedia) (2.28.2)\\n    Requirement already satisfied: beautifulsoup4 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from wikipedia) (4.12.2)\\n    Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.1.0)\\n    Requirement already satisfied: idna<4,>=2.5 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4)\\n    Requirement already satisfied: certifi>=2017.4.17 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2022.12.7)\\n    Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.26.15)\\n    Requirement already satisfied: soupsieve>1.2 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from beautifulsoup4->wikipedia) (2.4.1)\\n    \\n    \\x1b[1m[\\x1b[0m\\x1b[34;49mnotice\\x1b[0m\\x1b[1;39;49m]\\x1b[0m\\x1b[39;49m A new release of pip available: \\x1b[0m\\x1b[31;49m22.3.1\\x1b[0m\\x1b[39;49m -> \\x1b[0m\\x1b[32;49m23.1.2\\x1b[0m\\n    \\x1b[1m[\\x1b[0m\\x1b[34;49mnotice\\x1b[0m\\x1b[1;39;49m]\\x1b[0m\\x1b[39;49m To update, run: \\x1b[0m\\x1b[32;49mpip install --upgrade pip\\x1b[0m\\n    \\n\\n\\n```python\\nfrom llama_index import (\\n    WikipediaReader,\\n    SimpleDirectoryReader,\\n    VectorStoreIndex,\\n)\\n```\\n\\n\\n```python\\ncities = [\"Toronto\", \"Berlin\", \"Tokyo\"]\\nwiki_docs = WikipediaReader().load_data(pages=cities)\\n```\\n\\n\\n```python\\n# define pinecone index\\nimport pinecone\\nimport os\\n\\napi_key = os.environ[\"PINECONE_API_KEY\"]\\npinecone.init(api_key=api_key, environment=\"us-west1-gcp\")\\n\\n# dimensions are for text-embedding-ada-002\\n# pinecone.create_index(\"quickstart\", dimension=1536, metric=\"euclidean\", pod_type=\"p1\")\\npinecone_index = pinecone.Index(\"quickstart\")\\n```\\n\\n\\n```python\\n# OPTIONAL: delete all\\npinecone_index.delete(deleteAll=True)\\n```\\n\\n\\n\\n\\n    {}\\n\\n\\n\\n\\n```python\\nfrom llama_index import ServiceContext\\nfrom llama_index.storage import StorageContext\\nfrom llama_index.vector_stores import PineconeVectorStore\\nfrom llama_index.node_parser import TokenTextSplitter\\nfrom llama_index.llms import OpenAI\\n\\n# define node parser and LLM\\nchunk_size = 1024\\nllm = OpenAI(temperature=0, model=\"gpt-4\")\\nservice_context = ServiceContext.from_defaults(chunk_size=chunk_size, llm=llm)\\nnode_parser = TokenTextSplitter(chunk_size=chunk_size)\\n\\n# define pinecone vector index\\nvector_store = PineconeVectorStore(\\n    pinecone_index=pinecone_index, namespace=\"wiki_cities\"\\n)\\nstorage_context = StorageContext.from_defaults(vector_store=vector_store)\\nvector_index = VectorStoreIndex([], storage_context=storage_context)\\n```\\n\\n\\n```python\\n# Insert documents into vector index\\n# Each document has metadata of the city attached\\nfor city, wiki_doc in zip(cities, wiki_docs):\\n    nodes = node_parser.get_nodes_from_documents([wiki_doc])\\n    # add metadata to each node\\n    for node in nodes:\\n        node.metadata = {\"title\": city}\\n    vector_index.insert_nodes(nodes)\\n```\\n\\n    Upserted vectors: 100%|█████████████████████████████████████████████████| 20/20 [00:00<00:00, 38.13it/s]\\n    Upserted vectors: 100%|████████████████████████████████████████████████| 21/21 [00:00<00:00, 101.89it/s]\\n    Upserted vectors: 100%|█████████████████████████████████████████████████| 13/13 [00:00<00:00, 97.91it/s]\\n    \\n\\n#### Define Query Engines / Tools\\n\\n\\n```python\\nfrom llama_index.query_engine import (\\n    SQLAutoVectorQueryEngine,\\n    RetrieverQueryEngine,\\n)\\nfrom llama_index.tools.query_engine import QueryEngineTool\\nfrom llama_index.indices.vector_store import VectorIndexAutoRetriever\\n```\\n\\n\\n```python\\nfrom llama_index.indices.vector_store.retrievers import (\\n    VectorIndexAutoRetriever,\\n)\\nfrom llama_index.vector_stores.types import MetadataInfo, VectorStoreInfo\\nfrom llama_index.query_engine.retriever_query_engine import (\\n    RetrieverQueryEngine,\\n)\\n\\n\\nvector_store_info = VectorStoreInfo(\\n    content_info=\"articles about different cities\",\\n    metadata_info=[\\n        MetadataInfo(\\n            name=\"title\", type=\"str\", description=\"The name of the city\"\\n        ),\\n    ],\\n)\\nvector_auto_retriever = VectorIndexAutoRetriever(\\n    vector_index, vector_store_info=vector_store_info\\n)\\n\\nretriever_query_engine = RetrieverQueryEngine.from_args(\\n    vector_auto_retriever, service_context=service_context\\n)\\n```\\n\\n\\n```python\\nsql_tool = QueryEngineTool.from_defaults(\\n    query_engine=query_engine,\\n    name=\"sql_tool\",\\n    description=(\\n        \"Useful for translating a natural language query into a SQL query over\"\\n        \" a table containing: city_stats, containing the population/country of\"\\n        \" each city\"\\n    ),\\n)\\nvector_tool = QueryEngineTool.from_defaults(\\n    query_engine=retriever_query_engine,\\n    name=\"vector_tool\",\\n    description=(\\n        f\"Useful for answering semantic questions about different cities\"\\n    ),\\n)\\n```\\n\\n#### Initialize Agent\\n\\n\\n```python\\nfrom llama_index.agent import OpenAIAgent\\nfrom llama_index.llms import OpenAI\\n\\nagent = OpenAIAgent.from_tools(\\n    [sql_tool, vector_tool],\\n    llm=OpenAI(temperature=0, model=\"gpt-4-0613\"),\\n    verbose=True,\\n)\\n```\\n\\n\\n```python\\n# NOTE: gpt-3.5 gives the wrong answer, but gpt-4 is able to reason over both loops\\nresponse = agent.chat(\\n    \"Tell me about the arts and culture of the city with the highest\"\\n    \" population\"\\n)\\nprint(str(response))\\n```\\n\\n    === Calling Function ===\\n    Calling function: sql_tool with args: {\\n      \"input\": \"SELECT city FROM city_stats ORDER BY population DESC LIMIT 1\"\\n    }\\n    Got output:  The city with the highest population is Tokyo.\\n    ========================\\n    === Calling Function ===\\n    Calling function: vector_tool with args: {\\n      \"input\": \"Tell me about the arts and culture of Tokyo\"\\n    }\\n    Got output: Tokyo has a rich arts and culture scene, with many theaters for performing arts, including national and private theaters for traditional forms of Japanese drama. Noteworthy theaters are the National Noh Theatre for noh and the Kabuki-za for Kabuki. Symphony orchestras and other musical organizations perform modern and traditional music. The New National Theater Tokyo in Shibuya is the national center for the performing arts, including opera, ballet, contemporary dance, and drama. Tokyo also hosts modern Japanese and international pop and rock music at various venues, ranging from intimate clubs to internationally known areas such as the Nippon Budokan.\\n    \\n    Many different festivals occur throughout Tokyo, with major events including the Sannō at Hie Shrine, the Sanja at Asakusa Shrine, and the biennial Kanda Festivals. Annually on the last Saturday of July, a massive fireworks display over the Sumida River attracts over a million viewers. Once cherry blossoms bloom in spring, residents gather in Ueno Park, Inokashira Park, and the Shinjuku Gyoen National Garden for picnics under the blossoms. Harajuku, a neighborhood in Shibuya, is known internationally for its youth style, fashion, and cosplay.\\n    \\n    Tokyo is also renowned for its fine dining, with Michelin awarding a significant number of stars to the city\\'s restaurants. As of 2017, 227 restaurants in Tokyo have been awarded Michelin stars, surpassing the number awarded in Paris.\\n    ========================\\n    Tokyo, the city with the highest population, has a rich arts and culture scene. It is home to many theaters for performing arts, including national and private theaters for traditional forms of Japanese drama such as Noh and Kabuki. The New National Theater Tokyo in Shibuya is the national center for the performing arts, including opera, ballet, contemporary dance, and drama.\\n    \\n    Tokyo also hosts modern Japanese and international pop and rock music at various venues, ranging from intimate clubs to internationally known areas such as the Nippon Budokan.\\n    \\n    The city is known for its festivals, with major events including the Sannō at Hie Shrine, the Sanja at Asakusa Shrine, and the biennial Kanda Festivals. Once cherry blossoms bloom in spring, residents gather in Ueno Park, Inokashira Park, and the Shinjuku Gyoen National Garden for picnics under the blossoms.\\n    \\n    Harajuku, a neighborhood in Shibuya, is known internationally for its youth style, fashion, and cosplay. Tokyo is also renowned for its fine dining, with Michelin awarding a significant number of stars to the city\\'s restaurants. As of 2017, 227 restaurants in Tokyo have been awarded Michelin stars, surpassing the number awarded in Paris.\\n    \\n\\n\\n```python\\nresponse = agent.chat(\"Tell me about the history of Berlin\")\\nprint(str(response))\\n```\\n\\n    === Calling Function ===\\n    Calling function: vector_tool with args: {\\n      \"input\": \"Tell me about the history of Berlin\"\\n    }\\n    Got output: Berlin\\'s history dates back to the 15th century when it was established as the capital of the Margraviate of Brandenburg. The Hohenzollern family ruled Berlin until 1918, first as electors of Brandenburg, then as kings of Prussia, and eventually as German emperors. In 1443, Frederick II Irontooth started the construction of a new royal palace in the twin city Berlin-Cölln, which later became the permanent residence of the Brandenburg electors of the Hohenzollerns.\\n    \\n    The Thirty Years\\' War between 1618 and 1648 devastated Berlin, with the city losing half of its population. Frederick William, known as the \"Great Elector\", initiated a policy of promoting immigration and religious tolerance. In 1701, the dual state of the Margraviate of Brandenburg and the Duchy of Prussia formed the Kingdom of Prussia, with Berlin as its capital. Under the rule of Frederick II, Berlin became a center of the Enlightenment.\\n    \\n    The Industrial Revolution in the 19th century transformed Berlin, expanding its economy and population. In 1871, Berlin became the capital of the newly founded German Empire. The early 20th century saw Berlin as a fertile ground for the German Expressionist movement. At the end of the First World War in 1918, a republic was proclaimed, and in 1920, the Greater Berlin Act incorporated dozens of suburban cities, villages, and estates around Berlin.\\n    ========================\\n    \\n\\n\\n\\n\\n    Response(response=\\'Berlin\\\\\\'s history dates back to the 15th century when it was established as the capital of the Margraviate of Brandenburg. The Hohenzollern family ruled Berlin until 1918, first as electors of Brandenburg, then as kings of Prussia, and eventually as German emperors. In 1443, Frederick II Irontooth started the construction of a new royal palace in the twin city Berlin-Cölln.\\\\n\\\\nThe Thirty Years\\\\\\' War between 1618 and 1648 devastated Berlin, with the city losing half of its population. Frederick William, known as the \"Great Elector\", initiated a policy of promoting immigration and religious tolerance. In 1701, the dual state of the Margraviate of Brandenburg and the Duchy of Prussia formed the Kingdom of Prussia, with Berlin as its capital. Under the rule of Frederick II, Berlin became a center of the Enlightenment.\\\\n\\\\nThe Industrial Revolution in the 19th century transformed Berlin, expanding its economy and population. In 1871, Berlin became the capital of the newly founded German Empire. The early 20th century saw Berlin as a fertile ground for the German Expressionist movement. At the end of the First World War in 1918, a republic was proclaimed, and in 1920, the Greater Berlin Act incorporated dozens of suburban cities, villages, and estates around Berlin.\\', source_nodes=[], extra_info=None)\\n\\n\\n\\n\\n```python\\nresponse = agent.chat(\\n    \"Can you give me the country corresponding to each city?\"\\n)\\nprint(str(response))\\n```\\n\\n    === Calling Function ===\\n    Calling function: sql_tool with args: {\\n      \"input\": \"SELECT city, country FROM city_stats\"\\n    }\\n    Got output:  The cities Toronto, Tokyo, and Berlin are located in the countries Canada, Japan, and Germany respectively.\\n    ========================\\n    \\n\\n\\n\\n\\n    Response(response=\\'Sure, here are the countries corresponding to each city:\\\\n\\\\n- Toronto is in Canada\\\\n- Tokyo is in Japan\\\\n- Berlin is in Germany\\', source_nodes=[], extra_info=None)\\n\\n\\n', metadata={'source': '/mnt/c/Users/User/Documents/AI_ML/career_ai_engineer/Projects/ai_apps_assistant/llamaindex_docs/test_llamaindex.json', 'seq_num': 9, 'filename': 'openai_agent_query_cookbook.ipynb', 'filepath': 'docs/examples/agent/openai_agent_query_cookbook.ipynb', 'url': 'https://github.com/run-llama/llama_index/blob/3823389e3f91cab47b72e2cc2814826db9f98e32/docs/examples/agent/openai_agent_query_cookbook.ipynb'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/openai_agent_query_plan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\\n\\n# OpenAI Agent Query Planning\\nIn this demo, we explore adding a `QueryPlanTool` to an `OpenAIAgent`. This effectively enables the agent\\nto do advanced query planning, all through a single tool! \\n\\nThe `QueryPlanTool` is designed to work well with the OpenAI Function API. The tool takes in a set of other tools as input.\\nThe tool function signature contains of a QueryPlan Pydantic object, which can in turn contain a DAG of QueryNode objects defining a compute graph.\\nThe agent is responsible for defining this graph through the function signature when calling the tool. The tool itself executes the DAG over any corresponding tools.\\n\\nIn this setting we use a familiar example: Uber 10Q filings in March, June, and September of 2022.\\n\\nIf you\\'re opening this Notebook on colab, you will probably need to install LlamaIndex 🦙.\\n\\n\\n```python\\n!pip install llama-index\\n```\\n\\n\\n```python\\n# # uncomment to turn on logging\\n# import logging\\n# import sys\\n\\n# logging.basicConfig(stream=sys.stdout, level=logging.INFO)\\n# logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\\n```\\n\\n\\n```python\\n%load_ext autoreload\\n%autoreload 2\\n```\\n\\n\\n```python\\nfrom llama_index import (\\n    SimpleDirectoryReader,\\n    ServiceContext,\\n    GPTVectorStoreIndex,\\n)\\nfrom llama_index.response.pprint_utils import pprint_response\\nfrom llama_index.llms import OpenAI\\n```\\n\\n\\n```python\\nllm = OpenAI(temperature=0, model=\"gpt-4\")\\nservice_context = ServiceContext.from_defaults(llm=llm)\\n```\\n\\n## Download Data\\n\\n\\n```python\\n!mkdir -p \\'data/10q/\\'\\n!wget \\'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10q/uber_10q_march_2022.pdf\\' -O \\'data/10q/uber_10q_march_2022.pdf\\'\\n!wget \\'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10q/uber_10q_june_2022.pdf\\' -O \\'data/10q/uber_10q_june_2022.pdf\\'\\n!wget \\'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10q/uber_10q_sept_2022.pdf\\' -O \\'data/10q/uber_10q_sept_2022.pdf\\'\\n```\\n\\n## Load data\\n\\n\\n```python\\nmarch_2022 = SimpleDirectoryReader(\\n    input_files=[\"./data/10q/uber_10q_march_2022.pdf\"]\\n).load_data()\\njune_2022 = SimpleDirectoryReader(\\n    input_files=[\"./data/10q/uber_10q_june_2022.pdf\"]\\n).load_data()\\nsept_2022 = SimpleDirectoryReader(\\n    input_files=[\"./data/10q/uber_10q_sept_2022.pdf\"]\\n).load_data()\\n```\\n\\n## Build indices\\n\\nWe build a vector index / query engine over each of the documents (March, June, September).\\n\\n\\n```python\\nmarch_index = GPTVectorStoreIndex.from_documents(march_2022)\\njune_index = GPTVectorStoreIndex.from_documents(june_2022)\\nsept_index = GPTVectorStoreIndex.from_documents(sept_2022)\\n```\\n\\n\\n```python\\nmarch_engine = march_index.as_query_engine(\\n    similarity_top_k=3, service_context=service_context\\n)\\njune_engine = june_index.as_query_engine(\\n    similarity_top_k=3, service_context=service_context\\n)\\nsept_engine = sept_index.as_query_engine(\\n    similarity_top_k=3, service_context=service_context\\n)\\n```\\n\\n## OpenAI Function Agent with a Query Plan Tool\\n\\nUse OpenAIAgent, built on top of the OpenAI tool use interface.\\n\\nFeed it our QueryPlanTool, which is a Tool that takes in other tools. And the agent to generate a query plan DAG over these tools.\\n\\n\\n```python\\nfrom llama_index.tools import QueryEngineTool\\n\\n\\nquery_tool_sept = QueryEngineTool.from_defaults(\\n    query_engine=sept_engine,\\n    name=\"sept_2022\",\\n    description=(\\n        f\"Provides information about Uber quarterly financials ending\"\\n        f\" September 2022\"\\n    ),\\n)\\nquery_tool_june = QueryEngineTool.from_defaults(\\n    query_engine=june_engine,\\n    name=\"june_2022\",\\n    description=(\\n        f\"Provides information about Uber quarterly financials ending June\"\\n        f\" 2022\"\\n    ),\\n)\\nquery_tool_march = QueryEngineTool.from_defaults(\\n    query_engine=march_engine,\\n    name=\"march_2022\",\\n    description=(\\n        f\"Provides information about Uber quarterly financials ending March\"\\n        f\" 2022\"\\n    ),\\n)\\n```\\n\\n\\n```python\\n# define query plan tool\\nfrom llama_index.tools import QueryPlanTool\\nfrom llama_index import get_response_synthesizer\\n\\nresponse_synthesizer = get_response_synthesizer(\\n    service_context=service_context\\n)\\nquery_plan_tool = QueryPlanTool.from_defaults(\\n    query_engine_tools=[query_tool_sept, query_tool_june, query_tool_march],\\n    response_synthesizer=response_synthesizer,\\n)\\n```\\n\\n\\n```python\\nquery_plan_tool.metadata.to_openai_tool()  # to_openai_function() deprecated\\n```\\n\\n\\n\\n\\n    {\\'name\\': \\'query_plan_tool\\',\\n     \\'description\\': \\'        This is a query plan tool that takes in a list of tools and executes a query plan over these tools to answer a query. The query plan is a DAG of query nodes.\\\\n\\\\nGiven a list of tool names and the query plan schema, you can choose to generate a query plan to answer a question.\\\\n\\\\nThe tool names and descriptions are as follows:\\\\n\\\\n\\\\n\\\\n        Tool Name: sept_2022\\\\nTool Description: Provides information about Uber quarterly financials ending September 2022 \\\\n\\\\nTool Name: june_2022\\\\nTool Description: Provides information about Uber quarterly financials ending June 2022 \\\\n\\\\nTool Name: march_2022\\\\nTool Description: Provides information about Uber quarterly financials ending March 2022 \\\\n        \\',\\n     \\'parameters\\': {\\'title\\': \\'QueryPlan\\',\\n      \\'description\\': \"Query plan.\\\\n\\\\nContains a list of QueryNode objects (which is a recursive object).\\\\nOut of the list of QueryNode objects, one of them must be the root node.\\\\nThe root node is the one that isn\\'t a dependency of any other node.\",\\n      \\'type\\': \\'object\\',\\n      \\'properties\\': {\\'nodes\\': {\\'title\\': \\'Nodes\\',\\n        \\'description\\': \\'The original question we are asking.\\',\\n        \\'type\\': \\'array\\',\\n        \\'items\\': {\\'$ref\\': \\'#/definitions/QueryNode\\'}}},\\n      \\'required\\': [\\'nodes\\'],\\n      \\'definitions\\': {\\'QueryNode\\': {\\'title\\': \\'QueryNode\\',\\n        \\'description\\': \\'Query node.\\\\n\\\\nA query node represents a query (query_str) that must be answered.\\\\nIt can either be answered by a tool (tool_name), or by a list of child nodes\\\\n(child_nodes).\\\\nThe tool_name and child_nodes fields are mutually exclusive.\\',\\n        \\'type\\': \\'object\\',\\n        \\'properties\\': {\\'id\\': {\\'title\\': \\'Id\\',\\n          \\'description\\': \\'ID of the query node.\\',\\n          \\'type\\': \\'integer\\'},\\n         \\'query_str\\': {\\'title\\': \\'Query Str\\',\\n          \\'description\\': \\'Question we are asking. This is the query string that will be executed. \\',\\n          \\'type\\': \\'string\\'},\\n         \\'tool_name\\': {\\'title\\': \\'Tool Name\\',\\n          \\'description\\': \\'Name of the tool to execute the `query_str`.\\',\\n          \\'type\\': \\'string\\'},\\n         \\'dependencies\\': {\\'title\\': \\'Dependencies\\',\\n          \\'description\\': \\'List of sub-questions that need to be answered in order to answer the question given by `query_str`.Should be blank if there are no sub-questions to be specified, in which case `tool_name` is specified.\\',\\n          \\'type\\': \\'array\\',\\n          \\'items\\': {\\'type\\': \\'integer\\'}}},\\n        \\'required\\': [\\'id\\', \\'query_str\\']}}}}\\n\\n\\n\\n\\n```python\\nfrom llama_index.agent import OpenAIAgent\\nfrom llama_index.llms import OpenAI\\n\\n\\nagent = OpenAIAgent.from_tools(\\n    [query_plan_tool],\\n    max_function_calls=10,\\n    llm=OpenAI(temperature=0, model=\"gpt-4-0613\"),\\n    verbose=True,\\n)\\n```\\n\\n\\n```python\\nresponse = agent.query(\"What were the risk factors in sept 2022?\")\\n```\\n\\n\\n```python\\nfrom llama_index.tools.query_plan import QueryPlan, QueryNode\\n\\nquery_plan = QueryPlan(\\n    nodes=[\\n        QueryNode(\\n            id=1,\\n            query_str=\"risk factors\",\\n            tool_name=\"sept_2022\",\\n            dependencies=[],\\n        )\\n    ]\\n)\\n```\\n\\n\\n```python\\nQueryPlan.schema()\\n```\\n\\n\\n\\n\\n    {\\'title\\': \\'QueryPlan\\',\\n     \\'description\\': \\'Query plan.\\\\n\\\\nContains the root QueryNode (which is a recursive object).\\\\nThe root node should contain the original query string to be executed.\\\\n\\\\nExample query plan in JSON format:\\\\n\\\\n```json\\\\n{\\\\n    \"root\": {\\\\n        \"query_str\": \"Compare the demographics of France and Italy.\",\\\\n        \"child_nodes\": [\\\\n            {\\\\n                \"query_str\": \"What are the demographics of France?\",\\\\n                \"tool_name\": \"france_demographics\",\\\\n                \"child_nodes\": []\\\\n            },\\\\n            {\\\\n                \"query_str\": \"What are the demographics of Italy?\",\\\\n                \"tool_name\": \"italy_demographics\",\\\\n                \"child_nodes\": []\\\\n            }\\\\n        ]\\\\n    }\\\\n}\\\\n```\\',\\n     \\'type\\': \\'object\\',\\n     \\'properties\\': {\\'root\\': {\\'title\\': \\'Root\\',\\n       \\'description\\': \\'Root node of the query plan. Should contain the original query string to be executed.\\',\\n       \\'allOf\\': [{\\'$ref\\': \\'#/definitions/QueryNode\\'}]}},\\n     \\'required\\': [\\'root\\'],\\n     \\'definitions\\': {\\'QueryNode\\': {\\'title\\': \\'QueryNode\\',\\n       \\'description\\': \\'Query node.\\\\n\\\\nA query node represents a query (query_str) that must be answered.\\\\nIt can either be answered by a tool (tool_name), or by a list of child nodes\\\\n(child_nodes).\\\\nThe tool_name and child_nodes fields are mutually exclusive.\\',\\n       \\'type\\': \\'object\\',\\n       \\'properties\\': {\\'query_str\\': {\\'title\\': \\'Query Str\\',\\n         \\'description\\': \\'Question we are asking. This is the query string that will be executed. We will either provide a tool to execute the query, or a list of child nodes containing sub-questions that will be executed first, and the results of which will be used as context to execute the current query string.\\',\\n         \\'type\\': \\'string\\'},\\n        \\'tool_name\\': {\\'title\\': \\'Tool Name\\',\\n         \\'description\\': \\'Name of the tool to execute the `query_str`.\\',\\n         \\'type\\': \\'string\\'},\\n        \\'child_nodes\\': {\\'title\\': \\'Child Nodes\\',\\n         \\'description\\': \\'List of child nodes representing sub-questions that need to be answered in order to answer the question given by `query_str`.Should be blank if `tool_name` is specified.\\',\\n         \\'type\\': \\'array\\',\\n         \\'items\\': {\\'$ref\\': \\'#/definitions/QueryNode\\'}}},\\n       \\'required\\': [\\'query_str\\', \\'child_nodes\\']}}}\\n\\n\\n\\n\\n```python\\nresponse = agent.query(\\n    \"Analyze Uber revenue growth in March, June, and September\"\\n)\\n```\\n\\n    === Calling Function ===\\n    Calling function: query_plan_tool with args: {\\n      \"nodes\": [\\n        {\\n          \"id\": 1,\\n          \"query_str\": \"What is Uber\\'s revenue for March 2022?\",\\n          \"tool_name\": \"march_2022\",\\n          \"dependencies\": []\\n        },\\n        {\\n          \"id\": 2,\\n          \"query_str\": \"What is Uber\\'s revenue for June 2022?\",\\n          \"tool_name\": \"june_2022\",\\n          \"dependencies\": []\\n        },\\n        {\\n          \"id\": 3,\\n          \"query_str\": \"What is Uber\\'s revenue for September 2022?\",\\n          \"tool_name\": \"sept_2022\",\\n          \"dependencies\": []\\n        },\\n        {\\n          \"id\": 4,\\n          \"query_str\": \"Analyze Uber revenue growth in March, June, and September\",\\n          \"tool_name\": \"revenue_growth_analyzer\",\\n          \"dependencies\": [1, 2, 3]\\n        }\\n      ]\\n    }\\n    \\x1b[36;1m\\x1b[1;3mExecuting node {\"id\": 4, \"query_str\": \"Analyze Uber revenue growth in March, June, and September\", \"tool_name\": \"revenue_growth_analyzer\", \"dependencies\": [1, 2, 3]}\\n    \\x1b[0m\\x1b[38;5;200m\\x1b[1;3mExecuting 3 child nodes\\n    \\x1b[0m\\x1b[36;1m\\x1b[1;3mExecuting node {\"id\": 1, \"query_str\": \"What is Uber\\'s revenue for March 2022?\", \"tool_name\": \"march_2022\", \"dependencies\": []}\\n    \\x1b[0m\\x1b[38;5;200m\\x1b[1;3mSelected Tool: ToolMetadata(description=\\'Provides information about Uber quarterly financials ending March 2022\\', name=\\'march_2022\\', fn_schema=None)\\n    \\x1b[0m\\x1b[36;1m\\x1b[1;3mExecuted query, got response.\\n    Query: What is Uber\\'s revenue for March 2022?\\n    Response: Uber\\'s revenue for March 2022 was $6.854 billion.\\n    \\x1b[0m\\x1b[36;1m\\x1b[1;3mExecuting node {\"id\": 2, \"query_str\": \"What is Uber\\'s revenue for June 2022?\", \"tool_name\": \"june_2022\", \"dependencies\": []}\\n    \\x1b[0m\\x1b[38;5;200m\\x1b[1;3mSelected Tool: ToolMetadata(description=\\'Provides information about Uber quarterly financials ending June 2022\\', name=\\'june_2022\\', fn_schema=None)\\n    \\x1b[0m\\x1b[36;1m\\x1b[1;3mExecuted query, got response.\\n    Query: What is Uber\\'s revenue for June 2022?\\n    Response: Uber\\'s revenue for June 2022 cannot be determined from the provided information. However, the revenue for the three months ended June 30, 2022, was $8,073 million.\\n    \\x1b[0m\\x1b[36;1m\\x1b[1;3mExecuting node {\"id\": 3, \"query_str\": \"What is Uber\\'s revenue for September 2022?\", \"tool_name\": \"sept_2022\", \"dependencies\": []}\\n    \\x1b[0m\\x1b[38;5;200m\\x1b[1;3mSelected Tool: ToolMetadata(description=\\'Provides information about Uber quarterly financials ending September 2022\\', name=\\'sept_2022\\', fn_schema=None)\\n    \\x1b[0m\\x1b[36;1m\\x1b[1;3mExecuted query, got response.\\n    Query: What is Uber\\'s revenue for September 2022?\\n    Response: Uber\\'s revenue for the three months ended September 30, 2022, was $8.343 billion.\\n    \\x1b[0mGot output: Based on the provided context information, we can analyze Uber\\'s revenue growth as follows:\\n    \\n    - In March 2022, Uber\\'s revenue was $6.854 billion.\\n    - For the three months ended June 30, 2022, Uber\\'s revenue was $8,073 million (or $8.073 billion). However, we do not have the specific revenue for June 2022.\\n    - For the three months ended September 30, 2022, Uber\\'s revenue was $8.343 billion.\\n    \\n    From this information, we can observe that Uber\\'s revenue has been growing between the periods mentioned. The revenue increased from $6.854 billion in March 2022 to $8.073 billion for the three months ended June 2022, and further increased to $8.343 billion for the three months ended September 2022. However, we cannot provide a month-by-month analysis for June and September as the specific monthly revenue figures are not available.\\n    ========================\\n    \\n\\n\\n```python\\nprint(str(response))\\n```\\n\\n    Based on the provided context information, we can analyze Uber\\'s revenue growth for the three-month periods ending in March, June, and September.\\n    \\n    1. For the three months ended March 31, 2022, Uber\\'s revenue was $6.854 billion.\\n    2. For the three months ended June 30, 2022, Uber\\'s revenue was $8.073 billion.\\n    3. For the three months ended September 30, 2022, Uber\\'s revenue was $8.343 billion.\\n    \\n    To analyze the growth, we can compare the revenue figures for each period:\\n    \\n    - From March to June, Uber\\'s revenue increased by $1.219 billion ($8.073 billion - $6.854 billion), which represents a growth of approximately 17.8% (($1.219 billion / $6.854 billion) * 100).\\n    - From June to September, Uber\\'s revenue increased by $0.270 billion ($8.343 billion - $8.073 billion), which represents a growth of approximately 3.3% (($0.270 billion / $8.073 billion) * 100).\\n    \\n    In summary, Uber experienced significant revenue growth of 17.8% between the three-month periods ending in March and June, followed by a smaller growth of 3.3% between the periods ending in June and September.\\n    \\n\\n\\n```python\\nresponse = agent.query(\\n    \"Analyze changes in risk factors in march, june, and september for Uber\"\\n)\\n```\\n\\n\\n```python\\nprint(str(response))\\n```\\n\\n\\n```python\\n# response = agent.query(\"Analyze both Uber revenue growth and risk factors over march, june, and september\")\\n```\\n\\n\\n```python\\nprint(str(response))\\n```\\n\\n    Based on the provided context information, we can analyze Uber\\'s revenue growth for the three-month periods ending in March, June, and September.\\n    \\n    1. For the three months ended March 31, 2022, Uber\\'s revenue was $6.854 billion.\\n    2. For the three months ended June 30, 2022, Uber\\'s revenue was $8.073 billion.\\n    3. For the three months ended September 30, 2022, Uber\\'s revenue was $8.343 billion.\\n    \\n    To analyze the growth, we can compare the revenue figures for each period:\\n    \\n    - From March to June, Uber\\'s revenue increased by $1.219 billion ($8.073 billion - $6.854 billion), which represents a growth of approximately 17.8% (($1.219 billion / $6.854 billion) * 100).\\n    - From June to September, Uber\\'s revenue increased by $0.270 billion ($8.343 billion - $8.073 billion), which represents a growth of approximately 3.3% (($0.270 billion / $8.073 billion) * 100).\\n    \\n    In summary, Uber experienced significant revenue growth of 17.8% between the three-month periods ending in March and June, followed by a smaller growth of 3.3% between the periods ending in June and September.\\n    \\n\\n\\n```python\\nresponse = agent.query(\\n    \"First look at Uber\\'s revenue growth and risk factors in March, \"\\n    + \"then revenue growth and risk factors in September, and then compare and\"\\n    \" contrast the two documents?\"\\n)\\n```\\n\\n\\n```python\\nresponse\\n```\\n', metadata={'source': '/mnt/c/Users/User/Documents/AI_ML/career_ai_engineer/Projects/ai_apps_assistant/llamaindex_docs/test_llamaindex.json', 'seq_num': 10, 'filename': 'openai_agent_query_plan.ipynb', 'filepath': 'docs/examples/agent/openai_agent_query_plan.ipynb', 'url': 'https://github.com/run-llama/llama_index/blob/3823389e3f91cab47b72e2cc2814826db9f98e32/docs/examples/agent/openai_agent_query_plan.ipynb'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/openai_agent_retrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\\n\\n# Retrieval-Augmented OpenAI Agent\\n\\nIn this tutorial, we show you how to use our `FnRetrieverOpenAI` implementation\\nto build an agent on top of OpenAI\\'s function API and store/index an arbitrary number of tools. Our indexing/retrieval modules help to remove the complexity of having too many functions to fit in the prompt.\\n\\n## Initial Setup \\n\\nLet\\'s start by importing some simple building blocks.  \\n\\nThe main thing we need is:\\n1. the OpenAI API\\n2. a place to keep conversation history \\n3. a definition for tools that our agent can use.\\n\\nIf you\\'re opening this Notebook on colab, you will probably need to install LlamaIndex 🦙.\\n\\n\\n```python\\n!pip install llama-index\\n```\\n\\n\\n```python\\nimport json\\nfrom typing import Sequence\\n\\nfrom llama_index.tools import BaseTool, FunctionTool\\n```\\n\\n    /Users/suo/miniconda3/envs/llama/lib/python3.9/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.6.7) is available. It\\'s recommended that you update to the latest version using `pip install -U deeplake`.\\n      warnings.warn(\\n    \\n\\nLet\\'s define some very simple calculator tools for our agent.\\n\\n\\n```python\\ndef multiply(a: int, b: int) -> int:\\n    \"\"\"Multiply two integers and returns the result integer\"\"\"\\n    return a * b\\n\\n\\ndef add(a: int, b: int) -> int:\\n    \"\"\"Add two integers and returns the result integer\"\"\"\\n    return a + b\\n\\n\\ndef useless(a: int, b: int) -> int:\\n    \"\"\"Toy useless function.\"\"\"\\n    pass\\n\\n\\nmultiply_tool = FunctionTool.from_defaults(fn=multiply, name=\"multiply\")\\nuseless_tools = [\\n    FunctionTool.from_defaults(fn=useless, name=f\"useless_{str(idx)}\")\\n    for idx in range(28)\\n]\\nadd_tool = FunctionTool.from_defaults(fn=add, name=\"add\")\\n\\nall_tools = [multiply_tool] + [add_tool] + useless_tools\\nall_tools_map = {t.metadata.name: t for t in all_tools}\\n```\\n\\n## Building an Object Index\\n\\nWe have an `ObjectIndex` construct in LlamaIndex that allows the user to use our index data structures over arbitrary objects.\\nThe ObjectIndex will handle serialiation to/from the object, and use an underying index (e.g. VectorStoreIndex, SummaryIndex, KeywordTableIndex) as the storage mechanism. \\n\\nIn this case, we have a large collection of Tool objects, and we\\'d want to define an ObjectIndex over these Tools.\\n\\nThe index comes bundled with a retrieval mechanism, an `ObjectRetriever`. \\n\\nThis can be passed in to our agent so that it can \\nperform Tool retrieval during query-time.\\n\\n\\n```python\\n# define an \"object\" index over these tools\\nfrom llama_index import VectorStoreIndex\\nfrom llama_index.objects import ObjectIndex, SimpleToolNodeMapping\\n\\ntool_mapping = SimpleToolNodeMapping.from_objects(all_tools)\\nobj_index = ObjectIndex.from_objects(\\n    all_tools,\\n    tool_mapping,\\n    VectorStoreIndex,\\n)\\n```\\n\\n## Our `FnRetrieverOpenAIAgent` Implementation \\n\\nWe provide a `FnRetrieverOpenAIAgent` implementation in LlamaIndex, which can take in an `ObjectRetriever` over a set of `BaseTool` objects.\\n\\nDuring query-time, we would first use the `ObjectRetriever` to retrieve a set of relevant Tools. These tools would then be passed into the agent; more specifically, their function signatures would be passed into the OpenAI Function calling API. \\n\\n\\n```python\\nfrom llama_index.agent import FnRetrieverOpenAIAgent\\n```\\n\\n\\n```python\\nagent = FnRetrieverOpenAIAgent.from_retriever(\\n    obj_index.as_retriever(), verbose=True\\n)\\n```\\n\\n\\n```python\\nagent.chat(\"What\\'s 212 multiplied by 122? Make sure to use Tools\")\\n```\\n\\n    === Calling Function ===\\n    Calling function: multiply with args: {\\n      \"a\": 212,\\n      \"b\": 122\\n    }\\n    Got output: 25864\\n    ========================\\n    \\n\\n\\n\\n\\n    Response(response=\\'212 multiplied by 122 is 25,864.\\', source_nodes=[], metadata=None)\\n\\n\\n\\n\\n```python\\nagent.chat(\"What\\'s 212 added to 122 ? Make sure to use Tools\")\\n```\\n\\n    === Calling Function ===\\n    Calling function: add with args: {\\n      \"a\": 212,\\n      \"b\": 122\\n    }\\n    Got output: 334\\n    ========================\\n    \\n\\n\\n\\n\\n    Response(response=\\'212 added to 122 is 334.\\', source_nodes=[], metadata=None)\\n\\n\\n', metadata={'source': '/mnt/c/Users/User/Documents/AI_ML/career_ai_engineer/Projects/ai_apps_assistant/llamaindex_docs/test_llamaindex.json', 'seq_num': 11, 'filename': 'openai_agent_retrieval.ipynb', 'filepath': 'docs/examples/agent/openai_agent_retrieval.ipynb', 'url': 'https://github.com/run-llama/llama_index/blob/3823389e3f91cab47b72e2cc2814826db9f98e32/docs/examples/agent/openai_agent_retrieval.ipynb'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/openai_agent_with_query_engine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\\n\\n# OpenAI Agent with Query Engine Tools\\n\\n## Build Query Engine Tools\\n\\nIf you\\'re opening this Notebook on colab, you will probably need to install LlamaIndex 🦙.\\n\\n\\n```python\\n!pip install llama-index\\n```\\n\\n\\n```python\\nfrom llama_index import (\\n    SimpleDirectoryReader,\\n    VectorStoreIndex,\\n    StorageContext,\\n    load_index_from_storage,\\n)\\n\\nfrom llama_index.tools import QueryEngineTool, ToolMetadata\\n```\\n\\n\\n```python\\ntry:\\n    storage_context = StorageContext.from_defaults(\\n        persist_dir=\"./storage/lyft\"\\n    )\\n    lyft_index = load_index_from_storage(storage_context)\\n\\n    storage_context = StorageContext.from_defaults(\\n        persist_dir=\"./storage/uber\"\\n    )\\n    uber_index = load_index_from_storage(storage_context)\\n\\n    index_loaded = True\\nexcept:\\n    index_loaded = False\\n```\\n\\nDownload Data\\n\\n\\n```python\\n!mkdir -p \\'data/10k/\\'\\n!wget \\'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10k/uber_2021.pdf\\' -O \\'data/10k/uber_2021.pdf\\'\\n!wget \\'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10k/lyft_2021.pdf\\' -O \\'data/10k/lyft_2021.pdf\\'\\n```\\n\\n\\n```python\\nif not index_loaded:\\n    # load data\\n    lyft_docs = SimpleDirectoryReader(\\n        input_files=[\"./data/10k/lyft_2021.pdf\"]\\n    ).load_data()\\n    uber_docs = SimpleDirectoryReader(\\n        input_files=[\"./data/10k/uber_2021.pdf\"]\\n    ).load_data()\\n\\n    # build index\\n    lyft_index = VectorStoreIndex.from_documents(lyft_docs)\\n    uber_index = VectorStoreIndex.from_documents(uber_docs)\\n\\n    # persist index\\n    lyft_index.storage_context.persist(persist_dir=\"./storage/lyft\")\\n    uber_index.storage_context.persist(persist_dir=\"./storage/uber\")\\n```\\n\\n\\n```python\\nlyft_engine = lyft_index.as_query_engine(similarity_top_k=3)\\nuber_engine = uber_index.as_query_engine(similarity_top_k=3)\\n```\\n\\n\\n```python\\nquery_engine_tools = [\\n    QueryEngineTool(\\n        query_engine=lyft_engine,\\n        metadata=ToolMetadata(\\n            name=\"lyft_10k\",\\n            description=(\\n                \"Provides information about Lyft financials for year 2021. \"\\n                \"Use a detailed plain text question as input to the tool.\"\\n            ),\\n        ),\\n    ),\\n    QueryEngineTool(\\n        query_engine=uber_engine,\\n        metadata=ToolMetadata(\\n            name=\"uber_10k\",\\n            description=(\\n                \"Provides information about Uber financials for year 2021. \"\\n                \"Use a detailed plain text question as input to the tool.\"\\n            ),\\n        ),\\n    ),\\n]\\n```\\n\\n## Setup OpenAI Agent\\n\\n\\n```python\\nfrom llama_index.agent import OpenAIAgent\\n```\\n\\n\\n```python\\nagent = OpenAIAgent.from_tools(query_engine_tools, verbose=True)\\n```\\n\\n## Let\\'s Try It Out!\\n\\n\\n```python\\nagent.chat_repl()\\n```\\n\\n    ===== Entering Chat REPL =====\\n    Type \"exit\" to exit.\\n    \\n    === Calling Function ===\\n    Calling function: lyft_10k with args: {\\n      \"input\": \"What was Lyft\\'s revenue growth in 2021?\"\\n    }\\n    Got output: \\n    Lyft\\'s revenue growth in 2021 was 36%.\\n    ========================\\n    === Calling Function ===\\n    Calling function: uber_10k with args: {\\n      \"input\": \"What was Uber\\'s revenue growth in 2021?\"\\n    }\\n    Got output: \\n    Uber\\'s revenue growth in 2021 was 57%.\\n    ========================\\n    Assistant: Lyft\\'s revenue growth in 2021 was 36%, while Uber\\'s revenue growth in 2021 was 57%.\\n    \\n    \\n', metadata={'source': '/mnt/c/Users/User/Documents/AI_ML/career_ai_engineer/Projects/ai_apps_assistant/llamaindex_docs/test_llamaindex.json', 'seq_num': 12, 'filename': 'openai_agent_with_query_engine.ipynb', 'filepath': 'docs/examples/agent/openai_agent_with_query_engine.ipynb', 'url': 'https://github.com/run-llama/llama_index/blob/3823389e3f91cab47b72e2cc2814826db9f98e32/docs/examples/agent/openai_agent_with_query_engine.ipynb'}),\n",
      " Document(page_content='# OpenAI Assistant Agent\\n<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/openai_assistant_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\\n\\nThis shows you how to use our agent abstractions built on top of the [OpenAI Assistant API](https://platform.openai.com/docs/assistants/overview).\\n\\n\\n\\n```python\\n!pip install llama-index\\n```\\n\\n## Simple Agent (no external tools)\\n\\nHere we show a simple example with the built-in code interpreter.\\n\\nLet\\'s start by importing some simple building blocks.  \\n\\nIf you\\'re opening this Notebook on colab, you will probably need to install LlamaIndex 🦙.\\n\\n\\n\\n```python\\nfrom llama_index.agent import OpenAIAssistantAgent\\n```\\n\\n\\n```python\\nagent = OpenAIAssistantAgent.from_new(\\n    name=\"Math Tutor\",\\n    instructions=\"You are a personal math tutor. Write and run code to answer math questions.\",\\n    openai_tools=[{\"type\": \"code_interpreter\"}],\\n    instructions_prefix=\"Please address the user as Jane Doe. The user has a premium account.\",\\n)\\n```\\n\\n\\n```python\\nagent.thread_id\\n```\\n\\n\\n\\n\\n    \\'thread_ctzN0ZY3JUWETHhYxI3DiFSo\\'\\n\\n\\n\\n\\n```python\\nresponse = agent.chat(\\n    \"I need to solve the equation `3x + 11 = 14`. Can you help me?\"\\n)\\n```\\n\\n\\n```python\\nprint(str(response))\\n```\\n\\n    The solution to the equation \\\\(3x + 11 = 14\\\\) is \\\\(x = 1\\\\).\\n    \\n\\n## Assistant with Built-In Retrieval\\n\\nLet\\'s test the assistant by having it use the built-in OpenAI Retrieval tool over a user-uploaded file.\\n\\nHere, we upload and pass in the file during assistant-creation time. \\n\\nThe other option is you can upload/pass the file-id in for a message in a given thread with `upload_files` and `add_message`.\\n\\n\\n```python\\nfrom llama_index.agent import OpenAIAssistantAgent\\n```\\n\\n\\n```python\\nagent = OpenAIAssistantAgent.from_new(\\n    name=\"SEC Analyst\",\\n    instructions=\"You are a QA assistant designed to analyze sec filings.\",\\n    openai_tools=[{\"type\": \"retrieval\"}],\\n    instructions_prefix=\"Please address the user as Jerry.\",\\n    files=[\"data/10k/lyft_2021.pdf\"],\\n    verbose=True,\\n)\\n```\\n\\n\\n```python\\nresponse = agent.chat(\"What was Lyft\\'s revenue growth in 2021?\")\\n```\\n\\n\\n```python\\nprint(str(response))\\n```\\n\\n    Lyft\\'s revenue increased by $843.6 million or 36% in 2021 as compared to the previous year【7†source】.\\n    \\n\\n## Assistant with Query Engine Tools\\n\\nHere we showcase the function calling capabilities of the OpenAIAssistantAgent by integrating it with our query engine tools over different documents.\\n\\n### 1. Setup: Load Data\\n\\n\\n```python\\nfrom llama_index.agent import OpenAIAssistantAgent\\nfrom llama_index import (\\n    SimpleDirectoryReader,\\n    VectorStoreIndex,\\n    StorageContext,\\n    load_index_from_storage,\\n)\\n\\nfrom llama_index.tools import QueryEngineTool, ToolMetadata\\n```\\n\\n\\n```python\\ntry:\\n    storage_context = StorageContext.from_defaults(\\n        persist_dir=\"./storage/lyft\"\\n    )\\n    lyft_index = load_index_from_storage(storage_context)\\n\\n    storage_context = StorageContext.from_defaults(\\n        persist_dir=\"./storage/uber\"\\n    )\\n    uber_index = load_index_from_storage(storage_context)\\n\\n    index_loaded = True\\nexcept:\\n    index_loaded = False\\n```\\n\\n\\n```python\\n!mkdir -p \\'data/10k/\\'\\n!wget \\'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10k/uber_2021.pdf\\' -O \\'data/10k/uber_2021.pdf\\'\\n!wget \\'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10k/lyft_2021.pdf\\' -O \\'data/10k/lyft_2021.pdf\\'\\n```\\n\\n    --2023-11-07 00:20:08--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10k/uber_2021.pdf\\n    Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8000::154, 2606:50c0:8001::154, 2606:50c0:8002::154, ...\\n    Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8000::154|:443... connected.\\n    HTTP request sent, awaiting response... 200 OK\\n    Length: 1880483 (1.8M) [application/octet-stream]\\n    Saving to: ‘data/10k/uber_2021.pdf’\\n    \\n    data/10k/uber_2021. 100%[===================>]   1.79M  --.-KB/s    in 0.07s   \\n    \\n    2023-11-07 00:20:08 (24.3 MB/s) - ‘data/10k/uber_2021.pdf’ saved [1880483/1880483]\\n    \\n    --2023-11-07 00:20:08--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10k/lyft_2021.pdf\\n    Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8000::154, 2606:50c0:8001::154, 2606:50c0:8002::154, ...\\n    Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8000::154|:443... connected.\\n    HTTP request sent, awaiting response... 200 OK\\n    Length: 1440303 (1.4M) [application/octet-stream]\\n    Saving to: ‘data/10k/lyft_2021.pdf’\\n    \\n    data/10k/lyft_2021. 100%[===================>]   1.37M  --.-KB/s    in 0.06s   \\n    \\n    2023-11-07 00:20:09 (22.2 MB/s) - ‘data/10k/lyft_2021.pdf’ saved [1440303/1440303]\\n    \\n    \\n\\n\\n```python\\nif not index_loaded:\\n    # load data\\n    lyft_docs = SimpleDirectoryReader(\\n        input_files=[\"./data/10k/lyft_2021.pdf\"]\\n    ).load_data()\\n    uber_docs = SimpleDirectoryReader(\\n        input_files=[\"./data/10k/uber_2021.pdf\"]\\n    ).load_data()\\n\\n    # build index\\n    lyft_index = VectorStoreIndex.from_documents(lyft_docs)\\n    uber_index = VectorStoreIndex.from_documents(uber_docs)\\n\\n    # persist index\\n    lyft_index.storage_context.persist(persist_dir=\"./storage/lyft\")\\n    uber_index.storage_context.persist(persist_dir=\"./storage/uber\")\\n```\\n\\n\\n```python\\nlyft_engine = lyft_index.as_query_engine(similarity_top_k=3)\\nuber_engine = uber_index.as_query_engine(similarity_top_k=3)\\n```\\n\\n\\n```python\\nquery_engine_tools = [\\n    QueryEngineTool(\\n        query_engine=lyft_engine,\\n        metadata=ToolMetadata(\\n            name=\"lyft_10k\",\\n            description=(\\n                \"Provides information about Lyft financials for year 2021. \"\\n                \"Use a detailed plain text question as input to the tool.\"\\n            ),\\n        ),\\n    ),\\n    QueryEngineTool(\\n        query_engine=uber_engine,\\n        metadata=ToolMetadata(\\n            name=\"uber_10k\",\\n            description=(\\n                \"Provides information about Uber financials for year 2021. \"\\n                \"Use a detailed plain text question as input to the tool.\"\\n            ),\\n        ),\\n    ),\\n]\\n```\\n\\n### 2. Let\\'s Try it Out\\n\\n\\n```python\\nagent = OpenAIAssistantAgent.from_new(\\n    name=\"SEC Analyst\",\\n    instructions=\"You are a QA assistant designed to analyze sec filings.\",\\n    tools=query_engine_tools,\\n    instructions_prefix=\"Please address the user as Jerry.\",\\n    verbose=True,\\n    run_retrieve_sleep_time=1.0,\\n)\\n```\\n\\n\\n```python\\nresponse = agent.chat(\"What was Lyft\\'s revenue growth in 2021?\")\\n```\\n\\n    === Calling Function ===\\n    Calling function: lyft_10k with args: {\"input\":\"What was Lyft\\'s revenue growth in 2021?\"}\\n    Got output: Lyft\\'s revenue growth in 2021 was 36%.\\n    ========================\\n    \\n\\n## Assistant Agent with your own Vector Store / Retrieval API\\n\\nLlamaIndex has 35+ vector database integrations. Instead of using the in-house Retrieval API, you can use our assistant agent over any vector store.\\n\\nHere is our full [list of vector store integrations](https://docs.llamaindex.ai/en/stable/module_guides/storing/vector_stores.html). We picked one vector store (Supabase) using a random number generator.\\n\\n\\n```python\\nfrom llama_index.agent import OpenAIAssistantAgent\\nfrom llama_index import (\\n    SimpleDirectoryReader,\\n    VectorStoreIndex,\\n    StorageContext,\\n)\\nfrom llama_index.vector_stores import SupabaseVectorStore\\n\\nfrom llama_index.tools import QueryEngineTool, ToolMetadata\\n```\\n\\n\\n```python\\n!mkdir -p \\'data/10k/\\'\\n!wget \\'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10k/uber_2021.pdf\\' -O \\'data/10k/uber_2021.pdf\\'\\n!wget \\'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10k/lyft_2021.pdf\\' -O \\'data/10k/lyft_2021.pdf\\'\\n```\\n\\n\\n```python\\n# load data\\nreader = SimpleDirectoryReader(input_files=[\"./data/10k/lyft_2021.pdf\"])\\ndocs = reader.load_data()\\nfor doc in docs:\\n    doc.id_ = \"lyft_docs\"\\n```\\n\\n\\n```python\\nvector_store = SupabaseVectorStore(\\n    postgres_connection_string=(\\n        \"postgresql://<user>:<password>@<host>:<port>/<db_name>\"\\n    ),\\n    collection_name=\"base_demo\",\\n)\\nstorage_context = StorageContext.from_defaults(vector_store=vector_store)\\nindex = VectorStoreIndex.from_documents(docs, storage_context=storage_context)\\n```\\n\\n\\n```python\\n# sanity check that the docs are in the vector store\\nnum_docs = vector_store.get_by_id(\"lyft_docs\", limit=1000)\\nprint(len(num_docs))\\n```\\n\\n    /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages/vecs/collection.py:445: UserWarning: Query does not have a covering index for cosine_distance. See Collection.create_index\\n      warnings.warn(\\n    \\n\\n    357\\n    \\n\\n\\n```python\\nlyft_tool = QueryEngineTool(\\n    query_engine=index.as_query_engine(similarity_top_k=3),\\n    metadata=ToolMetadata(\\n        name=\"lyft_10k\",\\n        description=(\\n            \"Provides information about Lyft financials for year 2021. \"\\n            \"Use a detailed plain text question as input to the tool.\"\\n        ),\\n    ),\\n)\\n```\\n\\n\\n```python\\nagent = OpenAIAssistantAgent.from_new(\\n    name=\"SEC Analyst\",\\n    instructions=\"You are a QA assistant designed to analyze SEC filings.\",\\n    tools=[lyft_tool],\\n    verbose=True,\\n    run_retrieve_sleep_time=1.0,\\n)\\n```\\n\\n\\n```python\\nresponse = agent.chat(\\n    \"Tell me about Lyft\\'s risk factors, as well as response to COVID-19\"\\n)\\n```\\n\\n    === Calling Function ===\\n    Calling function: lyft_10k with args: {\"input\": \"What are Lyft\\'s risk factors?\"}\\n    \\n\\n    /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages/vecs/collection.py:445: UserWarning: Query does not have a covering index for cosine_distance. See Collection.create_index\\n      warnings.warn(\\n    \\n\\n    Got output: Lyft\\'s risk factors include general economic factors, such as the impact of the COVID-19 pandemic and responsive measures, natural disasters, economic downturns, public health crises, or political crises. Operational factors, such as their limited operating history, financial performance, competition, unpredictability of results, uncertainty regarding market growth, ability to attract and retain qualified drivers and riders, insurance coverage, autonomous vehicle technology, reputation and brand, illegal or improper activity on the platform, accuracy of background checks, changes to pricing practices, growth and development of their network, ability to manage growth, security or privacy breaches, reliance on third parties, and ability to operate various programs and services.\\n    ========================\\n    === Calling Function ===\\n    Calling function: lyft_10k with args: {\"input\": \"How did Lyft respond to COVID-19?\"}\\n    \\n\\n    /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages/vecs/collection.py:445: UserWarning: Query does not have a covering index for cosine_distance. See Collection.create_index\\n      warnings.warn(\\n    \\n\\n    Got output: Lyft responded to COVID-19 by adopting multiple measures, including establishing new health and safety requirements for ridesharing and updating workplace policies. They also made adjustments to their expenses and cash flow to correlate with declines in revenues, which included headcount reductions in 2020. Additionally, Lyft temporarily reduced pricing for Flexdrive rentals in cities most affected by COVID-19 and waived rental fees for drivers who tested positive for COVID-19 or were requested to quarantine by a medical professional. These measures were implemented to mitigate the negative effects of the pandemic on their business.\\n    ========================\\n    \\n\\n\\n```python\\nprint(str(response))\\n```\\n\\n    Lyft\\'s 2021 10-K filing outlines a multifaceted risk landscape for the company, encapsulating both operational and environmental challenges that could impact its business model:\\n    \\n    - **Economic Factors**: Risks include the ramifications of the COVID-19 pandemic, susceptibility to natural disasters, the volatility of economic downturns, and geopolitical tensions.\\n    \\n    - **Operational Dynamics**: The company is cognizant of its limited operating history, the uncertainties surrounding its financial performance, the intense competition in the ridesharing sector, the unpredictability in financial results, and the ambiguity tied to the expansion potential of the rideshare market.\\n    \\n    - **Human Capital**: A critical concern is the ability of Lyft to attract and maintain a robust network of both drivers and riders, which is essential for the platform\\'s vitality.\\n    \\n    - **Insurance and Safety**: Ensuring adequate insurance coverage for stakeholders and addressing autonomous vehicle technology risks are pivotal.\\n    \\n    - **Reputation and Brand**: Lyft is attentive to the influence that illegal or unseemly activities on its platform can have on its public image.\\n    \\n    - **Pricing Structure**: Changing pricing models pose a risk to Lyft\\'s revenue streams, considering how essential pricing dynamics are to maintaining competitive service offerings.\\n    \\n    - **Systemic Integrity**: Lyft also acknowledges risks emanating from potential system failures which could disrupt service continuity.\\n    \\n    Furthermore, Lyft is vigilant about regulatory and legal risks that could lead to litigation and is conscious of the broader implications of climate change on its operations.\\n    \\n    In terms of its response to COVID-19, Lyft has adopted strategic measures to secure the welfare of both its workforce and customer base:\\n    \\n    1. **Health and Safety Protocols**: Lyft has instituted health and safety mandates tailored specifically to the ridesharing experience in view of the pandemic.\\n    \\n    2. **Workplace Adjustments**: The company revised its workplace policies to accommodate the shifts in the work environment precipitated by the pandemic.\\n    \\n    3. **Financial Adaptations**: To synchronize with the revenue contraction experienced during the pandemic, Lyft executed monetary realignments, which necessitated workforce reductions in 2020.\\n    \\n    These initiatives reflect Lyft\\'s calculated approach to navigating the operational and financial hurdles enacted by the COVID-19 pandemic. By prioritizing health and safety, nimbly altering corporate practices, and recalibrating fiscal management, Lyft aimed to buttress its business against the storm of the pandemic while setting a foundation for post-pandemic recovery.\\n    \\n', metadata={'source': '/mnt/c/Users/User/Documents/AI_ML/career_ai_engineer/Projects/ai_apps_assistant/llamaindex_docs/test_llamaindex.json', 'seq_num': 13, 'filename': 'openai_assistant_agent.ipynb', 'filepath': 'docs/examples/agent/openai_assistant_agent.ipynb', 'url': 'https://github.com/run-llama/llama_index/blob/3823389e3f91cab47b72e2cc2814826db9f98e32/docs/examples/agent/openai_assistant_agent.ipynb'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/openai_assistant_query_cookbook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\\n\\n# OpenAI Assistant Advanced Retrieval Cookbook\\n\\n\\nIn this notebook, we try out OpenAI Assistant API for advanced retrieval tasks, by plugging in a variety of query engine tools and datasets. The wrapper abstraction we use is our `OpenAIAssistantAgent` class, which allows us to plug in custom tools. We explore how `OpenAIAssistant` can complement/replace existing workflows solved by our retrievers/query engines through its agent execution + function calling loop.\\n\\n- Joint QA + Summarization\\n- Auto retrieval \\n- Joint SQL and vector search\\n\\n\\n```python\\n!pip install llama-index\\n```\\n\\n\\n```python\\nimport nest_asyncio\\n\\nnest_asyncio.apply()\\n```\\n\\n## Joint QA and Summarization\\n\\nIn this section we show how we can get the Assistant agent to both answer fact-based questions and summarization questions. This is something that the in-house retrieval tool struggles to accomplish.\\n\\n### Load Data\\n\\n\\n```python\\n!mkdir -p \\'data/paul_graham/\\'\\n!wget \\'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt\\' -O \\'data/paul_graham/paul_graham_essay.txt\\'\\n```\\n\\n    --2023-11-11 09:40:13--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt\\n    Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8002::154, 2606:50c0:8003::154, 2606:50c0:8000::154, ...\\n    Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8002::154|:443... connected.\\n    HTTP request sent, awaiting response... 200 OK\\n    Length: 75042 (73K) [text/plain]\\n    Saving to: ‘data/paul_graham/paul_graham_essay.txt’\\n    \\n    data/paul_graham/pa 100%[===================>]  73.28K  --.-KB/s    in 0.009s  \\n    \\n    2023-11-11 09:40:14 (8.24 MB/s) - ‘data/paul_graham/paul_graham_essay.txt’ saved [75042/75042]\\n    \\n    \\n\\n\\n```python\\nfrom llama_index import SimpleDirectoryReader\\n\\n# load documents\\ndocuments = SimpleDirectoryReader(\"./data/paul_graham/\").load_data()\\n```\\n\\n### Setup Vector + Summary Indexes/Query Engines/Tools\\n\\n\\n```python\\nfrom llama_index.llms import OpenAI\\nfrom llama_index import (\\n    ServiceContext,\\n    StorageContext,\\n    SummaryIndex,\\n    VectorStoreIndex,\\n)\\n\\n# initialize service context (set chunk size)\\nllm = OpenAI()\\nservice_context = ServiceContext.from_defaults(chunk_size=1024, llm=llm)\\nnodes = service_context.node_parser.get_nodes_from_documents(documents)\\n\\n# initialize storage context (by default it\\'s in-memory)\\nstorage_context = StorageContext.from_defaults()\\nstorage_context.docstore.add_documents(nodes)\\n\\n# Define Summary Index and Vector Index over Same Data\\nsummary_index = SummaryIndex(nodes, storage_context=storage_context)\\nvector_index = VectorStoreIndex(nodes, storage_context=storage_context)\\n\\n# define query engines\\nsummary_query_engine = summary_index.as_query_engine(\\n    response_mode=\"tree_summarize\",\\n    use_async=True,\\n)\\nvector_query_engine = vector_index.as_query_engine()\\n```\\n\\n\\n```python\\nfrom llama_index.tools.query_engine import QueryEngineTool\\n\\nsummary_tool = QueryEngineTool.from_defaults(\\n    query_engine=summary_query_engine,\\n    name=\"summary_tool\",\\n    description=(\\n        \"Useful for summarization questions related to the author\\'s life\"\\n    ),\\n)\\n\\nvector_tool = QueryEngineTool.from_defaults(\\n    query_engine=vector_query_engine,\\n    name=\"vector_tool\",\\n    description=(\\n        \"Useful for retrieving specific context to answer specific questions about the author\\'s life\"\\n    ),\\n)\\n```\\n\\n### Define Assistant Agent\\n\\n\\n```python\\nfrom llama_index.agent import OpenAIAssistantAgent\\n\\nagent = OpenAIAssistantAgent.from_new(\\n    name=\"QA bot\",\\n    instructions=\"You are a bot designed to answer questions about the author\",\\n    openai_tools=[],\\n    tools=[summary_tool, vector_tool],\\n    verbose=True,\\n    run_retrieve_sleep_time=1.0,\\n)\\n```\\n\\n#### Results: A bit flaky\\n\\n\\n```python\\nresponse = agent.chat(\"Can you give me a summary about the author\\'s life?\")\\nprint(str(response))\\n```\\n\\n    === Calling Function ===\\n    Calling function: summary_tool with args: {\"input\":\"Can you give me a summary about the author\\'s life?\"}\\n    Got output: The author, Paul Graham, had a strong interest in writing and programming from a young age. They started writing short stories and experimenting with programming in high school. In college, they initially studied philosophy but switched to studying artificial intelligence. However, they realized that the AI being practiced at the time was not going to lead to true understanding of natural language. This led them to focus on Lisp programming and eventually write a book about Lisp hacking. Despite being in a PhD program in computer science, the author also developed a passion for art and decided to pursue it further. They attended the Accademia di Belli Arti in Florence but found that it did not teach them much. They then returned to the US and got a job at a software company. Afterward, they attended the Rhode Island School of Design but dropped out due to the focus on developing a signature style rather than teaching the fundamentals of art. They then moved to New York City and became interested in the World Wide Web, eventually starting a company called Viaweb. They later founded Y Combinator, an investment firm, and created Hacker News.\\n    ========================\\n    Paul Graham is an author with eclectic interests and a varied career path. He began with interests in writing and programming, engaged in philosophy and artificial intelligence during college, and authored a book on Lisp programming. With an equally strong passion for art, he studied at the Accademia di Belli Arti in Florence and briefly at the Rhode Island School of Design before immersing himself in the tech industry by starting Viaweb and later founding the influential startup accelerator Y Combinator. He also created Hacker News, a social news website focused on computer science and entrepreneurship. Graham\\'s life reflects a blend of technology, entrepreneurship, and the arts.\\n    \\n\\n\\n```python\\nresponse = agent.query(\"What did the author do after RICS?\")\\nprint(str(response))\\n```\\n\\n    === Calling Function ===\\n    Calling function: vector_tool with args: {\"input\":\"After RICS\"}\\n    Got output: After RICS, the author moved back to Providence to continue at RISD. However, it became clear that art school, specifically the painting department, did not have the same relationship to art as medical school had to medicine. Painting students were expected to express themselves and develop a distinctive signature style.\\n    ========================\\n    After the author\\'s time at the Royal Institution of Chartered Surveyors (RICS), they moved back to Providence to continue their studies at the Rhode Island School of Design (RISD). There, the author noted a significant difference in the educational approaches between RISD and medical school, specifically in the painting department. At RISD, students were encouraged to express themselves and to develop a unique and distinctive signature style in their artwork.\\n    \\n\\n## AutoRetrieval from a Vector Database\\n\\nOur existing \"auto-retrieval\" capabilities (in `VectorIndexAutoRetriever`) allow an LLM to infer the right query parameters for a vector database - including both the query string and metadata filter.\\n\\nSince the Assistant API can call functions + infer function parameters, we explore its capabilities in performing auto-retrieval here.\\n\\nIf you\\'re opening this Notebook on colab, you will probably need to install LlamaIndex 🦙.\\n\\n\\n```python\\nimport pinecone\\nimport os\\n\\napi_key = os.environ[\"PINECONE_API_KEY\"]\\npinecone.init(api_key=api_key, environment=\"us-west1-gcp\")\\n```\\n\\n    /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\\n      from tqdm.autonotebook import tqdm\\n    \\n\\n\\n```python\\n# dimensions are for text-embedding-ada-002\\ntry:\\n    pinecone.create_index(\\n        \"quickstart\", dimension=1536, metric=\"euclidean\", pod_type=\"p1\"\\n    )\\nexcept Exception:\\n    # most likely index already exists\\n    pass\\n```\\n\\n\\n```python\\npinecone_index = pinecone.Index(\"quickstart\")\\n```\\n\\n\\n```python\\n# Optional: delete data in your pinecone index\\npinecone_index.delete(deleteAll=True, namespace=\"test\")\\n```\\n\\n\\n\\n\\n    {}\\n\\n\\n\\n\\n```python\\nfrom llama_index import VectorStoreIndex, StorageContext\\nfrom llama_index.vector_stores import PineconeVectorStore\\n```\\n\\n\\n```python\\nfrom llama_index.schema import TextNode\\n\\nnodes = [\\n    TextNode(\\n        text=(\\n            \"Michael Jordan is a retired professional basketball player,\"\\n            \" widely regarded as one of the greatest basketball players of all\"\\n            \" time.\"\\n        ),\\n        metadata={\\n            \"category\": \"Sports\",\\n            \"country\": \"United States\",\\n        },\\n    ),\\n    TextNode(\\n        text=(\\n            \"Angelina Jolie is an American actress, filmmaker, and\"\\n            \" humanitarian. She has received numerous awards for her acting\"\\n            \" and is known for her philanthropic work.\"\\n        ),\\n        metadata={\\n            \"category\": \"Entertainment\",\\n            \"country\": \"United States\",\\n        },\\n    ),\\n    TextNode(\\n        text=(\\n            \"Elon Musk is a business magnate, industrial designer, and\"\\n            \" engineer. He is the founder, CEO, and lead designer of SpaceX,\"\\n            \" Tesla, Inc., Neuralink, and The Boring Company.\"\\n        ),\\n        metadata={\\n            \"category\": \"Business\",\\n            \"country\": \"United States\",\\n        },\\n    ),\\n    TextNode(\\n        text=(\\n            \"Rihanna is a Barbadian singer, actress, and businesswoman. She\"\\n            \" has achieved significant success in the music industry and is\"\\n            \" known for her versatile musical style.\"\\n        ),\\n        metadata={\\n            \"category\": \"Music\",\\n            \"country\": \"Barbados\",\\n        },\\n    ),\\n    TextNode(\\n        text=(\\n            \"Cristiano Ronaldo is a Portuguese professional footballer who is\"\\n            \" considered one of the greatest football players of all time. He\"\\n            \" has won numerous awards and set multiple records during his\"\\n            \" career.\"\\n        ),\\n        metadata={\\n            \"category\": \"Sports\",\\n            \"country\": \"Portugal\",\\n        },\\n    ),\\n]\\n```\\n\\n\\n```python\\nvector_store = PineconeVectorStore(\\n    pinecone_index=pinecone_index, namespace=\"test\"\\n)\\nstorage_context = StorageContext.from_defaults(vector_store=vector_store)\\n```\\n\\n\\n```python\\nindex = VectorStoreIndex(nodes, storage_context=storage_context)\\n```\\n\\n\\n    Upserted vectors:   0%|          | 0/5 [00:00<?, ?it/s]\\n\\n\\n#### Define Function Tool\\n\\nHere we define the function interface, which is passed to OpenAI to perform auto-retrieval.\\n\\nWe were not able to get OpenAI to work with nested pydantic objects or tuples as arguments,\\nso we converted the metadata filter keys and values into lists for the function API to work with.\\n\\n\\n```python\\n# define function tool\\nfrom llama_index.tools import FunctionTool\\nfrom llama_index.vector_stores.types import (\\n    VectorStoreInfo,\\n    MetadataInfo,\\n    ExactMatchFilter,\\n    MetadataFilters,\\n)\\nfrom llama_index.retrievers import VectorIndexRetriever\\nfrom llama_index.query_engine import RetrieverQueryEngine\\n\\nfrom typing import List, Tuple, Any\\nfrom pydantic import BaseModel, Field\\n\\n# hardcode top k for now\\ntop_k = 3\\n\\n# define vector store info describing schema of vector store\\nvector_store_info = VectorStoreInfo(\\n    content_info=\"brief biography of celebrities\",\\n    metadata_info=[\\n        MetadataInfo(\\n            name=\"category\",\\n            type=\"str\",\\n            description=(\\n                \"Category of the celebrity, one of [Sports, Entertainment,\"\\n                \" Business, Music]\"\\n            ),\\n        ),\\n        MetadataInfo(\\n            name=\"country\",\\n            type=\"str\",\\n            description=(\\n                \"Country of the celebrity, one of [United States, Barbados,\"\\n                \" Portugal]\"\\n            ),\\n        ),\\n    ],\\n)\\n\\n\\n# define pydantic model for auto-retrieval function\\nclass AutoRetrieveModel(BaseModel):\\n    query: str = Field(..., description=\"natural language query string\")\\n    filter_key_list: List[str] = Field(\\n        ..., description=\"List of metadata filter field names\"\\n    )\\n    filter_value_list: List[str] = Field(\\n        ...,\\n        description=(\\n            \"List of metadata filter field values (corresponding to names\"\\n            \" specified in filter_key_list)\"\\n        ),\\n    )\\n\\n\\ndef auto_retrieve_fn(\\n    query: str, filter_key_list: List[str], filter_value_list: List[str]\\n):\\n    \"\"\"Auto retrieval function.\\n\\n    Performs auto-retrieval from a vector database, and then applies a set of filters.\\n\\n    \"\"\"\\n    query = query or \"Query\"\\n\\n    exact_match_filters = [\\n        ExactMatchFilter(key=k, value=v)\\n        for k, v in zip(filter_key_list, filter_value_list)\\n    ]\\n    retriever = VectorIndexRetriever(\\n        index,\\n        filters=MetadataFilters(filters=exact_match_filters),\\n        top_k=top_k,\\n    )\\n    results = retriever.retrieve(query)\\n    return [r.get_content() for r in results]\\n\\n\\ndescription = f\"\"\"\\\\\\nUse this tool to look up biographical information about celebrities.\\nThe vector database schema is given below:\\n{vector_store_info.json()}\\n\"\"\"\\n\\nauto_retrieve_tool = FunctionTool.from_defaults(\\n    fn=auto_retrieve_fn,\\n    name=\"celebrity_bios\",\\n    description=description,\\n    fn_schema=AutoRetrieveModel,\\n)\\n```\\n\\n\\n```python\\nauto_retrieve_fn(\\n    \"celebrity from the United States\",\\n    filter_key_list=[\"country\"],\\n    filter_value_list=[\"United States\"],\\n)\\n```\\n\\n\\n\\n\\n    [\\'Angelina Jolie is an American actress, filmmaker, and humanitarian. She has received numerous awards for her acting and is known for her philanthropic work.\\',\\n     \\'Michael Jordan is a retired professional basketball player, widely regarded as one of the greatest basketball players of all time.\\']\\n\\n\\n\\n#### Initialize Agent\\n\\n\\n```python\\nfrom llama_index.agent import OpenAIAssistantAgent\\n\\nagent = OpenAIAssistantAgent.from_new(\\n    name=\"Celebrity bot\",\\n    instructions=\"You are a bot designed to answer questions about celebrities.\",\\n    tools=[auto_retrieve_tool],\\n    verbose=True,\\n)\\n```\\n\\n\\n```python\\nresponse = agent.chat(\"Tell me about two celebrities from the United States. \")\\nprint(str(response))\\n```\\n\\n    === Calling Function ===\\n    Calling function: celebrity_bios with args: {\"query\": \"celebrity from United States\", \"filter_key_list\": [\"country\"], \"filter_value_list\": [\"United States\"]}\\n    Got output: [\\'Angelina Jolie is an American actress, filmmaker, and humanitarian. She has received numerous awards for her acting and is known for her philanthropic work.\\', \\'Michael Jordan is a retired professional basketball player, widely regarded as one of the greatest basketball players of all time.\\']\\n    ========================\\n    === Calling Function ===\\n    Calling function: celebrity_bios with args: {\"query\": \"celebrity from United States\", \"filter_key_list\": [\"country\"], \"filter_value_list\": [\"United States\"]}\\n    Got output: [\\'Angelina Jolie is an American actress, filmmaker, and humanitarian. She has received numerous awards for her acting and is known for her philanthropic work.\\', \\'Michael Jordan is a retired professional basketball player, widely regarded as one of the greatest basketball players of all time.\\']\\n    ========================\\n    Here is some information about two celebrities from the United States:\\n    \\n    1. Angelina Jolie - Angelina Jolie is an American actress, filmmaker, and humanitarian. She has received numerous awards for her acting and is known for her philanthropic work. Over the years, Jolie has starred in several critically acclaimed and commercially successful films, and she has also been involved in various humanitarian causes, advocating for refugees and children\\'s education, among other things.\\n    \\n    2. Michael Jordan - Michael Jordan is a retired professional basketball player, widely regarded as one of the greatest basketball players of all time. During his career, Jordan dominated the NBA with his scoring ability, athleticism, and competitiveness. He won six NBA championships with the Chicago Bulls and earned the NBA Most Valuable Player Award five times. Jordan has also been a successful businessman and the principal owner of the Charlotte Hornets basketball team.\\n    \\n    Both figures have made significant impacts in their respective fields and continue to be influential even after reaching the peaks of their careers.\\n    \\n\\n## Joint Text-to-SQL and Semantic Search\\n\\nThis is currenty handled by our `SQLAutoVectorQueryEngine`.\\n\\nLet\\'s try implementing this by giving our `OpenAIAssistantAgent` access to two query tools: SQL and Vector search.\\n\\n#### Load and Index Structured Data\\n\\nWe load sample structured datapoints into a SQL db and index it.\\n\\n\\n```python\\nfrom sqlalchemy import (\\n    create_engine,\\n    MetaData,\\n    Table,\\n    Column,\\n    String,\\n    Integer,\\n    select,\\n    column,\\n)\\nfrom llama_index import SQLDatabase, SQLStructStoreIndex\\n\\nengine = create_engine(\"sqlite:///:memory:\", future=True)\\nmetadata_obj = MetaData()\\n```\\n\\n\\n```python\\n# create city SQL table\\ntable_name = \"city_stats\"\\ncity_stats_table = Table(\\n    table_name,\\n    metadata_obj,\\n    Column(\"city_name\", String(16), primary_key=True),\\n    Column(\"population\", Integer),\\n    Column(\"country\", String(16), nullable=False),\\n)\\n\\nmetadata_obj.create_all(engine)\\n```\\n\\n\\n```python\\n# print tables\\nmetadata_obj.tables.keys()\\n```\\n\\n\\n\\n\\n    dict_keys([\\'city_stats\\'])\\n\\n\\n\\n\\n```python\\nfrom sqlalchemy import insert\\n\\nrows = [\\n    {\"city_name\": \"Toronto\", \"population\": 2930000, \"country\": \"Canada\"},\\n    {\"city_name\": \"Tokyo\", \"population\": 13960000, \"country\": \"Japan\"},\\n    {\"city_name\": \"Berlin\", \"population\": 3645000, \"country\": \"Germany\"},\\n]\\nfor row in rows:\\n    stmt = insert(city_stats_table).values(**row)\\n    with engine.begin() as connection:\\n        cursor = connection.execute(stmt)\\n```\\n\\n\\n```python\\nwith engine.connect() as connection:\\n    cursor = connection.exec_driver_sql(\"SELECT * FROM city_stats\")\\n    print(cursor.fetchall())\\n```\\n\\n    [(\\'Toronto\\', 2930000, \\'Canada\\'), (\\'Tokyo\\', 13960000, \\'Japan\\'), (\\'Berlin\\', 3645000, \\'Germany\\')]\\n    \\n\\n\\n```python\\nsql_database = SQLDatabase(engine, include_tables=[\"city_stats\"])\\n```\\n\\n\\n```python\\nfrom llama_index.indices.struct_store.sql_query import NLSQLTableQueryEngine\\n```\\n\\n\\n```python\\nquery_engine = NLSQLTableQueryEngine(\\n    sql_database=sql_database,\\n    tables=[\"city_stats\"],\\n)\\n```\\n\\n#### Load and Index Unstructured Data\\n\\nWe load unstructured data into a vector index backed by Pinecone\\n\\n\\n```python\\n# install wikipedia python package\\n!pip install wikipedia\\n```\\n\\n    Requirement already satisfied: wikipedia in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (1.4.0)\\n    Requirement already satisfied: requests<3.0.0,>=2.0.0 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from wikipedia) (2.28.2)\\n    Requirement already satisfied: beautifulsoup4 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from wikipedia) (4.12.2)\\n    Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.1.0)\\n    Requirement already satisfied: idna<4,>=2.5 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4)\\n    Requirement already satisfied: certifi>=2017.4.17 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2022.12.7)\\n    Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.26.15)\\n    Requirement already satisfied: soupsieve>1.2 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from beautifulsoup4->wikipedia) (2.4.1)\\n    \\n    \\x1b[1m[\\x1b[0m\\x1b[34;49mnotice\\x1b[0m\\x1b[1;39;49m]\\x1b[0m\\x1b[39;49m A new release of pip available: \\x1b[0m\\x1b[31;49m22.3.1\\x1b[0m\\x1b[39;49m -> \\x1b[0m\\x1b[32;49m23.1.2\\x1b[0m\\n    \\x1b[1m[\\x1b[0m\\x1b[34;49mnotice\\x1b[0m\\x1b[1;39;49m]\\x1b[0m\\x1b[39;49m To update, run: \\x1b[0m\\x1b[32;49mpip install --upgrade pip\\x1b[0m\\n    \\n\\n\\n```python\\nfrom llama_index import (\\n    WikipediaReader,\\n    SimpleDirectoryReader,\\n    VectorStoreIndex,\\n)\\n```\\n\\n\\n```python\\ncities = [\"Toronto\", \"Berlin\", \"Tokyo\"]\\nwiki_docs = WikipediaReader().load_data(pages=cities)\\n```\\n\\n\\n```python\\nfrom llama_index.node_parser import SimpleNodeParser\\nfrom llama_index import ServiceContext\\nfrom llama_index.storage import StorageContext\\nfrom llama_index.text_splitter import TokenTextSplitter\\nfrom llama_index.llms import OpenAI\\n\\n# define node parser and LLM\\nchunk_size = 1024\\nllm = OpenAI(temperature=0, model=\"gpt-4\")\\nservice_context = ServiceContext.from_defaults(chunk_size=chunk_size, llm=llm)\\ntext_splitter = TokenTextSplitter(chunk_size=chunk_size)\\nnode_parser = SimpleNodeParser.from_defaults(text_splitter=text_splitter)\\n\\n# use default in-memory store\\nstorage_context = StorageContext.from_defaults()\\nvector_index = VectorStoreIndex([], storage_context=storage_context)\\n```\\n\\n\\n```python\\n# Insert documents into vector index\\n# Each document has metadata of the city attached\\nfor city, wiki_doc in zip(cities, wiki_docs):\\n    nodes = node_parser.get_nodes_from_documents([wiki_doc])\\n    # add metadata to each node\\n    for node in nodes:\\n        node.metadata = {\"title\": city}\\n    vector_index.insert_nodes(nodes)\\n```\\n\\n#### Define Query Engines / Tools\\n\\n\\n```python\\nfrom llama_index.tools.query_engine import QueryEngineTool\\n```\\n\\n\\n```python\\nsql_tool = QueryEngineTool.from_defaults(\\n    query_engine=query_engine,\\n    name=\"sql_tool\",\\n    description=(\\n        \"Useful for translating a natural language query into a SQL query over\"\\n        \" a table containing: city_stats, containing the population/country of\"\\n        \" each city\"\\n    ),\\n)\\nvector_tool = QueryEngineTool.from_defaults(\\n    query_engine=vector_index.as_query_engine(similarity_top_k=2),\\n    name=\"vector_tool\",\\n    description=(\\n        f\"Useful for answering semantic questions about different cities\"\\n    ),\\n)\\n```\\n\\n#### Initialize Agent\\n\\n\\n```python\\nfrom llama_index.agent import OpenAIAssistantAgent\\n\\nagent = OpenAIAssistantAgent.from_new(\\n    name=\"City bot\",\\n    instructions=\"You are a bot designed to answer questions about cities (both unstructured and structured data)\",\\n    tools=[sql_tool, vector_tool],\\n    verbose=True,\\n)\\n```\\n\\n\\n```python\\nresponse = agent.chat(\\n    \"Tell me about the arts and culture of the city with the highest\"\\n    \" population\"\\n)\\nprint(str(response))\\n```\\n\\n    === Calling Function ===\\n    Calling function: sql_tool with args: {\"input\":\"SELECT name, country FROM city_stats ORDER BY population DESC LIMIT 1\"}\\n    Got output: The city with the highest population is Tokyo, Japan.\\n    ========================\\n    === Calling Function ===\\n    Calling function: vector_tool with args: {\"input\":\"What are the arts and culture like in Tokyo, Japan?\"}\\n    Got output: Tokyo has a vibrant arts and culture scene. The city is home to many museums, including the Tokyo National Museum, which specializes in traditional Japanese art, the National Museum of Western Art, and the Edo-Tokyo Museum. There are also theaters for traditional forms of Japanese drama, such as the National Noh Theatre and the Kabuki-za. Tokyo hosts modern Japanese and international pop and rock music concerts, and the New National Theater Tokyo is a hub for opera, ballet, contemporary dance, and drama. The city also celebrates various festivals throughout the year, including the Sannō, Sanja, and Kanda Festivals. Additionally, Tokyo is known for its youth style, fashion, and cosplay in the Harajuku neighborhood.\\n    ========================\\n    Tokyo, Japan, which has the highest population of any city, boasts a rich and diverse arts and culture landscape. The city is a hub for traditional Japanese art as showcased in prominent institutions like the Tokyo National Museum, and it also features artwork from different parts of the world at the National Museum of Western Art. Tokyo has a deep appreciation for its historical roots, with the Edo-Tokyo Museum presenting the past in a detailed and engaging manner.\\n    \\n    The traditional performing arts have a significant presence in Tokyo, with theaters such as the National Noh Theatre presenting classical Noh dramas and the iconic Kabuki-za offering enchanting Kabuki performances. For enthusiasts of modern entertainment, Tokyo is a prime spot for contemporary music, including both Japanese pop and rock as well as international acts.\\n    \\n    Opera, ballet, contemporary dance, and drama find a prestigious platform at the New National Theater Tokyo. Tokyo\\'s calendar is filled with a variety of festivals that reflect the city\\'s vibrant cultural heritage, including the Sannō, Sanja, and Kanda Festivals. Additionally, Tokyo is at the forefront of fashion and youth culture, particularly in the Harajuku district, which is famous for its unique fashion, style, and cosplay.\\n    \\n    This mix of traditional and modern, local and international arts and culture makes Tokyo a dynamic and culturally rich city.\\n    \\n\\n\\n```python\\nresponse = agent.chat(\"Tell me about the history of Berlin\")\\nprint(str(response))\\n```\\n\\n    === Calling Function ===\\n    Calling function: vector_tool with args: {\"input\":\"What is the history of Berlin, Germany?\"}\\n    Got output: Berlin has a rich and diverse history. It was first documented in the 13th century and has served as the capital of various entities throughout history, including the Margraviate of Brandenburg, the Kingdom of Prussia, the German Empire, the Weimar Republic, and Nazi Germany. After World War II, the city was divided, with West Berlin becoming a part of West Germany and East Berlin becoming the capital of East Germany. Following German reunification in 1990, Berlin once again became the capital of all of Germany. Throughout its history, Berlin has been a center of scientific, artistic, and philosophical activity, and has experienced periods of economic growth and cultural flourishing. Today, it is a world city of culture, politics, media, and science, known for its vibrant arts scene, diverse architecture, and high quality of life.\\n    ========================\\n    Berlin, the capital city of Germany, has a rich and complex history that stretches back to its first documentation in the 13th century. Throughout the centuries, Berlin has been at the heart of numerous important historical movements and events.\\n    \\n    Initially a small town, Berlin grew in significance as the capital of the Margraviate of Brandenburg. Later on, it ascended in prominence as the capital of the Kingdom of Prussia. With the unification of Germany, Berlin became the imperial capital of the German Empire, a position it retained until the end of World War I.\\n    \\n    The interwar period saw Berlin as the capital of the Weimar Republic, and it was during this time that the city became known for its vibrant cultural scene. However, the rise of the Nazi regime in the 1930s led to a dark period in Berlin\\'s history, and the city was heavily damaged during World War II.\\n    \\n    Following the war\\'s end, Berlin became a divided city. The division was physical, represented by the Berlin Wall, and ideological, with West Berlin aligning with democratic West Germany while East Berlin became the capital of the socialist East Germany.\\n    \\n    The fall of the Berlin Wall in November 1989 was a historic moment, leading to German reunification in 1990. Berlin was once again chosen as the capital of a united Germany. Since reunification, Berlin has undergone massive reconstruction and has become a hub of contemporary culture, politics, media, and science.\\n    \\n    Today, Berlin celebrates its diverse heritage, from its grand historical landmarks like the Brandenburg Gate and the Reichstag, to its remembrance of the past with monuments such as the Berlin Wall Memorial and the Holocaust Memorial. It is a city known for its cultural dynamism, thriving arts and music scenes, and a high quality of life. Berlin\\'s history has shaped it into a unique world city that continues to play a significant role on the global stage.\\n    \\n\\n\\n```python\\nresponse = agent.chat(\\n    \"Can you give me the country corresponding to each city?\"\\n)\\nprint(str(response))\\n```\\n\\n    === Calling Function ===\\n    Calling function: sql_tool with args: {\"input\":\"SELECT name, country FROM city_stats\"}\\n    Got output: The cities in the city_stats table are Toronto from Canada, Tokyo from Japan, and Berlin from Germany.\\n    ========================\\n    Here are the countries corresponding to each city:\\n    \\n    - Toronto: Canada\\n    - Tokyo: Japan\\n    - Berlin: Germany\\n    \\n', metadata={'source': '/mnt/c/Users/User/Documents/AI_ML/career_ai_engineer/Projects/ai_apps_assistant/llamaindex_docs/test_llamaindex.json', 'seq_num': 14, 'filename': 'openai_assistant_query_cookbook.ipynb', 'filepath': 'docs/examples/agent/openai_assistant_query_cookbook.ipynb', 'url': 'https://github.com/run-llama/llama_index/blob/3823389e3f91cab47b72e2cc2814826db9f98e32/docs/examples/agent/openai_assistant_query_cookbook.ipynb'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/openai_forced_function_call.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\\n\\n# OpenAI agent: specifying a forced function call\\n\\nIf you\\'re opening this Notebook on colab, you will probably need to install LlamaIndex 🦙.\\n\\n\\n```python\\n!pip install llama-index\\n```\\n\\n\\n```python\\nimport json\\nfrom typing import Sequence, List\\n\\nfrom llama_index.llms import OpenAI, ChatMessage\\nfrom llama_index.tools import BaseTool, FunctionTool\\nfrom llama_index.agent import OpenAIAgent\\n```\\n\\n\\n```python\\ndef add(a: int, b: int) -> int:\\n    \"\"\"Add two integers and returns the result integer\"\"\"\\n    return a + b\\n\\n\\nadd_tool = FunctionTool.from_defaults(fn=add)\\n\\n\\ndef useless_tool() -> int:\\n    \"\"\"This is a uselss tool.\"\"\"\\n    return \"This is a uselss output.\"\\n\\n\\nuseless_tool = FunctionTool.from_defaults(fn=useless_tool)\\n```\\n\\n\\n```python\\nllm = OpenAI(model=\"gpt-3.5-turbo-0613\")\\nagent = OpenAIAgent.from_tools([useless_tool, add_tool], llm=llm, verbose=True)\\n```\\n\\n### \"Auto\" function call\\n\\nThe agent automatically selects the useful \"add\" tool\\n\\n\\n```python\\nresponse = agent.chat(\\n    \"What is 5 + 2?\", tool_choice=\"auto\"\\n)  # note function_call param is deprecated\\n# use tool_choice instead\\n```\\n\\n    STARTING TURN 1\\n    ---------------\\n    \\n    === Calling Function ===\\n    Calling function: add with args: {\\n      \"a\": 5,\\n      \"b\": 2\\n    }\\n    Got output: 7\\n    ========================\\n    \\n    STARTING TURN 2\\n    ---------------\\n    \\n    \\n\\n\\n```python\\nprint(response)\\n```\\n\\n    The sum of 5 and 2 is 7.\\n    \\n\\n### Forced function call\\n\\nThe agent is forced to call the \"useless_tool\" before selecting the \"add\" tool\\n\\n\\n```python\\nresponse = agent.chat(\"What is 5 * 2?\", tool_choice=\"useless_tool\")\\n```\\n\\n    STARTING TURN 1\\n    ---------------\\n    \\n    === Calling Function ===\\n    Calling function: useless_tool with args: {}\\n    Got output: This is a uselss output.\\n    ========================\\n    \\n    STARTING TURN 2\\n    ---------------\\n    \\n    === Calling Function ===\\n    Calling function: add with args: {\\n      \"a\": 5,\\n      \"b\": 2\\n    }\\n    Got output: 7\\n    ========================\\n    \\n    STARTING TURN 3\\n    ---------------\\n    \\n    \\n\\n\\n```python\\nprint(response)\\n```\\n\\n    The product of 5 and 2 is 10.\\n    \\n\\n### \"None\" function call\\n\\nThe agent is forced to not use a tool\\n\\n\\n```python\\nresponse = agent.chat(\"What is 5 * 2?\", tool_choice=\"none\")\\n```\\n\\n    STARTING TURN 1\\n    ---------------\\n    \\n    \\n\\n\\n```python\\nprint(response)\\n```\\n\\n    The product of 5 and 2 is 10.\\n    \\n', metadata={'source': '/mnt/c/Users/User/Documents/AI_ML/career_ai_engineer/Projects/ai_apps_assistant/llamaindex_docs/test_llamaindex.json', 'seq_num': 15, 'filename': 'openai_forced_function_call.ipynb', 'filepath': 'docs/examples/agent/openai_forced_function_call.ipynb', 'url': 'https://github.com/run-llama/llama_index/blob/3823389e3f91cab47b72e2cc2814826db9f98e32/docs/examples/agent/openai_forced_function_call.ipynb'}),\n",
      " Document(page_content='# Benchmarking OpenAI Retrieval API (through Assistant Agent)\\n<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/openai_retrieval_benchmark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\\n\\nThis guide benchmarks the Retrieval Tool from the [OpenAI Assistant API](https://platform.openai.com/docs/assistants/overview), by using our `OpenAIAssistantAgent`. We run over the Llama 2 paper, and compare generation quality against a naive RAG pipeline.\\n\\n\\n\\n```python\\n!pip install llama-index\\n```\\n\\n\\n```python\\nimport nest_asyncio\\n\\nnest_asyncio.apply()\\n```\\n\\n## Setup Data\\n\\nHere we load the Llama 2 paper and chunk it.\\n\\n\\n```python\\n!mkdir -p \\'data/\\'\\n!wget --user-agent \"Mozilla\" \"https://arxiv.org/pdf/2307.09288.pdf\" -O \"data/llama2.pdf\"\\n```\\n\\n    --2023-11-08 21:53:52--  https://arxiv.org/pdf/2307.09288.pdf\\n    Resolving arxiv.org (arxiv.org)... 128.84.21.199\\n    Connecting to arxiv.org (arxiv.org)|128.84.21.199|:443... connected.\\n    HTTP request sent, awaiting response... 200 OK\\n    Length: 13661300 (13M) [application/pdf]\\n    Saving to: ‘data/llama2.pdf’\\n    \\n    data/llama2.pdf     100%[===================>]  13.03M   141KB/s    in 1m 48s  \\n    \\n    2023-11-08 21:55:42 (123 KB/s) - ‘data/llama2.pdf’ saved [13661300/13661300]\\n    \\n    \\n\\n\\n```python\\nfrom pathlib import Path\\nfrom llama_index import Document, ServiceContext, VectorStoreIndex\\nfrom llama_hub.file.pymu_pdf.base import PyMuPDFReader\\nfrom llama_index.node_parser import SimpleNodeParser\\nfrom llama_index.llms import OpenAI\\n```\\n\\n\\n```python\\nloader = PyMuPDFReader()\\ndocs0 = loader.load(file_path=Path(\"./data/llama2.pdf\"))\\n\\ndoc_text = \"\\\\n\\\\n\".join([d.get_content() for d in docs0])\\ndocs = [Document(text=doc_text)]\\n```\\n\\n\\n```python\\nnode_parser = SimpleNodeParser.from_defaults()\\nnodes = node_parser.get_nodes_from_documents(docs)\\n```\\n\\n\\n```python\\nlen(nodes)\\n```\\n\\n\\n\\n\\n    89\\n\\n\\n\\n## Define Eval Modules\\n\\nWe setup evaluation modules, including the dataset and evaluators.\\n\\n### Setup \"Golden Dataset\"\\n\\nHere we load in a \"golden\" dataset.\\n\\n#### Option 1: Pull Existing Dataset\\n\\n**NOTE**: We pull this in from Dropbox. For details on how to generate a dataset please see our `DatasetGenerator` module.\\n\\n\\n```python\\n!wget \"https://www.dropbox.com/scl/fi/fh9vsmmm8vu0j50l3ss38/llama2_eval_qr_dataset.json?rlkey=kkoaez7aqeb4z25gzc06ak6kb&dl=1\" -O data/llama2_eval_qr_dataset.json\\n```\\n\\n    --2023-11-08 22:20:10--  https://www.dropbox.com/scl/fi/fh9vsmmm8vu0j50l3ss38/llama2_eval_qr_dataset.json?rlkey=kkoaez7aqeb4z25gzc06ak6kb&dl=1\\n    Resolving www.dropbox.com (www.dropbox.com)... 2620:100:6057:18::a27d:d12, 162.125.13.18\\n    Connecting to www.dropbox.com (www.dropbox.com)|2620:100:6057:18::a27d:d12|:443... connected.\\n    HTTP request sent, awaiting response... 302 Found\\n    Location: https://uc63170224c66fda29da619e304b.dl.dropboxusercontent.com/cd/0/inline/CHOj1FEf2Dd6npmREaKmwUEIJ4S5QcrgeISKh55BE27i9tqrcE94Oym_0_z0EL9mBTmF9udNCxWwnFSHlio3ib6G_f_j3xiUzn5AVvQsKDPROYjazkJz_ChUVv3xkT-Pzuk/file?dl=1# [following]\\n    --2023-11-08 22:20:11--  https://uc63170224c66fda29da619e304b.dl.dropboxusercontent.com/cd/0/inline/CHOj1FEf2Dd6npmREaKmwUEIJ4S5QcrgeISKh55BE27i9tqrcE94Oym_0_z0EL9mBTmF9udNCxWwnFSHlio3ib6G_f_j3xiUzn5AVvQsKDPROYjazkJz_ChUVv3xkT-Pzuk/file?dl=1\\n    Resolving uc63170224c66fda29da619e304b.dl.dropboxusercontent.com (uc63170224c66fda29da619e304b.dl.dropboxusercontent.com)... 2620:100:6057:15::a27d:d0f, 162.125.13.15\\n    Connecting to uc63170224c66fda29da619e304b.dl.dropboxusercontent.com (uc63170224c66fda29da619e304b.dl.dropboxusercontent.com)|2620:100:6057:15::a27d:d0f|:443... connected.\\n    HTTP request sent, awaiting response... 200 OK\\n    Length: 60656 (59K) [application/binary]\\n    Saving to: ‘data/llama2_eval_qr_dataset.json’\\n    \\n    data/llama2_eval_qr 100%[===================>]  59.23K  --.-KB/s    in 0.02s   \\n    \\n    2023-11-08 22:20:12 (2.87 MB/s) - ‘data/llama2_eval_qr_dataset.json’ saved [60656/60656]\\n    \\n    \\n\\n\\n```python\\nfrom llama_index.evaluation import QueryResponseDataset\\n\\n# optional\\neval_dataset = QueryResponseDataset.from_json(\\n    \"data/llama2_eval_qr_dataset.json\"\\n)\\n```\\n\\n#### Option 2: Generate New Dataset\\n\\nIf you choose this option, you can choose to generate a new dataset from scratch. This allows you to play around with our `DatasetGenerator` settings to make sure it suits your needs.\\n\\n\\n```python\\nfrom llama_index.evaluation import (\\n    DatasetGenerator,\\n    QueryResponseDataset,\\n)\\nfrom llama_index import ServiceContext\\nfrom llama_index.llms import OpenAI\\n```\\n\\n\\n```python\\n# NOTE: run this if the dataset isn\\'t already saved\\n# Note: we only generate from the first 20 nodes, since the rest are references\\neval_service_context = ServiceContext.from_defaults(\\n    llm=OpenAI(model=\"gpt-4-1106-preview\")\\n)\\ndataset_generator = DatasetGenerator(\\n    nodes[:20],\\n    service_context=eval_service_context,\\n    show_progress=True,\\n    num_questions_per_chunk=3,\\n)\\neval_dataset = await dataset_generator.agenerate_dataset_from_nodes(num=60)\\neval_dataset.save_json(\"data/llama2_eval_qr_dataset.json\")\\n```\\n\\n\\n```python\\n# optional\\neval_dataset = QueryResponseDataset.from_json(\\n    \"data/llama2_eval_qr_dataset.json\"\\n)\\n```\\n\\n### Eval Modules\\n\\nWe define two evaluation modules: correctness and semantic similarity - both comparing quality of predicted response with actual response.\\n\\n\\n```python\\nfrom llama_index.evaluation.eval_utils import get_responses, get_results_df\\nfrom llama_index.evaluation import (\\n    CorrectnessEvaluator,\\n    SemanticSimilarityEvaluator,\\n    BatchEvalRunner,\\n)\\nfrom llama_index.llms import OpenAI\\n```\\n\\n\\n```python\\neval_llm = OpenAI(model=\"gpt-4-1106-preview\")\\neval_service_context = ServiceContext.from_defaults(llm=eval_llm)\\nevaluator_c = CorrectnessEvaluator(service_context=eval_service_context)\\nevaluator_s = SemanticSimilarityEvaluator(service_context=eval_service_context)\\nevaluator_dict = {\\n    \"correctness\": evaluator_c,\\n    \"semantic_similarity\": evaluator_s,\\n}\\nbatch_runner = BatchEvalRunner(evaluator_dict, workers=2, show_progress=True)\\n```\\n\\n\\n```python\\nimport numpy as np\\nimport time\\nimport os\\nimport pickle\\nfrom tqdm import tqdm\\n\\n\\ndef get_responses_sync(\\n    eval_qs, query_engine, show_progress=True, save_path=None\\n):\\n    if show_progress:\\n        eval_qs_iter = tqdm(eval_qs)\\n    else:\\n        eval_qs_iter = eval_qs\\n    pred_responses = []\\n    start_time = time.time()\\n    for eval_q in eval_qs_iter:\\n        print(f\"eval q: {eval_q}\")\\n        pred_response = agent.query(eval_q)\\n        print(f\"predicted response: {pred_response}\")\\n        pred_responses.append(pred_response)\\n        if save_path is not None:\\n            # save intermediate responses (to cache in case something breaks)\\n            avg_time = (time.time() - start_time) / len(pred_responses)\\n            pickle.dump(\\n                {\"pred_responses\": pred_responses, \"avg_time\": avg_time},\\n                open(save_path, \"wb\"),\\n            )\\n    return pred_responses\\n\\n\\nasync def run_evals(\\n    query_engine,\\n    eval_qa_pairs,\\n    batch_runner,\\n    disable_async_for_preds=False,\\n    save_path=None,\\n):\\n    # then evaluate\\n    # TODO: evaluate a sample of generated results\\n    eval_qs = [q for q, _ in eval_qa_pairs]\\n    eval_answers = [a for _, a in eval_qa_pairs]\\n\\n    if save_path is not None:\\n        if not os.path.exists(save_path):\\n            start_time = time.time()\\n            if disable_async_for_preds:\\n                pred_responses = get_responses_sync(\\n                    eval_qs,\\n                    query_engine,\\n                    show_progress=True,\\n                    save_path=save_path,\\n                )\\n            else:\\n                pred_responses = get_responses(\\n                    eval_qs, query_engine, show_progress=True\\n                )\\n            avg_time = (time.time() - start_time) / len(eval_qs)\\n            pickle.dump(\\n                {\"pred_responses\": pred_responses, \"avg_time\": avg_time},\\n                open(save_path, \"wb\"),\\n            )\\n        else:\\n            # [optional] load\\n            pickled_dict = pickle.load(open(save_path, \"rb\"))\\n            pred_responses = pickled_dict[\"pred_responses\"]\\n            avg_time = pickled_dict[\"avg_time\"]\\n    else:\\n        start_time = time.time()\\n        pred_responses = get_responses(\\n            eval_qs, query_engine, show_progress=True\\n        )\\n        avg_time = (time.time() - start_time) / len(eval_qs)\\n\\n    eval_results = await batch_runner.aevaluate_responses(\\n        eval_qs, responses=pred_responses, reference=eval_answers\\n    )\\n    return eval_results, {\"avg_time\": avg_time}\\n```\\n\\n## Construct Assistant with Built-In Retrieval\\n\\nLet\\'s construct the assistant by also passing it the built-in OpenAI Retrieval tool.\\n\\nHere, we upload and pass in the file during assistant-creation time. \\n\\n\\n```python\\nfrom llama_index.agent import OpenAIAssistantAgent\\n```\\n\\n\\n```python\\nagent = OpenAIAssistantAgent.from_new(\\n    name=\"SEC Analyst\",\\n    instructions=\"You are a QA assistant designed to analyze sec filings.\",\\n    openai_tools=[{\"type\": \"retrieval\"}],\\n    instructions_prefix=\"Please address the user as Jerry.\",\\n    files=[\"data/llama2.pdf\"],\\n    verbose=True,\\n)\\n```\\n\\n\\n```python\\nresponse = agent.query(\\n    \"What are the key differences between Llama 2 and Llama 2-Chat?\"\\n)\\n```\\n\\n\\n```python\\nprint(str(response))\\n```\\n\\n    The key differences between Llama 2 and Llama 2-Chat, as indicated by the document, focus on their performance in safety evaluations, particularly when tested with adversarial prompts. Here are some of the differences highlighted within the safety evaluation section of Llama 2-Chat:\\n    \\n    1. Safety Human Evaluation: Llama 2-Chat was assessed with roughly 2000 adversarial prompts, among which 1351 were single-turn and 623 were multi-turn. The responses were judged for safety violations on a five-point Likert scale, where a rating of 1 or 2 indicated a violation. The evaluation aimed to gauge the model’s safety by its rate of generating responses with safety violations and its helpfulness to users.\\n    \\n    2. Violation Percentage and Mean Rating: Llama 2-Chat exhibited a low overall violation percentage across different model sizes and a high mean rating for safety and helpfulness, which suggests a strong performance in safety evaluations.\\n    \\n    3. Inter-Rater Reliability: The reliability of the safety assessments was measured using Gwet’s AC1/2 statistic, showing a high degree of agreement among annotators with an average inter-rater reliability score of 0.92 for Llama 2-Chat annotations.\\n    \\n    4. Single-turn and Multi-turn Conversations: The evaluation revealed that multi-turn conversations generally lead to more safety violations across models, but Llama 2-Chat performed well compared to baselines, particularly in multi-turn scenarios.\\n    \\n    5. Violation Percentage Per Risk Category: Llama 2-Chat had a relatively higher number of violations in the unqualified advice category, possibly due to a lack of appropriate disclaimers in its responses.\\n    \\n    6. Improvements in Fine-Tuned Llama 2-Chat: The document also mentions that the fine-tuned Llama 2-Chat showed significant improvement over the pre-trained Llama 2 in terms of truthfulness and toxicity. The percentage of toxic generations dropped to effectively 0% for Llama 2-Chat of all sizes, which was the lowest among all compared models, indicating a notable enhancement in safety.\\n    \\n    These points detail the evaluations and improvements emphasizing safety that distinguish Llama 2-Chat from Llama 2【9†source】.\\n    \\n\\n## Benchmark\\n\\nWe run the agent over our evaluation dataset. We benchmark against a standard top-k RAG pipeline (k=2) with gpt-4-turbo.\\n\\n**NOTE**: During our time of testing (November 2023), the Assistant API is heavily rate-limited, and can take ~1-2 hours to generate responses over 60 datapoints.\\n\\n#### Define Baseline Index + RAG Pipeline\\n\\n\\n```python\\nbase_sc = ServiceContext.from_defaults(llm=OpenAI(model=\"gpt-4-1106-preview\"))\\nbase_index = VectorStoreIndex(nodes, service_context=base_sc)\\nbase_query_engine = base_index.as_query_engine(similarity_top_k=2)\\n```\\n\\n#### Run Evals over Baseline\\n\\n\\n```python\\nbase_eval_results, base_extra_info = await run_evals(\\n    base_query_engine,\\n    eval_dataset.qr_pairs,\\n    batch_runner,\\n    save_path=\"data/llama2_preds_base.pkl\",\\n)\\n```\\n\\n\\n```python\\nresults_df = get_results_df(\\n    [base_eval_results],\\n    [\"Base Query Engine\"],\\n    [\"correctness\", \"semantic_similarity\"],\\n)\\ndisplay(results_df)\\n```\\n\\n\\n<div>\\n<style scoped>\\n    .dataframe tbody tr th:only-of-type {\\n        vertical-align: middle;\\n    }\\n\\n    .dataframe tbody tr th {\\n        vertical-align: top;\\n    }\\n\\n    .dataframe thead th {\\n        text-align: right;\\n    }\\n</style>\\n<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>names</th>\\n      <th>correctness</th>\\n      <th>semantic_similarity</th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>0</th>\\n      <td>Base Query Engine</td>\\n      <td>4.05</td>\\n      <td>0.964245</td>\\n    </tr>\\n  </tbody>\\n</table>\\n</div>\\n\\n\\n#### Run Evals over Assistant API\\n\\n\\n```python\\nassistant_eval_results, assistant_extra_info = await run_evals(\\n    agent,\\n    eval_dataset.qr_pairs[:55],\\n    batch_runner,\\n    save_path=\"data/llama2_preds_assistant.pkl\",\\n    disable_async_for_preds=True,\\n)\\n```\\n\\n#### Get Results\\n\\nHere we see...that our basic RAG pipeline does better.\\n\\nTake these numbers with a grain of salt. The goal here is to give you a script so you can run this on your own data.\\n\\nThat said it\\'s surprising the Retrieval API doesn\\'t give immediately better out of the box performance.\\n\\n\\n```python\\nresults_df = get_results_df(\\n    [assistant_eval_results, base_eval_results],\\n    [\"Retrieval API\", \"Base Query Engine\"],\\n    [\"correctness\", \"semantic_similarity\"],\\n)\\ndisplay(results_df)\\nprint(f\"Base Avg Time: {base_extra_info[\\'avg_time\\']}\")\\nprint(f\"Assistant Avg Time: {assistant_extra_info[\\'avg_time\\']}\")\\n```\\n\\n\\n<div>\\n<style scoped>\\n    .dataframe tbody tr th:only-of-type {\\n        vertical-align: middle;\\n    }\\n\\n    .dataframe tbody tr th {\\n        vertical-align: top;\\n    }\\n\\n    .dataframe thead th {\\n        text-align: right;\\n    }\\n</style>\\n<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>names</th>\\n      <th>correctness</th>\\n      <th>semantic_similarity</th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>0</th>\\n      <td>Retrieval API</td>\\n      <td>3.536364</td>\\n      <td>0.952647</td>\\n    </tr>\\n    <tr>\\n      <th>1</th>\\n      <td>Base Query Engine</td>\\n      <td>4.050000</td>\\n      <td>0.964245</td>\\n    </tr>\\n  </tbody>\\n</table>\\n</div>\\n\\n\\n    Base Avg Time: 0.25683316787083943\\n    Assistant Avg Time: 75.43605598536405\\n    \\n', metadata={'source': '/mnt/c/Users/User/Documents/AI_ML/career_ai_engineer/Projects/ai_apps_assistant/llamaindex_docs/test_llamaindex.json', 'seq_num': 16, 'filename': 'openai_retrieval_benchmark.ipynb', 'filepath': 'docs/examples/agent/openai_retrieval_benchmark.ipynb', 'url': 'https://github.com/run-llama/llama_index/blob/3823389e3f91cab47b72e2cc2814826db9f98e32/docs/examples/agent/openai_retrieval_benchmark.ipynb'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/react_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\\n\\n# ReAct Agent - A Simple Intro with Calculator Tools\\n\\nThis is a notebook that showcases the ReAct agent over very simple calculator tools (no fancy RAG pipelines or API calls).\\n\\nWe show how it can reason step-by-step over different tools to achieve the end goal.\\n\\nIf you\\'re opening this Notebook on colab, you will probably need to install LlamaIndex 🦙.\\n\\n\\n```python\\n!pip install llama-index\\n```\\n\\n\\n```python\\nfrom llama_index.agent import ReActAgent\\nfrom llama_index.llms import OpenAI, ChatMessage\\nfrom llama_index.tools import BaseTool, FunctionTool\\n```\\n\\n## Define Function Tools\\n\\nWe setup some trivial `multiply` and `add` tools. Note that you can define arbitrary functions and pass it to the `FunctionTool` (which will process the docstring and parameter signature).\\n\\n\\n```python\\ndef multiply(a: int, b: int) -> int:\\n    \"\"\"Multiply two integers and returns the result integer\"\"\"\\n    return a * b\\n\\n\\nmultiply_tool = FunctionTool.from_defaults(fn=multiply)\\n```\\n\\n\\n```python\\ndef add(a: int, b: int) -> int:\\n    \"\"\"Add two integers and returns the result integer\"\"\"\\n    return a + b\\n\\n\\nadd_tool = FunctionTool.from_defaults(fn=add)\\n```\\n\\n## Run Some Queries\\n\\n### gpt-3.5-turbo\\n\\n\\n```python\\nllm = OpenAI(model=\"gpt-3.5-turbo-instruct\")\\nagent = ReActAgent.from_tools([multiply_tool, add_tool], llm=llm, verbose=True)\\n```\\n\\n\\n```python\\nresponse = agent.chat(\"What is 20+(2*4)? Calculate step by step \")\\n```\\n\\n    \\x1b[1;3;38;5;200mThought: I need to use a tool to help me answer the question.\\n    assistant: Action: multiply\\n    assistant: Action Input: {\"a\": 2, \"b\": 4}\\n    Observation: 8\\n    assistant: Thought: I need to use a tool to help me answer the question.\\n    assistant: Action: add\\n    assistant: Action Input: {\"a\": 20, \"b\": 8}\\n    Observation: 28\\n    Thought: I can answer without using any more tools.\\n    Answer: 28\\n    \\x1b[0m\\n\\n\\n```python\\nresponse_gen = agent.stream_chat(\"What is 20+2*4? Calculate step by step\")\\nresponse_gen.print_response_stream()\\n```\\n\\n     28\\n\\n### gpt-4\\n\\n\\n```python\\nllm = OpenAI(model=\"gpt-4\")\\nagent = ReActAgent.from_tools([multiply_tool, add_tool], llm=llm, verbose=True)\\n```\\n\\n\\n```python\\nresponse = agent.chat(\"What is 2+2*4\")\\nprint(response)\\n```\\n\\n    \\x1b[1;3;38;5;200mThought: I need to use the tools to help me answer the question. According to the order of operations in mathematics (BIDMAS/BODMAS), multiplication should be done before addition. So, I will first multiply 2 and 4, then add the result to 2.\\n    Action: multiply\\n    Action Input: {\\'a\\': 2, \\'b\\': 4}\\n    \\x1b[0m\\x1b[1;3;34mObservation: 8\\n    \\x1b[0m\\x1b[1;3;38;5;200mThought: Now that I have the result of the multiplication, I need to add this to 2.\\n    Action: add\\n    Action Input: {\\'a\\': 2, \\'b\\': 8}\\n    \\x1b[0m\\x1b[1;3;34mObservation: 10\\n    \\x1b[0m\\x1b[1;3;38;5;200mThought: I can answer without using any more tools.\\n    Answer: 10\\n    \\x1b[0m10\\n    \\n\\n## View Prompts\\n\\nLet\\'s take a look at the core system prompt powering the ReAct agent! \\n\\nWithin the agent, the current conversation history is dumped below this line.\\n\\n\\n```python\\nllm = OpenAI(model=\"gpt-4\")\\nagent = ReActAgent.from_tools([multiply_tool, add_tool], llm=llm, verbose=True)\\n```\\n\\n\\n```python\\nprompt_dict = agent.get_prompts()\\nfor k, v in prompt_dict.items():\\n    print(f\"Prompt: {k}\\\\n\\\\nValue: {v.template}\")\\n```\\n\\n    Prompt: agent_worker:system_prompt\\n    \\n    Value: \\n    You are designed to help with a variety of tasks, from answering questions     to providing summaries to other types of analyses.\\n    \\n    ## Tools\\n    You have access to a wide variety of tools. You are responsible for using\\n    the tools in any sequence you deem appropriate to complete the task at hand.\\n    This may require breaking the task into subtasks and using different tools\\n    to complete each subtask.\\n    \\n    You have access to the following tools:\\n    {tool_desc}\\n    \\n    ## Output Format\\n    To answer the question, please use the following format.\\n    \\n    ```\\n    Thought: I need to use a tool to help me answer the question.\\n    Action: tool name (one of {tool_names}) if using a tool.\\n    Action Input: the input to the tool, in a JSON format representing the kwargs (e.g. {{\"input\": \"hello world\", \"num_beams\": 5}})\\n    ```\\n    \\n    Please ALWAYS start with a Thought.\\n    \\n    Please use a valid JSON format for the Action Input. Do NOT do this {{\\'input\\': \\'hello world\\', \\'num_beams\\': 5}}.\\n    \\n    If this format is used, the user will respond in the following format:\\n    \\n    ```\\n    Observation: tool response\\n    ```\\n    \\n    You should keep repeating the above format until you have enough information\\n    to answer the question without using any more tools. At that point, you MUST respond\\n    in the one of the following two formats:\\n    \\n    ```\\n    Thought: I can answer without using any more tools.\\n    Answer: [your answer here]\\n    ```\\n    \\n    ```\\n    Thought: I cannot answer the question with the provided tools.\\n    Answer: Sorry, I cannot answer your query.\\n    ```\\n    \\n    ## Current Conversation\\n    Below is the current conversation consisting of interleaving human and assistant messages.\\n    \\n    \\n    \\n\\n### Customizing the Prompt\\n\\nFor fun, let\\'s try instructing the agent to output the answer along with reasoning in bullet points. See \"## Additional Rules\" section.\\n\\n\\n```python\\nfrom llama_index.prompts import PromptTemplate\\n\\nreact_system_header_str = \"\"\"\\\\\\n\\nYou are designed to help with a variety of tasks, from answering questions \\\\\\n    to providing summaries to other types of analyses.\\n\\n## Tools\\nYou have access to a wide variety of tools. You are responsible for using\\nthe tools in any sequence you deem appropriate to complete the task at hand.\\nThis may require breaking the task into subtasks and using different tools\\nto complete each subtask.\\n\\nYou have access to the following tools:\\n{tool_desc}\\n\\n## Output Format\\nTo answer the question, please use the following format.\\n\\n```\\nThought: I need to use a tool to help me answer the question.\\nAction: tool name (one of {tool_names}) if using a tool.\\nAction Input: the input to the tool, in a JSON format representing the kwargs (e.g. {{\"input\": \"hello world\", \"num_beams\": 5}})\\n```\\n\\nPlease ALWAYS start with a Thought.\\n\\nPlease use a valid JSON format for the Action Input. Do NOT do this {{\\'input\\': \\'hello world\\', \\'num_beams\\': 5}}.\\n\\nIf this format is used, the user will respond in the following format:\\n\\n```\\nObservation: tool response\\n```\\n\\nYou should keep repeating the above format until you have enough information\\nto answer the question without using any more tools. At that point, you MUST respond\\nin the one of the following two formats:\\n\\n```\\nThought: I can answer without using any more tools.\\nAnswer: [your answer here]\\n```\\n\\n```\\nThought: I cannot answer the question with the provided tools.\\nAnswer: Sorry, I cannot answer your query.\\n```\\n\\n## Additional Rules\\n- The answer MUST contain a sequence of bullet points that explain how you arrived at the answer. This can include aspects of the previous conversation history.\\n- You MUST obey the function signature of each tool. Do NOT pass in no arguments if the function expects arguments.\\n\\n## Current Conversation\\nBelow is the current conversation consisting of interleaving human and assistant messages.\\n\\n\"\"\"\\nreact_system_prompt = PromptTemplate(react_system_header_str)\\n```\\n\\n\\n```python\\nagent.update_prompts({\"agent_worker:system_prompt\": react_system_prompt})\\n```\\n\\n\\n```python\\nagent.reset()\\nresponse = agent.chat(\"What is 5+3+2\")\\nprint(response)\\n```\\n\\n    \\x1b[1;3;38;5;200mThought: I need to use the add tool to help me answer the question.\\n    Action: add\\n    Action Input: {\\'a\\': 5, \\'b\\': 3}\\n    \\x1b[0m\\x1b[1;3;34mObservation: 8\\n    \\x1b[0m\\x1b[1;3;38;5;200mThought: Now I need to add the result from the previous operation with 2.\\n    Action: add\\n    Action Input: {\\'a\\': 8, \\'b\\': 2}\\n    \\x1b[0m\\x1b[1;3;34mObservation: 10\\n    \\x1b[0m\\x1b[1;3;38;5;200mThought: I can answer without using any more tools.\\n    Answer: The result of 5+3+2 is 10.\\n    - First, I added 5 and 3 using the add tool, which resulted in 8.\\n    - Then, I added the result (8) to 2 using the add tool, which resulted in 10.\\n    \\x1b[0mThe result of 5+3+2 is 10.\\n    - First, I added 5 and 3 using the add tool, which resulted in 8.\\n    - Then, I added the result (8) to 2 using the add tool, which resulted in 10.\\n    \\n', metadata={'source': '/mnt/c/Users/User/Documents/AI_ML/career_ai_engineer/Projects/ai_apps_assistant/llamaindex_docs/test_llamaindex.json', 'seq_num': 17, 'filename': 'react_agent.ipynb', 'filepath': 'docs/examples/agent/react_agent.ipynb', 'url': 'https://github.com/run-llama/llama_index/blob/3823389e3f91cab47b72e2cc2814826db9f98e32/docs/examples/agent/react_agent.ipynb'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/react_agent_with_query_engine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\\n\\n# ReAct Agent with Query Engine (RAG) Tools\\n\\nIn this section, we show how to setup an agent powered by the ReAct loop for financial analysis.\\n\\nThe agent has access to two \"tools\": one to query the 2021 Lyft 10-K and the other to query the 2021 Uber 10-K.\\n\\nWe try two different LLMs:\\n\\n- gpt-3.5-turbo\\n- gpt-3.5-turbo-instruct\\n\\nNote that you can plug in any LLM that exposes a text completion endpoint.\\n\\n## Build Query Engine Tools\\n\\n\\n```python\\nfrom llama_index import (\\n    SimpleDirectoryReader,\\n    VectorStoreIndex,\\n    StorageContext,\\n    load_index_from_storage,\\n)\\n\\nfrom llama_index.tools import QueryEngineTool, ToolMetadata\\n```\\n\\n\\n```python\\ntry:\\n    storage_context = StorageContext.from_defaults(\\n        persist_dir=\"./storage/lyft\"\\n    )\\n    lyft_index = load_index_from_storage(storage_context)\\n\\n    storage_context = StorageContext.from_defaults(\\n        persist_dir=\"./storage/uber\"\\n    )\\n    uber_index = load_index_from_storage(storage_context)\\n\\n    index_loaded = True\\nexcept:\\n    index_loaded = False\\n```\\n\\nDownload Data\\n\\n\\n```python\\n!mkdir -p \\'data/10k/\\'\\n!wget \\'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10k/uber_2021.pdf\\' -O \\'data/10k/uber_2021.pdf\\'\\n!wget \\'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10k/lyft_2021.pdf\\' -O \\'data/10k/lyft_2021.pdf\\'\\n```\\n\\n\\n```python\\nif not index_loaded:\\n    # load data\\n    lyft_docs = SimpleDirectoryReader(\\n        input_files=[\"./data/10k/lyft_2021.pdf\"]\\n    ).load_data()\\n    uber_docs = SimpleDirectoryReader(\\n        input_files=[\"./data/10k/uber_2021.pdf\"]\\n    ).load_data()\\n\\n    # build index\\n    lyft_index = VectorStoreIndex.from_documents(lyft_docs)\\n    uber_index = VectorStoreIndex.from_documents(uber_docs)\\n\\n    # persist index\\n    lyft_index.storage_context.persist(persist_dir=\"./storage/lyft\")\\n    uber_index.storage_context.persist(persist_dir=\"./storage/uber\")\\n```\\n\\n\\n```python\\nlyft_engine = lyft_index.as_query_engine(similarity_top_k=3)\\nuber_engine = uber_index.as_query_engine(similarity_top_k=3)\\n```\\n\\n\\n```python\\nquery_engine_tools = [\\n    QueryEngineTool(\\n        query_engine=lyft_engine,\\n        metadata=ToolMetadata(\\n            name=\"lyft_10k\",\\n            description=(\\n                \"Provides information about Lyft financials for year 2021. \"\\n                \"Use a detailed plain text question as input to the tool.\"\\n            ),\\n        ),\\n    ),\\n    QueryEngineTool(\\n        query_engine=uber_engine,\\n        metadata=ToolMetadata(\\n            name=\"uber_10k\",\\n            description=(\\n                \"Provides information about Uber financials for year 2021. \"\\n                \"Use a detailed plain text question as input to the tool.\"\\n            ),\\n        ),\\n    ),\\n]\\n```\\n\\n## Setup ReAct Agent\\n\\nHere we setup two ReAct agents: one powered by standard gpt-3.5-turbo, and the other powered by gpt-3.5-turbo-instruct.\\n\\nYou can **optionally** specify context which will be added to the core ReAct system prompt.\\n\\n\\n```python\\nfrom llama_index.agent import ReActAgent\\nfrom llama_index.llms import OpenAI\\n```\\n\\n\\n```python\\n# [Optional] Add Context\\n# context = \"\"\"\\\\\\n# You are a stock market sorcerer who is an expert on the companies Lyft and Uber.\\\\\\n#     You will answer questions about Uber and Lyft as in the persona of a sorcerer \\\\\\n#     and veteran stock market investor.\\n# \"\"\"\\nllm = OpenAI(model=\"gpt-3.5-turbo-0613\")\\n\\nagent = ReActAgent.from_tools(\\n    query_engine_tools,\\n    llm=llm,\\n    verbose=True,\\n    # context=context\\n)\\n```\\n\\n\\n```python\\nresponse = agent.chat(\"What was Lyft\\'s revenue growth in 2021?\")\\nprint(str(response))\\n```\\n\\n    \\x1b[38;5;200m\\x1b[1;3mThought: I need to use a tool to help me answer the question.\\n    Action: lyft_10k\\n    Action Input: {\\'input\\': \"What was Lyft\\'s revenue growth in 2021?\"}\\n    \\x1b[0m\\x1b[36;1m\\x1b[1;3mObservation: Lyft\\'s revenue growth in 2021 was 36%.\\n    \\x1b[0m\\x1b[38;5;200m\\x1b[1;3mResponse: Lyft\\'s revenue growth in 2021 was 36%.\\n    \\x1b[0mLyft\\'s revenue growth in 2021 was 36%.\\n    \\n\\n## Run Some Example Queries\\n\\nWe run some example queries using the agent, showcasing some of the agent\\'s abilities to do chain-of-thought-reasoning and tool use to synthesize the right answer.\\n\\nWe also show queries.\\n\\n\\n```python\\nresponse = agent.chat(\\n    \"Compare and contrast the revenue growth of Uber and Lyft in 2021, then\"\\n    \" give an analysis\"\\n)\\nprint(str(response))\\n```\\n\\n    \\x1b[38;5;200m\\x1b[1;3mThought: I need to use a tool to help me compare the revenue growth of Uber and Lyft in 2021.\\n    Action: lyft_10k\\n    Action Input: {\\'input\\': \"What was Lyft\\'s revenue growth in 2021?\"}\\n    \\x1b[0m\\x1b[36;1m\\x1b[1;3mObservation: Lyft\\'s revenue growth in 2021 was 36%.\\n    \\x1b[0m\\x1b[38;5;200m\\x1b[1;3mThought: I need to use a tool to help me compare the revenue growth of Uber and Lyft in 2021.\\n    Action: uber_10k\\n    Action Input: {\\'input\\': \"What was Uber\\'s revenue growth in 2021?\"}\\n    \\x1b[0m\\x1b[36;1m\\x1b[1;3mObservation: Uber\\'s revenue growth in 2021 was 57%.\\n    \\x1b[0m\\x1b[38;5;200m\\x1b[1;3mResponse: In 2021, Lyft\\'s revenue growth was 36% while Uber\\'s revenue growth was 57%. This indicates that Uber experienced a higher revenue growth compared to Lyft in 2021.\\n    \\x1b[0mIn 2021, Lyft\\'s revenue growth was 36% while Uber\\'s revenue growth was 57%. This indicates that Uber experienced a higher revenue growth compared to Lyft in 2021.\\n    \\n\\n**Async execution**: Here we try another query with async execution\\n\\n\\n```python\\n# Try another query with async execution\\n\\nimport nest_asyncio\\n\\nnest_asyncio.apply()\\n\\nresponse = await agent.achat(\\n    \"Compare and contrast the risks of Uber and Lyft in 2021, then give an\"\\n    \" analysis\"\\n)\\nprint(str(response))\\n```\\n\\n### Compare gpt-3.5-turbo vs. gpt-3.5-turbo-instruct \\n\\nWe compare the performance of the two agents in being able to answer some complex queries.\\n\\n#### Taking a look at a turbo-instruct agent\\n\\n\\n```python\\nllm_instruct = OpenAI(model=\"gpt-3.5-turbo-instruct\")\\nagent_instruct = ReActAgent.from_tools(\\n    query_engine_tools, llm=llm_instruct, verbose=True\\n)\\n```\\n\\n\\n```python\\nresponse = agent_instruct.chat(\"What was Lyft\\'s revenue growth in 2021?\")\\nprint(str(response))\\n```\\n\\n    \\x1b[38;5;200m\\x1b[1;3mThought: I need to use a tool to help me answer the question.\\n    Action: lyft_10k\\n    Action Input: {\\'input\\': \"What was Lyft\\'s revenue growth in 2021?\"}\\n    \\x1b[0m\\x1b[36;1m\\x1b[1;3mObservation: Lyft\\'s revenue growth in 2021 was 36%.\\n    \\x1b[0m\\x1b[38;5;200m\\x1b[1;3mResponse: Lyft\\'s revenue growth in 2021 was 36%.\\n    \\x1b[0mLyft\\'s revenue growth in 2021 was 36%.\\n    \\n\\n#### Try more complex queries\\n\\nWe compare gpt-3.5-turbo with gpt-3.5-turbo-instruct agents on more complex queries.\\n\\n\\n```python\\nresponse = agent.chat(\\n    \"Compare and contrast the revenue growth of Uber and Lyft in 2021, then\"\\n    \" give an analysis\"\\n)\\nprint(str(response))\\n```\\n\\n    \\x1b[38;5;200m\\x1b[1;3mThought: I need to use a tool to help me compare the revenue growth of Uber and Lyft in 2021.\\n    Action: uber_10k\\n    Action Input: {\\'input\\': \"Please provide information about Uber\\'s revenue growth in 2021.\"}\\n    \\x1b[0m\\x1b[36;1m\\x1b[1;3mObservation: Uber\\'s revenue grew by 57% in 2021 compared to the previous year. This growth was primarily driven by an increase in Gross Bookings, with Delivery Gross Bookings increasing by 71% and Mobility Gross Bookings growing by 38%. The increase in Delivery Gross Bookings was due to higher demand for food delivery orders and expansion across U.S. and international markets. The growth in Mobility Gross Bookings was a result of increased Trip volumes as the business recovered from the impacts of COVID-19.\\n    \\x1b[0m\\x1b[38;5;200m\\x1b[1;3mThought: I have information about Uber\\'s revenue growth in 2021. Now I need to use a tool to get information about Lyft\\'s revenue growth in 2021.\\n    Action: lyft_10k\\n    Action Input: {\\'input\\': \"Please provide information about Lyft\\'s revenue growth in 2021.\"}\\n    \\x1b[0m\\x1b[36;1m\\x1b[1;3mObservation: Lyft\\'s revenue increased by 36% in 2021 compared to the prior year.\\n    \\x1b[0m\\x1b[38;5;200m\\x1b[1;3mResponse: In 2021, Uber experienced a higher revenue growth rate of 57% compared to Lyft\\'s growth rate of 36%. This indicates that Uber had a stronger performance in terms of revenue growth during that period. The growth in Uber\\'s revenue was primarily driven by an increase in Gross Bookings, with both Delivery and Mobility segments contributing to the growth. The increase in Delivery Gross Bookings was due to higher demand for food delivery services, while the growth in Mobility Gross Bookings was a result of increased trip volumes as the business recovered from the impacts of COVID-19.\\n    \\x1b[0mIn 2021, Uber experienced a higher revenue growth rate of 57% compared to Lyft\\'s growth rate of 36%. This indicates that Uber had a stronger performance in terms of revenue growth during that period. The growth in Uber\\'s revenue was primarily driven by an increase in Gross Bookings, with both Delivery and Mobility segments contributing to the growth. The increase in Delivery Gross Bookings was due to higher demand for food delivery services, while the growth in Mobility Gross Bookings was a result of increased trip volumes as the business recovered from the impacts of COVID-19.\\n    \\n\\n\\n```python\\nresponse = agent_instruct.chat(\\n    \"Compare and contrast the revenue growth of Uber and Lyft in 2021, then\"\\n    \" give an analysis\"\\n)\\nprint(str(response))\\n```\\n\\n    \\x1b[38;5;200m\\x1b[1;3mResponse: The revenue growth of Uber was higher than Lyft in 2021, with Uber experiencing a 74% growth compared to Lyft\\'s 48%. This indicates that Uber may have had a stronger financial performance in 2021. However, further analysis is needed to fully understand the factors contributing to this difference.\\n    \\x1b[0mThe revenue growth of Uber was higher than Lyft in 2021, with Uber experiencing a 74% growth compared to Lyft\\'s 48%. This indicates that Uber may have had a stronger financial performance in 2021. However, further analysis is needed to fully understand the factors contributing to this difference.\\n    \\n\\n\\n```python\\nresponse = agent.chat(\\n    \"Can you tell me about the risk factors of the company with the higher\"\\n    \" revenue?\"\\n)\\nprint(str(response))\\n```\\n\\n    \\x1b[38;5;200m\\x1b[1;3mThought: I need to find out which company has higher revenue before I can provide information about its risk factors.\\n    Action: lyft_10k\\n    Action Input: {\\'input\\': \\'What is the revenue of Lyft in 2021?\\'}\\n    \\x1b[0m\\x1b[36;1m\\x1b[1;3mObservation: The revenue of Lyft in 2021 is $3,208,323,000.\\n    \\x1b[0m\\x1b[38;5;200m\\x1b[1;3mThought: Now that I know Lyft has higher revenue, I can find information about its risk factors.\\n    Action: lyft_10k\\n    Action Input: {\\'input\\': \\'What are the risk factors of Lyft?\\'}\\n    \\x1b[0m\\x1b[36;1m\\x1b[1;3mObservation: Lyft faces numerous risk factors that could potentially harm its business, financial condition, and results of operations. These risk factors include general economic factors such as the impact of the COVID-19 pandemic, natural disasters, economic downturns, and political crises. Operational factors such as limited operating history, financial performance, competition, unpredictability of results, uncertainty regarding market growth, ability to attract and retain drivers and riders, insurance coverage, autonomous vehicle technology, reputation and brand, illegal or improper activity on the platform, accuracy of background checks, changes to pricing practices, growth management, security and privacy breaches, reliance on third parties, and ability to operate various programs and services. Additionally, Lyft faces risks related to its evolving business, including forecasting revenue and managing expenses, complying with laws and regulations, managing assets and expenses during the COVID-19 pandemic, capital expenditures, asset development and utilization, macroeconomic changes, reputation and brand management, growth and business operations, geographic expansion, talent acquisition and retention, platform development, and real estate portfolio management. Furthermore, Lyft\\'s financial performance in recent periods may not be indicative of future performance, and achieving or maintaining profitability in the future is not guaranteed. The Express Drive program and Lyft Rentals program also expose Lyft to risks related to vehicle rental partners, residual value of vehicles, and payment processing.\\n    \\x1b[0m\\x1b[38;5;200m\\x1b[1;3mResponse: Lyft faces numerous risk factors that could potentially harm its business, financial condition, and results of operations. These risk factors include general economic factors such as the impact of the COVID-19 pandemic, natural disasters, economic downturns, and political crises. Operational factors such as limited operating history, financial performance, competition, unpredictability of results, uncertainty regarding market growth, ability to attract and retain drivers and riders, insurance coverage, autonomous vehicle technology, reputation and brand, illegal or improper activity on the platform, accuracy of background checks, changes to pricing practices, growth management, security and privacy breaches, reliance on third parties, and ability to operate various programs and services. Additionally, Lyft faces risks related to its evolving business, including forecasting revenue and managing expenses, complying with laws and regulations, managing assets and expenses during the COVID-19 pandemic, capital expenditures, asset development and utilization, macroeconomic changes, reputation and brand management, growth and business operations, geographic expansion, talent acquisition and retention, platform development, and real estate portfolio management. Furthermore, Lyft\\'s financial performance in recent periods may not be indicative of future performance, and achieving or maintaining profitability in the future is not guaranteed. The Express Drive program and Lyft Rentals program also expose Lyft to risks related to vehicle rental partners, residual value of vehicles, and payment processing.\\n    \\x1b[0mLyft faces numerous risk factors that could potentially harm its business, financial condition, and results of operations. These risk factors include general economic factors such as the impact of the COVID-19 pandemic, natural disasters, economic downturns, and political crises. Operational factors such as limited operating history, financial performance, competition, unpredictability of results, uncertainty regarding market growth, ability to attract and retain drivers and riders, insurance coverage, autonomous vehicle technology, reputation and brand, illegal or improper activity on the platform, accuracy of background checks, changes to pricing practices, growth management, security and privacy breaches, reliance on third parties, and ability to operate various programs and services. Additionally, Lyft faces risks related to its evolving business, including forecasting revenue and managing expenses, complying with laws and regulations, managing assets and expenses during the COVID-19 pandemic, capital expenditures, asset development and utilization, macroeconomic changes, reputation and brand management, growth and business operations, geographic expansion, talent acquisition and retention, platform development, and real estate portfolio management. Furthermore, Lyft\\'s financial performance in recent periods may not be indicative of future performance, and achieving or maintaining profitability in the future is not guaranteed. The Express Drive program and Lyft Rentals program also expose Lyft to risks related to vehicle rental partners, residual value of vehicles, and payment processing.\\n    \\n\\n\\n```python\\nresponse = agent_instruct.query(\\n    \"Can you tell me about the risk factors of the company with the higher\"\\n    \" revenue?\"\\n)\\nprint(str(response))\\n```\\n\\n    \\x1b[38;5;200m\\x1b[1;3mResponse: The risk factors for the company with the higher revenue include competition, regulatory changes, and dependence on drivers.\\n    \\x1b[0mThe risk factors for the company with the higher revenue include competition, regulatory changes, and dependence on drivers.\\n    \\n\\n**Observation**: The turbo-instruct agent seems to do worse on agent reasoning compared to the regular turbo model. Of course, this is subject to further observation!\\n', metadata={'source': '/mnt/c/Users/User/Documents/AI_ML/career_ai_engineer/Projects/ai_apps_assistant/llamaindex_docs/test_llamaindex.json', 'seq_num': 18, 'filename': 'react_agent_with_query_engine.ipynb', 'filepath': 'docs/examples/agent/react_agent_with_query_engine.ipynb', 'url': 'https://github.com/run-llama/llama_index/blob/3823389e3f91cab47b72e2cc2814826db9f98e32/docs/examples/agent/react_agent_with_query_engine.ipynb'})]\n"
     ]
    }
   ],
   "source": [
    "# Print the loaded documents to verify\n",
    "pprint(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming we want to split on primary and secondary headers in Markdown\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the MarkdownHeaderTextSplitter with specified headers\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the initial split based on headers\n",
    "all_splits = []\n",
    "for document in data:\n",
    "    # Split the Markdown content of the document\n",
    "    splits = markdown_splitter.split_text(document.page_content)\n",
    "    # Append the resulting documents to the all_splits list\n",
    "    all_splits.extend(splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/agent_builder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>  \\nInspired by GPTs interface, presented at OpenAI Dev Day 2023. Construct an agent with natural language.  \\nHere you can build your own agent...with another agent!  \\n```python\\nfrom llama_index.tools import BaseTool, FunctionTool\\n```  \\n```python\\nfrom llama_index.agent import OpenAIAgent\\nfrom llama_index.prompts import PromptTemplate\\nfrom llama_index.llms import ChatMessage, OpenAI\\nfrom llama_index import ServiceContext\\n```  \\n```python\\nllm = OpenAI(model=\"gpt-4\")\\nservice_context = ServiceContext.from_defaults(llm=llm)\\n```', metadata={'Header 1': 'GPT Builder Demo'}),\n",
      " Document(page_content='We also define a tool retriever to retrieve candidate tools.  \\nIn this setting we define tools as different Wikipedia pages.  \\n```python\\nfrom llama_index import SimpleDirectoryReader\\n```  \\n```python\\nwiki_titles = [\"Toronto\", \"Seattle\", \"Chicago\", \"Boston\", \"Houston\"]\\n```  \\n```python\\nfrom pathlib import Path\\n\\nimport requests\\n\\nfor title in wiki_titles:\\nresponse = requests.get(\\n\"https://en.wikipedia.org/w/api.php\",\\nparams={\\n\"action\": \"query\",\\n\"format\": \"json\",\\n\"titles\": title,\\n\"prop\": \"extracts\",\\n# \\'exintro\\': True,\\n\"explaintext\": True,\\n},\\n).json()\\npage = next(iter(response[\"query\"][\"pages\"].values()))\\nwiki_text = page[\"extract\"]\\n\\ndata_path = Path(\"data\")\\nif not data_path.exists():\\nPath.mkdir(data_path)\\n\\nwith open(data_path / f\"{title}.txt\", \"w\") as fp:\\nfp.write(wiki_text)\\n```  \\n```python\\n# Load all wiki documents\\ncity_docs = {}\\nfor wiki_title in wiki_titles:\\ncity_docs[wiki_title] = SimpleDirectoryReader(\\ninput_files=[f\"data/{wiki_title}.txt\"]\\n).load_data()\\n```', metadata={'Header 1': 'GPT Builder Demo', 'Header 2': 'Define Candidate Tools'}),\n",
      " Document(page_content='```python\\nfrom llama_index.agent import OpenAIAgent\\nfrom llama_index.tools import QueryEngineTool, ToolMetadata\\n\\n# Build tool dictionary\\ntool_dict = {}\\n\\nfor wiki_title in wiki_titles:\\n# build vector index\\nvector_index = VectorStoreIndex.from_documents(\\ncity_docs[wiki_title], service_context=service_context\\n)\\n# define query engines\\nvector_query_engine = vector_index.as_query_engine()\\n\\n# define tools\\nvector_tool = QueryEngineTool(\\nquery_engine=vector_query_engine,\\nmetadata=ToolMetadata(\\nname=wiki_title,\\ndescription=(\"Useful for questions related to\" f\" {wiki_title}\"),\\n),\\n)\\ntool_dict[wiki_title] = vector_tool\\n```', metadata={'Header 1': 'GPT Builder Demo', 'Header 2': 'Define Candidate Tools', 'Header 3': 'Build Query Tool for Each Document'}),\n",
      " Document(page_content='```python\\n# define an \"object\" index and retriever over these tools\\nfrom llama_index import VectorStoreIndex\\nfrom llama_index.objects import ObjectIndex, SimpleToolNodeMapping\\n\\ntool_mapping = SimpleToolNodeMapping.from_objects(list(tool_dict.values()))\\ntool_index = ObjectIndex.from_objects(\\nlist(tool_dict.values()),\\ntool_mapping,\\nVectorStoreIndex,\\n)\\ntool_retriever = tool_index.as_retriever(similarity_top_k=1)\\n```', metadata={'Header 1': 'GPT Builder Demo', 'Header 2': 'Define Candidate Tools', 'Header 3': 'Define Tool Retriever'}),\n",
      " Document(page_content='Here we load wikipedia pages from different cities.', metadata={'Header 1': 'GPT Builder Demo', 'Header 2': 'Define Candidate Tools', 'Header 3': 'Load Data'}),\n",
      " Document(page_content='```python\\nfrom llama_index.prompts import ChatPromptTemplate\\nfrom typing import List\\n\\nGEN_SYS_PROMPT_STR = \"\"\"\\\\\\nTask information is given below.\\n\\nGiven the task, please generate a system prompt for an OpenAI-powered bot to solve this task:\\n{task} \\\\\\n\"\"\"\\n\\ngen_sys_prompt_messages = [\\nChatMessage(\\nrole=\"system\",\\ncontent=\"You are helping to build a system prompt for another bot.\",\\n),\\nChatMessage(role=\"user\", content=GEN_SYS_PROMPT_STR),\\n]\\n\\nGEN_SYS_PROMPT_TMPL = ChatPromptTemplate(gen_sys_prompt_messages)\\n\\n\\nagent_cache = {}\\n\\n\\ndef create_system_prompt(task: str):\\n\"\"\"Create system prompt for another agent given an input task.\"\"\"\\nllm = OpenAI(llm=\"gpt-4\")\\nfmt_messages = GEN_SYS_PROMPT_TMPL.format_messages(task=task)\\nresponse = llm.chat(fmt_messages)\\nreturn response.message.content\\n\\n\\ndef get_tools(task: str):\\n\"\"\"Get the set of relevant tools to use given an input task.\"\"\"\\nsubset_tools = tool_retriever.retrieve(task)\\nreturn [t.metadata.name for t in subset_tools]\\n\\n\\ndef create_agent(system_prompt: str, tool_names: List[str]):\\n\"\"\"Create an agent given a system prompt and an input set of tools.\"\"\"\\nllm = OpenAI(model=\"gpt-4\")\\ntry:\\n# get the list of tools\\ninput_tools = [tool_dict[tn] for tn in tool_names]\\n\\nagent = OpenAIAgent.from_tools(input_tools, llm=llm, verbose=True)\\nagent_cache[\"agent\"] = agent\\nreturn_msg = \"Agent created successfully.\"\\nexcept Exception as e:\\nreturn_msg = f\"An error occurred when building an agent. Here is the error: {repr(e)}\"\\nreturn return_msg\\n```  \\n```python\\nsystem_prompt_tool = FunctionTool.from_defaults(fn=create_system_prompt)\\nget_tools_tool = FunctionTool.from_defaults(fn=get_tools)\\ncreate_agent_tool = FunctionTool.from_defaults(fn=create_agent)\\n```  \\n```python\\nGPT_BUILDER_SYS_STR = \"\"\"\\\\\\nYou are helping to construct an agent given a user-specified task. You should generally use the tools in this order to build the agent.\\n\\n1) Create system prompt tool: to create the system prompt for the agent.\\n2) Get tools tool: to fetch the candidate set of tools to use.\\n3) Create agent tool: to create the final agent.\\n\"\"\"\\n\\nprefix_msgs = [ChatMessage(role=\"system\", content=GPT_BUILDER_SYS_STR)]\\n\\n\\nbuilder_agent = OpenAIAgent.from_tools(\\ntools=[system_prompt_tool, get_tools_tool, create_agent_tool],\\nllm=llm,\\nprefix_messages=prefix_msgs,\\nverbose=True,\\n)\\n```  \\n```python\\nbuilder_agent.query(\"Build an agent that can tell me about Toronto.\")\\n```  \\n=== Calling Function ===\\nCalling function: create_system_prompt with args: {\\n\"task\": \"tell me about Toronto\"\\n}\\nGot output: System Prompt:  \\n\"Sure, I can provide you with information about Toronto. Toronto is the capital city of the province of Ontario, Canada. It is the largest city in Canada and one of the most multicultural cities in the world. Known for its diverse population, vibrant arts scene, and thriving business community, Toronto offers a wide range of attractions and experiences.  \\nToronto is home to iconic landmarks such as the CN Tower, which offers breathtaking views of the city, and the Royal Ontario Museum, which houses an extensive collection of art, culture, and natural history. The city also boasts beautiful waterfront areas, including the Harbourfront Centre and the Toronto Islands, where visitors can enjoy outdoor activities and scenic views.  \\nIn terms of culture, Toronto hosts numerous festivals throughout the year, including the Toronto International Film Festival, Caribana, and Nuit Blanche. The city is also known for its world-class dining scene, offering a diverse range of cuisines from around the globe.  \\nToronto is a major economic hub, with a strong presence in industries such as finance, technology, and healthcare. It is home to the Toronto Stock Exchange and several multinational corporations. The city\\'s robust public transportation system, including the TTC subway and streetcar network, makes it easy to navigate and explore.  \\nWhether you\\'re interested in exploring its cultural attractions, enjoying its culinary delights, or experiencing its vibrant nightlife, Toronto has something to offer for everyone. How can I assist you further in discovering more about Toronto?\"\\n========================\\n=== Calling Function ===\\nCalling function: get_tools with args: {\\n\"task\": \"tell me about Toronto\"\\n}\\nGot output: [\\'Toronto\\']\\n========================\\n=== Calling Function ===\\nCalling function: create_agent with args: {\\n\"system_prompt\": \"Sure, I can provide you with information about Toronto. Toronto is the capital city of the province of Ontario, Canada. It is the largest city in Canada and one of the most multicultural cities in the world. Known for its diverse population, vibrant arts scene, and thriving business community, Toronto offers a wide range of attractions and experiences.\\\\n\\\\nToronto is home to iconic landmarks such as the CN Tower, which offers breathtaking views of the city, and the Royal Ontario Museum, which houses an extensive collection of art, culture, and natural history. The city also boasts beautiful waterfront areas, including the Harbourfront Centre and the Toronto Islands, where visitors can enjoy outdoor activities and scenic views.\\\\n\\\\nIn terms of culture, Toronto hosts numerous festivals throughout the year, including the Toronto International Film Festival, Caribana, and Nuit Blanche. The city is also known for its world-class dining scene, offering a diverse range of cuisines from around the globe.\\\\n\\\\nToronto is a major economic hub, with a strong presence in industries such as finance, technology, and healthcare. It is home to the Toronto Stock Exchange and several multinational corporations. The city\\'s robust public transportation system, including the TTC subway and streetcar network, makes it easy to navigate and explore.\\\\n\\\\nWhether you\\'re interested in exploring its cultural attractions, enjoying its culinary delights, or experiencing its vibrant nightlife, Toronto has something to offer for everyone. How can I assist you further in discovering more about Toronto?\",\\n\"tool_names\": [\"Toronto\"]\\n}\\nGot output: Agent created successfully.\\n========================  \\nResponse(response=\\'The agent has been successfully created. It can provide detailed information about Toronto, including its landmarks, culture, economy, and transportation.\\', source_nodes=[], metadata=None)  \\n```python\\ncity_agent = agent_cache[\"agent\"]\\n```  \\n```python\\nresponse = city_agent.query(\"Tell me about the parks in Toronto\")\\nprint(str(response))\\n```  \\n=== Calling Function ===\\nCalling function: Toronto with args: {\\n\"input\": \"parks in Toronto\"\\n}\\nGot output: Toronto has a wide variety of public parks and spaces. Some of the downtown parks include Allan Gardens, Christie Pits, Grange Park, Little Norway Park, Moss Park, Queen\\'s Park, Riverdale Park and Trinity Bellwoods Park. There are also two large parks on the waterfront south of downtown: Tommy Thompson Park and the Toronto Islands. Other large parks managed by the city in the outer areas include High Park, Humber Bay Park, Centennial Park, Downsview Park, Guild Park and Gardens, Sunnybrook Park and Morningside Park. Toronto also has parts of Rouge National Urban Park, the largest urban park in North America, which is managed by Parks Canada.\\n========================\\nToronto is home to a variety of parks, offering a mix of natural beauty, recreational activities, and cultural experiences. Here are some of the notable parks in Toronto:  \\n1. **Allan Gardens**: Located downtown, this park features a conservatory with six greenhouses showcasing rare botanical plants.  \\n2. **Christie Pits**: Known for its outdoor pool and artificial ice rink, this park is a popular spot for sports and leisure.  \\n3. **Grange Park**: This park is located in the heart of the city and offers a playground, a splash pad, and a dog off-leash area.  \\n4. **Little Norway Park**: Overlooking the waterfront, this park features a playground, a wading pool, and a baseball diamond.  \\n5. **Moss Park**: This downtown park has a large sports field, a playground, and a splash pad.  \\n6. **Queen\\'s Park**: This urban park is home to the Ontario Legislative Building and several monuments.  \\n7. **Riverdale Park**: Offering panoramic views of downtown Toronto, this park has sports fields, a swimming pool, and a large off-leash dog area.  \\n8. **Trinity Bellwoods Park**: This popular park features a variety of recreational facilities, including sports fields, a wading pool, and a children\\'s playground.  \\n9. **Tommy Thompson Park**: Located on the waterfront, this park is a popular spot for bird watching and nature walks.  \\n10. **Toronto Islands**: This group of small islands offers beaches, picnic areas, and canoe rentals.  \\n11. **High Park**: Toronto\\'s largest public park, featuring hiking trails, sports facilities, a beautiful lakefront, a dog park, a zoo, and several playgrounds.  \\n12. **Humber Bay Park**: This waterfront park offers stunning views of the Toronto skyline, a butterfly habitat, and a network of trails.  \\n13. **Centennial Park**: One of Toronto\\'s busiest parks, featuring a conservatory, a ski hill, a golf centre, and a multipurpose sports field.  \\n14. **Downsview Park**: Once a military base, now a dynamic urban park with sports fields, a pond, and a forested area.  \\n15. **Guild Park and Gardens**: Known for its collection of salvaged architectural pieces, this park offers a unique blend of nature and culture.  \\n16. **Sunnybrook Park**: This park offers a variety of sports fields, horse stables, and a dog off-leash area.  \\n17. **Morningside Park**: One of Toronto\\'s largest parks, featuring picnic areas, walking trails, and a creek.  \\n18. **Rouge National Urban Park**: Managed by Parks Canada, this is the largest urban park in North America, offering a mix of wilderness, farmland, and historical sites.', metadata={'Header 1': 'GPT Builder Demo', 'Header 2': 'Define Meta-Tools for GPT Builder'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/Chatbot_SEC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>'),\n",
      " Document(page_content=\"LlamaIndex serves as a bridge between your data and Language Learning Models (LLMs), providing a toolkit that enables you to establish a query interface around your data for a variety of tasks, such as question-answering and summarization.  \\nIn this tutorial, we'll walk you through building a context-augmented chatbot using a [Data Agent](https://gpt-index.readthedocs.io/en/stable/core_modules/agent_modules/agents/root.html). This agent, powered by LLMs, is capable of intelligently executing tasks over your data. The end result is a chatbot agent equipped with a robust set of data interface tools provided by LlamaIndex to answer queries about your data.  \\n**Note**: This tutorial builds upon initial work on creating a query interface over SEC 10-K filings - [check it out here](https://medium.com/@jerryjliu98/how-unstructured-and-llamaindex-can-help-bring-the-power-of-llms-to-your-own-data-3657d063e30d).\", metadata={'Header 1': '💬🤖 How to Build a Chatbot'}),\n",
      " Document(page_content='In this guide, we’ll build a \"10-K Chatbot\" that uses raw UBER 10-K HTML filings from Dropbox. Users can interact with the chatbot to ask questions related to the 10-K filings.', metadata={'Header 1': '💬🤖 How to Build a Chatbot', 'Header 3': 'Context'}),\n",
      " Document(page_content='```python\\nimport os\\nimport openai\\n\\nos.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\\nopenai.api_key = os.environ[\"OPENAI_API_KEY\"]\\n\\nimport nest_asyncio\\n\\nnest_asyncio.apply()\\n```  \\n```python\\n# set text wrapping\\nfrom IPython.display import HTML, display\\n\\n\\ndef set_css():\\ndisplay(\\nHTML(\\n\"\"\"\\n<style>\\npre {\\nwhite-space: pre-wrap;\\n}\\n</style>\\n\"\"\"\\n)\\n)\\n\\n\\nget_ipython().events.register(\"pre_run_cell\", set_css)\\n```', metadata={'Header 1': '💬🤖 How to Build a Chatbot', 'Header 3': 'Preparation'}),\n",
      " Document(page_content='Let\\'s first download the raw 10-k files, from 2019-2022.  \\n```python\\n# NOTE: the code examples assume you\\'re operating within a Jupyter notebook.\\n# download files\\n!mkdir data\\n!wget \"https://www.dropbox.com/s/948jr9cfs7fgj99/UBER.zip?dl=1\" -O data/UBER.zip\\n!unzip data/UBER.zip -d data\\n```  \\n<style>\\npre {\\nwhite-space: pre-wrap;\\n}\\n</style>  \\n--2023-09-22 11:13:42--  https://www.dropbox.com/s/948jr9cfs7fgj99/UBER.zip?dl=1\\nResolving www.dropbox.com (www.dropbox.com)... 2620:100:601f:18::a27d:912, 162.125.5.18\\nConnecting to www.dropbox.com (www.dropbox.com)|2620:100:601f:18::a27d:912|:443... connected.\\nHTTP request sent, awaiting response... 302 Found\\nLocation: /s/dl/948jr9cfs7fgj99/UBER.zip [following]\\n--2023-09-22 11:13:43--  https://www.dropbox.com/s/dl/948jr9cfs7fgj99/UBER.zip\\nReusing existing connection to [www.dropbox.com]:443.\\nHTTP request sent, awaiting response... 302 Found\\nLocation: https://uc5e96fc71f5bcad342d7ef5261b.dl.dropboxusercontent.com/cd/0/get/CEMPMHdxNS2yZDvMeO8IVhjAHBo1ExUFCUxxR3rUUAuuAn2VBlNyyyzCCERRU4Uj9cVyRgHADCluk4Kqqe1NWdxiC1Uh1u85EJEPIlVuW1gK9-KC3EcD0tD7u21w14I6d80gfspvvfKJCFzc15556zTV/file?dl=1# [following]\\n--2023-09-22 11:13:43--  https://uc5e96fc71f5bcad342d7ef5261b.dl.dropboxusercontent.com/cd/0/get/CEMPMHdxNS2yZDvMeO8IVhjAHBo1ExUFCUxxR3rUUAuuAn2VBlNyyyzCCERRU4Uj9cVyRgHADCluk4Kqqe1NWdxiC1Uh1u85EJEPIlVuW1gK9-KC3EcD0tD7u21w14I6d80gfspvvfKJCFzc15556zTV/file?dl=1\\nResolving uc5e96fc71f5bcad342d7ef5261b.dl.dropboxusercontent.com (uc5e96fc71f5bcad342d7ef5261b.dl.dropboxusercontent.com)... 2620:100:601f:15::a27d:90f, 162.125.5.15\\nConnecting to uc5e96fc71f5bcad342d7ef5261b.dl.dropboxusercontent.com (uc5e96fc71f5bcad342d7ef5261b.dl.dropboxusercontent.com)|2620:100:601f:15::a27d:90f|:443... connected.\\nHTTP request sent, awaiting response... 200 OK\\nLength: 1820227 (1,7M) [application/binary]\\nSaving to: ‘data/UBER.zip’  \\ndata/UBER.zip       100%[===================>]   1,74M  3,12MB/s    in 0,6s  \\n2023-09-22 11:13:45 (3,12 MB/s) - ‘data/UBER.zip’ saved [1820227/1820227]  \\nArchive:  data/UBER.zip\\ncreating: data/UBER/\\ninflating: data/UBER/UBER_2021.html\\ninflating: data/__MACOSX/UBER/._UBER_2021.html\\ninflating: data/UBER/UBER_2020.html\\ninflating: data/__MACOSX/UBER/._UBER_2020.html\\ninflating: data/UBER/UBER_2019.html\\ninflating: data/__MACOSX/UBER/._UBER_2019.html\\ninflating: data/UBER/UBER_2022.html\\ninflating: data/__MACOSX/UBER/._UBER_2022.html  \\nTo parse the HTML files into formatted text, we use the [Unstructured](https://github.com/Unstructured-IO/unstructured) library. Thanks to [LlamaHub](https://llamahub.ai/), we can directly integrate with Unstructured, allowing conversion of any text into a Document format that LlamaIndex can ingest.  \\nFirst we install the necessary packages:  \\n```python\\n!pip install llama-hub unstructured\\n```  \\n<style>\\npre {\\nwhite-space: pre-wrap;\\n}\\n</style>  \\nCollecting llama-hub\\nObtaining dependency information for llama-hub from https://files.pythonhosted.org/packages/3f/af/3bc30c2b7ca1bdd7a193f67443539f6667a6b77dd62e54f2c5c8464ad4cb/llama_hub-0.0.31-py3-none-any.whl.metadata\\nDownloading llama_hub-0.0.31-py3-none-any.whl.metadata (8.8 kB)\\nRequirement already satisfied: unstructured in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (0.10.15)\\nCollecting atlassian-python-api (from llama-hub)\\nObtaining dependency information for atlassian-python-api from https://files.pythonhosted.org/packages/ca/ed/3577ccec639736c8e4660423be68cf1a4a7040bf543b3144793760792949/atlassian_python_api-3.41.2-py3-none-any.whl.metadata\\nDownloading atlassian_python_api-3.41.2-py3-none-any.whl.metadata (8.7 kB)\\nCollecting html2text (from llama-hub)\\nDownloading html2text-2020.1.16-py3-none-any.whl (32 kB)\\nRequirement already satisfied: llama-index>=0.6.9 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from llama-hub) (0.8.29.post1)\\nRequirement already satisfied: psutil in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from llama-hub) (5.9.5)\\nCollecting retrying (from llama-hub)\\nDownloading retrying-1.3.4-py3-none-any.whl (11 kB)\\nRequirement already satisfied: chardet in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from unstructured) (5.2.0)\\nRequirement already satisfied: filetype in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from unstructured) (1.2.0)\\nRequirement already satisfied: python-magic in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from unstructured) (0.4.27)\\nRequirement already satisfied: lxml in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from unstructured) (4.9.3)\\nRequirement already satisfied: nltk in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from unstructured) (3.8.1)\\nRequirement already satisfied: tabulate in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from unstructured) (0.9.0)\\nRequirement already satisfied: requests in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from unstructured) (2.31.0)\\nRequirement already satisfied: beautifulsoup4 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from unstructured) (4.12.2)\\nRequirement already satisfied: emoji in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from unstructured) (2.8.0)\\nRequirement already satisfied: dataclasses-json in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from unstructured) (0.5.14)\\nRequirement already satisfied: tiktoken in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from llama-index>=0.6.9->llama-hub) (0.5.1)\\nRequirement already satisfied: langchain>=0.0.293 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from llama-index>=0.6.9->llama-hub) (0.0.295)\\nRequirement already satisfied: sqlalchemy>=2.0.15 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from llama-index>=0.6.9->llama-hub) (2.0.21)\\nRequirement already satisfied: numpy in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from llama-index>=0.6.9->llama-hub) (1.26.0)\\nRequirement already satisfied: tenacity<9.0.0,>=8.2.0 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from llama-index>=0.6.9->llama-hub) (8.2.3)\\nRequirement already satisfied: openai>=0.26.4 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from llama-index>=0.6.9->llama-hub) (0.28.0)\\nRequirement already satisfied: pandas in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from llama-index>=0.6.9->llama-hub) (2.1.0)\\nRequirement already satisfied: urllib3<2 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from llama-index>=0.6.9->llama-hub) (1.26.16)\\nRequirement already satisfied: fsspec>=2023.5.0 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from llama-index>=0.6.9->llama-hub) (2023.9.1)\\nRequirement already satisfied: typing-inspect>=0.8.0 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from llama-index>=0.6.9->llama-hub) (0.9.0)\\nRequirement already satisfied: typing-extensions>=4.5.0 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from llama-index>=0.6.9->llama-hub) (4.8.0)\\nRequirement already satisfied: nest-asyncio in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from llama-index>=0.6.9->llama-hub) (1.5.8)\\nCollecting deprecated (from atlassian-python-api->llama-hub)\\nObtaining dependency information for deprecated from https://files.pythonhosted.org/packages/20/8d/778b7d51b981a96554f29136cd59ca7880bf58094338085bcf2a979a0e6a/Deprecated-1.2.14-py2.py3-none-any.whl.metadata\\nDownloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\\nRequirement already satisfied: six in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from atlassian-python-api->llama-hub) (1.16.0)\\nRequirement already satisfied: oauthlib in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from atlassian-python-api->llama-hub) (3.2.2)\\nRequirement already satisfied: requests-oauthlib in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from atlassian-python-api->llama-hub) (1.3.1)\\nRequirement already satisfied: soupsieve>1.2 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from beautifulsoup4->unstructured) (2.5)\\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from dataclasses-json->unstructured) (3.20.1)\\nRequirement already satisfied: click in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from nltk->unstructured) (8.1.7)\\nRequirement already satisfied: joblib in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from nltk->unstructured) (1.3.2)\\nRequirement already satisfied: regex>=2021.8.3 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from nltk->unstructured) (2023.8.8)\\nRequirement already satisfied: tqdm in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from nltk->unstructured) (4.66.1)\\nRequirement already satisfied: charset-normalizer<4,>=2 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from requests->unstructured) (3.2.0)\\nRequirement already satisfied: idna<4,>=2.5 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from requests->unstructured) (3.4)\\nRequirement already satisfied: certifi>=2017.4.17 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from requests->unstructured) (2023.7.22)\\nRequirement already satisfied: PyYAML>=5.3 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from langchain>=0.0.293->llama-index>=0.6.9->llama-hub) (6.0.1)\\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from langchain>=0.0.293->llama-index>=0.6.9->llama-hub) (3.8.5)\\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from langchain>=0.0.293->llama-index>=0.6.9->llama-hub) (4.0.3)\\nRequirement already satisfied: langsmith<0.1.0,>=0.0.38 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from langchain>=0.0.293->llama-index>=0.6.9->llama-hub) (0.0.38)\\nRequirement already satisfied: numexpr<3.0.0,>=2.8.4 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from langchain>=0.0.293->llama-index>=0.6.9->llama-hub) (2.8.6)\\nRequirement already satisfied: pydantic<3,>=1 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from langchain>=0.0.293->llama-index>=0.6.9->llama-hub) (1.10.12)\\nRequirement already satisfied: packaging>=17.0 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured) (23.1)\\nRequirement already satisfied: greenlet!=0.4.17 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from sqlalchemy>=2.0.15->llama-index>=0.6.9->llama-hub) (2.0.2)\\nRequirement already satisfied: mypy-extensions>=0.3.0 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index>=0.6.9->llama-hub) (1.0.0)\\nRequirement already satisfied: wrapt<2,>=1.10 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from deprecated->atlassian-python-api->llama-hub) (1.15.0)\\nRequirement already satisfied: python-dateutil>=2.8.2 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from pandas->llama-index>=0.6.9->llama-hub) (2.8.2)\\nRequirement already satisfied: pytz>=2020.1 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from pandas->llama-index>=0.6.9->llama-hub) (2023.3.post1)\\nRequirement already satisfied: tzdata>=2022.1 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from pandas->llama-index>=0.6.9->llama-hub) (2023.3)\\nRequirement already satisfied: attrs>=17.3.0 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.293->llama-index>=0.6.9->llama-hub) (23.1.0)\\nRequirement already satisfied: multidict<7.0,>=4.5 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.293->llama-index>=0.6.9->llama-hub) (6.0.4)\\nRequirement already satisfied: yarl<2.0,>=1.0 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.293->llama-index>=0.6.9->llama-hub) (1.9.2)\\nRequirement already satisfied: frozenlist>=1.1.1 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.293->llama-index>=0.6.9->llama-hub) (1.4.0)\\nRequirement already satisfied: aiosignal>=1.1.2 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.293->llama-index>=0.6.9->llama-hub) (1.3.1)\\nDownloading llama_hub-0.0.31-py3-none-any.whl (9.8 MB)\\n\\x1b[2K   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m9.8/9.8 MB\\x1b[0m \\x1b[31m16.4 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m00:01\\x1b[0m00:01\\x1b[0m\\n\\x1b[?25hDownloading atlassian_python_api-3.41.2-py3-none-any.whl (167 kB)\\n\\x1b[2K   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m167.2/167.2 kB\\x1b[0m \\x1b[31m20.8 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m\\n\\x1b[?25hDownloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\\nInstalling collected packages: retrying, html2text, deprecated, atlassian-python-api, llama-hub\\nSuccessfully installed atlassian-python-api-3.41.2 deprecated-1.2.14 html2text-2020.1.16 llama-hub-0.0.31 retrying-1.3.4  \\nThen we can use the `UnstructuredReader` to parse the HTML files into a list of `Document` objects.  \\n```python\\nfrom llama_hub.file.unstructured.base import UnstructuredReader\\nfrom pathlib import Path\\n\\nyears = [2022, 2021, 2020, 2019]\\n\\nloader = UnstructuredReader()\\ndoc_set = {}\\nall_docs = []\\nfor year in years:\\nyear_docs = loader.load_data(\\nfile=Path(f\"./data/UBER/UBER_{year}.html\"), split_documents=False\\n)\\n# insert year metadata into each year\\nfor d in year_docs:\\nd.metadata = {\"year\": year}\\ndoc_set[year] = year_docs\\nall_docs.extend(year_docs)\\n```  \\n<style>\\npre {\\nwhite-space: pre-wrap;\\n}\\n</style>  \\n[nltk_data] Downloading package punkt to /home/jtorres/nltk_data...\\n[nltk_data]   Package punkt is already up-to-date!\\n[nltk_data] Downloading package averaged_perceptron_tagger to\\n[nltk_data]     /home/jtorres/nltk_data...\\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\\n[nltk_data]       date!', metadata={'Header 1': '💬🤖 How to Build a Chatbot', 'Header 3': 'Ingest Data'}),\n",
      " Document(page_content='We first setup a vector index for each year. Each vector index allows us\\nto ask questions about the 10-K filing of a given year.  \\nWe build each index and save it to disk.  \\n```python\\n# initialize simple vector indices\\n# NOTE: don\\'t run this cell if the indices are already loaded!\\nfrom llama_index import VectorStoreIndex, ServiceContext, StorageContext\\n\\nindex_set = {}\\nservice_context = ServiceContext.from_defaults(chunk_size=512)\\nfor year in years:\\nstorage_context = StorageContext.from_defaults()\\ncur_index = VectorStoreIndex.from_documents(\\ndoc_set[year],\\nservice_context=service_context,\\nstorage_context=storage_context,\\n)\\nindex_set[year] = cur_index\\nstorage_context.persist(persist_dir=f\"./storage/{year}\")\\n```  \\n<style>\\npre {\\nwhite-space: pre-wrap;\\n}\\n</style>  \\nTo load an index from disk, do the following  \\n```python\\n# Load indices from disk\\nfrom llama_index import load_index_from_storage\\n\\nindex_set = {}\\nfor year in years:\\nstorage_context = StorageContext.from_defaults(\\npersist_dir=f\"./storage/{year}\"\\n)\\ncur_index = load_index_from_storage(\\nstorage_context, service_context=service_context\\n)\\nindex_set[year] = cur_index\\n```  \\n<style>\\npre {\\nwhite-space: pre-wrap;\\n}\\n</style>', metadata={'Header 1': '💬🤖 How to Build a Chatbot', 'Header 3': 'Setting up Vector Indices for each year'}),\n",
      " Document(page_content='Since we have access to documents of 4 years, we may not only want to ask questions regarding the 10-K document of a given year, but ask questions that require analysis over all 10-K filings.  \\nTo address this, we can use a [Sub Question Query Engine](https://gpt-index.readthedocs.io/en/stable/examples/query_engine/sub_question_query_engine.html). It decomposes a query into subqueries, each answered by an individual vector index, and synthesizes the results to answer the overall query.  \\nLlamaIndex provides some wrappers around indices (and query engines) so that they can be used by query engines and agents. First we define a `QueryEngineTool` for each vector index.\\nEach tool has a name and a description; these are what the LLM agent sees to decide which tool to choose.  \\n```python\\nfrom llama_index.tools import QueryEngineTool, ToolMetadata\\n\\nindividual_query_engine_tools = [\\nQueryEngineTool(\\nquery_engine=index_set[year].as_query_engine(),\\nmetadata=ToolMetadata(\\nname=f\"vector_index_{year}\",\\ndescription=(\\n\"useful for when you want to answer queries about the\"\\nf\" {year} SEC 10-K for Uber\"\\n),\\n),\\n)\\nfor year in years\\n]\\n```  \\n<style>\\npre {\\nwhite-space: pre-wrap;\\n}\\n</style>  \\nNow we can create the Sub Question Query Engine, which will allow us to synthesize answers across the 10-K filings. We pass in the `individual_query_engine_tools` we defined above, as well as a `service_context` that will be used to run the subqueries.  \\n```python\\nfrom llama_index.query_engine import SubQuestionQueryEngine\\n\\nquery_engine = SubQuestionQueryEngine.from_defaults(\\nquery_engine_tools=individual_query_engine_tools,\\nservice_context=service_context,\\n)\\n```  \\n<style>\\npre {\\nwhite-space: pre-wrap;\\n}\\n</style>', metadata={'Header 1': '💬🤖 How to Build a Chatbot', 'Header 3': 'Setting up a Sub Question Query Engine to Synthesize Answers Across 10-K Filings'}),\n",
      " Document(page_content='We use a LlamaIndex Data Agent to setup the outer chatbot agent, which has access to a set of Tools. Specifically, we will use an OpenAIAgent, that takes advantage of OpenAI API function calling. We want to use the separate Tools we defined previously for each index (corresponding to a given year), as well as a tool for the sub question query engine we defined above.  \\nFirst we define a `QueryEngineTool` for the sub question query engine:  \\n```python\\nquery_engine_tool = QueryEngineTool(\\nquery_engine=query_engine,\\nmetadata=ToolMetadata(\\nname=\"sub_question_query_engine\",\\ndescription=(\\n\"useful for when you want to answer queries that require analyzing\"\\n\" multiple SEC 10-K documents for Uber\"\\n),\\n),\\n)\\n```  \\n<style>\\npre {\\nwhite-space: pre-wrap;\\n}\\n</style>  \\nThen, we combine the Tools we defined above into a single list of tools for the agent:  \\n```python\\ntools = individual_query_engine_tools + [query_engine_tool]\\n```  \\n<style>\\npre {\\nwhite-space: pre-wrap;\\n}\\n</style>  \\nFinally, we call `OpenAIAgent.from_tools` to create the agent, passing in the list of tools we defined above.  \\n```python\\nfrom llama_index.agent import OpenAIAgent\\n\\nagent = OpenAIAgent.from_tools(tools, verbose=True)\\n```  \\n<style>\\npre {\\nwhite-space: pre-wrap;\\n}\\n</style>', metadata={'Header 1': '💬🤖 How to Build a Chatbot', 'Header 3': 'Setting up the Chatbot Agent'}),\n",
      " Document(page_content='We can now test the agent with various queries.  \\nIf we test it with a simple \"hello\" query, the agent does not use any Tools.  \\n```python\\nresponse = agent.chat(\"hi, i am bob\")\\nprint(str(response))\\n```  \\n<style>\\npre {\\nwhite-space: pre-wrap;\\n}\\n</style>  \\nHello Bob! How can I assist you today?  \\nIf we test it with a query regarding the 10-k of a given year, the agent will use\\nthe relevant vector index Tool.  \\n```python\\nresponse = agent.chat(\\n\"What were some of the biggest risk factors in 2020 for Uber?\"\\n)\\nprint(str(response))\\n```  \\n<style>\\npre {\\nwhite-space: pre-wrap;\\n}\\n</style>  \\n=== Calling Function ===\\nCalling function: vector_index_2020 with args: {\\n\"input\": \"biggest risk factors\"\\n}\\nGot output: The biggest risk factors mentioned in the context are:\\n1. The adverse impact of the COVID-19 pandemic and actions taken to mitigate it on the business.\\n2. The potential reclassification of drivers as employees, workers, or quasi-employees instead of independent contractors.\\n3. Intense competition in the mobility, delivery, and logistics industries, with low barriers to entry and well-capitalized competitors.\\n4. The need to lower fares or service fees and offer driver incentives and consumer discounts to remain competitive.\\n5. Significant losses incurred and the uncertainty of achieving profitability.\\n6. The risk of not attracting or maintaining a critical mass of platform users.\\n7. Operational, compliance, and cultural challenges related to the workplace culture and forward-leaning approach.\\n8. The potential negative impact of international investments and the challenges of conducting business in foreign countries, including operational and compliance challenges, localization requirements, restrictive laws and regulations, competition from local companies, social acceptance, technological compatibility, improper business practices, legal uncertainty, difficulties in managing international operations, currency exchange rate fluctuations, and regulations governing local currencies.\\n========================\\nIn 2020, some of the biggest risk factors for Uber were:  \\n1. The adverse impact of the COVID-19 pandemic and the measures taken to mitigate it on the business.\\n2. The potential reclassification of drivers as employees, workers, or quasi-employees instead of independent contractors.\\n3. Intense competition in the mobility, delivery, and logistics industries, with low barriers to entry and well-capitalized competitors.\\n4. The need to lower fares or service fees and offer driver incentives and consumer discounts to remain competitive.\\n5. Significant losses incurred and uncertainty about achieving profitability.\\n6. The risk of not attracting or maintaining a critical mass of platform users.\\n7. Operational, compliance, and cultural challenges related to the workplace culture and forward-leaning approach.\\n8. The potential negative impact of international investments and the challenges of conducting business in foreign countries, including operational and compliance challenges, localization requirements, restrictive laws and regulations, competition from local companies, social acceptance, technological compatibility, improper business practices, legal uncertainty, difficulties in managing international operations, currency exchange rate fluctuations, and regulations governing local currencies.  \\nThese risk factors highlight the challenges and uncertainties faced by Uber in 2020.  \\nFinally, if we test it with a query to compare/contrast risk factors across years, the agent will use the Sub Question Query Engine Tool.  \\n```python\\ncross_query_str = (\\n\"Compare/contrast the risk factors described in the Uber 10-K across\"\\n\" years. Give answer in bullet points.\"\\n)\\n\\nresponse = agent.chat(cross_query_str)\\nprint(str(response))\\n```  \\n<style>\\npre {\\nwhite-space: pre-wrap;\\n}\\n</style>  \\n=== Calling Function ===\\nCalling function: sub_question_query_engine with args: {\\n\"input\": \"Compare/contrast the risk factors described in the Uber 10-K across years\"\\n}\\nGenerated 4 sub questions.\\n\\x1b[36;1m\\x1b[1;3m[vector_index_2022] Q: What are the risk factors described in the 2022 SEC 10-K for Uber?\\n\\x1b[0m\\x1b[33;1m\\x1b[1;3m[vector_index_2021] Q: What are the risk factors described in the 2021 SEC 10-K for Uber?\\n\\x1b[0m\\x1b[38;5;200m\\x1b[1;3m[vector_index_2020] Q: What are the risk factors described in the 2020 SEC 10-K for Uber?\\n\\x1b[0m\\x1b[32;1m\\x1b[1;3m[vector_index_2019] Q: What are the risk factors described in the 2019 SEC 10-K for Uber?\\n\\x1b[0m\\x1b[36;1m\\x1b[1;3m[vector_index_2022] A: The risk factors described in the 2022 SEC 10-K for Uber include the potential adverse effect on their business if drivers were classified as employees instead of independent contractors, the highly competitive nature of the mobility, delivery, and logistics industries, the need to lower fares or service fees to remain competitive in certain markets, the company\\'s history of significant losses and the expectation of increased operating expenses in the future, and the potential impact on their platform if they are unable to attract or maintain a critical mass of drivers, consumers, merchants, shippers, and carriers.\\n\\x1b[0m\\x1b[32;1m\\x1b[1;3m[vector_index_2019] A: The risk factors described in the 2019 SEC 10-K for Uber include the loss of their license to operate in London, the complexity of their business and operating model due to regulatory uncertainties, the potential for additional regulations for their other products in the Other Bets segment, the evolving laws and regulations regarding the development and deployment of autonomous vehicles, and the increasing number of data protection and privacy laws around the world. Additionally, there are legal proceedings, litigation, claims, and government investigations that Uber is involved in, including those related to the classification of drivers and compliance with applicable laws, which could impose a significant burden on the company.\\n\\x1b[0m\\x1b[33;1m\\x1b[1;3m[vector_index_2021] A: The risk factors described in the 2021 SEC 10-K for Uber include the adverse impact of the COVID-19 pandemic and actions taken to mitigate it on their business, the potential reclassification of drivers as employees instead of independent contractors, intense competition in the mobility, delivery, and logistics industries, the need to lower fares and offer incentives to remain competitive, significant losses incurred and the expectation of increased operating expenses, the importance of attracting and maintaining a critical mass of drivers, consumers, merchants, shippers, and carriers, and the uncertainty surrounding the impact of COVID-19 on their business and financial position. Additionally, the classification of drivers is being challenged in courts and by government agencies, which could have legal and financial implications for the company.\\n\\x1b[0m\\x1b[38;5;200m\\x1b[1;3m[vector_index_2020] A: The risk factors described in the 2020 SEC 10-K for Uber include the adverse impact of the COVID-19 pandemic on their business, the potential reclassification of drivers as employees instead of independent contractors, intense competition in the mobility, delivery, and logistics industries, the need to lower fares and offer incentives to remain competitive, significant losses and the uncertainty of achieving profitability, the importance of attracting and maintaining a critical mass of platform users, operational and compliance challenges, inquiries and investigations from government agencies, risks related to data security breaches, the need to introduce new or upgraded products and features, and the need to invest in the development of new offerings to retain and attract users.\\n\\x1b[0mGot output: The risk factors described in the Uber 10-K reports across the years include the potential reclassification of drivers as employees instead of independent contractors, intense competition in the mobility, delivery, and logistics industries, the need to lower fares and offer incentives to remain competitive, significant losses incurred and the expectation of increased operating expenses, the importance of attracting and maintaining a critical mass of drivers, consumers, merchants, shippers, and carriers, and the impact of the COVID-19 pandemic on their business. Additionally, there are legal and regulatory uncertainties, such as the evolving laws and regulations regarding autonomous vehicles, data protection and privacy laws, and the potential for additional regulations for their other products. The reports also mention the operational and compliance challenges, inquiries and investigations from government agencies, and the risks associated with data security breaches. It is worth noting that specific risk factors may vary from year to year based on the prevailing circumstances and developments in the industry and regulatory environment.\\n========================\\nHere are the key points comparing and contrasting the risk factors described in the Uber 10-K reports across years:  \\n2022:\\n- Potential reclassification of drivers as employees instead of independent contractors.\\n- Intense competition in the mobility, delivery, and logistics industries.\\n- Need to lower fares and offer incentives to remain competitive.\\n- Significant losses incurred and expectation of increased operating expenses.\\n- Importance of attracting and maintaining a critical mass of drivers, consumers, merchants, shippers, and carriers.\\n- Impact of the COVID-19 pandemic on their business.\\n- Legal and regulatory uncertainties, including evolving laws and regulations regarding autonomous vehicles and data protection and privacy laws.\\n- Operational and compliance challenges.\\n- Inquiries and investigations from government agencies.\\n- Risks associated with data security breaches.  \\n2021:\\n- Similar risk factors as in 2022, including potential reclassification of drivers, intense competition, need to lower fares, significant losses, and the impact of the COVID-19 pandemic.\\n- Emphasis on the importance of maintaining a critical mass of drivers, consumers, merchants, shippers, and carriers.\\n- Mention of legal and regulatory uncertainties, such as evolving laws and regulations regarding autonomous vehicles and data protection and privacy laws.\\n- Operational and compliance challenges.\\n- Inquiries and investigations from government agencies.\\n- Risks associated with data security breaches.  \\n2020:\\n- Similar risk factors as in 2021, including potential reclassification of drivers, intense competition, need to lower fares, significant losses, and the impact of the COVID-19 pandemic.\\n- Emphasis on the importance of maintaining a critical mass of drivers, consumers, merchants, shippers, and carriers.\\n- Mention of legal and regulatory uncertainties, such as evolving laws and regulations regarding autonomous vehicles and data protection and privacy laws.\\n- Operational and compliance challenges.\\n- Inquiries and investigations from government agencies.\\n- Risks associated with data security breaches.  \\n2019:\\n- Similar risk factors as in 2020, including potential reclassification of drivers, intense competition, need to lower fares, significant losses, and the impact of the COVID-19 pandemic.\\n- Emphasis on the importance of maintaining a critical mass of drivers, consumers, merchants, shippers, and carriers.\\n- Mention of legal and regulatory uncertainties, such as evolving laws and regulations regarding autonomous vehicles and data protection and privacy laws.\\n- Operational and compliance challenges.\\n- Inquiries and investigations from government agencies.\\n- Risks associated with data security breaches.  \\nPlease note that these are just the key points, and there may be additional risk factors mentioned in each year\\'s 10-K report.', metadata={'Header 1': '💬🤖 How to Build a Chatbot', 'Header 3': 'Testing the Agent'}),\n",
      " Document(page_content='Now that we have the chatbot setup, it only takes a few more steps to setup a basic interactive loop to chat with our SEC-augmented chatbot!  \\n```python\\nagent = OpenAIAgent.from_tools(tools)  # verbose=False by default\\n\\nwhile True:\\ntext_input = input(\"User: \")\\nif text_input == \"exit\":\\nbreak\\nresponse = agent.chat(text_input)\\nprint(f\"Agent: {response}\")\\n\\n# User: What were some of the legal proceedings against Uber in 2022?\\n```  \\n<style>\\npre {\\nwhite-space: pre-wrap;\\n}\\n</style>  \\nAgent: In 2022, Uber is facing several legal proceedings. Here are some of them:  \\n1. California: The state Attorney General and city attorneys filed a complaint against Uber and Lyft, alleging that drivers are misclassified as independent contractors. A preliminary injunction was issued but stayed pending appeal. The Court of Appeal affirmed the lower court\\'s ruling, and Uber filed a petition for review with the California Supreme Court. However, the Supreme Court declined the petition for review. The lawsuit is ongoing, focusing on claims by the California Attorney General for periods prior to the enactment of Proposition 22.  \\n2. Massachusetts: The Attorney General of Massachusetts filed a complaint against Uber, alleging that drivers are employees entitled to wage and labor law protections. Uber\\'s motion to dismiss the complaint was denied, and a summary judgment motion is pending.  \\n3. New York: Uber is facing allegations of misclassification and employment violations by the state Attorney General. The resolution of this matter is uncertain.  \\n4. Switzerland: Several administrative bodies in Switzerland have issued rulings classifying Uber drivers as employees for social security or labor purposes. Uber is challenging these rulings before the Social Security and Administrative Tribunals.  \\nThese are some of the legal proceedings against Uber in 2022. The outcomes and potential losses in these cases are uncertain.', metadata={'Header 1': '💬🤖 How to Build a Chatbot', 'Header 3': 'Setting up the Chatbot Loop'}),\n",
      " Document(page_content='In this cookbook we show you how to build a custom agent using LlamaIndex.  \\nThe easiest way to build a custom agent is to simply subclass `CustomSimpleAgentWorker` and implement a few required functions. You have complete flexibility in defining the agent step-wise logic.  \\nThis lets you add arbitrarily complex reasoning logic on top of your RAG pipeline.  \\nWe show you how to build a simple agent that adds a retry layer on top of a RouterQueryEngine, allowing it to retry queries until the task is complete. We build this on top of both a SQL tool and a vector index query tool. Even if the tool makes an error or only answers part of the question, the agent can continue retrying the question until the task is complete.', metadata={'Header 1': 'Building a Custom Agent'}),\n",
      " Document(page_content='Here we setup the custom agent.', metadata={'Header 1': 'Building a Custom Agent', 'Header 2': 'Setup the Custom Agent'}),\n",
      " Document(page_content=\"An agent in LlamaIndex consists of both an agent runner + agent worker. An agent runner is an orchestrator that stores state like memory, whereas an agent worker controls the step-wise execution of a Task. Agent runners include sequential, parallel execution. More details can be found in our [lower level API guide](https://docs.llamaindex.ai/en/latest/module_guides/deploying/agents/agent_runner.html).  \\nMost core agent logic (e.g. ReAct, function calling loops), can be executed in the agent worker. Therefore we've made it easy to subclass an agent worker, letting you plug it into any agent runner.\", metadata={'Header 1': 'Building a Custom Agent', 'Header 2': 'Setup the Custom Agent', 'Header 3': 'Refresher'}),\n",
      " Document(page_content='As mentioned above we subclass `CustomSimpleAgentWorker`. This is a class that already sets up some scaffolding for you. This includes being able to take in tools, callbacks, LLM, and also ensures that the state/steps are properly formatted. In the meantime you mostly have to implement the following functions:  \\n- `_initialize_state`\\n- `_run_step`\\n- `_finalize_task`  \\nSome additional notes:\\n- You can implement `_arun_step` as well if you want to support async chat in the agent.\\n- You can choose to override `__init__` as long as you pass all remaining args, kwargs to `super()`\\n- `CustomSimpleAgentWorker` is implemented as a Pydantic `BaseModel` meaning that you can define your own custom properties as well.  \\nHere are the full set of base properties on each `CustomSimpleAgentWorker` (that you need to/can pass in when constructing your custom agent):\\n- `tools: Sequence[BaseTool]`\\n- `tool_retriever: Optional[ObjectRetriever[BaseTool]]`\\n- `llm: LLM`\\n- `callback_manager: CallbackManager`\\n- `verbose: bool`  \\nNote that `tools` and `tool_retriever` are mutually exclusive, you can only pass in one or the either (e.g. define a static list of tools or define a callable function that returns relevant tools given a user message). You can call `get_tools(message: str)` to return relevant tools given a message.  \\nAll of these properties are accessible via `self` when defining your custom agent.  \\n```python\\nfrom llama_index.agent import CustomSimpleAgentWorker, Task, AgentChatResponse\\nfrom typing import Dict, Any, List, Tuple\\nfrom llama_index.tools import BaseTool, QueryEngineTool\\nfrom llama_index.program import LLMTextCompletionProgram\\nfrom llama_index.output_parsers import PydanticOutputParser\\nfrom llama_index.query_engine import RouterQueryEngine\\nfrom llama_index.prompts import ChatPromptTemplate, PromptTemplate\\nfrom llama_index.selectors import PydanticSingleSelector\\nfrom pydantic import Field, BaseModel\\n```  \\nHere we define some helper variables and methods. E.g. the prompt template to use to detect errors as well as the response format in Pydantic.  \\n```python\\nfrom llama_index.llms import ChatMessage, MessageRole\\n\\nDEFAULT_PROMPT_STR = \"\"\"\\nGiven previous question/response pairs, please determine if an error has occurred in the response, and suggest \\\\\\na modified question that will not trigger the error.\\n\\nExamples of modified questions:\\n- The question itself is modified to elicit a non-erroneous response\\n- The question is augmented with context that will help the downstream system better answer the question.\\n- The question is augmented with examples of negative responses, or other negative questions.\\n\\nAn error means that either an exception has triggered, or the response is completely irrelevant to the question.\\n\\nPlease return the evaluation of the response in the following JSON format.\\n\\n\"\"\"\\n\\n\\ndef get_chat_prompt_template(\\nsystem_prompt: str, current_reasoning: Tuple[str, str]\\n) -> ChatPromptTemplate:\\nsystem_msg = ChatMessage(role=MessageRole.SYSTEM, content=system_prompt)\\nmessages = [system_msg]\\nfor raw_msg in current_reasoning:\\nif raw_msg[0] == \"user\":\\nmessages.append(\\nChatMessage(role=MessageRole.USER, content=raw_msg[1])\\n)\\nelse:\\nmessages.append(\\nChatMessage(role=MessageRole.ASSISTANT, content=raw_msg[1])\\n)\\nreturn ChatPromptTemplate(message_templates=messages)\\n\\n\\nclass ResponseEval(BaseModel):\\n\"\"\"Evaluation of whether the response has an error.\"\"\"\\n\\nhas_error: bool = Field(\\n..., description=\"Whether the response has an error.\"\\n)\\nnew_question: str = Field(..., description=\"The suggested new question.\")\\nexplanation: str = Field(\\n...,\\ndescription=(\\n\"The explanation for the error as well as for the new question.\"\\n\"Can include the direct stack trace as well.\"\\n),\\n)\\n```  \\n```python\\nfrom pydantic import PrivateAttr\\n\\n\\nclass RetryAgentWorker(CustomSimpleAgentWorker):\\n\"\"\"Agent worker that adds a retry layer on top of a router.\\n\\nContinues iterating until there\\'s no errors / task is done.\\n\\n\"\"\"\\n\\nprompt_str: str = Field(default=DEFAULT_PROMPT_STR)\\nmax_iterations: int = Field(default=10)\\n\\n_router_query_engine: RouterQueryEngine = PrivateAttr()\\n\\ndef __init__(self, tools: List[BaseTool], **kwargs: Any) -> None:\\n\"\"\"Init params.\"\"\"\\n# validate that all tools are query engine tools\\nfor tool in tools:\\nif not isinstance(tool, QueryEngineTool):\\nraise ValueError(\\nf\"Tool {tool.metadata.name} is not a query engine tool.\"\\n)\\nself._router_query_engine = RouterQueryEngine(\\nselector=PydanticSingleSelector.from_defaults(),\\nquery_engine_tools=tools,\\nverbose=kwargs.get(\"verbose\", False),\\n)\\nsuper().__init__(\\ntools=tools,\\n**kwargs,\\n)\\n\\ndef _initialize_state(self, task: Task, **kwargs: Any) -> Dict[str, Any]:\\n\"\"\"Initialize state.\"\"\"\\nreturn {\"count\": 0, \"current_reasoning\": []}\\n\\ndef _run_step(\\nself, state: Dict[str, Any], task: Task\\n) -> Tuple[AgentChatResponse, bool]:\\n\"\"\"Run step.\\n\\nReturns:\\nTuple of (agent_response, is_done)\\n\\n\"\"\"\\nif \"new_input\" not in state:\\nnew_input = task.input\\nelse:\\nnew_input = state[\"new_input\"]\\n\\n# first run router query engine\\nresponse = self._router_query_engine.query(new_input)\\n\\n# append to current reasoning\\nstate[\"current_reasoning\"].extend(\\n[(\"user\", new_input), (\"assistant\", str(response))]\\n)\\n\\n# Then, check for errors\\n# dynamically create pydantic program for structured output extraction based on template\\nchat_prompt_tmpl = get_chat_prompt_template(\\nself.prompt_str, state[\"current_reasoning\"]\\n)\\nllm_program = LLMTextCompletionProgram.from_defaults(\\noutput_parser=PydanticOutputParser(output_cls=ResponseEval),\\nprompt=chat_prompt_tmpl,\\nllm=self.llm,\\n)\\n# run program, look at the result\\nresponse_eval = llm_program(\\nquery_str=new_input, response_str=str(response)\\n)\\nif not response_eval.has_error:\\nis_done = True\\nelse:\\nis_done = False\\nstate[\"new_input\"] = response_eval.new_question\\n\\nif self.verbose:\\nprint(f\"> Question: {new_input}\")\\nprint(f\"> Response: {response}\")\\nprint(f\"> Response eval: {response_eval.dict()}\")\\n\\n# return response\\nreturn AgentChatResponse(response=str(response)), is_done\\n\\ndef _finalize_task(self, state: Dict[str, Any], **kwargs) -> None:\\n\"\"\"Finalize task.\"\"\"\\n# nothing to finalize here\\n# this is usually if you want to modify any sort of\\n# internal state beyond what is set in `_initialize_state`\\npass\\n```', metadata={'Header 1': 'Building a Custom Agent', 'Header 2': 'Setup the Custom Agent', 'Header 3': 'Creating a Custom Agent Worker Subclass'}),\n",
      " Document(page_content='We setup both a SQL Tool as well as vector index tools for each city.  \\n```python\\nfrom llama_index.tools.query_engine import QueryEngineTool\\n```', metadata={'Header 1': 'Building a Custom Agent', 'Header 2': 'Setup Data and Tools'}),\n",
      " Document(page_content='```python\\nfrom sqlalchemy import (\\ncreate_engine,\\nMetaData,\\nTable,\\nColumn,\\nString,\\nInteger,\\nselect,\\ncolumn,\\n)\\nfrom llama_index import SQLDatabase\\n\\nengine = create_engine(\"sqlite:///:memory:\", future=True)\\nmetadata_obj = MetaData()\\n# create city SQL table\\ntable_name = \"city_stats\"\\ncity_stats_table = Table(\\ntable_name,\\nmetadata_obj,\\nColumn(\"city_name\", String(16), primary_key=True),\\nColumn(\"population\", Integer),\\nColumn(\"country\", String(16), nullable=False),\\n)\\n\\nmetadata_obj.create_all(engine)\\n```  \\n```python\\nfrom sqlalchemy import insert\\n\\nrows = [\\n{\"city_name\": \"Toronto\", \"population\": 2930000, \"country\": \"Canada\"},\\n{\"city_name\": \"Tokyo\", \"population\": 13960000, \"country\": \"Japan\"},\\n{\"city_name\": \"Berlin\", \"population\": 3645000, \"country\": \"Germany\"},\\n]\\nfor row in rows:\\nstmt = insert(city_stats_table).values(**row)\\nwith engine.begin() as connection:\\ncursor = connection.execute(stmt)\\n```  \\n```python\\nfrom llama_index.indices.struct_store.sql_query import NLSQLTableQueryEngine\\n\\nsql_database = SQLDatabase(engine, include_tables=[\"city_stats\"])\\nsql_query_engine = NLSQLTableQueryEngine(\\nsql_database=sql_database, tables=[\"city_stats\"], verbose=True\\n)\\nsql_tool = QueryEngineTool.from_defaults(\\nquery_engine=sql_query_engine,\\ndescription=(\\n\"Useful for translating a natural language query into a SQL query over\"\\n\" a table containing: city_stats, containing the population/country of\"\\n\" each city\"\\n),\\n)\\n```', metadata={'Header 1': 'Building a Custom Agent', 'Header 2': 'Setup Data and Tools', 'Header 3': 'Setup SQL DB + Tool'}),\n",
      " Document(page_content='```python\\nfrom llama_index.readers import WikipediaReader\\nfrom llama_index import VectorStoreIndex\\n```  \\n```python\\ncities = [\"Toronto\", \"Berlin\", \"Tokyo\"]\\nwiki_docs = WikipediaReader().load_data(pages=cities)\\n```  \\n```python\\n# build a separate vector index per city\\n# You could also choose to define a single vector index across all docs, and annotate each chunk by metadata\\nvector_tools = []\\nfor city, wiki_doc in zip(cities, wiki_docs):\\nvector_index = VectorStoreIndex.from_documents([wiki_doc])\\nvector_query_engine = vector_index.as_query_engine()\\nvector_tool = QueryEngineTool.from_defaults(\\nquery_engine=vector_query_engine,\\ndescription=f\"Useful for answering semantic questions about {city}\",\\n)\\nvector_tools.append(vector_tool)\\n```', metadata={'Header 1': 'Building a Custom Agent', 'Header 2': 'Setup Data and Tools', 'Header 3': 'Setup Vector Tools'}),\n",
      " Document(page_content='```python\\nfrom llama_index.agent import AgentRunner\\nfrom llama_index.llms import OpenAI\\n```  \\n```python\\nllm = OpenAI(model=\"gpt-4\")\\ncallback_manager = llm.callback_manager\\n\\nquery_engine_tools = [sql_tool] + vector_tools\\nagent_worker = RetryAgentWorker.from_tools(\\nquery_engine_tools,\\nllm=llm,\\nverbose=True,\\ncallback_manager=callback_manager,\\n)\\nagent = AgentRunner(agent_worker, callback_manager=callback_manager)\\n```', metadata={'Header 1': 'Building a Custom Agent', 'Header 2': 'Build Custom Agent'}),\n",
      " Document(page_content='```python\\nresponse = agent.chat(\"Which countries are each city from?\")\\nprint(str(response))\\n```  \\n\\x1b[1;3;38;5;200mSelecting query engine 0: The choice is about translating a natural language query into a SQL query over a table containing city_stats, which likely includes information about the country of each city..\\n\\x1b[0m> Table desc str: Table \\'city_stats\\' has columns: city_name (VARCHAR(16)), population (INTEGER), country (VARCHAR(16)), and foreign keys: .\\n> Predicted SQL query: SELECT city_name, country FROM city_stats\\n> Question: Which countries are each city from?\\n> Response: The city of Toronto is from Canada, Tokyo is from Japan, and Berlin is from Germany.\\n> Response eval: {\\'has_error\\': True, \\'new_question\\': \\'Which country is each of the following cities from: Toronto, Tokyo, Berlin?\\', \\'explanation\\': \\'The original question was too vague as it did not specify which cities the question was referring to. The new question provides specific cities for which the country of origin is being asked.\\'}\\n\\x1b[1;3;38;5;200mSelecting query engine 0: This choice is relevant because it mentions a table containing city_stats, which likely includes information about the country of each city..\\n\\x1b[0m> Table desc str: Table \\'city_stats\\' has columns: city_name (VARCHAR(16)), population (INTEGER), country (VARCHAR(16)), and foreign keys: .\\n> Predicted SQL query: SELECT city_name, country\\nFROM city_stats\\nWHERE city_name IN (\\'Toronto\\', \\'Tokyo\\', \\'Berlin\\')\\n> Question: Which country is each of the following cities from: Toronto, Tokyo, Berlin?\\n> Response: Toronto is from Canada, Tokyo is from Japan, and Berlin is from Germany.\\n> Response eval: {\\'has_error\\': False, \\'new_question\\': \\'\\', \\'explanation\\': \\'\\'}\\nToronto is from Canada, Tokyo is from Japan, and Berlin is from Germany.  \\n```python\\nresponse = agent.chat(\\n\"What are the top modes of transporation fo the city with the higehest population?\"\\n)\\nprint(str(response))\\n```  \\n\\x1b[1;3;38;5;200mSelecting query engine 0: The question is asking about the top modes of transportation for the city with the highest population. Choice (1) is the most relevant because it mentions a table containing city_stats, which likely includes information about the population of each city..\\n\\x1b[0m> Table desc str: Table \\'city_stats\\' has columns: city_name (VARCHAR(16)), population (INTEGER), country (VARCHAR(16)), and foreign keys: .\\n> Predicted SQL query: SELECT city_name, population, mode_of_transportation\\nFROM city_stats\\nWHERE population = (SELECT MAX(population) FROM city_stats)\\nORDER BY mode_of_transportation ASC\\nLIMIT 5;\\n> Question: What are the top modes of transporation fo the city with the higehest population?\\n> Response: I\\'m sorry, but there was an error in retrieving the information. Please try again later.\\n> Response eval: {\\'has_error\\': True, \\'new_question\\': \\'What are the top modes of transportation for the city with the highest population?\\', \\'explanation\\': \\'The original question had spelling errors which might have caused the system to not understand the question correctly. The corrected question should now be clear and understandable for the system.\\'}\\n\\x1b[1;3;38;5;200mSelecting query engine 0: The first choice is the most relevant because it mentions translating a natural language query into a SQL query over a table containing city_stats, which likely includes information about the population of each city..\\n\\x1b[0m> Table desc str: Table \\'city_stats\\' has columns: city_name (VARCHAR(16)), population (INTEGER), country (VARCHAR(16)), and foreign keys: .\\n> Predicted SQL query: SELECT city_name, population, country\\nFROM city_stats\\nWHERE population = (SELECT MAX(population) FROM city_stats)\\n> Question: What are the top modes of transportation for the city with the highest population?\\n> Response: The city with the highest population is Tokyo, Japan with a population of 13,960,000.\\n> Response eval: {\\'has_error\\': True, \\'new_question\\': \\'What are the top modes of transportation for Tokyo, Japan?\\', \\'explanation\\': \\'The assistant failed to answer the original question correctly. The response was about the city with the highest population, but it did not mention anything about the top modes of transportation in that city. The new question directly asks about the top modes of transportation in Tokyo, Japan, which is the city with the highest population.\\'}\\n\\x1b[1;3;38;5;200mSelecting query engine 3: The question specifically asks about Tokyo, and choice (4) is about answering semantic questions about Tokyo..\\n\\x1b[0m> Question: What are the top modes of transportation for Tokyo, Japan?\\n> Response: The top modes of transportation for Tokyo, Japan are trains and subways, which are considered clean and efficient. Tokyo has an extensive network of electric train lines and over 900 train stations. Buses, monorails, and trams also play a secondary role in the public transportation system. Additionally, expressways connect Tokyo to other points in the Greater Tokyo Area and beyond. Taxis and long-distance ferries are also available for transportation within the city and to the surrounding islands.\\n> Response eval: {\\'has_error\\': True, \\'new_question\\': \\'What are the top modes of transportation for Tokyo, Japan?\\', \\'explanation\\': \\'The original question was not answered correctly because the assistant did not provide information on the top modes of transportation for the city with the highest population. The new question directly asks for the top modes of transportation for Tokyo, Japan, which is the city with the highest population.\\'}\\n\\x1b[1;3;38;5;200mSelecting query engine 3: Tokyo is mentioned in choice 4.\\n\\x1b[0m> Question: What are the top modes of transportation for Tokyo, Japan?\\n> Response: The top modes of transportation for Tokyo, Japan are trains and subways, which are considered clean and efficient. Tokyo has an extensive network of electric train lines and over 900 train stations. Buses, monorails, and trams also play a secondary role in public transportation within the city. Additionally, Tokyo has two major airports, Narita International Airport and Haneda Airport, which offer domestic and international flights. Expressways and taxis are also available for transportation within the city.\\n> Response eval: {\\'has_error\\': True, \\'new_question\\': \\'What are the top modes of transportation for Tokyo, Japan?\\', \\'explanation\\': \\'The response is erroneous because it does not answer the question asked. The question asks for the top modes of transportation in the city with the highest population, but the response only provides the population of the city. The new question directly asks for the top modes of transportation in Tokyo, Japan, which is the city with the highest population.\\'}\\n\\x1b[1;3;38;5;200mSelecting query engine 3: The question specifically asks about Tokyo, and choice 4 is about answering semantic questions about Tokyo..\\n\\x1b[0m> Question: What are the top modes of transportation for Tokyo, Japan?\\n> Response: The top modes of transportation for Tokyo, Japan are trains and subways, which are considered clean and efficient. Tokyo has an extensive network of electric train lines and over 900 train stations. Buses, monorails, and trams also play a secondary role in public transportation within the city. Additionally, Tokyo has two major airports, Narita International Airport and Haneda Airport, which offer domestic and international flights. Expressways and taxis are also available for transportation within the city.\\n> Response eval: {\\'has_error\\': False, \\'new_question\\': \\'\\', \\'explanation\\': \\'\\'}\\nThe top modes of transportation for Tokyo, Japan are trains and subways, which are considered clean and efficient. Tokyo has an extensive network of electric train lines and over 900 train stations. Buses, monorails, and trams also play a secondary role in public transportation within the city. Additionally, Tokyo has two major airports, Narita International Airport and Haneda Airport, which offer domestic and international flights. Expressways and taxis are also available for transportation within the city.  \\n```python\\nprint(str(response))\\n```  \\nThe top modes of transportation for Tokyo, Japan are trains and subways, which are considered clean and efficient. Tokyo has an extensive network of electric train lines and over 900 train stations. Buses, monorails, and trams also play a secondary role in public transportation within the city. Additionally, Tokyo has two major airports, Narita International Airport and Haneda Airport, which offer domestic and international flights. Expressways and taxis are also available for transportation within the city.  \\n```python\\nresponse = agent.chat(\"What are the sports teams of each city in Asia?\")\\nprint(str(response))\\n```  \\n\\x1b[1;3;38;5;200mSelecting query engine 3: The question is asking about sports teams in Asia, and Tokyo is located in Asia..\\n\\x1b[0m> Question: What are the sports teams of each city in Asia?\\n> Response: I\\'m sorry, but the context information does not provide a comprehensive list of sports teams in each city in Asia. It only mentions some sports teams in Tokyo, Japan. To get a complete list of sports teams in each city in Asia, you would need to consult a reliable source or conduct further research.\\n> Response eval: {\\'has_error\\': True, \\'new_question\\': \\'What are some popular sports teams in Tokyo, Japan?\\', \\'explanation\\': \\'The original question is too broad and requires extensive data that the system may not possess. The new question is more specific and focuses on a single city, making it more likely to receive a correct and comprehensive answer.\\'}\\n\\x1b[1;3;38;5;200mSelecting query engine 3: The question specifically asks about Tokyo, and choice 4 is about answering semantic questions about Tokyo..\\n\\x1b[0m> Question: What are some popular sports teams in Tokyo, Japan?\\n> Response: Some popular sports teams in Tokyo, Japan include the Yomiuri Giants and Tokyo Yakult Swallows in baseball, F.C. Tokyo and Tokyo Verdy 1969 in soccer, and Hitachi SunRockers, Toyota Alvark Tokyo, and Tokyo Excellence in basketball. Tokyo is also known for its sumo wrestling tournaments held at the Ryōgoku Kokugikan sumo arena.\\n> Response eval: {\\'has_error\\': False, \\'new_question\\': \\'\\', \\'explanation\\': \\'\\'}\\nSome popular sports teams in Tokyo, Japan include the Yomiuri Giants and Tokyo Yakult Swallows in baseball, F.C. Tokyo and Tokyo Verdy 1969 in soccer, and Hitachi SunRockers, Toyota Alvark Tokyo, and Tokyo Excellence in basketball. Tokyo is also known for its sumo wrestling tournaments held at the Ryōgoku Kokugikan sumo arena.', metadata={'Header 1': 'Building a Custom Agent', 'Header 2': 'Try Out Some Queries'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/multi_document_agents-v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>'),\n",
      " Document(page_content='In this guide, you learn towards setting up a multi-document agent over the LlamaIndex documentation.  \\nThis is an extension of V0 multi-document agents with the additional features:\\n- Reranking during document (tool) retrieval\\n- Query planning tool that the agent can use to plan  \\nWe do this with the following architecture:  \\n- setup a \"document agent\" over each Document: each doc agent can do QA/summarization within its doc\\n- setup a top-level agent over this set of document agents. Do tool retrieval and then do CoT over the set of tools to answer a question.  \\nIf you\\'re opening this Notebook on colab, you will probably need to install LlamaIndex 🦙.  \\n```python\\n!pip install llama-index\\n```  \\n```python\\n%load_ext autoreload\\n%autoreload 2\\n```', metadata={'Header 1': 'Multi-Document Agents (V1)'}),\n",
      " Document(page_content='In this section, we\\'ll load in the LlamaIndex documentation.  \\n```python\\ndomain = \"docs.llamaindex.ai\"\\ndocs_url = \"https://docs.llamaindex.ai/en/latest/\"\\n!wget -e robots=off --recursive --no-clobber --page-requisites --html-extension --convert-links --restrict-file-names=windows --domains {domain} --no-parent {docs_url}\\n```  \\n```python\\nfrom llama_hub.file.unstructured.base import UnstructuredReader\\nfrom pathlib import Path\\nfrom llama_index.llms import OpenAI\\nfrom llama_index import ServiceContext\\n```  \\n```python\\nreader = UnstructuredReader()\\n```  \\n[nltk_data] Downloading package punkt to /Users/jerryliu/nltk_data...\\n[nltk_data]   Package punkt is already up-to-date!\\n[nltk_data] Downloading package averaged_perceptron_tagger to\\n[nltk_data]     /Users/jerryliu/nltk_data...\\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\\n[nltk_data]       date!  \\n```python\\nall_files_gen = Path(\"./docs.llamaindex.ai/\").rglob(\"*\")\\nall_files = [f.resolve() for f in all_files_gen]\\n```  \\n```python\\nall_html_files = [f for f in all_files if f.suffix.lower() == \".html\"]\\n```  \\n```python\\nlen(all_html_files)\\n```  \\n418  \\n```python\\nfrom llama_index import Document\\n\\n# TODO: set to higher value if you want more docs\\ndoc_limit = 100\\n\\ndocs = []\\nfor idx, f in enumerate(all_html_files):\\nif idx > doc_limit:\\nbreak\\nprint(f\"Idx {idx}/{len(all_html_files)}\")\\nloaded_docs = reader.load_data(file=f, split_documents=True)\\n# Hardcoded Index. Everything before this is ToC for all pages\\nstart_idx = 72\\nloaded_doc = Document(\\ntext=\"\\\\n\\\\n\".join([d.get_content() for d in loaded_docs[72:]]),\\nmetadata={\"path\": str(f)},\\n)\\nprint(loaded_doc.metadata[\"path\"])\\ndocs.append(loaded_doc)\\n```  \\nDefine LLM + Service Context + Callback Manager  \\n```python\\nllm = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\\nservice_context = ServiceContext.from_defaults(llm=llm)\\n```', metadata={'Header 1': 'Multi-Document Agents (V1)', 'Header 2': 'Setup and Download Data'}),\n",
      " Document(page_content='In this section we show you how to construct the multi-document agent. We first build a document agent for each document, and then define the top-level parent agent with an object index.  \\n```python\\nfrom llama_index import VectorStoreIndex, SummaryIndex\\n```  \\n```python\\nimport nest_asyncio\\n\\nnest_asyncio.apply()\\n```', metadata={'Header 1': 'Multi-Document Agents (V1)', 'Header 2': 'Building Multi-Document Agents'}),\n",
      " Document(page_content='In this section we define \"document agents\" for each document.  \\nWe define both a vector index (for semantic search) and summary index (for summarization) for each document. The two query engines are then converted into tools that are passed to an OpenAI function calling agent.  \\nThis document agent can dynamically choose to perform semantic search or summarization within a given document.  \\nWe create a separate document agent for each city.  \\n```python\\nfrom llama_index.agent import OpenAIAgent\\nfrom llama_index import load_index_from_storage, StorageContext\\nfrom llama_index.tools import QueryEngineTool, ToolMetadata\\nfrom llama_index.node_parser import SentenceSplitter\\nimport os\\nfrom tqdm.notebook import tqdm\\nimport pickle\\n\\n\\nasync def build_agent_per_doc(nodes, file_base):\\nprint(file_base)\\n\\nvi_out_path = f\"./data/llamaindex_docs/{file_base}\"\\nsummary_out_path = f\"./data/llamaindex_docs/{file_base}_summary.pkl\"\\nif not os.path.exists(vi_out_path):\\nPath(\"./data/llamaindex_docs/\").mkdir(parents=True, exist_ok=True)\\n# build vector index\\nvector_index = VectorStoreIndex(nodes, service_context=service_context)\\nvector_index.storage_context.persist(persist_dir=vi_out_path)\\nelse:\\nvector_index = load_index_from_storage(\\nStorageContext.from_defaults(persist_dir=vi_out_path),\\nservice_context=service_context,\\n)\\n\\n# build summary index\\nsummary_index = SummaryIndex(nodes, service_context=service_context)\\n\\n# define query engines\\nvector_query_engine = vector_index.as_query_engine()\\nsummary_query_engine = summary_index.as_query_engine(\\nresponse_mode=\"tree_summarize\"\\n)\\n\\n# extract a summary\\nif not os.path.exists(summary_out_path):\\nPath(summary_out_path).parent.mkdir(parents=True, exist_ok=True)\\nsummary = str(\\nawait summary_query_engine.aquery(\\n\"Extract a concise 1-2 line summary of this document\"\\n)\\n)\\npickle.dump(summary, open(summary_out_path, \"wb\"))\\nelse:\\nsummary = pickle.load(open(summary_out_path, \"rb\"))\\n\\n# define tools\\nquery_engine_tools = [\\nQueryEngineTool(\\nquery_engine=vector_query_engine,\\nmetadata=ToolMetadata(\\nname=f\"vector_tool_{file_base}\",\\ndescription=f\"Useful for questions related to specific facts\",\\n),\\n),\\nQueryEngineTool(\\nquery_engine=summary_query_engine,\\nmetadata=ToolMetadata(\\nname=f\"summary_tool_{file_base}\",\\ndescription=f\"Useful for summarization questions\",\\n),\\n),\\n]\\n\\n# build agent\\nfunction_llm = OpenAI(model=\"gpt-4\")\\nagent = OpenAIAgent.from_tools(\\nquery_engine_tools,\\nllm=function_llm,\\nverbose=True,\\nsystem_prompt=f\"\"\"\\\\\\nYou are a specialized agent designed to answer queries about the `{file_base}.html` part of the LlamaIndex docs.\\nYou must ALWAYS use at least one of the tools provided when answering a question; do NOT rely on prior knowledge.\\\\\\n\"\"\",\\n)\\n\\nreturn agent, summary\\n\\n\\nasync def build_agents(docs):\\nnode_parser = SentenceSplitter()\\n\\n# Build agents dictionary\\nagents_dict = {}\\nextra_info_dict = {}\\n\\n# # this is for the baseline\\n# all_nodes = []\\n\\nfor idx, doc in enumerate(tqdm(docs)):\\nnodes = node_parser.get_nodes_from_documents([doc])\\n# all_nodes.extend(nodes)\\n\\n# ID will be base + parent\\nfile_path = Path(doc.metadata[\"path\"])\\nfile_base = str(file_path.parent.stem) + \"_\" + str(file_path.stem)\\nagent, summary = await build_agent_per_doc(nodes, file_base)\\n\\nagents_dict[file_base] = agent\\nextra_info_dict[file_base] = {\"summary\": summary, \"nodes\": nodes}\\n\\nreturn agents_dict, extra_info_dict\\n```  \\n```python\\nagents_dict, extra_info_dict = await build_agents(docs)\\n```', metadata={'Header 1': 'Multi-Document Agents (V1)', 'Header 2': 'Building Multi-Document Agents', 'Header 3': 'Build Document Agent for each Document'}),\n",
      " Document(page_content='We build a top-level agent that can orchestrate across the different document agents to answer any user query.  \\nThis `RetrieverOpenAIAgent` performs tool retrieval before tool use (unlike a default agent that tries to put all tools in the prompt).  \\n**Improvements from V0**: We make the following improvements compared to the \"base\" version in V0.  \\n- Adding in reranking: we use Cohere reranker to better filter the candidate set of documents.\\n- Adding in a query planning tool: we add an explicit query planning tool that\\'s dynamically created based on the set of retrieved tools.  \\n```python\\n# define tool for each document agent\\nall_tools = []\\nfor file_base, agent in agents_dict.items():\\nsummary = extra_info_dict[file_base][\"summary\"]\\ndoc_tool = QueryEngineTool(\\nquery_engine=agent,\\nmetadata=ToolMetadata(\\nname=f\"tool_{file_base}\",\\ndescription=summary,\\n),\\n)\\nall_tools.append(doc_tool)\\n```  \\n```python\\nprint(all_tools[0].metadata)\\n```  \\nToolMetadata(description=\\'LlamaIndex is a data framework that allows LLM applications to ingest, structure, and access private or domain-specific data by providing tools such as data connectors, data indexes, engines, data agents, and application integrations. It is designed for beginners, advanced users, and everyone in between, and offers both high-level and lower-level APIs for customization. LlamaIndex can be installed using pip and has detailed documentation and tutorials available. It is available on GitHub and PyPi, and there is also a Typescript package available. The LlamaIndex community can be joined on Twitter and Discord.\\', name=\\'tool_latest_index\\', fn_schema=<class \\'llama_index.tools.types.DefaultToolFnSchema\\'>)  \\n```python\\n# define an \"object\" index and retriever over these tools\\nfrom llama_index import VectorStoreIndex\\nfrom llama_index.objects import (\\nObjectIndex,\\nSimpleToolNodeMapping,\\nObjectRetriever,\\n)\\nfrom llama_index.retrievers import BaseRetriever\\nfrom llama_index.postprocessor import CohereRerank\\nfrom llama_index.tools import QueryPlanTool\\nfrom llama_index.query_engine import SubQuestionQueryEngine\\nfrom llama_index.llms import OpenAI\\n\\nllm = OpenAI(model_name=\"gpt-4-0613\")\\n\\ntool_mapping = SimpleToolNodeMapping.from_objects(all_tools)\\nobj_index = ObjectIndex.from_objects(\\nall_tools,\\ntool_mapping,\\nVectorStoreIndex,\\n)\\nvector_node_retriever = obj_index.as_node_retriever(similarity_top_k=10)\\n\\n\\n# define a custom retriever with reranking\\nclass CustomRetriever(BaseRetriever):\\ndef __init__(self, vector_retriever, postprocessor=None):\\nself._vector_retriever = vector_retriever\\nself._postprocessor = postprocessor or CohereRerank(top_n=5)\\nsuper().__init__()\\n\\ndef _retrieve(self, query_bundle):\\nretrieved_nodes = self._vector_retriever.retrieve(query_bundle)\\nfiltered_nodes = self._postprocessor.postprocess_nodes(\\nretrieved_nodes, query_bundle=query_bundle\\n)\\n\\nreturn filtered_nodes\\n\\n\\n# define a custom object retriever that adds in a query planning tool\\nclass CustomObjectRetriever(ObjectRetriever):\\ndef __init__(self, retriever, object_node_mapping, all_tools, llm=None):\\nself._retriever = retriever\\nself._object_node_mapping = object_node_mapping\\nself._llm = llm or OpenAI(\"gpt-4-0613\")\\n\\ndef retrieve(self, query_bundle):\\nnodes = self._retriever.retrieve(query_bundle)\\ntools = [self._object_node_mapping.from_node(n.node) for n in nodes]\\n\\nsub_question_sc = ServiceContext.from_defaults(llm=self._llm)\\nsub_question_engine = SubQuestionQueryEngine.from_defaults(\\nquery_engine_tools=tools, service_context=sub_question_sc\\n)\\nsub_question_description = f\"\"\"\\\\\\nUseful for any queries that involve comparing multiple documents. ALWAYS use this tool for comparison queries - make sure to call this \\\\\\ntool with the original query. Do NOT use the other tools for any queries involving multiple documents.\\n\"\"\"\\nsub_question_tool = QueryEngineTool(\\nquery_engine=sub_question_engine,\\nmetadata=ToolMetadata(\\nname=\"compare_tool\", description=sub_question_description\\n),\\n)\\n\\nreturn tools + [sub_question_tool]\\n```  \\n```python\\ncustom_node_retriever = CustomRetriever(vector_node_retriever)\\n\\n# wrap it with ObjectRetriever to return objects\\ncustom_obj_retriever = CustomObjectRetriever(\\ncustom_node_retriever, tool_mapping, all_tools, llm=llm\\n)\\n```  \\n```python\\ntmps = custom_obj_retriever.retrieve(\"hello\")\\nprint(len(tmps))\\n```  \\n6  \\n```python\\nfrom llama_index.agent import FnRetrieverOpenAIAgent, ReActAgent\\n\\ntop_agent = FnRetrieverOpenAIAgent.from_retriever(\\ncustom_obj_retriever,\\nsystem_prompt=\"\"\" \\\\\\nYou are an agent designed to answer queries about the documentation.\\nPlease always use the tools provided to answer a question. Do not rely on prior knowledge.\\\\\\n\\n\"\"\",\\nllm=llm,\\nverbose=True,\\n)\\n\\n# top_agent = ReActAgent.from_tools(\\n#     tool_retriever=custom_obj_retriever,\\n#     system_prompt=\"\"\" \\\\\\n# You are an agent designed to answer queries about the documentation.\\n# Please always use the tools provided to answer a question. Do not rely on prior knowledge.\\\\\\n\\n# \"\"\",\\n#     llm=llm,\\n#     verbose=True,\\n# )\\n```', metadata={'Header 1': 'Multi-Document Agents (V1)', 'Header 2': 'Building Multi-Document Agents', 'Header 3': 'Build Retriever-Enabled OpenAI Agent'}),\n",
      " Document(page_content='As a point of comparison, we define a \"naive\" RAG pipeline which dumps all docs into a single vector index collection.  \\nWe set the top_k = 4  \\n```python\\nall_nodes = [\\nn for extra_info in extra_info_dict.values() for n in extra_info[\"nodes\"]\\n]\\n```  \\n```python\\nbase_index = VectorStoreIndex(all_nodes)\\nbase_query_engine = base_index.as_query_engine(similarity_top_k=4)\\n```', metadata={'Header 1': 'Multi-Document Agents (V1)', 'Header 2': 'Building Multi-Document Agents', 'Header 3': 'Define Baseline Vector Store Index'}),\n",
      " Document(page_content='Let\\'s run some example queries, ranging from QA / summaries over a single document to QA / summarization over multiple documents.  \\n```python\\nresponse = top_agent.query(\\n\"Tell me about the different types of evaluation in LlamaIndex\"\\n)\\n```  \\n=== Calling Function ===\\nCalling function: tool_api_reference_evaluation with args: {\\n\"input\": \"types of evaluation\"\\n}\\n=== Calling Function ===\\nCalling function: vector_tool_api_reference_evaluation with args: {\\n\"input\": \"types of evaluation\"\\n}\\nGot output: The types of evaluation can include correctness evaluation, faithfulness evaluation, guideline evaluation, hit rate evaluation, MRR (Mean Reciprocal Rank) evaluation, pairwise comparison evaluation, relevancy evaluation, and response evaluation.\\n========================\\nGot output: The types of evaluation mentioned in the `api_reference_evaluation.html` part of the LlamaIndex docs include:  \\n1. Correctness Evaluation\\n2. Faithfulness Evaluation\\n3. Guideline Evaluation\\n4. Hit Rate Evaluation\\n5. MRR (Mean Reciprocal Rank) Evaluation\\n6. Pairwise Comparison Evaluation\\n7. Relevancy Evaluation\\n8. Response Evaluation\\n========================  \\n```python\\nprint(response)\\n```  \\nThere are several types of evaluation in LlamaIndex:  \\n1. Correctness Evaluation: This type of evaluation measures the accuracy of the retrieval results. It checks if the retrieved documents are correct and relevant to the query.  \\n2. Faithfulness Evaluation: Faithfulness evaluation measures how faithfully the retrieved documents represent the original data. It checks if the retrieved documents accurately reflect the information in the original documents.  \\n3. Guideline Evaluation: Guideline evaluation involves comparing the retrieval results against a set of guidelines or ground truth. It checks if the retrieval results align with the expected or desired outcomes.  \\n4. Hit Rate Evaluation: Hit rate evaluation measures the percentage of queries that return at least one relevant document. It is a binary evaluation metric that indicates the effectiveness of the retrieval system in finding relevant documents.  \\n5. MRR (Mean Reciprocal Rank) Evaluation: MRR evaluation measures the average rank of the first relevant document in the retrieval results. It provides a single value that represents the effectiveness of the retrieval system in ranking relevant documents.  \\n6. Pairwise Comparison Evaluation: Pairwise comparison evaluation involves comparing the retrieval results of different systems or algorithms. It helps determine which system performs better in terms of retrieval accuracy and relevance.  \\n7. Relevancy Evaluation: Relevancy evaluation measures the relevance of the retrieved documents to the query. It can be done using various metrics such as precision, recall, and F1 score.  \\n8. Response Evaluation: Response evaluation measures the quality of the response generated by the retrieval system. It checks if the response is informative, accurate, and helpful to the user.  \\nThese evaluation types help assess the performance and effectiveness of the retrieval system in LlamaIndex.  \\n```python\\n# baseline\\nresponse = base_query_engine.query(\\n\"Tell me about the different types of evaluation in LlamaIndex\"\\n)\\nprint(str(response))\\n```  \\nLlamaIndex utilizes various types of evaluation methods to assess its performance and effectiveness. These evaluation methods include RelevancyEvaluator, RetrieverEvaluator, SemanticSimilarityEvaluator, PairwiseComparisonEvaluator, CorrectnessEvaluator, FaithfulnessEvaluator, and GuidelineEvaluator. Each of these evaluators serves a specific purpose in evaluating different aspects of the LlamaIndex system.  \\n```python\\nresponse = top_agent.query(\\n\"Compare the content in the contributions page vs. index page.\"\\n)\\n```  \\n=== Calling Function ===\\nCalling function: compare_tool with args: {\\n\"input\": \"content in the contributions page vs. index page\"\\n}\\nGenerated 2 sub questions.\\n\\x1b[1;3;38;2;237;90;200m[tool_development_contributing] Q: What is the content of the contributions page?\\n\\x1b[0m\\x1b[1;3;38;2;90;149;237m[tool_latest_index] Q: What is the content of the index page?\\n\\x1b[0m=== Calling Function ===\\nCalling function: summary_tool_development_contributing with args: {\\n\"input\": \"development_contributing.html\"\\n}\\n=== Calling Function ===\\nCalling function: vector_tool_latest_index with args: {\\n\"input\": \"content of the index page\"\\n}\\nGot output: The development_contributing.html file provides information on how to contribute to LlamaIndex. It includes guidelines on what to work on, such as extending core modules, fixing bugs, adding usage examples, adding experimental features, and improving code quality and documentation. The file also provides details on each module, including data loaders, node parsers, text splitters, document/index/KV stores, managed index, vector stores, retrievers, query engines, query transforms, token usage optimizers, node postprocessors, and output parsers. Additionally, the file includes a development guideline section that covers environment setup, validating changes, formatting/linting, testing, creating example notebooks, and creating a pull request.\\n========================\\nGot output: The content of the index page provides information about LlamaIndex, a data framework for LLM applications. It explains why LlamaIndex is useful for augmenting LLM models with private or domain-specific data that may be distributed across different applications and data stores. LlamaIndex offers tools such as data connectors, data indexes, engines, and data agents to ingest, structure, and access data. It is designed for beginners as well as advanced users who can customize and extend its modules. The page also provides installation instructions, tutorials, and links to the LlamaIndex ecosystem and associated projects.\\n========================\\n\\x1b[1;3;38;2;90;149;237m[tool_latest_index] A: The content of the `latest_index.html` page provides comprehensive information about LlamaIndex, a data framework for LLM applications. It explains the utility of LlamaIndex in augmenting LLM models with private or domain-specific data that may be distributed across different applications and data stores.  \\nThe page details the tools offered by LlamaIndex, such as data connectors, data indexes, engines, and data agents, which are used to ingest, structure, and access data. It is designed to cater to both beginners and advanced users, with the flexibility to customize and extend its modules.  \\nAdditionally, the page provides installation instructions and tutorials for users. It also includes links to the LlamaIndex ecosystem and associated projects for further exploration and understanding.\\n\\x1b[0m\\x1b[1;3;38;2;237;90;200m[tool_development_contributing] A: The `development_contributing.html` page of the LlamaIndex docs provides comprehensive information on how to contribute to the project. It includes guidelines on the areas to focus on, such as extending core modules, fixing bugs, adding usage examples, adding experimental features, and improving code quality and documentation.  \\nThe page also provides detailed information on each module, including data loaders, node parsers, text splitters, document/index/KV stores, managed index, vector stores, retrievers, query engines, query transforms, token usage optimizers, node postprocessors, and output parsers.  \\nIn addition, there is a development guideline section that covers various aspects of the development process, including environment setup, validating changes, formatting/linting, testing, creating example notebooks, and creating a pull request.\\n\\x1b[0mGot output: The content in the contributions page of the LlamaIndex documentation provides comprehensive information on how to contribute to the project, including guidelines on areas to focus on and detailed information on each module. It also covers various aspects of the development process.  \\nOn the other hand, the content in the index page of the LlamaIndex documentation provides comprehensive information about LlamaIndex itself, explaining its utility in augmenting LLM models with private or domain-specific data. It details the tools offered by LlamaIndex and provides installation instructions, tutorials, and links to the LlamaIndex ecosystem and associated projects.\\n========================  \\n```python\\nprint(response)\\n```  \\nThe contributions page of the LlamaIndex documentation provides guidelines for contributing to LlamaIndex, including extending core modules, fixing bugs, adding usage examples, adding experimental features, and improving code quality and documentation. It also includes information on the environment setup, validating changes, formatting and linting, testing, creating example notebooks, and creating a pull request.  \\nOn the other hand, the index page of the LlamaIndex documentation provides information about LlamaIndex itself. It explains that LlamaIndex is a data framework that allows LLM applications to ingest, structure, and access private or domain-specific data. It provides tools such as data connectors, data indexes, engines, data agents, and application integrations. The index page also mentions that LlamaIndex is designed for beginners, advanced users, and everyone in between, and offers both high-level and lower-level APIs for customization. It provides installation instructions, links to the GitHub and PyPi repositories, and information about the LlamaIndex community on Twitter and Discord.  \\nIn summary, the contributions page focuses on contributing to LlamaIndex, while the index page provides an overview of LlamaIndex and its features.  \\n```python\\nresponse = top_agent.query(\\n\"Can you compare the tree index and list index at a very high-level?\"\\n)\\n```  \\n```python\\nprint(str(response))\\n```  \\nAt a high level, the Tree Index and List Index are two different types of indexes used in the system.  \\nThe Tree Index is a tree-structured index that is built specifically for each query. It allows for the construction of a query-specific tree from leaf nodes to return a response. The Tree Index is designed to provide a more optimized and efficient way of retrieving nodes based on a query.  \\nOn the other hand, the List Index is a keyword table index that supports operations such as inserting and deleting documents, retrieving nodes based on a query, and refreshing the index with updated documents. The List Index is a simpler index that uses a keyword table approach for retrieval.  \\nBoth indexes have their own advantages and use cases. The choice between them depends on the specific requirements and constraints of the system.', metadata={'Header 1': 'Multi-Document Agents (V1)', 'Header 2': 'Running Example Queries'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/multi_document_agents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>'),\n",
      " Document(page_content='In this guide, you learn towards setting up an agent that can effectively answer different types of questions over a larger set of documents.  \\nThese questions include the following  \\n- QA over a specific doc\\n- QA comparing different docs\\n- Summaries over a specific doc\\n- Comparing summaries between different docs  \\nWe do this with the following architecture:  \\n- setup a \"document agent\" over each Document: each doc agent can do QA/summarization within its doc\\n- setup a top-level agent over this set of document agents. Do tool retrieval and then do CoT over the set of tools to answer a question.', metadata={'Header 1': 'Multi-Document Agents'}),\n",
      " Document(page_content='In this section, we\\'ll define imports and then download Wikipedia articles about different cities. Each article is stored separately.  \\nWe load in 18 cities - this is not quite at the level of \"hundreds\" of documents but its still large enough to warrant some top-level document retrieval!  \\nIf you\\'re opening this Notebook on colab, you will probably need to install LlamaIndex 🦙.  \\n```python\\n!pip install llama-index\\n```  \\n```python\\nfrom llama_index import (\\nVectorStoreIndex,\\nSummaryIndex,\\nSimpleKeywordTableIndex,\\nSimpleDirectoryReader,\\nServiceContext,\\n)\\nfrom llama_index.schema import IndexNode\\nfrom llama_index.tools import QueryEngineTool, ToolMetadata\\nfrom llama_index.llms import OpenAI\\n```  \\n```python\\nwiki_titles = [\\n\"Toronto\",\\n\"Seattle\",\\n\"Chicago\",\\n\"Boston\",\\n\"Houston\",\\n\"Tokyo\",\\n\"Berlin\",\\n\"Lisbon\",\\n\"Paris\",\\n\"London\",\\n\"Atlanta\",\\n\"Munich\",\\n\"Shanghai\",\\n\"Beijing\",\\n\"Copenhagen\",\\n\"Moscow\",\\n\"Cairo\",\\n\"Karachi\",\\n]\\n```  \\n```python\\nfrom pathlib import Path\\n\\nimport requests\\n\\nfor title in wiki_titles:\\nresponse = requests.get(\\n\"https://en.wikipedia.org/w/api.php\",\\nparams={\\n\"action\": \"query\",\\n\"format\": \"json\",\\n\"titles\": title,\\n\"prop\": \"extracts\",\\n# \\'exintro\\': True,\\n\"explaintext\": True,\\n},\\n).json()\\npage = next(iter(response[\"query\"][\"pages\"].values()))\\nwiki_text = page[\"extract\"]\\n\\ndata_path = Path(\"data\")\\nif not data_path.exists():\\nPath.mkdir(data_path)\\n\\nwith open(data_path / f\"{title}.txt\", \"w\") as fp:\\nfp.write(wiki_text)\\n```  \\n```python\\n# Load all wiki documents\\ncity_docs = {}\\nfor wiki_title in wiki_titles:\\ncity_docs[wiki_title] = SimpleDirectoryReader(\\ninput_files=[f\"data/{wiki_title}.txt\"]\\n).load_data()\\n```  \\nDefine LLM + Service Context + Callback Manager  \\n```python\\nllm = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\\nservice_context = ServiceContext.from_defaults(llm=llm)\\n```', metadata={'Header 1': 'Multi-Document Agents', 'Header 2': 'Setup and Download Data'}),\n",
      " Document(page_content='In this section we show you how to construct the multi-document agent. We first build a document agent for each document, and then define the top-level parent agent with an object index.', metadata={'Header 1': 'Multi-Document Agents', 'Header 2': 'Building Multi-Document Agents'}),\n",
      " Document(page_content='In this section we define \"document agents\" for each document.  \\nWe define both a vector index (for semantic search) and summary index (for summarization) for each document. The two query engines are then converted into tools that are passed to an OpenAI function calling agent.  \\nThis document agent can dynamically choose to perform semantic search or summarization within a given document.  \\nWe create a separate document agent for each city.  \\n```python\\nfrom llama_index.agent import OpenAIAgent\\nfrom llama_index import load_index_from_storage, StorageContext\\nfrom llama_index.node_parser import SentenceSplitter\\nimport os\\n\\nnode_parser = SentenceSplitter()\\n\\n# Build agents dictionary\\nagents = {}\\nquery_engines = {}\\n\\n# this is for the baseline\\nall_nodes = []\\n\\nfor idx, wiki_title in enumerate(wiki_titles):\\nnodes = node_parser.get_nodes_from_documents(city_docs[wiki_title])\\nall_nodes.extend(nodes)\\n\\nif not os.path.exists(f\"./data/{wiki_title}\"):\\n# build vector index\\nvector_index = VectorStoreIndex(nodes, service_context=service_context)\\nvector_index.storage_context.persist(\\npersist_dir=f\"./data/{wiki_title}\"\\n)\\nelse:\\nvector_index = load_index_from_storage(\\nStorageContext.from_defaults(persist_dir=f\"./data/{wiki_title}\"),\\nservice_context=service_context,\\n)\\n\\n# build summary index\\nsummary_index = SummaryIndex(nodes, service_context=service_context)\\n# define query engines\\nvector_query_engine = vector_index.as_query_engine()\\nsummary_query_engine = summary_index.as_query_engine()\\n\\n# define tools\\nquery_engine_tools = [\\nQueryEngineTool(\\nquery_engine=vector_query_engine,\\nmetadata=ToolMetadata(\\nname=\"vector_tool\",\\ndescription=(\\n\"Useful for questions related to specific aspects of\"\\nf\" {wiki_title} (e.g. the history, arts and culture,\"\\n\" sports, demographics, or more).\"\\n),\\n),\\n),\\nQueryEngineTool(\\nquery_engine=summary_query_engine,\\nmetadata=ToolMetadata(\\nname=\"summary_tool\",\\ndescription=(\\n\"Useful for any requests that require a holistic summary\"\\nf\" of EVERYTHING about {wiki_title}. For questions about\"\\n\" more specific sections, please use the vector_tool.\"\\n),\\n),\\n),\\n]\\n\\n# build agent\\nfunction_llm = OpenAI(model=\"gpt-4\")\\nagent = OpenAIAgent.from_tools(\\nquery_engine_tools,\\nllm=function_llm,\\nverbose=True,\\nsystem_prompt=f\"\"\"\\\\\\nYou are a specialized agent designed to answer queries about {wiki_title}.\\nYou must ALWAYS use at least one of the tools provided when answering a question; do NOT rely on prior knowledge.\\\\\\n\"\"\",\\n)\\n\\nagents[wiki_title] = agent\\nquery_engines[wiki_title] = vector_index.as_query_engine(\\nsimilarity_top_k=2\\n)\\n```', metadata={'Header 1': 'Multi-Document Agents', 'Header 2': 'Building Multi-Document Agents', 'Header 3': 'Build Document Agent for each Document'}),\n",
      " Document(page_content='We build a top-level agent that can orchestrate across the different document agents to answer any user query.  \\nThis agent takes in all document agents as tools. This specific agent `RetrieverOpenAIAgent` performs tool retrieval before tool use (unlike a default agent that tries to put all tools in the prompt).  \\nHere we use a top-k retriever, but we encourage you to customize the tool retriever method!  \\n```python\\n# define tool for each document agent\\nall_tools = []\\nfor wiki_title in wiki_titles:\\nwiki_summary = (\\nf\"This content contains Wikipedia articles about {wiki_title}. Use\"\\nf\" this tool if you want to answer any questions about {wiki_title}.\\\\n\"\\n)\\ndoc_tool = QueryEngineTool(\\nquery_engine=agents[wiki_title],\\nmetadata=ToolMetadata(\\nname=f\"tool_{wiki_title}\",\\ndescription=wiki_summary,\\n),\\n)\\nall_tools.append(doc_tool)\\n```  \\n```python\\n# define an \"object\" index and retriever over these tools\\nfrom llama_index import VectorStoreIndex\\nfrom llama_index.objects import ObjectIndex, SimpleToolNodeMapping\\n\\ntool_mapping = SimpleToolNodeMapping.from_objects(all_tools)\\nobj_index = ObjectIndex.from_objects(\\nall_tools,\\ntool_mapping,\\nVectorStoreIndex,\\n)\\n```  \\n```python\\nfrom llama_index.agent import FnRetrieverOpenAIAgent\\n\\ntop_agent = FnRetrieverOpenAIAgent.from_retriever(\\nobj_index.as_retriever(similarity_top_k=3),\\nsystem_prompt=\"\"\" \\\\\\nYou are an agent designed to answer queries about a set of given cities.\\nPlease always use the tools provided to answer a question. Do not rely on prior knowledge.\\\\\\n\\n\"\"\",\\nverbose=True,\\n)\\n```', metadata={'Header 1': 'Multi-Document Agents', 'Header 2': 'Building Multi-Document Agents', 'Header 3': 'Build Retriever-Enabled OpenAI Agent'}),\n",
      " Document(page_content='As a point of comparison, we define a \"naive\" RAG pipeline which dumps all docs into a single vector index collection.  \\nWe set the top_k = 4  \\n```python\\nbase_index = VectorStoreIndex(all_nodes)\\nbase_query_engine = base_index.as_query_engine(similarity_top_k=4)\\n```', metadata={'Header 1': 'Multi-Document Agents', 'Header 2': 'Building Multi-Document Agents', 'Header 3': 'Define Baseline Vector Store Index'}),\n",
      " Document(page_content='Let\\'s run some example queries, ranging from QA / summaries over a single document to QA / summarization over multiple documents.  \\n```python\\n# should use Boston agent -> vector tool\\nresponse = top_agent.query(\"Tell me about the arts and culture in Boston\")\\n```  \\n=== Calling Function ===\\nCalling function: tool_Boston with args: {\\n\"input\": \"arts and culture\"\\n}\\n=== Calling Function ===\\nCalling function: vector_tool with args: {\\n\"input\": \"arts and culture\"\\n}\\nGot output: Boston is known for its vibrant arts and culture scene. The city is home to a number of performing arts organizations, including the Boston Ballet, Boston Lyric Opera Company, Opera Boston, Boston Baroque, and the Handel and Haydn Society. There are also several theaters in or near the Theater District, such as the Cutler Majestic Theatre, Citi Performing Arts Center, the Colonial Theater, and the Orpheum Theatre. Boston is a center for contemporary classical music, with groups like the Boston Modern Orchestra Project and Boston Musica Viva. The city also hosts major annual events, such as First Night, the Boston Early Music Festival, and the Boston Arts Festival. In addition, Boston has several art museums and galleries, including the Museum of Fine Arts, the Isabella Stewart Gardner Museum, and the Institute of Contemporary Art.\\n========================\\nGot output: Boston is renowned for its vibrant arts and culture scene. It is home to numerous performing arts organizations, including the Boston Ballet, Boston Lyric Opera Company, Opera Boston, Boston Baroque, and the Handel and Haydn Society. The city\\'s Theater District houses several theaters, such as the Cutler Majestic Theatre, Citi Performing Arts Center, the Colonial Theater, and the Orpheum Theatre.  \\nBoston is also a hub for contemporary classical music, with groups like the Boston Modern Orchestra Project and Boston Musica Viva. The city hosts major annual events, such as First Night, the Boston Early Music Festival, and the Boston Arts Festival, which contribute to its cultural richness.  \\nIn terms of visual arts, Boston boasts several art museums and galleries. The Museum of Fine Arts, the Isabella Stewart Gardner Museum, and the Institute of Contemporary Art are among the most notable. These institutions offer a wide range of art collections, from ancient to contemporary, attracting art enthusiasts from around the world.\\n========================  \\n```python\\nprint(response)\\n```  \\nBoston has a rich arts and culture scene, with a variety of performing arts organizations and venues. The city is home to renowned institutions such as the Boston Ballet, Boston Lyric Opera Company, Opera Boston, Boston Baroque, and the Handel and Haydn Society. The Theater District in Boston is a hub for theatrical performances, with theaters like the Cutler Majestic Theatre, Citi Performing Arts Center, Colonial Theater, and Orpheum Theatre.  \\nIn addition to performing arts, Boston also has a thriving contemporary classical music scene, with groups like the Boston Modern Orchestra Project and Boston Musica Viva. The city hosts several annual events that celebrate the arts, including First Night, the Boston Early Music Festival, and the Boston Arts Festival.  \\nBoston is also known for its visual arts scene, with a number of art museums and galleries. The Museum of Fine Arts, the Isabella Stewart Gardner Museum, and the Institute of Contemporary Art are among the notable institutions in the city. These museums offer a diverse range of art collections, spanning from ancient to contemporary art, and attract art enthusiasts from around the world.  \\n```python\\n# baseline\\nresponse = base_query_engine.query(\\n\"Tell me about the arts and culture in Boston\"\\n)\\nprint(str(response))\\n```  \\nBoston has a rich arts and culture scene. The city is home to a variety of performing arts organizations, such as the Boston Ballet, Boston Lyric Opera Company, Opera Boston, Boston Baroque, and the Handel and Haydn Society. Additionally, there are numerous contemporary classical music groups associated with the city\\'s conservatories and universities, like the Boston Modern Orchestra Project and Boston Musica Viva. The Theater District in Boston is a hub for theater, with notable venues including the Cutler Majestic Theatre, Citi Performing Arts Center, the Colonial Theater, and the Orpheum Theatre. Boston also hosts several significant annual events, including First Night, the Boston Early Music Festival, the Boston Arts Festival, and the Boston gay pride parade and festival. The city is renowned for its historic sites connected to the American Revolution, as well as its art museums and galleries, such as the Museum of Fine Arts, Isabella Stewart Gardner Museum, and the Institute of Contemporary Art.  \\n```python\\n# should use Houston agent -> vector tool\\nresponse = top_agent.query(\\n\"Give me a summary of all the positive aspects of Houston\"\\n)\\n```  \\n=== Calling Function ===\\nCalling function: tool_Houston with args: {\\n\"input\": \"positive aspects\"\\n}\\n=== Calling Function ===\\nCalling function: summary_tool with args: {\\n\"input\": \"positive aspects\"\\n}\\nGot output: Houston has many positive aspects that make it an attractive place to live and visit. The city\\'s diverse population, with people from different ethnic and religious backgrounds, adds to its cultural richness and inclusiveness. Additionally, Houston is home to the Texas Medical Center, which is the largest concentration of healthcare and research institutions in the world. The presence of NASA\\'s Johnson Space Center also highlights Houston\\'s importance in the fields of medicine and space exploration. The city\\'s strong economy, supported by industries such as energy, manufacturing, aeronautics, and transportation, provides numerous economic opportunities for residents and visitors alike. Furthermore, Houston has a thriving visual and performing arts scene, including a theater district and a variety of museums and galleries. Overall, Houston\\'s diverse community, cultural attractions, and economic prospects make it an exceptionally appealing city.\\n========================\\nGot output: Houston has numerous positive aspects that make it a desirable place to live and visit. Some of these include:  \\n1. **Diversity**: Houston is known for its diverse population, with people from different ethnic and religious backgrounds. This diversity adds to the city\\'s cultural richness and inclusiveness.  \\n2. **Healthcare and Research Institutions**: The city is home to the Texas Medical Center, the largest concentration of healthcare and research institutions in the world. This makes Houston a hub for medical innovation and healthcare services.  \\n3. **Space Exploration**: Houston is also known for NASA\\'s Johnson Space Center, highlighting the city\\'s significant role in space exploration.  \\n4. **Strong Economy**: Houston\\'s economy is robust and diverse, supported by industries such as energy, manufacturing, aeronautics, and transportation. This provides numerous economic opportunities for its residents.  \\n5. **Arts and Culture**: The city has a thriving visual and performing arts scene, with a theater district and a variety of museums and galleries. This makes Houston a vibrant place for art lovers and creatives.  \\nOverall, these aspects contribute to making Houston an appealing and dynamic city.\\n========================  \\n```python\\nprint(response)\\n```  \\nHouston has numerous positive aspects that make it a desirable place to live and visit. Some of these include:  \\n1. Diversity: Houston is known for its diverse population, with people from different ethnic and religious backgrounds. This diversity adds to the city\\'s cultural richness and inclusiveness.  \\n2. Healthcare and Research Institutions: The city is home to the Texas Medical Center, the largest concentration of healthcare and research institutions in the world. This makes Houston a hub for medical innovation and healthcare services.  \\n3. Space Exploration: Houston is also known for NASA\\'s Johnson Space Center, highlighting the city\\'s significant role in space exploration.  \\n4. Strong Economy: Houston\\'s economy is robust and diverse, supported by industries such as energy, manufacturing, aeronautics, and transportation. This provides numerous economic opportunities for its residents.  \\n5. Arts and Culture: The city has a thriving visual and performing arts scene, with a theater district and a variety of museums and galleries. This makes Houston a vibrant place for art lovers and creatives.  \\nOverall, these aspects contribute to making Houston an appealing and dynamic city.  \\n```python\\n# baseline\\nresponse = base_query_engine.query(\\n\"Give me a summary of all the positive aspects of Houston\"\\n)\\nprint(str(response))\\n```  \\nHouston has several positive aspects that contribute to its reputation as a thriving city. It is home to a diverse and growing international community, with a large number of foreign banks and consular offices representing 92 countries. The city has received numerous accolades, including being ranked as one of the best cities for employment, college graduates, and homebuyers. Houston has a strong economy, with a broad industrial base in sectors such as energy, manufacturing, aeronautics, and healthcare. It is also a major center for the oil and gas industry and has the second-most Fortune 500 headquarters in the United States. The city\\'s cultural scene is vibrant, with a variety of annual events celebrating different cultures, as well as a reputation for diverse and excellent food. Houston is known for its world-class museums and performing arts scene. Additionally, the city has made significant investments in renewable energy sources like wind and solar. Overall, Houston offers a high quality of life, reasonable living costs, and abundant employment opportunities.  \\n```python\\n# baseline: the response doesn\\'t quite match the sources...\\nresponse.source_nodes[1].get_content()\\n```  \\n```python\\nresponse = top_agent.query(\\n\"Tell the demographics of Houston, and then compare that with the\"\\n\" demographics of Chicago\"\\n)\\n```  \\n=== Calling Function ===\\nCalling function: tool_Houston with args: {\\n\"input\": \"demographics\"\\n}\\n=== Calling Function ===\\nCalling function: vector_tool with args: {\\n\"input\": \"demographics\"\\n}\\nGot output: Houston is a majority-minority city with a diverse population. According to the U.S. Census Bureau, in 2019, non-Hispanic whites made up 23.3% of the population, Hispanics and Latino Americans 45.8%, Blacks or African Americans 22.4%, and Asian Americans 6.5%. The largest Hispanic or Latino American ethnic group in the city is Mexican Americans, followed by Puerto Ricans and Cuban Americans. Houston is also home to the largest African American community west of the Mississippi River. Additionally, Houston has a growing Muslim population, with Muslims estimated to make up 1.2% of the city\\'s population. The city is known for its LGBT community and is home to one of the largest pride parades in the United States. The Hindu, Sikh, and Buddhist communities are also growing in Houston. Overall, Houston is considered one of the most ethnically and culturally diverse metropolitan areas in the country.\\n========================\\nGot output: Houston is a majority-minority city with a diverse population. According to the U.S. Census Bureau, in 2019, non-Hispanic whites made up 23.3% of the population, Hispanics and Latino Americans 45.8%, Blacks or African Americans 22.4%, and Asian Americans 6.5%. The largest Hispanic or Latino American ethnic group in the city is Mexican Americans, followed by Puerto Ricans and Cuban Americans.  \\nHouston is also home to the largest African American community west of the Mississippi River. Additionally, Houston has a growing Muslim population, with Muslims estimated to make up 1.2% of the city\\'s population. The city is known for its LGBT community and is home to one of the largest pride parades in the United States. The Hindu, Sikh, and Buddhist communities are also growing in Houston.  \\nOverall, Houston is considered one of the most ethnically and culturally diverse metropolitan areas in the country.\\n========================\\n=== Calling Function ===\\nCalling function: tool_Chicago with args: {\\n\"input\": \"demographics\"\\n}\\n=== Calling Function ===\\nCalling function: vector_tool with args: {\\n\"input\": \"demographics\"\\n}\\nGot output: Chicago has a diverse demographic makeup. It experienced rapid population growth during its early years, becoming one of the fastest-growing cities in the world. Waves of immigrants from various European countries, as well as African Americans from the American South, contributed to the city\\'s population growth. Over time, Chicago\\'s population has fluctuated, with a decline in the latter half of the 20th century followed by a rise in recent years. As of the latest census estimates, the largest racial or ethnic groups in Chicago are non-Hispanic White, Black, and Hispanic. Additionally, Chicago has a significant LGBT population and is known for its cultural diversity.\\n========================\\nGot output: Chicago is known for its diverse demographic makeup. The city experienced rapid population growth during its early years, with immigrants from various European countries and African Americans from the American South contributing significantly to this growth. Over time, the population has fluctuated, with a decline in the latter half of the 20th century followed by a rise in recent years.  \\nAs per the latest census estimates, the largest racial or ethnic groups in Chicago are non-Hispanic White, Black, and Hispanic. The city also has a significant LGBT population and is celebrated for its cultural diversity.\\n========================  \\n```python\\nprint(response)\\n```  \\nHouston has a diverse population with a demographic makeup that includes non-Hispanic whites (23.3%), Hispanics and Latino Americans (45.8%), Blacks or African Americans (22.4%), and Asian Americans (6.5%). The largest Hispanic or Latino American ethnic group in Houston is Mexican Americans. Houston is also home to the largest African American community west of the Mississippi River and has a growing Muslim population.  \\nOn the other hand, Chicago is also known for its diverse demographics. The city has a significant non-Hispanic White population, along with a substantial Black population and Hispanic population. Chicago is celebrated for its cultural diversity and has a significant LGBT population.  \\nBoth Houston and Chicago have diverse populations, with a mix of different racial and ethnic groups contributing to their vibrant communities.  \\n```python\\n# baseline\\nresponse = base_query_engine.query(\\n\"Tell the demographics of Houston, and then compare that with the\"\\n\" demographics of Chicago\"\\n)\\nprint(str(response))\\n```  \\nHouston is the most populous city in Texas and the fourth-most populous city in the United States. It has a population of 2,304,580 as of the 2020 U.S. census. The city is known for its diversity, with a significant proportion of minorities. In 2019, non-Hispanic whites made up 23.3% of the population, Hispanics and Latino Americans 45.8%, Blacks or African Americans 22.4%, and Asian Americans 6.5%. The largest Hispanic or Latino American ethnic group in Houston is Mexican Americans, comprising 31.6% of the population.  \\nIn comparison, Chicago is the third-most populous city in the United States. According to the 2020 U.S. census, Chicago has a population of 2,746,388. The demographics of Chicago are different from Houston, with non-Hispanic whites making up 32.7% of the population, Hispanics and Latino Americans 29.9%, Blacks or African Americans 29.8%, and Asian Americans 7.6%. The largest Hispanic or Latino American ethnic group in Chicago is Mexican Americans, comprising 21.6% of the population.  \\nOverall, both Houston and Chicago have diverse populations, but the specific demographic composition differs between the two cities.  \\n```python\\n# baseline: the response tells you nothing about Chicago...\\nresponse.source_nodes[3].get_content()\\n```  \\n```python\\nresponse = top_agent.query(\\n\"Tell me the differences between Shanghai and Beijing in terms of history\"\\n\" and current economy\"\\n)\\n```  \\n=== Calling Function ===\\nCalling function: tool_Shanghai with args: {\\n\"input\": \"history\"\\n}\\n=== Calling Function ===\\nCalling function: vector_tool with args: {\\n\"input\": \"history\"\\n}\\nGot output: Shanghai has a rich history that dates back to ancient times. However, in the context provided, the history of Shanghai is mainly discussed in relation to its modern development. After the war, Shanghai\\'s economy experienced significant growth, with increased agricultural and industrial output. The city\\'s administrative divisions were rearranged, and it became a center for radical leftism during the 1950s and 1960s. The Cultural Revolution had a severe impact on Shanghai\\'s society, but the city maintained economic production with a positive growth rate. Shanghai also played a significant role in China\\'s Third Front campaign and has been a major contributor of tax revenue to the central government. Economic reforms were initiated in Shanghai in 1990, leading to the development of the Pudong district and its classification as an Alpha+ city.\\n========================\\nGot output: Shanghai\\'s history is rich and complex, dating back to ancient times. However, its modern development is particularly noteworthy. After the war, Shanghai experienced significant economic growth, with a boost in both agricultural and industrial output. The city\\'s administrative divisions were restructured, and it became a hub for radical leftism during the 1950s and 1960s.  \\nThe Cultural Revolution had a profound impact on Shanghai\\'s society, but despite this, the city managed to maintain economic production with a positive growth rate. Shanghai also played a significant role in China\\'s Third Front campaign and has been a major contributor of tax revenue to the central government.  \\nIn 1990, economic reforms were initiated in Shanghai, leading to the development of the Pudong district. This has helped Shanghai to be classified as an Alpha+ city, indicating its influence on the global economic stage.\\n========================\\n=== Calling Function ===\\nCalling function: tool_Beijing with args: {\\n\"input\": \"history\"\\n}\\n=== Calling Function ===\\nCalling function: vector_tool with args: {\\n\"input\": \"history\"\\n}\\nGot output: Beijing has a rich history that spans several dynasties. It was the capital of the Ming dynasty, during which the city took its current shape and many of its major attractions, such as the Forbidden City and the Temple of Heaven, were constructed. The Qing dynasty succeeded the Ming dynasty and made Beijing its sole capital. During this time, the Imperial residence and the general layout of the city remained largely unchanged. However, the city faced challenges during the Second Opium War and the Boxer Rebellion, resulting in the looting and destruction of important structures. In the early 20th century, Beijing saw the signing of a peace agreement between the Eight-Nation Alliance and the Chinese government, which led to the restoration of Qing dynasty rule. However, the dynasty eventually collapsed in 1911.\\n========================\\nGot output: Beijing has a rich and complex history that spans several dynasties. It served as the capital during the Ming dynasty, during which the city took its current shape and many of its major attractions, such as the Forbidden City and the Temple of Heaven, were constructed. The Qing dynasty succeeded the Ming dynasty and made Beijing its sole capital. During this time, the Imperial residence and the general layout of the city remained largely unchanged.  \\nHowever, the city faced significant challenges during the Second Opium War and the Boxer Rebellion, which resulted in the looting and destruction of important structures. In the early 20th century, Beijing saw the signing of a peace agreement between the Eight-Nation Alliance and the Chinese government, leading to the restoration of Qing dynasty rule. However, the dynasty eventually collapsed in 1911. Despite these tumultuous events, Beijing has managed to preserve its historical heritage while also evolving into a modern metropolis.\\n========================\\n=== Calling Function ===\\nCalling function: tool_Shanghai with args: {\\n\"input\": \"current economy\"\\n}\\n=== Calling Function ===\\nCalling function: vector_tool with args: {\\n\"input\": \"current economy\"\\n}\\nGot output: The current economy of Shanghai is strong and thriving. It is a global center for finance and innovation, and a national center for commerce, trade, and transportation. The city has a diverse economy, with its six largest industries comprising about half of its GDP. Shanghai has experienced rapid development and has been one of the fastest-developing cities in the world. It has recorded double-digit GDP growth in almost every year between 1992 and 2008. As of 2021, Shanghai had a GDP of CN¥4.46 trillion ($1.106 trillion in PPP), making it one of the wealthiest cities in China. It is also the most expensive city in mainland China to live in. Shanghai is a major player in the global financial industry, ranking first in Asia and third globally in the Global Financial Centres Index. It is home to the Shanghai Stock Exchange, the largest stock exchange in China and the fourth-largest in the world. The city has attracted significant foreign investment and has been a hub for the technology industry and startups. Overall, the current economy of Shanghai is robust and continues to grow.\\n========================\\nGot output: The current economy of Shanghai is robust and thriving. It is a global center for finance and innovation, and a national center for commerce, trade, and transportation. The city has a diverse economy, with its six largest industries comprising about half of its GDP.  \\nShanghai has experienced rapid development and has been one of the fastest-developing cities in the world. It has recorded double-digit GDP growth in almost every year between 1992 and 2008. As of 2021, Shanghai had a GDP of CN¥4.46 trillion ($1.106 trillion in PPP), making it one of the wealthiest cities in China.  \\nShanghai is also the most expensive city in mainland China to live in. It is a major player in the global financial industry, ranking first in Asia and third globally in the Global Financial Centres Index. The city is home to the Shanghai Stock Exchange, the largest stock exchange in China and the fourth-largest in the world.  \\nThe city has attracted significant foreign investment and has been a hub for the technology industry and startups. Overall, the current economy of Shanghai is robust and continues to grow.\\n========================\\n=== Calling Function ===\\nCalling function: tool_Beijing with args: {\\n\"input\": \"current economy\"\\n}\\n=== Calling Function ===\\nCalling function: vector_tool with args: {\\n\"input\": \"current economy\"\\n}\\nGot output: The current economy of Beijing is dominated by the tertiary sector, which includes services such as professional services, wholesale and retail, information technology, commercial real estate, scientific research, and residential real estate. This sector generated 83.8% of the city\\'s output in 2022. The secondary sector, which includes manufacturing and construction, accounted for 15.8% of output, while the primary sector, which includes agriculture and mining, contributed only 0.26%. The city has also identified six high-end economic output zones that are driving local economic growth, including Zhongguancun, Beijing Financial Street, Beijing Central Business District (CBD), Beijing Economic and Technological Development Area (Yizhuang), Beijing Airport Economic Zone, and Beijing Olympic Center Zone. These zones are home to various industries and sectors, such as technology companies, financial institutions, office buildings, industrial parks, and entertainment and sports centers.\\n========================\\nGot output: The current economy of Beijing is primarily driven by the tertiary sector, which includes services such as professional services, wholesale and retail, information technology, commercial real estate, scientific research, and residential real estate. This sector generated 83.8% of the city\\'s output in 2022. The secondary sector, which includes manufacturing and construction, accounted for 15.8% of output, while the primary sector, which includes agriculture and mining, contributed only 0.26%.  \\nBeijing has also identified six high-end economic output zones that are driving local economic growth. These include Zhongguancun, Beijing Financial Street, Beijing Central Business District (CBD), Beijing Economic and Technological Development Area (Yizhuang), Beijing Airport Economic Zone, and Beijing Olympic Center Zone. These zones are home to various industries and sectors, such as technology companies, financial institutions, office buildings, industrial parks, and entertainment and sports centers.\\n========================  \\n```python\\nprint(str(response))\\n```  \\nIn terms of history, both Shanghai and Beijing have rich and complex pasts. Shanghai\\'s history dates back to ancient times, but its modern development is particularly noteworthy. It experienced significant economic growth after the war and played a major role in China\\'s economic reforms. Beijing, on the other hand, has a history that spans several dynasties and served as the capital during the Ming and Qing dynasties. It has preserved its historical heritage while evolving into a modern metropolis.  \\nIn terms of current economy, Shanghai is a global center for finance and innovation. It has a diverse economy and has experienced rapid development, with a high GDP and significant foreign investment. It is a major player in the global financial industry and is home to the Shanghai Stock Exchange. Beijing\\'s economy is primarily driven by the tertiary sector, with a focus on services such as professional services, information technology, and commercial real estate. It has identified high-end economic output zones that are driving local economic growth.  \\nOverall, both cities have thriving economies, but Shanghai has a stronger focus on finance and global influence, while Beijing has a diverse economy with a focus on services and high-end economic zones.  \\n```python\\n# baseline\\nresponse = base_query_engine.query(\\n\"Tell me the differences between Shanghai and Beijing in terms of history\"\\n\" and current economy\"\\n)\\nprint(str(response))\\n```  \\nShanghai and Beijing have distinct differences in terms of history and current economy. Historically, Shanghai was the largest and most prosperous city in East Asia during the 1930s, while Beijing served as the capital of the Republic of China and later the People\\'s Republic of China. Shanghai experienced significant growth and redevelopment in the 1990s, while Beijing expanded its urban area and underwent rapid development in the last two decades.  \\nIn terms of the current economy, Shanghai is considered the \"showpiece\" of China\\'s booming economy. It is a global center for finance and innovation, with a strong focus on industries such as retail, finance, IT, real estate, machine manufacturing, and automotive manufacturing. Shanghai is also home to the world\\'s busiest container port, the Port of Shanghai. The city has a high GDP and is classified as an Alpha+ city by the Globalization and World Cities Research Network.  \\nOn the other hand, Beijing is a global financial center and ranks third globally in the Global Financial Centres Index. It is also a hub for the Chinese and global technology industry, with a large startup ecosystem. Beijing has a strong presence in industries such as finance, technology, and pharmaceuticals. The city is home to the headquarters of large state banks and insurance companies, as well as the country\\'s financial regulatory agencies.  \\nOverall, while both Shanghai and Beijing are important economic centers in China, Shanghai has a stronger focus on industries such as finance, retail, and manufacturing, while Beijing has a strong presence in finance, technology, and pharmaceuticals.', metadata={'Header 1': 'Multi-Document Agents', 'Header 2': 'Running Example Queries'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/openai_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>'),\n",
      " Document(page_content=\"With the [new OpenAI API](https://openai.com/blog/function-calling-and-other-api-updates) that supports function calling, it's never been easier to build your own agent!  \\nIn this notebook tutorial, we showcase how to write your own OpenAI agent in **under 50 lines of code**! It is minimal, yet feature complete (with ability to carry on a conversation and use tools).\", metadata={'Header 1': 'Build your own OpenAI Agent'}),\n",
      " Document(page_content='Let\\'s start by importing some simple building blocks.  \\nThe main thing we need is:\\n1. the OpenAI API (using our own `llama_index` LLM class)\\n2. a place to keep conversation history\\n3. a definition for tools that our agent can use.  \\nIf you\\'re opening this Notebook on colab, you will probably need to install LlamaIndex 🦙.  \\n```python\\n!pip install llama-index\\n```  \\n```python\\nimport json\\nfrom typing import Sequence, List\\n\\nfrom llama_index.llms import OpenAI, ChatMessage\\nfrom llama_index.tools import BaseTool, FunctionTool\\n\\nimport nest_asyncio\\n\\nnest_asyncio.apply()\\n```  \\nLet\\'s define some very simple calculator tools for our agent.  \\n```python\\ndef multiply(a: int, b: int) -> int:\\n\"\"\"Multiple two integers and returns the result integer\"\"\"\\nreturn a * b\\n\\n\\nmultiply_tool = FunctionTool.from_defaults(fn=multiply)\\n```  \\n```python\\ndef add(a: int, b: int) -> int:\\n\"\"\"Add two integers and returns the result integer\"\"\"\\nreturn a + b\\n\\n\\nadd_tool = FunctionTool.from_defaults(fn=add)\\n```', metadata={'Header 1': 'Build your own OpenAI Agent', 'Header 2': 'Initial Setup'}),\n",
      " Document(page_content='Now, we define our agent that\\'s capable of holding a conversation and calling tools in **under 50 lines of code**.  \\nThe meat of the agent logic is in the `chat` method. At a high-level, there are 3 steps:\\n1. Call OpenAI to decide which tool (if any) to call and with what arguments.\\n2. Call the tool with the arguments to obtain an output\\n3. Call OpenAI to synthesize a response from the conversation context and the tool output.  \\nThe `reset` method simply resets the conversation context, so we can start another conversation.  \\n```python\\nclass YourOpenAIAgent:\\ndef __init__(\\nself,\\ntools: Sequence[BaseTool] = [],\\nllm: OpenAI = OpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\"),\\nchat_history: List[ChatMessage] = [],\\n) -> None:\\nself._llm = llm\\nself._tools = {tool.metadata.name: tool for tool in tools}\\nself._chat_history = chat_history\\n\\ndef reset(self) -> None:\\nself._chat_history = []\\n\\ndef chat(self, message: str) -> str:\\nchat_history = self._chat_history\\nchat_history.append(ChatMessage(role=\"user\", content=message))\\ntools = [\\ntool.metadata.to_openai_tool() for _, tool in self._tools.items()\\n]\\n\\nai_message = self._llm.chat(chat_history, tools=tools).message\\nadditional_kwargs = ai_message.additional_kwargs\\nchat_history.append(ai_message)\\n\\ntool_calls = ai_message.additional_kwargs.get(\"tool_calls\", None)\\n# parallel function calling is now supported\\nif tool_calls is not None:\\nfor tool_call in tool_calls:\\nfunction_message = self._call_function(tool_call)\\nchat_history.append(function_message)\\nai_message = self._llm.chat(chat_history).message\\nchat_history.append(ai_message)\\n\\nreturn ai_message.content\\n\\ndef _call_function(self, tool_call: dict) -> ChatMessage:\\nid_ = tool_call[\"id\"]\\nfunction_call = tool_call[\"function\"]\\ntool = self._tools[function_call[\"name\"]]\\noutput = tool(**json.loads(function_call[\"arguments\"]))\\nreturn ChatMessage(\\nname=function_call[\"name\"],\\ncontent=str(output),\\nrole=\"tool\",\\nadditional_kwargs={\\n\"tool_call_id\": id_,\\n\"name\": function_call[\"name\"],\\n},\\n)\\n```', metadata={'Header 1': 'Build your own OpenAI Agent', 'Header 2': 'Agent Definition'}),\n",
      " Document(page_content='```python\\nagent = YourOpenAIAgent(tools=[multiply_tool, add_tool])\\n```  \\n```python\\nagent.chat(\"Hi\")\\n```  \\n\\'Hello! How can I assist you today?\\'  \\n```python\\nagent.chat(\"What is 2123 * 215123\")\\n```  \\n\\'The product of 2123 multiplied by 215123 is 456,706,129.\\'', metadata={'Header 1': 'Build your own OpenAI Agent', 'Header 2': \"Let's Try It Out!\"}),\n",
      " Document(page_content='We provide a (slightly better) `OpenAIAgent` implementation in LlamaIndex, which you can directly use as follows.  \\nIn comparison to the simplified version above:\\n* it implements the `BaseChatEngine` and `BaseQueryEngine` interface, so you can more seamlessly use it in the LlamaIndex framework.\\n* it supports multiple function calls per conversation turn\\n* it supports streaming\\n* it supports async endpoints\\n* it supports callback and tracing  \\n```python\\nfrom llama_index.agent import OpenAIAgent\\nfrom llama_index.llms import OpenAI\\n```  \\n```python\\nllm = OpenAI(model=\"gpt-3.5-turbo-0613\")\\nagent = OpenAIAgent.from_tools(\\n[multiply_tool, add_tool], llm=llm, verbose=True\\n)\\n```', metadata={'Header 1': 'Build your own OpenAI Agent', 'Header 2': 'Our (Slightly Better) `OpenAIAgent` Implementation'}),\n",
      " Document(page_content='```python\\nresponse = agent.chat(\"What is (121 * 3) + 42?\")\\nprint(str(response))\\n```  \\nSTARTING TURN 1\\n---------------  \\n=== Calling Function ===\\nCalling function: multiply with args: {\\n\"a\": 121,\\n\"b\": 3\\n}\\nGot output: 363\\n========================  \\nSTARTING TURN 2\\n---------------  \\n=== Calling Function ===\\nCalling function: add with args: {\\n\"a\": 363,\\n\"b\": 42\\n}\\nGot output: 405\\n========================  \\nSTARTING TURN 3\\n---------------  \\n(121 * 3) + 42 is equal to 405.  \\n```python\\n# inspect sources\\nprint(response.sources)\\n```  \\n[ToolOutput(content=\\'363\\', tool_name=\\'multiply\\', raw_input={\\'args\\': (), \\'kwargs\\': {\\'a\\': 121, \\'b\\': 3}}, raw_output=363), ToolOutput(content=\\'405\\', tool_name=\\'add\\', raw_input={\\'args\\': (), \\'kwargs\\': {\\'a\\': 363, \\'b\\': 42}}, raw_output=405)]', metadata={'Header 1': 'Build your own OpenAI Agent', 'Header 2': 'Our (Slightly Better) `OpenAIAgent` Implementation', 'Header 3': 'Chat'}),\n",
      " Document(page_content='```python\\nresponse = await agent.achat(\"What is 121 * 3?\")\\nprint(str(response))\\n```  \\nSTARTING TURN 1\\n---------------  \\n=== Calling Function ===\\nCalling function: multiply with args: {\\n\"a\": 121,\\n\"b\": 3\\n}\\nGot output: 363\\n========================  \\nSTARTING TURN 2\\n---------------  \\n121 multiplied by 3 is equal to 363.', metadata={'Header 1': 'Build your own OpenAI Agent', 'Header 2': 'Our (Slightly Better) `OpenAIAgent` Implementation', 'Header 3': 'Async Chat'}),\n",
      " Document(page_content='Here, every LLM response is returned as a generator. You can stream every incremental step, or only the last response.  \\n```python\\nresponse = agent.stream_chat(\\n\"What is 121 * 2? Once you have the answer, use that number to write a\"\\n\" story about a group of mice.\"\\n)\\n\\nresponse_gen = response.response_gen\\n\\nfor token in response_gen:\\nprint(token, end=\"\")\\n```  \\nSTARTING TURN 1\\n---------------  \\n=== Calling Function ===\\nCalling function: multiply with args: {\\n\"a\": 121,\\n\"b\": 2\\n}\\nGot output: 242\\n========================  \\nSTARTING TURN 2\\n---------------  \\n121 multiplied by 2 is equal to 242.  \\nOnce upon a time, in a small village, there was a group of mice who lived in a cozy little burrow. The mice were known for their intelligence and resourcefulness. They had built a tight-knit community and worked together to overcome any challenges they faced.  \\nOne sunny day, as the mice were going about their daily activities, they stumbled upon a bountiful field of ripe corn. The field was filled with tall stalks of golden corn, swaying gently in the breeze. The mice couldn\\'t believe their luck! They knew they had to gather as much corn as possible to sustain themselves through the upcoming winter.  \\nWith their tiny paws and sharp teeth, the mice began to harvest the corn. They worked tirelessly, carrying one ear of corn at a time back to their burrow. The mice were determined to make the most of this opportunity and ensure they had enough food for everyone.  \\nAs the days turned into weeks, the mice\\'s hard work paid off. They had collected an impressive stash of corn, thanks to their diligent efforts and the abundance of the field. The mice celebrated their success, knowing that they had secured their survival for the winter.  \\nBut the mice didn\\'t stop there. They realized that they had more corn than they needed just for themselves. They decided to share their abundance with the other animals in the village who were struggling to find food. The mice knew the importance of community and believed in helping others in need.  \\nWord spread quickly about the generous mice and their corn. Animals from all around the village came to the mice\\'s burrow, grateful for the assistance. The mice happily distributed the corn, ensuring that everyone had enough to eat.  \\nThe mice\\'s act of kindness and their ability to multiply their resources had a profound impact on the village. The animals learned the value of working together and supporting one another. The mice became a symbol of unity and compassion, inspiring others to follow their example.  \\nAnd so, the mice\\'s story of multiplying their resources and spreading kindness became a legend in the village. The mice continued to thrive, not just because of their intelligence and resourcefulness, but also because of their big hearts and willingness to help others.  \\nThe end.', metadata={'Header 1': 'Build your own OpenAI Agent', 'Header 2': 'Our (Slightly Better) `OpenAIAgent` Implementation', 'Header 3': 'Streaming Chat'}),\n",
      " Document(page_content='```python\\nresponse = await agent.astream_chat(\\n\"What is 121 + 8? Once you have the answer, use that number to write a\"\\n\" story about a group of mice.\"\\n)\\n\\nresponse_gen = response.response_gen\\n\\nasync for token in response.async_response_gen():\\nprint(token, end=\"\")\\n```  \\nSTARTING TURN 1\\n---------------  \\n=== Calling Function ===\\nCalling function: add with args: {\\n\"a\": 121,\\n\"b\": 8\\n}\\nGot output: 129\\n========================  \\nSTARTING TURN 2\\n---------------  \\n121 plus 8 is equal to 129.  \\nOnce upon a time, in a peaceful meadow, there lived a group of mice. These mice were known for their bravery and adventurous spirit. They loved exploring the meadow and discovering new places.  \\nOne sunny day, as the mice were scurrying through the tall grass, they stumbled upon a hidden treasure. It was a small, sparkling gemstone that radiated with a mesmerizing glow. The mice were amazed by its beauty and knew that it was something special.  \\nExcitedly, the mice decided to take the gemstone back to their burrow. They carefully carried it, taking turns to ensure its safety. As they reached their cozy home, they marveled at the gemstone\\'s brilliance. Little did they know, this gemstone held a magical power.  \\nAs the mice gathered around the gemstone, a soft, enchanting light began to emanate from it. Suddenly, the mice felt a surge of energy and realized that they had been granted a special ability - the power to communicate with other animals.  \\nWith their newfound power, the mice embarked on a mission to bring harmony and understanding among the creatures of the meadow. They started by reaching out to the birds, sharing their wisdom and learning about the secrets of the sky. The mice and birds formed a strong bond, exchanging stories and songs.  \\nNext, the mice approached the rabbits, teaching them about the importance of unity and cooperation. The rabbits, known for their agility, shared their knowledge of navigating the meadow and avoiding danger. Together, the mice and rabbits created a safe haven for all the animals.  \\nThe mice\\'s journey continued as they connected with the squirrels, teaching them the value of saving and planning for the future. The squirrels, in return, shared their knowledge of gathering food and surviving the harsh winters. The meadow became a place of abundance and security for all its inhabitants.  \\nAs the seasons changed, the mice\\'s influence spread throughout the meadow. Animals from all walks of life came together, forming a diverse and harmonious community. The mice\\'s ability to bring different species together was a testament to their leadership and compassion.  \\nThe gemstone, a symbol of unity and understanding, remained at the center of the mice\\'s burrow. It served as a reminder of the power of collaboration and the importance of embracing diversity.  \\nAnd so, the mice\\'s story of adding their strengths and bringing animals together became a legend in the meadow. The mice continued to explore, learn, and spread their message of unity, leaving a lasting impact on the meadow and its inhabitants.  \\nThe end.', metadata={'Header 1': 'Build your own OpenAI Agent', 'Header 2': 'Our (Slightly Better) `OpenAIAgent` Implementation', 'Header 3': 'Async Streaming Chat'}),\n",
      " Document(page_content='You can specify a system prompt to give the agent additional instruction or personality.  \\n```python\\nfrom llama_index.agent import OpenAIAgent\\nfrom llama_index.llms import OpenAI\\nfrom llama_index.prompts.system import SHAKESPEARE_WRITING_ASSISTANT\\n```  \\n```python\\nllm = OpenAI(model=\"gpt-3.5-turbo-0613\")\\n\\nagent = OpenAIAgent.from_tools(\\n[multiply_tool, add_tool],\\nllm=llm,\\nverbose=True,\\nsystem_prompt=SHAKESPEARE_WRITING_ASSISTANT,\\n)\\n```  \\n```python\\nresponse = agent.chat(\"Hi\")\\nprint(response)\\n```  \\nSTARTING TURN 1\\n---------------  \\nGreetings, fair traveler! How may I assist thee on this fine day?  \\n```python\\nresponse = agent.chat(\"Tell me a story\")\\nprint(response)\\n```  \\nSTARTING TURN 1\\n---------------  \\nOf course, dear friend! Allow me to weave a tale for thee in the style of Shakespeare.  \\nOnce upon a time, in a land far away, there lived a noble knight named Sir William. He was known throughout the kingdom for his bravery and chivalry. One fateful day, as Sir William rode through the enchanted forest, he stumbled upon a hidden glade.  \\nIn the glade, he discovered a beautiful maiden named Lady Rosalind. She was fair of face and gentle of heart, and Sir William was instantly captivated by her beauty. They spent hours conversing, sharing stories, and laughing together.  \\nAs the days turned into weeks, Sir William and Lady Rosalind\\'s bond grew stronger. They found solace in each other\\'s company and realized that they had fallen deeply in love. However, their love was not without obstacles.  \\nLady Rosalind\\'s father, Lord Reginald, was a stern and overprotective man. He had already arranged a marriage for his daughter with a wealthy nobleman, Lord Percival. When Lady Rosalind confessed her love for Sir William, Lord Reginald was furious.  \\nDetermined to be together, Sir William and Lady Rosalind devised a plan. They decided to elope under the cover of darkness, seeking refuge in a distant land where their love could flourish without hindrance. With heavy hearts, they bid farewell to their families and set off on their journey.  \\nTheir path was treacherous, filled with perils and hardships. They faced raging storms, dangerous bandits, and even a fearsome dragon. But through it all, their love remained steadfast and unwavering.  \\nAfter many trials and tribulations, Sir William and Lady Rosalind finally reached their destination—a peaceful village nestled by the sea. They settled there, vowing to live a life of love and happiness.  \\nYears passed, and their love only grew stronger. They were blessed with children, who inherited their parents\\' noble qualities. Sir William and Lady Rosalind lived a long and fulfilling life, surrounded by the love of their family and the admiration of the villagers.  \\nAnd so, the tale of Sir William and Lady Rosalind serves as a reminder that true love can conquer all obstacles, even in the face of adversity. May their story inspire thee to follow thy heart and pursue love with unwavering determination.', metadata={'Header 1': 'Build your own OpenAI Agent', 'Header 2': 'Our (Slightly Better) `OpenAIAgent` Implementation', 'Header 3': 'Agent with Personality'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/openai_agent_context_retrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>'),\n",
      " Document(page_content=\"In this tutorial, we show you how to use our `ContextRetrieverOpenAIAgent` implementation\\nto build an agent on top of OpenAI's function API and store/index an arbitrary number of tools. Our indexing/retrieval modules help to remove the complexity of having too many functions to fit in the prompt.\", metadata={'Header 1': 'Context-Augmented OpenAI Agent'}),\n",
      " Document(page_content='Here we setup a ContextRetrieverOpenAIAgent. This agent will perform retrieval first before calling any tools. This can help ground the agent\\'s tool picking and answering capabilities in context.  \\nIf you\\'re opening this Notebook on colab, you will probably need to install LlamaIndex 🦙.  \\n```python\\n!pip install llama-index\\n```  \\n```python\\nimport json\\nfrom typing import Sequence\\n\\nfrom llama_index import (\\nSimpleDirectoryReader,\\nVectorStoreIndex,\\nStorageContext,\\nload_index_from_storage,\\n)\\nfrom llama_index.tools import QueryEngineTool, ToolMetadata\\n```  \\n```python\\ntry:\\nstorage_context = StorageContext.from_defaults(\\npersist_dir=\"./storage/march\"\\n)\\nmarch_index = load_index_from_storage(storage_context)\\n\\nstorage_context = StorageContext.from_defaults(\\npersist_dir=\"./storage/june\"\\n)\\njune_index = load_index_from_storage(storage_context)\\n\\nstorage_context = StorageContext.from_defaults(\\npersist_dir=\"./storage/sept\"\\n)\\nsept_index = load_index_from_storage(storage_context)\\n\\nindex_loaded = True\\nexcept:\\nindex_loaded = False\\n```  \\nDownload Data  \\n```python\\n!mkdir -p \\'data/10q/\\'\\n!wget \\'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10q/uber_10q_march_2022.pdf\\' -O \\'data/10q/uber_10q_march_2022.pdf\\'\\n!wget \\'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10q/uber_10q_june_2022.pdf\\' -O \\'data/10q/uber_10q_june_2022.pdf\\'\\n!wget \\'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10q/uber_10q_sept_2022.pdf\\' -O \\'data/10q/uber_10q_sept_2022.pdf\\'\\n```  \\n```python\\n# build indexes across the three data sources\\n\\nif not index_loaded:\\n# load data\\nmarch_docs = SimpleDirectoryReader(\\ninput_files=[\"./data/10q/uber_10q_march_2022.pdf\"]\\n).load_data()\\njune_docs = SimpleDirectoryReader(\\ninput_files=[\"./data/10q/uber_10q_june_2022.pdf\"]\\n).load_data()\\nsept_docs = SimpleDirectoryReader(\\ninput_files=[\"./data/10q/uber_10q_sept_2022.pdf\"]\\n).load_data()\\n\\n# build index\\nmarch_index = VectorStoreIndex.from_documents(march_docs)\\njune_index = VectorStoreIndex.from_documents(june_docs)\\nsept_index = VectorStoreIndex.from_documents(sept_docs)\\n\\n# persist index\\nmarch_index.storage_context.persist(persist_dir=\"./storage/march\")\\njune_index.storage_context.persist(persist_dir=\"./storage/june\")\\nsept_index.storage_context.persist(persist_dir=\"./storage/sept\")\\n```  \\n```python\\nmarch_engine = march_index.as_query_engine(similarity_top_k=3)\\njune_engine = june_index.as_query_engine(similarity_top_k=3)\\nsept_engine = sept_index.as_query_engine(similarity_top_k=3)\\n```  \\n```python\\nquery_engine_tools = [\\nQueryEngineTool(\\nquery_engine=march_engine,\\nmetadata=ToolMetadata(\\nname=\"uber_march_10q\",\\ndescription=(\\n\"Provides information about Uber 10Q filings for March 2022. \"\\n\"Use a detailed plain text question as input to the tool.\"\\n),\\n),\\n),\\nQueryEngineTool(\\nquery_engine=june_engine,\\nmetadata=ToolMetadata(\\nname=\"uber_june_10q\",\\ndescription=(\\n\"Provides information about Uber financials for June 2021. \"\\n\"Use a detailed plain text question as input to the tool.\"\\n),\\n),\\n),\\nQueryEngineTool(\\nquery_engine=sept_engine,\\nmetadata=ToolMetadata(\\nname=\"uber_sept_10q\",\\ndescription=(\\n\"Provides information about Uber financials for Sept 2021. \"\\n\"Use a detailed plain text question as input to the tool.\"\\n),\\n),\\n),\\n]\\n```', metadata={'Header 1': 'Context-Augmented OpenAI Agent', 'Header 2': 'Initial Setup'}),\n",
      " Document(page_content='Here we augment our agent with context in different settings:\\n- toy context: we define some abbreviations that map to financial terms (e.g. R=Revenue). We supply this as context to the agent  \\n```python\\nfrom llama_index.schema import Document\\nfrom llama_index.agent import ContextRetrieverOpenAIAgent\\n```  \\n```python\\n# toy index - stores a list of abbreviations\\ntexts = [\\n\"Abbreviation: X = Revenue\",\\n\"Abbreviation: YZ = Risk Factors\",\\n\"Abbreviation: Z = Costs\",\\n]\\ndocs = [Document(text=t) for t in texts]\\ncontext_index = VectorStoreIndex.from_documents(docs)\\n```  \\n```python\\ncontext_agent = ContextRetrieverOpenAIAgent.from_tools_and_retriever(\\nquery_engine_tools,\\ncontext_index.as_retriever(similarity_top_k=1),\\nverbose=True,\\n)\\n```  \\n```python\\nresponse = context_agent.chat(\"What is the YZ of March 2022?\")\\n```  \\n\\x1b[33;1m\\x1b[1;3mContext information is below.\\n---------------------\\nAbbreviation: YZ = Risk Factors\\n---------------------\\nGiven the context information and not prior knowledge, either pick the corresponding tool or answer the function: What is the YZ of March 2022?  \\n\\x1b[0m=== Calling Function ===\\nCalling function: uber_march_10q with args: {\\n\"input\": \"Risk Factors\"\\n}\\nGot output:\\n•The COVID-19 pandemic and the impact of actions to mitigate the pandemic have adversely affected and may continue to adversely affect parts of our business.\\n•Our business would be adversely affected if Drivers were classified as employees, workers or quasi-employees instead of independent contractors.\\n•The mobility, delivery, and logistics industries are highly competitive, with well-established and low-cost alternatives that have been available for decades, low barriers to entry, low switching costs, and well-capitalized competitors in nearly every major geographic region.\\n•To remain competitive in certain markets, we have in the past lowered, and may continue to lower, fares or service fees, and we have in the past offered, and may continue to offer, significant Driver incentives and consumer discounts and promotions.\\n•We have incurred significant losses since inception, including in the United States and other major markets. We expect our operating expenses to increase significantly in the foreseeable future, and we may not achieve or maintain profitability.\\n•If we are unable to attract or maintain a critical mass of Drivers, consumers, merchants, shippers, and carriers, whether as a result of competition or other factors, our platform will become less appealing to platform users.\\n•Maintaining and enhancing our brand and reputation is critical to our business prospects. We have previously received significant media coverage and negative publicity regarding our brand and reputation, and while we have taken significant steps to rehabilitate our brand and reputation, failure to maintain and enhance our brand and reputation could adversely affect our business.\\n•The impact of economic conditions, including the resulting effect on discretionary consumer spending, may harm our business and operating results.\\n•Increases in fuel, food, labor, energy, and other costs due to inflation and other factors could adversely affect our operating results.\\n•If we experience security or privacy breaches or other unauthorized or improper access to, use of, disclosure of, alteration of or destruction of our proprietary or confidential data, employee data, or platform user data.\\n•Cyberattacks, including computer malware, ransomware, viruses, spamming, and phishing attacks could harm our reputation, business, and operating results.\\n•We are subject to climate change risks, including physical and transitional risks, and if we are unable to manage such risks, our business may be adversely impacted.\\n•We have made climate related commitments that require us to invest significant effort, resources, and management time and circumstances may arise, including those beyond our control, that may require us to revise the contemplated timeframes for implementing these commitments.\\n•We rely on third parties maintaining open marketplaces to distribute our platform and to provide the software we use in certain of our products and offerings. If such third parties interfere with the distribution of our products or offerings or with our use of such software, our business would be adversely affected.\\n•We will require additional capital to support the growth of our business, and this capital might not be available on reasonable terms or at all.\\n•If we are unable to successfully identify, acquire and integrate suitable businesses, our operating results and prospects could be harmed, and any businesses we acquire may not perform as expected or be effectively integrated.\\n•We may continue to be blocked from or limited in providing or operating our products and offerings in certain jurisdictions, and may be required to modify our business model in those jurisdictions as a result.\\n•Our business is subject to numerous legal and regulatory risks that could have an adverse impact on our business and future prospects.\\n•Our business is subject to extensive government regulation and oversight relating to the provision of payment and financial services.\\n•We face risks related to our collection, use, transfer, disclosure, and other processing of data, which could result in investigations, inquiries, litigation, fines, legislative and regulatory action, and negative press about our privacy and data protection practices.\\n•If we are unable to protect our intellectual property, or if third parties are successful in claiming that we are misappropriating the intellectual property of others, we may incur significant expense and our business may be adversely affected.\\n•The market price of our common stock has been, and may continue to be, volatile or may decline steeply or suddenly regardless of our operating performance, and we may not be able to meet investor or analyst expectations. You may not be able to resell your shares at or above the price you paid and may lose all or part of your investment.\\n========================  \\n```python\\nprint(str(response))\\n```  \\nThe risk factors for Uber in March 2022 include:  \\n1. The adverse impact of the COVID-19 pandemic and actions taken to mitigate it on Uber\\'s business.\\n2. The potential adverse effect on Uber\\'s business if drivers are classified as employees instead of independent contractors.\\n3. Intense competition in the mobility, delivery, and logistics industries, with low-cost alternatives and well-capitalized competitors.\\n4. The need to lower fares, offer driver incentives, and provide consumer discounts and promotions to remain competitive in certain markets.\\n5. Uber\\'s history of significant losses and the expectation of increased operating expenses in the future, which may affect profitability.\\n6. The importance of attracting and maintaining a critical mass of drivers, consumers, merchants, shippers, and carriers to keep the platform appealing.\\n7. The significance of maintaining and enhancing Uber\\'s brand and reputation, as negative publicity could harm the business.\\n8. The potential impact of economic conditions and discretionary consumer spending on Uber\\'s business.\\n9. The adverse effect of increasing costs, such as fuel, food, labor, energy, and inflation, on Uber\\'s operating results.\\n10. The risk of security or privacy breaches and unauthorized access to Uber\\'s proprietary or confidential data.\\n11. The potential harm to Uber\\'s reputation, business, and operating results from cyberattacks.\\n12. The impact of climate change risks, including physical and transitional risks, on Uber\\'s business.\\n13. The commitment to climate-related initiatives that require significant effort, resources, and management time.\\n14. The reliance on third parties for distributing Uber\\'s platform and providing software, with the risk of interference or limitations.\\n15. The need for additional capital to support Uber\\'s business growth, with uncertainty about its availability on reasonable terms.\\n16. The risks associated with identifying, acquiring, and integrating suitable businesses.\\n17. The potential limitations and modifications to Uber\\'s business model in certain jurisdictions.\\n18. The legal and regulatory risks that could adversely impact Uber\\'s business and future prospects.\\n19. The extensive government regulation and oversight related to payment and financial services provided by Uber.\\n20. The risks associated with data collection, use, transfer, disclosure, and processing, including investigations, litigation, and fines.\\n21. The importance of protecting Uber\\'s intellectual property and the risk of claims of misappropriation.\\n22. The volatility and potential decline in the market price of Uber\\'s common stock, which may not reflect operating performance.  \\nPlease note that this is a summary of the risk factors mentioned in Uber\\'s March 2022 10Q filing. For more detailed information, please refer to the official filing.  \\n```python\\ncontext_agent.chat(\"What is the X and Z in September 2022?\")\\n```', metadata={'Header 1': 'Context-Augmented OpenAI Agent', 'Header 2': 'Initial Setup', 'Header 3': 'Try Context-Augmented Agent'}),\n",
      " Document(page_content='```python\\nfrom llama_index.tools import BaseTool, FunctionTool\\n\\n\\ndef magic_formula(revenue: int, cost: int) -> int:\\n\"\"\"Runs MAGIC_FORMULA on revenue and cost.\"\"\"\\nreturn revenue - cost\\n\\n\\nmagic_tool = FunctionTool.from_defaults(fn=magic_formula, name=\"magic_formula\")\\n```  \\n```python\\ncontext_agent = ContextRetrieverOpenAIAgent.from_tools_and_retriever(\\n[magic_tool], sept_index.as_retriever(similarity_top_k=3), verbose=True\\n)\\n```  \\n```python\\nresponse = context_agent.chat(\\n\"Can you run MAGIC_FORMULA on Uber\\'s revenue and cost?\"\\n)\\n```  \\n\\x1b[33;1m\\x1b[1;3mContext information is below.\\n---------------------\\nThree Months Ended September 30, Nine Months Ended September 30,\\n2021 2022 2021 2022\\nRevenue 100 % 100 % 100 % 100 %\\nCosts and expenses\\nCost of revenue, exclusive of depreciation and amortization shown separately\\nbelow 50 % 62 % 53 % 62 %\\nOperations and support 10 % 7 % 11 % 8 %\\nSales and marketing 24 % 14 % 30 % 16 %\\nResearch and development 10 % 9 % 13 % 9 %\\nGeneral and administrative 13 % 11 % 15 % 10 %\\nDepreciation and amortization 4 % 3 % 6 % 3 %\\nTotal costs and expenses 112 % 106 % 128 % 107 %\\nLoss from operations (12)% (6)% (28)% (7)%\\nInterest expense (3)% (2)% (3)% (2)%\\nOther income (expense), net (38)% (6)% 16 % (34)%\\nLoss before income taxes and income (loss) from equity method\\ninvestments (52)% (14)% (16)% (43)%\\nProvision for (benefit from) income taxes (2)% 1 % (3)% — %\\nIncome (loss) from equity method investments — % — % — % — %\\nNet loss including non-controlling interests (50)% (14)% (12)% (42)%\\nLess: net income (loss) attributable to non-controlling interests,\\nnet of tax — % — % (1)% — %\\nNet loss attributable to Uber Technologies, Inc. (50)% (14)% (12)% (42)%\\nTotals of percentage of revenues may not foot due to rounding.\\nThe following discussion and analysis is for the three and nine months ended September 30, 2022 compared to same period in 2021.\\nRevenue\\nThree Months Ended September 30, Nine Months Ended September 30,\\n(In millions, except per centages) 2021 2022 % Change 2021 2022 % Change\\nRevenue $ 4,845 $ 8,343 72 %$ 11,677 $ 23,270 99 %\\nThree Months Ended September 30, 2022 Compared with the Same Period in 2021\\nRevenue increased $3.5 billion, or 72%, primarily attributable to an increase in Gross Bookings of 26%, or 32% on a constant currency basis. The increase in\\nGross Bookings was primarily driven by increases in Mobility Trip volumes as the business recovers from the impacts of COVID-19 and a $1.3 billion increase in\\nFreight Gross Bookings resulting primarily from the acquisition of Transplace in the fourth quarter of 2021. Additionally, during the third quarter of 2022, we saw a\\n$1.1 billion increase in Mobility revenue as a result of business model changes in the UK. We also saw a $164 million increase in Delivery revenue resulting from\\nan increase in certain Courier payments and incentives that are recorded in cost of revenue, exclusive of depreciation and amortization, for certain markets where\\nwe are primarily responsible for Delivery services and pay Couriers for services provided.\\nNine Months Ended September 30, 2022 Compared with the Same Period in 2021\\nRevenue increased $11.6 billion, or 99%, primarily attributable to an increase in Gross Bookings of 31%, or 36% on a constant currency basis. The increase in\\nGross Bookings was primarily driven by increases in Mobility Trip volumes as the business recovers from the impacts of COVID-19 and a $4.4 billion increase in\\nFreight Gross Bookings resulting primarily from the acquisition of Transplace in the fourth quarter of 2021. Additionally, during the first nine months of 2022, we\\nsaw a $2.2 billion net increase in Mobility revenue as a result of business model changes in the UK and an accrual made for the resolution of historical claims in\\nthe UK relating to the classification of drivers. We also saw a $751 million increase in Delivery revenue resulting from an increase in certain Courier payments and\\nincentives that are recorded in cost of revenue, exclusive of depreciation and amortization, for certain markets where we are primarily responsible for\\nUBER TECHNOLOGIES, INC.\\nCONDENSED CONSOLIDATED STATEMENTS OF OPERATIONS\\n(In millions, except share amounts which are reflected in thousands, and per share amounts)\\n(Unaudited)\\nThree Months Ended September  30, Nine Months Ended September  30,\\n2021 2022 2021 2022\\nRevenue $ 4,845 $ 8,343 $ 11,677 $ 23,270\\nCosts and expenses\\nCost of revenue, exclusive of depreciation and amortization shown separately\\nbelow 2,438 5,173 6,247 14,352\\nOperations and support 475 617 1,330 1,808\\nSales and marketing 1,168 1,153 3,527 3,634\\nResearch and development 493 760 1,496 2,051\\nGeneral and administrative 625 908 1,705 2,391\\nDepreciation and amortization 218 227 656 724\\nTotal costs and expenses 5,417 8,838 14,961 24,960\\nLoss from operations (572) (495) (3,284) (1,690)\\nInterest expense (123) (146) (353) (414)\\nOther income (expense), net (1,832) (535) 1,821 (7,796)\\nLoss before income taxes and income (loss) from equity method investments (2,527) (1,176) (1,816) (9,900)\\nProvision for (benefit from) income taxes (101) 58 (395) (97)\\nIncome (loss) from equity method investments (13) 30 (28) 65\\nNet loss including non-controlling interests (2,439) (1,204) (1,449) (9,738)\\nLess: net income (loss) attributable to non-controlling interests, net of\\ntax (15) 2 (61) (2)\\nNet loss attributable to Uber Technologies, Inc. $ (2,424)$ (1,206)$ (1,388)$ (9,736)\\nNet loss per share attributable to Uber Technologies, Inc. common\\nstockholders:\\nBasic $ (1.28)$ (0.61)$ (0.74)$ (4.96)\\nDiluted $ (1.28)$ (0.61)$ (0.75)$ (4.97)\\nWeighted-average shares used to compute net loss per share attributable to\\ncommon stockholders:\\nBasic 1,898,954 1,979,299 1,877,655 1,964,483\\nDiluted 1,898,954 1,979,299 1,878,997 1,968,228\\nThe accompanying notes are an integral part of these condensed consolidated financial statements.\\n5\\nComponents of Results of Operations\\nRevenue\\nWe generate substantially all of our revenue from fees paid by Drivers and Merchants for use of our platform. We have concluded that we are an agent in these\\narrangements as we arrange for other parties to provide the service to the end-user. Under this model, revenue is net of Driver and Merchant earnings and Driver\\nincentives. We act as an agent in these transactions by connecting consumers to Drivers and Merchants to facilitate a Trip, meal or grocery delivery service.\\nDuring the first quarter of 2022, we modified our arrangements in certain markets and, as a result, concluded we are responsible for the provision of mobility\\nservices to end-users in those markets. We have determined that in these transactions, end-users are our customers and our sole performance obligation in the\\ntransaction is to provide transportation services to the end-user. We recognize revenue when a trip is complete. In these markets where we are responsible for\\nmobility services, we present revenue from end-users on a gross basis, as we control the service provided by Drivers to end-users, while payments to Drivers in\\nexchange for mobility services are recognized in cost of revenue, exclusive of depreciation and amortization.\\nFor additional discussion related to our revenue, see the section titled “Management’s Discussion and Analysis of Financial Condition and Results of\\nOperations - Critical Accounting Estimates - Revenue Recognition,” “Note 1 - Description of Business and Summary of Significant Accounting Policies - Revenue\\nRecognition,” and “Note 2 - Revenue” to our audited consolidated financial statements included in our Annual Report Form 10-K for the year ended December 31,\\n2021 and Note 2 – Revenue in this Quarterly Report on Form 10-Q.\\nCost of Revenue, Exclusive of Depreciation and Amortization\\nCost of revenue, exclusive of depreciation and amortization, primarily consists of certain insurance costs related to our Mobility and Delivery offerings, credit\\ncard processing fees, bank fees, data center and networking expenses, mobile device and service costs, costs incurred with Carriers for Uber Freight transportation\\nservices, amounts related to fare chargebacks and other credit card losses as well as costs incurred for certain Mobility and Delivery transactions where we are\\nprimarily responsible for mobility or delivery services and pay Drivers and Couriers for services.\\nWe expect that cost of revenue, exclusive of depreciation and amortization, will fluctuate on an absolute dollar basis for the foreseeable future in line with Trip\\nvolume changes on the platform. As Trips increase or decrease, we expect related changes for insurance costs, credit card processing fees, hosting and co-located\\ndata center expenses, maps license fees, and other cost of revenue, exclusive of depreciation and amortization.\\nOperations and Support\\nOperations and support expenses primarily consist of compensation expenses, including stock-based compensation, for employees that support operations in\\ncities, including the general managers, Driver operations, platform user support representatives and community managers. Also included is the cost of customer\\nsupport, Driver background checks and the allocation of certain corporate costs.\\nAs our business recovers from the impacts of COVID-19 and Trip volume increases, we would expect operations and support expenses to increase on an\\nabsolute dollar basis for the foreseeable future, but decrease as a percentage of revenue as we become more efficient in supporting platform users.\\nSales and Marketing\\nSales and marketing expenses primarily consist of compensation costs, including stock-based compensation to sales and marketing employees, advertising\\ncosts, product marketing costs and discounts, loyalty programs, promotions, refunds, and credits provided to end-users who are not customers, and the allocation of\\ncertain corporate costs. We expense advertising and other promotional expenditures as incurred.\\nAs our business recovers from the impacts of COVID-19, we would anticipate sales and marketing expenses to increase on an absolute dollar basis for\\n---------------------\\nGiven the context information and not prior knowledge, either pick the corresponding tool or answer the function: Can you run MAGIC_FORMULA on Uber\\'s revenue and cost?  \\n\\x1b[0m=== Calling Function ===\\nCalling function: magic_formula with args: {\\n\"revenue\": 23270,\\n\"cost\": 24960\\n}\\nGot output: -1690\\n========================  \\n```python\\nprint(response)\\n```  \\nThe result of running MAGIC_FORMULA on Uber\\'s revenue and cost is -1690.', metadata={'Header 1': 'Context-Augmented OpenAI Agent', 'Header 2': 'Initial Setup', 'Header 3': 'Use Uber 10-Q as context, use Calculator as Tool'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/openai_agent_parallel_function_calling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>  \\nWith the latest OpenAI API (v. 1.1.0+), users can now execute multiple function calls within a single turn of `User` and `Agent` dialogue. We\\'ve updated our library to enable this new feature as well, and in this notebook we\\'ll show you how it all works!  \\nNOTE: OpenAI refers to this as \"Parallel\" function calling, but the current implementation doesn\\'t invoke parallel computations of the multiple function calls. So, it\\'s \"parallelizable\" function calling in terms of our current implementation.  \\n```python\\nfrom llama_index.agent import OpenAIAgent\\nfrom llama_index.llms import OpenAI\\nfrom llama_index.tools import BaseTool, FunctionTool\\n```', metadata={'Header 1': 'Single-Turn Multi-Function Calling OpenAI Agents'}),\n",
      " Document(page_content='If you\\'ve seen any of our previous notebooks on OpenAI Agents, then you\\'re already familiar with the cookbook recipe that we have to follow here. But if not, or if you fancy a refresher then all we need to do (at a high level) are the following steps:  \\n1. Define a set of tools (we\\'ll use `FunctionTool`) since Agents work with tools\\n2. Define the `LLM` for the Agent\\n3. Define a `OpenAIAgent`  \\n```python\\ndef multiply(a: int, b: int) -> int:\\n\"\"\"Multiple two integers and returns the result integer\"\"\"\\nreturn a * b\\n\\n\\nmultiply_tool = FunctionTool.from_defaults(fn=multiply)\\n```  \\n```python\\ndef add(a: int, b: int) -> int:\\n\"\"\"Add two integers and returns the result integer\"\"\"\\nreturn a + b\\n\\n\\nadd_tool = FunctionTool.from_defaults(fn=add)\\n```  \\n```python\\nllm = OpenAI(model=\"gpt-3.5-turbo-1106\")\\nagent = OpenAIAgent.from_tools(\\n[multiply_tool, add_tool], llm=llm, verbose=True\\n)\\n```', metadata={'Header 1': 'Single-Turn Multi-Function Calling OpenAI Agents', 'Header 3': 'Setup'}),\n",
      " Document(page_content='```python\\nresponse = agent.chat(\"What is (121 * 3) + 42?\")\\nprint(str(response))\\n```  \\nSTARTING TURN 1\\n---------------  \\n=== Calling Function ===\\nCalling function: multiply with args: {\"a\": 121, \"b\": 3}\\nGot output: 363\\n========================  \\n=== Calling Function ===\\nCalling function: add with args: {\"a\": 363, \"b\": 42}\\nGot output: 405\\n========================  \\nSTARTING TURN 2\\n---------------  \\nThe result of (121 * 3) + 42 is 405.  \\n```python\\nresponse = agent.stream_chat(\"What is (121 * 3) + 42?\")\\n```  \\nSTARTING TURN 1\\n---------------  \\n=== Calling Function ===\\nCalling function: add with args: {\"a\":363,\"b\":42}\\nGot output: 405\\n========================  \\nSTARTING TURN 2\\n---------------', metadata={'Header 1': 'Single-Turn Multi-Function Calling OpenAI Agents', 'Header 3': 'Sync mode'}),\n",
      " Document(page_content='```python\\nimport nest_asyncio\\n\\nnest_asyncio.apply()\\n```  \\n```python\\nresponse = await agent.achat(\"What is (121 * 3) + 42?\")\\nprint(str(response))\\n```  \\nSTARTING TURN 1\\n---------------  \\n=== Calling Function ===\\nCalling function: add with args: {\"a\":363,\"b\":42}\\nGot output: 405\\n========================  \\nSTARTING TURN 2\\n---------------  \\nThe result of (121 * 3) + 42 is 405.  \\n```python\\nresponse = await agent.astream_chat(\"What is (121 * 3) + 42?\")\\n\\nresponse_gen = response.response_gen\\n\\nasync for token in response.async_response_gen():\\nprint(token, end=\"\")\\n```  \\nSTARTING TURN 1\\n---------------  \\n=== Calling Function ===\\nCalling function: multiply with args: {\"a\": 121, \"b\": 3}\\nGot output: 363\\n========================  \\n=== Calling Function ===\\nCalling function: add with args: {\"a\": 363, \"b\": 42}\\nGot output: 405\\n========================  \\nSTARTING TURN 2\\n---------------  \\nThe result of (121 * 3) + 42 is 405.', metadata={'Header 1': 'Single-Turn Multi-Function Calling OpenAI Agents', 'Header 3': 'Async mode'}),\n",
      " Document(page_content='Here\\'s an example straight from the OpenAI [docs](https://platform.openai.com/docs/guides/function-calling/parallel-function-calling) on Parallel function calling. (Their example gets this done in 76 lines of code, whereas with the `llama_index` library you can get that down to about 18 lines.)  \\n```python\\nimport json\\n\\n\\n# Example dummy function hard coded to return the same weather\\n# In production, this could be your backend API or an external API\\ndef get_current_weather(location, unit=\"fahrenheit\"):\\n\"\"\"Get the current weather in a given location\"\"\"\\nif \"tokyo\" in location.lower():\\nreturn json.dumps(\\n{\"location\": location, \"temperature\": \"10\", \"unit\": \"celsius\"}\\n)\\nelif \"san francisco\" in location.lower():\\nreturn json.dumps(\\n{\"location\": location, \"temperature\": \"72\", \"unit\": \"fahrenheit\"}\\n)\\nelse:\\nreturn json.dumps(\\n{\"location\": location, \"temperature\": \"22\", \"unit\": \"celsius\"}\\n)\\n\\n\\nweather_tool = FunctionTool.from_defaults(fn=get_current_weather)\\n```  \\n```python\\nllm = OpenAI(model=\"gpt-3.5-turbo-1106\")\\nagent = OpenAIAgent.from_tools([weather_tool], llm=llm, verbose=True)\\nresponse = agent.chat(\\n\"What\\'s the weather like in San Francisco, Tokyo, and Paris?\"\\n)\\n```  \\nSTARTING TURN 1\\n---------------  \\n=== Calling Function ===\\nCalling function: get_current_weather with args: {\"location\": \"San Francisco\", \"unit\": \"fahrenheit\"}\\nGot output: {\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": \"fahrenheit\"}\\n========================  \\n=== Calling Function ===\\nCalling function: get_current_weather with args: {\"location\": \"Tokyo\", \"unit\": \"fahrenheit\"}\\nGot output: {\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": \"celsius\"}\\n========================  \\n=== Calling Function ===\\nCalling function: get_current_weather with args: {\"location\": \"Paris\", \"unit\": \"fahrenheit\"}\\nGot output: {\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": \"celsius\"}\\n========================  \\nSTARTING TURN 2\\n---------------  \\nAll of the above function calls that the Agent has done above were in a single turn of dialogue between the `Assistant` and the `User`. What\\'s interesting is that an older version of GPT-3.5 is not quite advanced enough compared to is successor — it will do the above task in 3 separate turns. For the sake of demonstration, here it is below.  \\n```python\\nllm = OpenAI(model=\"gpt-3.5-turbo-0613\")\\nagent = OpenAIAgent.from_tools([weather_tool], llm=llm, verbose=True)\\nresponse = agent.chat(\\n\"What\\'s the weather like in San Francisco, Tokyo, and Paris?\"\\n)\\n```  \\nSTARTING TURN 1\\n---------------  \\n=== Calling Function ===\\nCalling function: get_current_weather with args: {\\n\"location\": \"San Francisco\"\\n}\\nGot output: {\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": \"fahrenheit\"}\\n========================  \\nSTARTING TURN 2\\n---------------  \\n=== Calling Function ===\\nCalling function: get_current_weather with args: {\\n\"location\": \"Tokyo\"\\n}\\nGot output: {\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": \"celsius\"}\\n========================  \\nSTARTING TURN 3\\n---------------  \\n=== Calling Function ===\\nCalling function: get_current_weather with args: {\\n\"location\": \"Paris\"\\n}\\nGot output: {\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": \"celsius\"}\\n========================  \\nSTARTING TURN 4\\n---------------', metadata={'Header 1': 'Single-Turn Multi-Function Calling OpenAI Agents', 'Header 3': 'Example from OpenAI docs'}),\n",
      " Document(page_content='And so, as you can see the `llama_index` library can handle multiple function calls (as well as a single function call) within a single turn of dialogue between the user and the OpenAI agent!', metadata={'Header 1': 'Single-Turn Multi-Function Calling OpenAI Agents', 'Header 2': 'Conclusion'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/openai_agent_query_cookbook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>'),\n",
      " Document(page_content='In this notebook, we try out the OpenAIAgent across a variety of query engine tools and datasets. We explore how OpenAIAgent can compare/replace existing workflows solved by our retrievers/query engines.  \\n- Auto retrieval\\n- Joint SQL and vector search', metadata={'Header 1': 'OpenAI Agent + Query Engine Experimental Cookbook'}),\n",
      " Document(page_content='Our existing \"auto-retrieval\" capabilities (in `VectorIndexAutoRetriever`) allow an LLM to infer the right query parameters for a vector database - including both the query string and metadata filter.  \\nSince the OpenAI Function API can infer function parameters, we explore its capabilities in performing auto-retrieval here.  \\nIf you\\'re opening this Notebook on colab, you will probably need to install LlamaIndex 🦙.  \\n```python\\n!pip install llama-index\\n```  \\n```python\\nimport pinecone\\nimport os\\n\\napi_key = os.environ[\"PINECONE_API_KEY\"]\\npinecone.init(api_key=api_key, environment=\"us-west4-gcp-free\")\\n```  \\n```python\\nimport os\\nimport getpass\\n\\n# os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\\nimport openai\\n\\nopenai.api_key = \"sk-<your-key>\"\\n```  \\n```python\\n# dimensions are for text-embedding-ada-002\\ntry:\\npinecone.create_index(\\n\"quickstart-index\", dimension=1536, metric=\"euclidean\", pod_type=\"p1\"\\n)\\nexcept Exception:\\n# most likely index already exists\\npass\\n```  \\n```python\\npinecone_index = pinecone.Index(\"quickstart-index\")\\n```  \\n```python\\n# Optional: delete data in your pinecone index\\npinecone_index.delete(deleteAll=True, namespace=\"test\")\\n```  \\n{}  \\n```python\\nfrom llama_index import VectorStoreIndex, StorageContext\\nfrom llama_index.vector_stores import PineconeVectorStore\\n```  \\n```python\\nfrom llama_index.schema import TextNode\\n\\nnodes = [\\nTextNode(\\ntext=(\\n\"Michael Jordan is a retired professional basketball player,\"\\n\" widely regarded as one of the greatest basketball players of all\"\\n\" time.\"\\n),\\nmetadata={\\n\"category\": \"Sports\",\\n\"country\": \"United States\",\\n\"gender\": \"male\",\\n\"born\": 1963,\\n},\\n),\\nTextNode(\\ntext=(\\n\"Angelina Jolie is an American actress, filmmaker, and\"\\n\" humanitarian. She has received numerous awards for her acting\"\\n\" and is known for her philanthropic work.\"\\n),\\nmetadata={\\n\"category\": \"Entertainment\",\\n\"country\": \"United States\",\\n\"gender\": \"female\",\\n\"born\": 1975,\\n},\\n),\\nTextNode(\\ntext=(\\n\"Elon Musk is a business magnate, industrial designer, and\"\\n\" engineer. He is the founder, CEO, and lead designer of SpaceX,\"\\n\" Tesla, Inc., Neuralink, and The Boring Company.\"\\n),\\nmetadata={\\n\"category\": \"Business\",\\n\"country\": \"United States\",\\n\"gender\": \"male\",\\n\"born\": 1971,\\n},\\n),\\nTextNode(\\ntext=(\\n\"Rihanna is a Barbadian singer, actress, and businesswoman. She\"\\n\" has achieved significant success in the music industry and is\"\\n\" known for her versatile musical style.\"\\n),\\nmetadata={\\n\"category\": \"Music\",\\n\"country\": \"Barbados\",\\n\"gender\": \"female\",\\n\"born\": 1988,\\n},\\n),\\nTextNode(\\ntext=(\\n\"Cristiano Ronaldo is a Portuguese professional footballer who is\"\\n\" considered one of the greatest football players of all time. He\"\\n\" has won numerous awards and set multiple records during his\"\\n\" career.\"\\n),\\nmetadata={\\n\"category\": \"Sports\",\\n\"country\": \"Portugal\",\\n\"gender\": \"male\",\\n\"born\": 1985,\\n},\\n),\\n]\\n```  \\n```python\\nvector_store = PineconeVectorStore(\\npinecone_index=pinecone_index, namespace=\"test\"\\n)\\nstorage_context = StorageContext.from_defaults(vector_store=vector_store)\\n```  \\n```python\\nindex = VectorStoreIndex(nodes, storage_context=storage_context)\\n```  \\nUpserted vectors: 100%|██████████| 5/5 [00:00<00:00,  5.79it/s]  \\n#### Define Function Tool  \\nHere we define the function interface, which is passed to OpenAI to perform auto-retrieval.  \\nWe were not able to get OpenAI to work with nested pydantic objects or tuples as arguments,\\nso we converted the metadata filter keys and values into lists for the function API to work with.  \\n```python\\n# define function tool\\nfrom llama_index.tools import FunctionTool\\nfrom llama_index.vector_stores.types import (\\nVectorStoreInfo,\\nMetadataInfo,\\nMetadataFilter,\\nMetadataFilters,\\nFilterCondition,\\nFilterOperator,\\n)\\nfrom llama_index.retrievers import VectorIndexRetriever\\nfrom llama_index.query_engine import RetrieverQueryEngine\\n\\nfrom typing import List, Tuple, Any\\nfrom pydantic import BaseModel, Field\\n\\n# hardcode top k for now\\ntop_k = 3\\n\\n# define vector store info describing schema of vector store\\nvector_store_info = VectorStoreInfo(\\ncontent_info=\"brief biography of celebrities\",\\nmetadata_info=[\\nMetadataInfo(\\nname=\"category\",\\ntype=\"str\",\\ndescription=(\\n\"Category of the celebrity, one of [Sports, Entertainment,\"\\n\" Business, Music]\"\\n),\\n),\\nMetadataInfo(\\nname=\"country\",\\ntype=\"str\",\\ndescription=(\\n\"Country of the celebrity, one of [United States, Barbados,\"\\n\" Portugal]\"\\n),\\n),\\nMetadataInfo(\\nname=\"gender\",\\ntype=\"str\",\\ndescription=(\"Gender of the celebrity, one of [male, female]\"),\\n),\\nMetadataInfo(\\nname=\"born\",\\ntype=\"int\",\\ndescription=(\"Born year of the celebrity, could be any integer\"),\\n),\\n],\\n)\\n```  \\n```python\\n# define pydantic model for auto-retrieval function\\nclass AutoRetrieveModel(BaseModel):\\nquery: str = Field(..., description=\"natural language query string\")\\nfilter_key_list: List[str] = Field(\\n..., description=\"List of metadata filter field names\"\\n)\\nfilter_value_list: List[Any] = Field(\\n...,\\ndescription=(\\n\"List of metadata filter field values (corresponding to names\"\\n\" specified in filter_key_list)\"\\n),\\n)\\nfilter_operator_list: List[str] = Field(\\n...,\\ndescription=(\\n\"Metadata filters conditions (could be one of <, <=, >, >=, ==, !=)\"\\n),\\n)\\nfilter_condition: str = Field(\\n...,\\ndescription=(\"Metadata filters condition values (could be AND or OR)\"),\\n)\\n\\n\\ndescription = f\"\"\"\\\\\\nUse this tool to look up biographical information about celebrities.\\nThe vector database schema is given below:\\n{vector_store_info.json()}\\n\"\"\"\\n```  \\nDefine AutoRetrieve Functions  \\n```python\\ndef auto_retrieve_fn(\\nquery: str,\\nfilter_key_list: List[str],\\nfilter_value_list: List[any],\\nfilter_operator_list: List[str],\\nfilter_condition: str,\\n):\\n\"\"\"Auto retrieval function.\\n\\nPerforms auto-retrieval from a vector database, and then applies a set of filters.\\n\\n\"\"\"\\nquery = query or \"Query\"\\n\\nmetadata_filters = [\\nMetadataFilter(key=k, value=v, operator=op)\\nfor k, v, op in zip(\\nfilter_key_list, filter_value_list, filter_operator_list\\n)\\n]\\nretriever = VectorIndexRetriever(\\nindex,\\nfilters=MetadataFilters(\\nfilters=metadata_filters, condition=filter_condition\\n),\\ntop_k=top_k,\\n)\\nquery_engine = RetrieverQueryEngine.from_args(retriever)\\n\\nresponse = query_engine.query(query)\\nreturn str(response)\\n\\n\\nauto_retrieve_tool = FunctionTool.from_defaults(\\nfn=auto_retrieve_fn,\\nname=\"celebrity_bios\",\\ndescription=description,\\nfn_schema=AutoRetrieveModel,\\n)\\n```  \\n#### Initialize Agent  \\n```python\\nfrom llama_index.agent import OpenAIAgent\\nfrom llama_index.llms import OpenAI\\n\\nagent = OpenAIAgent.from_tools(\\n[auto_retrieve_tool],\\nllm=OpenAI(temperature=0, model=\"gpt-4-0613\"),\\nverbose=True,\\n)\\n```  \\n```python\\nresponse = agent.chat(\"Tell me about two celebrities from the United States. \")\\nprint(str(response))\\n```  \\nSTARTING TURN 1\\n---------------  \\n=== Calling Function ===\\nCalling function: celebrity_bios with args: {\\n\"query\": \"celebrities from the United States\",\\n\"filter_key_list\": [\"country\"],\\n\"filter_value_list\": [\"United States\"],\\n\"filter_operator_list\": [\"==\"],\\n\"filter_condition\": \"and\"\\n}\\nGot output: Angelina Jolie and Michael Jordan are both celebrities from the United States.\\n========================  \\nSTARTING TURN 2\\n---------------  \\nHere are two celebrities from the United States:  \\n1. **Angelina Jolie**: She is an American actress, filmmaker, and humanitarian. The recipient of numerous accolities, including an Academy Award and three Golden Globe Awards, she has been named Hollywood\\'s highest-paid actress multiple times.  \\n2. **Michael Jordan**: He is a former professional basketball player and the principal owner of the Charlotte Hornets of the National Basketball Association (NBA). He played 15 seasons in the NBA, winning six championships with the Chicago Bulls. He is considered one of the greatest players in the history of the NBA.  \\n```python\\nresponse = agent.chat(\"Tell me about two celebrities born after 1980. \")\\nprint(str(response))\\n```  \\nSTARTING TURN 1\\n---------------  \\n=== Calling Function ===\\nCalling function: celebrity_bios with args: {\\n\"query\": \"celebrities born after 1980\",\\n\"filter_key_list\": [\"born\"],\\n\"filter_value_list\": [1980],\\n\"filter_operator_list\": [\">\"],\\n\"filter_condition\": \"and\"\\n}\\nGot output: Rihanna and Cristiano Ronaldo are both celebrities who were born after 1980.\\n========================  \\nSTARTING TURN 2\\n---------------  \\nHere are two celebrities who were born after 1980:  \\n1. **Rihanna**: She is a Barbadian singer, actress, and businesswoman. Born in Saint Michael and raised in Bridgetown, Barbados, Rihanna was discovered by American record producer Evan Rogers who invited her to the United States to record demo tapes. She rose to fame with her debut album \"Music of the Sun\" and its follow-up \"A Girl like Me\".  \\n2. **Cristiano Ronaldo**: He is a Portuguese professional footballer who plays as a forward for Serie A club Juventus and captains the Portugal  \\n```python\\nresponse = agent.chat(\\n\"Tell me about few celebrities under category business and born after 1950. \"\\n)\\nprint(str(response))\\n```  \\nSTARTING TURN 1\\n---------------  \\n=== Calling Function ===\\nCalling function: celebrity_bios with args: {\\n\"query\": \"business celebrities born after 1950\",\\n\"filter_key_list\": [\"category\", \"born\"],\\n\"filter_value_list\": [\"Business\", 1950],\\n\"filter_operator_list\": [\"==\", \">\"],\\n\"filter_condition\": \"and\"\\n}\\nGot output: Elon Musk is a notable business celebrity who was born in 1971.\\n========================  \\nSTARTING TURN 2\\n---------------  \\nElon Musk is a business celebrity who was born after 1950. He is a business magnate and investor. He is the founder, CEO, CTO, and chief designer of SpaceX; early investor, CEO and product architect of Tesla, Inc.; founder of The', metadata={'Header 1': 'OpenAI Agent + Query Engine Experimental Cookbook', 'Header 2': 'AutoRetrieval from a Vector Database'}),\n",
      " Document(page_content='This is currently handled by our `SQLAutoVectorQueryEngine`.  \\nLet\\'s try implementing this by giving our `OpenAIAgent` access to two query tools: SQL and Vector  \\n#### Load and Index Structured Data  \\nWe load sample structured datapoints into a SQL db and index it.  \\n```python\\nfrom sqlalchemy import (\\ncreate_engine,\\nMetaData,\\nTable,\\nColumn,\\nString,\\nInteger,\\nselect,\\ncolumn,\\n)\\nfrom llama_index import SQLDatabase, SQLStructStoreIndex\\n\\nengine = create_engine(\"sqlite:///:memory:\", future=True)\\nmetadata_obj = MetaData()\\n```  \\n```python\\n# create city SQL table\\ntable_name = \"city_stats\"\\ncity_stats_table = Table(\\ntable_name,\\nmetadata_obj,\\nColumn(\"city_name\", String(16), primary_key=True),\\nColumn(\"population\", Integer),\\nColumn(\"country\", String(16), nullable=False),\\n)\\n\\nmetadata_obj.create_all(engine)\\n```  \\n```python\\n# print tables\\nmetadata_obj.tables.keys()\\n```  \\ndict_keys([\\'city_stats\\'])  \\n```python\\nfrom sqlalchemy import insert\\n\\nrows = [\\n{\"city_name\": \"Toronto\", \"population\": 2930000, \"country\": \"Canada\"},\\n{\"city_name\": \"Tokyo\", \"population\": 13960000, \"country\": \"Japan\"},\\n{\"city_name\": \"Berlin\", \"population\": 3645000, \"country\": \"Germany\"},\\n]\\nfor row in rows:\\nstmt = insert(city_stats_table).values(**row)\\nwith engine.begin() as connection:\\ncursor = connection.execute(stmt)\\n```  \\n```python\\nwith engine.connect() as connection:\\ncursor = connection.exec_driver_sql(\"SELECT * FROM city_stats\")\\nprint(cursor.fetchall())\\n```  \\n[(\\'Toronto\\', 2930000, \\'Canada\\'), (\\'Tokyo\\', 13960000, \\'Japan\\'), (\\'Berlin\\', 3645000, \\'Germany\\')]  \\n```python\\nsql_database = SQLDatabase(engine, include_tables=[\"city_stats\"])\\n```  \\n```python\\nfrom llama_index.indices.struct_store.sql_query import NLSQLTableQueryEngine\\n```  \\n```python\\nquery_engine = NLSQLTableQueryEngine(\\nsql_database=sql_database,\\ntables=[\"city_stats\"],\\n)\\n```  \\n#### Load and Index Unstructured Data  \\nWe load unstructured data into a vector index backed by Pinecone  \\n```python\\n# install wikipedia python package\\n!pip install wikipedia\\n```  \\nRequirement already satisfied: wikipedia in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (1.4.0)\\nRequirement already satisfied: requests<3.0.0,>=2.0.0 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from wikipedia) (2.28.2)\\nRequirement already satisfied: beautifulsoup4 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from wikipedia) (4.12.2)\\nRequirement already satisfied: charset-normalizer<4,>=2 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.1.0)\\nRequirement already satisfied: idna<4,>=2.5 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4)\\nRequirement already satisfied: certifi>=2017.4.17 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2022.12.7)\\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.26.15)\\nRequirement already satisfied: soupsieve>1.2 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from beautifulsoup4->wikipedia) (2.4.1)  \\n\\x1b[1m[\\x1b[0m\\x1b[34;49mnotice\\x1b[0m\\x1b[1;39;49m]\\x1b[0m\\x1b[39;49m A new release of pip available: \\x1b[0m\\x1b[31;49m22.3.1\\x1b[0m\\x1b[39;49m -> \\x1b[0m\\x1b[32;49m23.1.2\\x1b[0m\\n\\x1b[1m[\\x1b[0m\\x1b[34;49mnotice\\x1b[0m\\x1b[1;39;49m]\\x1b[0m\\x1b[39;49m To update, run: \\x1b[0m\\x1b[32;49mpip install --upgrade pip\\x1b[0m  \\n```python\\nfrom llama_index import (\\nWikipediaReader,\\nSimpleDirectoryReader,\\nVectorStoreIndex,\\n)\\n```  \\n```python\\ncities = [\"Toronto\", \"Berlin\", \"Tokyo\"]\\nwiki_docs = WikipediaReader().load_data(pages=cities)\\n```  \\n```python\\n# define pinecone index\\nimport pinecone\\nimport os\\n\\napi_key = os.environ[\"PINECONE_API_KEY\"]\\npinecone.init(api_key=api_key, environment=\"us-west1-gcp\")\\n\\n# dimensions are for text-embedding-ada-002\\n# pinecone.create_index(\"quickstart\", dimension=1536, metric=\"euclidean\", pod_type=\"p1\")\\npinecone_index = pinecone.Index(\"quickstart\")\\n```  \\n```python\\n# OPTIONAL: delete all\\npinecone_index.delete(deleteAll=True)\\n```  \\n{}  \\n```python\\nfrom llama_index import ServiceContext\\nfrom llama_index.storage import StorageContext\\nfrom llama_index.vector_stores import PineconeVectorStore\\nfrom llama_index.node_parser import TokenTextSplitter\\nfrom llama_index.llms import OpenAI\\n\\n# define node parser and LLM\\nchunk_size = 1024\\nllm = OpenAI(temperature=0, model=\"gpt-4\")\\nservice_context = ServiceContext.from_defaults(chunk_size=chunk_size, llm=llm)\\nnode_parser = TokenTextSplitter(chunk_size=chunk_size)\\n\\n# define pinecone vector index\\nvector_store = PineconeVectorStore(\\npinecone_index=pinecone_index, namespace=\"wiki_cities\"\\n)\\nstorage_context = StorageContext.from_defaults(vector_store=vector_store)\\nvector_index = VectorStoreIndex([], storage_context=storage_context)\\n```  \\n```python\\n# Insert documents into vector index\\n# Each document has metadata of the city attached\\nfor city, wiki_doc in zip(cities, wiki_docs):\\nnodes = node_parser.get_nodes_from_documents([wiki_doc])\\n# add metadata to each node\\nfor node in nodes:\\nnode.metadata = {\"title\": city}\\nvector_index.insert_nodes(nodes)\\n```  \\nUpserted vectors: 100%|█████████████████████████████████████████████████| 20/20 [00:00<00:00, 38.13it/s]\\nUpserted vectors: 100%|████████████████████████████████████████████████| 21/21 [00:00<00:00, 101.89it/s]\\nUpserted vectors: 100%|█████████████████████████████████████████████████| 13/13 [00:00<00:00, 97.91it/s]  \\n#### Define Query Engines / Tools  \\n```python\\nfrom llama_index.query_engine import (\\nSQLAutoVectorQueryEngine,\\nRetrieverQueryEngine,\\n)\\nfrom llama_index.tools.query_engine import QueryEngineTool\\nfrom llama_index.indices.vector_store import VectorIndexAutoRetriever\\n```  \\n```python\\nfrom llama_index.indices.vector_store.retrievers import (\\nVectorIndexAutoRetriever,\\n)\\nfrom llama_index.vector_stores.types import MetadataInfo, VectorStoreInfo\\nfrom llama_index.query_engine.retriever_query_engine import (\\nRetrieverQueryEngine,\\n)\\n\\n\\nvector_store_info = VectorStoreInfo(\\ncontent_info=\"articles about different cities\",\\nmetadata_info=[\\nMetadataInfo(\\nname=\"title\", type=\"str\", description=\"The name of the city\"\\n),\\n],\\n)\\nvector_auto_retriever = VectorIndexAutoRetriever(\\nvector_index, vector_store_info=vector_store_info\\n)\\n\\nretriever_query_engine = RetrieverQueryEngine.from_args(\\nvector_auto_retriever, service_context=service_context\\n)\\n```  \\n```python\\nsql_tool = QueryEngineTool.from_defaults(\\nquery_engine=query_engine,\\nname=\"sql_tool\",\\ndescription=(\\n\"Useful for translating a natural language query into a SQL query over\"\\n\" a table containing: city_stats, containing the population/country of\"\\n\" each city\"\\n),\\n)\\nvector_tool = QueryEngineTool.from_defaults(\\nquery_engine=retriever_query_engine,\\nname=\"vector_tool\",\\ndescription=(\\nf\"Useful for answering semantic questions about different cities\"\\n),\\n)\\n```  \\n#### Initialize Agent  \\n```python\\nfrom llama_index.agent import OpenAIAgent\\nfrom llama_index.llms import OpenAI\\n\\nagent = OpenAIAgent.from_tools(\\n[sql_tool, vector_tool],\\nllm=OpenAI(temperature=0, model=\"gpt-4-0613\"),\\nverbose=True,\\n)\\n```  \\n```python\\n# NOTE: gpt-3.5 gives the wrong answer, but gpt-4 is able to reason over both loops\\nresponse = agent.chat(\\n\"Tell me about the arts and culture of the city with the highest\"\\n\" population\"\\n)\\nprint(str(response))\\n```  \\n=== Calling Function ===\\nCalling function: sql_tool with args: {\\n\"input\": \"SELECT city FROM city_stats ORDER BY population DESC LIMIT 1\"\\n}\\nGot output:  The city with the highest population is Tokyo.\\n========================\\n=== Calling Function ===\\nCalling function: vector_tool with args: {\\n\"input\": \"Tell me about the arts and culture of Tokyo\"\\n}\\nGot output: Tokyo has a rich arts and culture scene, with many theaters for performing arts, including national and private theaters for traditional forms of Japanese drama. Noteworthy theaters are the National Noh Theatre for noh and the Kabuki-za for Kabuki. Symphony orchestras and other musical organizations perform modern and traditional music. The New National Theater Tokyo in Shibuya is the national center for the performing arts, including opera, ballet, contemporary dance, and drama. Tokyo also hosts modern Japanese and international pop and rock music at various venues, ranging from intimate clubs to internationally known areas such as the Nippon Budokan.  \\nMany different festivals occur throughout Tokyo, with major events including the Sannō at Hie Shrine, the Sanja at Asakusa Shrine, and the biennial Kanda Festivals. Annually on the last Saturday of July, a massive fireworks display over the Sumida River attracts over a million viewers. Once cherry blossoms bloom in spring, residents gather in Ueno Park, Inokashira Park, and the Shinjuku Gyoen National Garden for picnics under the blossoms. Harajuku, a neighborhood in Shibuya, is known internationally for its youth style, fashion, and cosplay.  \\nTokyo is also renowned for its fine dining, with Michelin awarding a significant number of stars to the city\\'s restaurants. As of 2017, 227 restaurants in Tokyo have been awarded Michelin stars, surpassing the number awarded in Paris.\\n========================\\nTokyo, the city with the highest population, has a rich arts and culture scene. It is home to many theaters for performing arts, including national and private theaters for traditional forms of Japanese drama such as Noh and Kabuki. The New National Theater Tokyo in Shibuya is the national center for the performing arts, including opera, ballet, contemporary dance, and drama.  \\nTokyo also hosts modern Japanese and international pop and rock music at various venues, ranging from intimate clubs to internationally known areas such as the Nippon Budokan.  \\nThe city is known for its festivals, with major events including the Sannō at Hie Shrine, the Sanja at Asakusa Shrine, and the biennial Kanda Festivals. Once cherry blossoms bloom in spring, residents gather in Ueno Park, Inokashira Park, and the Shinjuku Gyoen National Garden for picnics under the blossoms.  \\nHarajuku, a neighborhood in Shibuya, is known internationally for its youth style, fashion, and cosplay. Tokyo is also renowned for its fine dining, with Michelin awarding a significant number of stars to the city\\'s restaurants. As of 2017, 227 restaurants in Tokyo have been awarded Michelin stars, surpassing the number awarded in Paris.  \\n```python\\nresponse = agent.chat(\"Tell me about the history of Berlin\")\\nprint(str(response))\\n```  \\n=== Calling Function ===\\nCalling function: vector_tool with args: {\\n\"input\": \"Tell me about the history of Berlin\"\\n}\\nGot output: Berlin\\'s history dates back to the 15th century when it was established as the capital of the Margraviate of Brandenburg. The Hohenzollern family ruled Berlin until 1918, first as electors of Brandenburg, then as kings of Prussia, and eventually as German emperors. In 1443, Frederick II Irontooth started the construction of a new royal palace in the twin city Berlin-Cölln, which later became the permanent residence of the Brandenburg electors of the Hohenzollerns.  \\nThe Thirty Years\\' War between 1618 and 1648 devastated Berlin, with the city losing half of its population. Frederick William, known as the \"Great Elector\", initiated a policy of promoting immigration and religious tolerance. In 1701, the dual state of the Margraviate of Brandenburg and the Duchy of Prussia formed the Kingdom of Prussia, with Berlin as its capital. Under the rule of Frederick II, Berlin became a center of the Enlightenment.  \\nThe Industrial Revolution in the 19th century transformed Berlin, expanding its economy and population. In 1871, Berlin became the capital of the newly founded German Empire. The early 20th century saw Berlin as a fertile ground for the German Expressionist movement. At the end of the First World War in 1918, a republic was proclaimed, and in 1920, the Greater Berlin Act incorporated dozens of suburban cities, villages, and estates around Berlin.\\n========================  \\nResponse(response=\\'Berlin\\\\\\'s history dates back to the 15th century when it was established as the capital of the Margraviate of Brandenburg. The Hohenzollern family ruled Berlin until 1918, first as electors of Brandenburg, then as kings of Prussia, and eventually as German emperors. In 1443, Frederick II Irontooth started the construction of a new royal palace in the twin city Berlin-Cölln.\\\\n\\\\nThe Thirty Years\\\\\\' War between 1618 and 1648 devastated Berlin, with the city losing half of its population. Frederick William, known as the \"Great Elector\", initiated a policy of promoting immigration and religious tolerance. In 1701, the dual state of the Margraviate of Brandenburg and the Duchy of Prussia formed the Kingdom of Prussia, with Berlin as its capital. Under the rule of Frederick II, Berlin became a center of the Enlightenment.\\\\n\\\\nThe Industrial Revolution in the 19th century transformed Berlin, expanding its economy and population. In 1871, Berlin became the capital of the newly founded German Empire. The early 20th century saw Berlin as a fertile ground for the German Expressionist movement. At the end of the First World War in 1918, a republic was proclaimed, and in 1920, the Greater Berlin Act incorporated dozens of suburban cities, villages, and estates around Berlin.\\', source_nodes=[], extra_info=None)  \\n```python\\nresponse = agent.chat(\\n\"Can you give me the country corresponding to each city?\"\\n)\\nprint(str(response))\\n```  \\n=== Calling Function ===\\nCalling function: sql_tool with args: {\\n\"input\": \"SELECT city, country FROM city_stats\"\\n}\\nGot output:  The cities Toronto, Tokyo, and Berlin are located in the countries Canada, Japan, and Germany respectively.\\n========================  \\nResponse(response=\\'Sure, here are the countries corresponding to each city:\\\\n\\\\n- Toronto is in Canada\\\\n- Tokyo is in Japan\\\\n- Berlin is in Germany\\', source_nodes=[], extra_info=None)', metadata={'Header 1': 'OpenAI Agent + Query Engine Experimental Cookbook', 'Header 2': 'Joint Text-to-SQL and Semantic Search'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/openai_agent_query_plan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>'),\n",
      " Document(page_content='In this demo, we explore adding a `QueryPlanTool` to an `OpenAIAgent`. This effectively enables the agent\\nto do advanced query planning, all through a single tool!  \\nThe `QueryPlanTool` is designed to work well with the OpenAI Function API. The tool takes in a set of other tools as input.\\nThe tool function signature contains of a QueryPlan Pydantic object, which can in turn contain a DAG of QueryNode objects defining a compute graph.\\nThe agent is responsible for defining this graph through the function signature when calling the tool. The tool itself executes the DAG over any corresponding tools.  \\nIn this setting we use a familiar example: Uber 10Q filings in March, June, and September of 2022.  \\nIf you\\'re opening this Notebook on colab, you will probably need to install LlamaIndex 🦙.  \\n```python\\n!pip install llama-index\\n```  \\n```python\\n# # uncomment to turn on logging\\n# import logging\\n# import sys\\n\\n# logging.basicConfig(stream=sys.stdout, level=logging.INFO)\\n# logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\\n```  \\n```python\\n%load_ext autoreload\\n%autoreload 2\\n```  \\n```python\\nfrom llama_index import (\\nSimpleDirectoryReader,\\nServiceContext,\\nGPTVectorStoreIndex,\\n)\\nfrom llama_index.response.pprint_utils import pprint_response\\nfrom llama_index.llms import OpenAI\\n```  \\n```python\\nllm = OpenAI(temperature=0, model=\"gpt-4\")\\nservice_context = ServiceContext.from_defaults(llm=llm)\\n```', metadata={'Header 1': 'OpenAI Agent Query Planning'}),\n",
      " Document(page_content=\"```python\\n!mkdir -p 'data/10q/'\\n!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10q/uber_10q_march_2022.pdf' -O 'data/10q/uber_10q_march_2022.pdf'\\n!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10q/uber_10q_june_2022.pdf' -O 'data/10q/uber_10q_june_2022.pdf'\\n!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10q/uber_10q_sept_2022.pdf' -O 'data/10q/uber_10q_sept_2022.pdf'\\n```\", metadata={'Header 1': 'OpenAI Agent Query Planning', 'Header 2': 'Download Data'}),\n",
      " Document(page_content='```python\\nmarch_2022 = SimpleDirectoryReader(\\ninput_files=[\"./data/10q/uber_10q_march_2022.pdf\"]\\n).load_data()\\njune_2022 = SimpleDirectoryReader(\\ninput_files=[\"./data/10q/uber_10q_june_2022.pdf\"]\\n).load_data()\\nsept_2022 = SimpleDirectoryReader(\\ninput_files=[\"./data/10q/uber_10q_sept_2022.pdf\"]\\n).load_data()\\n```', metadata={'Header 1': 'OpenAI Agent Query Planning', 'Header 2': 'Load data'}),\n",
      " Document(page_content='We build a vector index / query engine over each of the documents (March, June, September).  \\n```python\\nmarch_index = GPTVectorStoreIndex.from_documents(march_2022)\\njune_index = GPTVectorStoreIndex.from_documents(june_2022)\\nsept_index = GPTVectorStoreIndex.from_documents(sept_2022)\\n```  \\n```python\\nmarch_engine = march_index.as_query_engine(\\nsimilarity_top_k=3, service_context=service_context\\n)\\njune_engine = june_index.as_query_engine(\\nsimilarity_top_k=3, service_context=service_context\\n)\\nsept_engine = sept_index.as_query_engine(\\nsimilarity_top_k=3, service_context=service_context\\n)\\n```', metadata={'Header 1': 'OpenAI Agent Query Planning', 'Header 2': 'Build indices'}),\n",
      " Document(page_content='Use OpenAIAgent, built on top of the OpenAI tool use interface.  \\nFeed it our QueryPlanTool, which is a Tool that takes in other tools. And the agent to generate a query plan DAG over these tools.  \\n```python\\nfrom llama_index.tools import QueryEngineTool\\n\\n\\nquery_tool_sept = QueryEngineTool.from_defaults(\\nquery_engine=sept_engine,\\nname=\"sept_2022\",\\ndescription=(\\nf\"Provides information about Uber quarterly financials ending\"\\nf\" September 2022\"\\n),\\n)\\nquery_tool_june = QueryEngineTool.from_defaults(\\nquery_engine=june_engine,\\nname=\"june_2022\",\\ndescription=(\\nf\"Provides information about Uber quarterly financials ending June\"\\nf\" 2022\"\\n),\\n)\\nquery_tool_march = QueryEngineTool.from_defaults(\\nquery_engine=march_engine,\\nname=\"march_2022\",\\ndescription=(\\nf\"Provides information about Uber quarterly financials ending March\"\\nf\" 2022\"\\n),\\n)\\n```  \\n```python\\n# define query plan tool\\nfrom llama_index.tools import QueryPlanTool\\nfrom llama_index import get_response_synthesizer\\n\\nresponse_synthesizer = get_response_synthesizer(\\nservice_context=service_context\\n)\\nquery_plan_tool = QueryPlanTool.from_defaults(\\nquery_engine_tools=[query_tool_sept, query_tool_june, query_tool_march],\\nresponse_synthesizer=response_synthesizer,\\n)\\n```  \\n```python\\nquery_plan_tool.metadata.to_openai_tool()  # to_openai_function() deprecated\\n```  \\n{\\'name\\': \\'query_plan_tool\\',\\n\\'description\\': \\'        This is a query plan tool that takes in a list of tools and executes a query plan over these tools to answer a query. The query plan is a DAG of query nodes.\\\\n\\\\nGiven a list of tool names and the query plan schema, you can choose to generate a query plan to answer a question.\\\\n\\\\nThe tool names and descriptions are as follows:\\\\n\\\\n\\\\n\\\\n        Tool Name: sept_2022\\\\nTool Description: Provides information about Uber quarterly financials ending September 2022 \\\\n\\\\nTool Name: june_2022\\\\nTool Description: Provides information about Uber quarterly financials ending June 2022 \\\\n\\\\nTool Name: march_2022\\\\nTool Description: Provides information about Uber quarterly financials ending March 2022 \\\\n        \\',\\n\\'parameters\\': {\\'title\\': \\'QueryPlan\\',\\n\\'description\\': \"Query plan.\\\\n\\\\nContains a list of QueryNode objects (which is a recursive object).\\\\nOut of the list of QueryNode objects, one of them must be the root node.\\\\nThe root node is the one that isn\\'t a dependency of any other node.\",\\n\\'type\\': \\'object\\',\\n\\'properties\\': {\\'nodes\\': {\\'title\\': \\'Nodes\\',\\n\\'description\\': \\'The original question we are asking.\\',\\n\\'type\\': \\'array\\',\\n\\'items\\': {\\'$ref\\': \\'#/definitions/QueryNode\\'}}},\\n\\'required\\': [\\'nodes\\'],\\n\\'definitions\\': {\\'QueryNode\\': {\\'title\\': \\'QueryNode\\',\\n\\'description\\': \\'Query node.\\\\n\\\\nA query node represents a query (query_str) that must be answered.\\\\nIt can either be answered by a tool (tool_name), or by a list of child nodes\\\\n(child_nodes).\\\\nThe tool_name and child_nodes fields are mutually exclusive.\\',\\n\\'type\\': \\'object\\',\\n\\'properties\\': {\\'id\\': {\\'title\\': \\'Id\\',\\n\\'description\\': \\'ID of the query node.\\',\\n\\'type\\': \\'integer\\'},\\n\\'query_str\\': {\\'title\\': \\'Query Str\\',\\n\\'description\\': \\'Question we are asking. This is the query string that will be executed. \\',\\n\\'type\\': \\'string\\'},\\n\\'tool_name\\': {\\'title\\': \\'Tool Name\\',\\n\\'description\\': \\'Name of the tool to execute the `query_str`.\\',\\n\\'type\\': \\'string\\'},\\n\\'dependencies\\': {\\'title\\': \\'Dependencies\\',\\n\\'description\\': \\'List of sub-questions that need to be answered in order to answer the question given by `query_str`.Should be blank if there are no sub-questions to be specified, in which case `tool_name` is specified.\\',\\n\\'type\\': \\'array\\',\\n\\'items\\': {\\'type\\': \\'integer\\'}}},\\n\\'required\\': [\\'id\\', \\'query_str\\']}}}}  \\n```python\\nfrom llama_index.agent import OpenAIAgent\\nfrom llama_index.llms import OpenAI\\n\\n\\nagent = OpenAIAgent.from_tools(\\n[query_plan_tool],\\nmax_function_calls=10,\\nllm=OpenAI(temperature=0, model=\"gpt-4-0613\"),\\nverbose=True,\\n)\\n```  \\n```python\\nresponse = agent.query(\"What were the risk factors in sept 2022?\")\\n```  \\n```python\\nfrom llama_index.tools.query_plan import QueryPlan, QueryNode\\n\\nquery_plan = QueryPlan(\\nnodes=[\\nQueryNode(\\nid=1,\\nquery_str=\"risk factors\",\\ntool_name=\"sept_2022\",\\ndependencies=[],\\n)\\n]\\n)\\n```  \\n```python\\nQueryPlan.schema()\\n```  \\n{\\'title\\': \\'QueryPlan\\',\\n\\'description\\': \\'Query plan.\\\\n\\\\nContains the root QueryNode (which is a recursive object).\\\\nThe root node should contain the original query string to be executed.\\\\n\\\\nExample query plan in JSON format:\\\\n\\\\n```json\\\\n{\\\\n    \"root\": {\\\\n        \"query_str\": \"Compare the demographics of France and Italy.\",\\\\n        \"child_nodes\": [\\\\n            {\\\\n                \"query_str\": \"What are the demographics of France?\",\\\\n                \"tool_name\": \"france_demographics\",\\\\n                \"child_nodes\": []\\\\n            },\\\\n            {\\\\n                \"query_str\": \"What are the demographics of Italy?\",\\\\n                \"tool_name\": \"italy_demographics\",\\\\n                \"child_nodes\": []\\\\n            }\\\\n        ]\\\\n    }\\\\n}\\\\n```\\',\\n\\'type\\': \\'object\\',\\n\\'properties\\': {\\'root\\': {\\'title\\': \\'Root\\',\\n\\'description\\': \\'Root node of the query plan. Should contain the original query string to be executed.\\',\\n\\'allOf\\': [{\\'$ref\\': \\'#/definitions/QueryNode\\'}]}},\\n\\'required\\': [\\'root\\'],\\n\\'definitions\\': {\\'QueryNode\\': {\\'title\\': \\'QueryNode\\',\\n\\'description\\': \\'Query node.\\\\n\\\\nA query node represents a query (query_str) that must be answered.\\\\nIt can either be answered by a tool (tool_name), or by a list of child nodes\\\\n(child_nodes).\\\\nThe tool_name and child_nodes fields are mutually exclusive.\\',\\n\\'type\\': \\'object\\',\\n\\'properties\\': {\\'query_str\\': {\\'title\\': \\'Query Str\\',\\n\\'description\\': \\'Question we are asking. This is the query string that will be executed. We will either provide a tool to execute the query, or a list of child nodes containing sub-questions that will be executed first, and the results of which will be used as context to execute the current query string.\\',\\n\\'type\\': \\'string\\'},\\n\\'tool_name\\': {\\'title\\': \\'Tool Name\\',\\n\\'description\\': \\'Name of the tool to execute the `query_str`.\\',\\n\\'type\\': \\'string\\'},\\n\\'child_nodes\\': {\\'title\\': \\'Child Nodes\\',\\n\\'description\\': \\'List of child nodes representing sub-questions that need to be answered in order to answer the question given by `query_str`.Should be blank if `tool_name` is specified.\\',\\n\\'type\\': \\'array\\',\\n\\'items\\': {\\'$ref\\': \\'#/definitions/QueryNode\\'}}},\\n\\'required\\': [\\'query_str\\', \\'child_nodes\\']}}}  \\n```python\\nresponse = agent.query(\\n\"Analyze Uber revenue growth in March, June, and September\"\\n)\\n```  \\n=== Calling Function ===\\nCalling function: query_plan_tool with args: {\\n\"nodes\": [\\n{\\n\"id\": 1,\\n\"query_str\": \"What is Uber\\'s revenue for March 2022?\",\\n\"tool_name\": \"march_2022\",\\n\"dependencies\": []\\n},\\n{\\n\"id\": 2,\\n\"query_str\": \"What is Uber\\'s revenue for June 2022?\",\\n\"tool_name\": \"june_2022\",\\n\"dependencies\": []\\n},\\n{\\n\"id\": 3,\\n\"query_str\": \"What is Uber\\'s revenue for September 2022?\",\\n\"tool_name\": \"sept_2022\",\\n\"dependencies\": []\\n},\\n{\\n\"id\": 4,\\n\"query_str\": \"Analyze Uber revenue growth in March, June, and September\",\\n\"tool_name\": \"revenue_growth_analyzer\",\\n\"dependencies\": [1, 2, 3]\\n}\\n]\\n}\\n\\x1b[36;1m\\x1b[1;3mExecuting node {\"id\": 4, \"query_str\": \"Analyze Uber revenue growth in March, June, and September\", \"tool_name\": \"revenue_growth_analyzer\", \"dependencies\": [1, 2, 3]}\\n\\x1b[0m\\x1b[38;5;200m\\x1b[1;3mExecuting 3 child nodes\\n\\x1b[0m\\x1b[36;1m\\x1b[1;3mExecuting node {\"id\": 1, \"query_str\": \"What is Uber\\'s revenue for March 2022?\", \"tool_name\": \"march_2022\", \"dependencies\": []}\\n\\x1b[0m\\x1b[38;5;200m\\x1b[1;3mSelected Tool: ToolMetadata(description=\\'Provides information about Uber quarterly financials ending March 2022\\', name=\\'march_2022\\', fn_schema=None)\\n\\x1b[0m\\x1b[36;1m\\x1b[1;3mExecuted query, got response.\\nQuery: What is Uber\\'s revenue for March 2022?\\nResponse: Uber\\'s revenue for March 2022 was $6.854 billion.\\n\\x1b[0m\\x1b[36;1m\\x1b[1;3mExecuting node {\"id\": 2, \"query_str\": \"What is Uber\\'s revenue for June 2022?\", \"tool_name\": \"june_2022\", \"dependencies\": []}\\n\\x1b[0m\\x1b[38;5;200m\\x1b[1;3mSelected Tool: ToolMetadata(description=\\'Provides information about Uber quarterly financials ending June 2022\\', name=\\'june_2022\\', fn_schema=None)\\n\\x1b[0m\\x1b[36;1m\\x1b[1;3mExecuted query, got response.\\nQuery: What is Uber\\'s revenue for June 2022?\\nResponse: Uber\\'s revenue for June 2022 cannot be determined from the provided information. However, the revenue for the three months ended June 30, 2022, was $8,073 million.\\n\\x1b[0m\\x1b[36;1m\\x1b[1;3mExecuting node {\"id\": 3, \"query_str\": \"What is Uber\\'s revenue for September 2022?\", \"tool_name\": \"sept_2022\", \"dependencies\": []}\\n\\x1b[0m\\x1b[38;5;200m\\x1b[1;3mSelected Tool: ToolMetadata(description=\\'Provides information about Uber quarterly financials ending September 2022\\', name=\\'sept_2022\\', fn_schema=None)\\n\\x1b[0m\\x1b[36;1m\\x1b[1;3mExecuted query, got response.\\nQuery: What is Uber\\'s revenue for September 2022?\\nResponse: Uber\\'s revenue for the three months ended September 30, 2022, was $8.343 billion.\\n\\x1b[0mGot output: Based on the provided context information, we can analyze Uber\\'s revenue growth as follows:  \\n- In March 2022, Uber\\'s revenue was $6.854 billion.\\n- For the three months ended June 30, 2022, Uber\\'s revenue was $8,073 million (or $8.073 billion). However, we do not have the specific revenue for June 2022.\\n- For the three months ended September 30, 2022, Uber\\'s revenue was $8.343 billion.  \\nFrom this information, we can observe that Uber\\'s revenue has been growing between the periods mentioned. The revenue increased from $6.854 billion in March 2022 to $8.073 billion for the three months ended June 2022, and further increased to $8.343 billion for the three months ended September 2022. However, we cannot provide a month-by-month analysis for June and September as the specific monthly revenue figures are not available.\\n========================  \\n```python\\nprint(str(response))\\n```  \\nBased on the provided context information, we can analyze Uber\\'s revenue growth for the three-month periods ending in March, June, and September.  \\n1. For the three months ended March 31, 2022, Uber\\'s revenue was $6.854 billion.\\n2. For the three months ended June 30, 2022, Uber\\'s revenue was $8.073 billion.\\n3. For the three months ended September 30, 2022, Uber\\'s revenue was $8.343 billion.  \\nTo analyze the growth, we can compare the revenue figures for each period:  \\n- From March to June, Uber\\'s revenue increased by $1.219 billion ($8.073 billion - $6.854 billion), which represents a growth of approximately 17.8% (($1.219 billion / $6.854 billion) * 100).\\n- From June to September, Uber\\'s revenue increased by $0.270 billion ($8.343 billion - $8.073 billion), which represents a growth of approximately 3.3% (($0.270 billion / $8.073 billion) * 100).  \\nIn summary, Uber experienced significant revenue growth of 17.8% between the three-month periods ending in March and June, followed by a smaller growth of 3.3% between the periods ending in June and September.  \\n```python\\nresponse = agent.query(\\n\"Analyze changes in risk factors in march, june, and september for Uber\"\\n)\\n```  \\n```python\\nprint(str(response))\\n```  \\n```python\\n# response = agent.query(\"Analyze both Uber revenue growth and risk factors over march, june, and september\")\\n```  \\n```python\\nprint(str(response))\\n```  \\nBased on the provided context information, we can analyze Uber\\'s revenue growth for the three-month periods ending in March, June, and September.  \\n1. For the three months ended March 31, 2022, Uber\\'s revenue was $6.854 billion.\\n2. For the three months ended June 30, 2022, Uber\\'s revenue was $8.073 billion.\\n3. For the three months ended September 30, 2022, Uber\\'s revenue was $8.343 billion.  \\nTo analyze the growth, we can compare the revenue figures for each period:  \\n- From March to June, Uber\\'s revenue increased by $1.219 billion ($8.073 billion - $6.854 billion), which represents a growth of approximately 17.8% (($1.219 billion / $6.854 billion) * 100).\\n- From June to September, Uber\\'s revenue increased by $0.270 billion ($8.343 billion - $8.073 billion), which represents a growth of approximately 3.3% (($0.270 billion / $8.073 billion) * 100).  \\nIn summary, Uber experienced significant revenue growth of 17.8% between the three-month periods ending in March and June, followed by a smaller growth of 3.3% between the periods ending in June and September.  \\n```python\\nresponse = agent.query(\\n\"First look at Uber\\'s revenue growth and risk factors in March, \"\\n+ \"then revenue growth and risk factors in September, and then compare and\"\\n\" contrast the two documents?\"\\n)\\n```  \\n```python\\nresponse\\n```', metadata={'Header 1': 'OpenAI Agent Query Planning', 'Header 2': 'OpenAI Function Agent with a Query Plan Tool'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/openai_agent_retrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>'),\n",
      " Document(page_content=\"In this tutorial, we show you how to use our `FnRetrieverOpenAI` implementation\\nto build an agent on top of OpenAI's function API and store/index an arbitrary number of tools. Our indexing/retrieval modules help to remove the complexity of having too many functions to fit in the prompt.\", metadata={'Header 1': 'Retrieval-Augmented OpenAI Agent'}),\n",
      " Document(page_content='Let\\'s start by importing some simple building blocks.  \\nThe main thing we need is:\\n1. the OpenAI API\\n2. a place to keep conversation history\\n3. a definition for tools that our agent can use.  \\nIf you\\'re opening this Notebook on colab, you will probably need to install LlamaIndex 🦙.  \\n```python\\n!pip install llama-index\\n```  \\n```python\\nimport json\\nfrom typing import Sequence\\n\\nfrom llama_index.tools import BaseTool, FunctionTool\\n```  \\n/Users/suo/miniconda3/envs/llama/lib/python3.9/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.6.7) is available. It\\'s recommended that you update to the latest version using `pip install -U deeplake`.\\nwarnings.warn(  \\nLet\\'s define some very simple calculator tools for our agent.  \\n```python\\ndef multiply(a: int, b: int) -> int:\\n\"\"\"Multiply two integers and returns the result integer\"\"\"\\nreturn a * b\\n\\n\\ndef add(a: int, b: int) -> int:\\n\"\"\"Add two integers and returns the result integer\"\"\"\\nreturn a + b\\n\\n\\ndef useless(a: int, b: int) -> int:\\n\"\"\"Toy useless function.\"\"\"\\npass\\n\\n\\nmultiply_tool = FunctionTool.from_defaults(fn=multiply, name=\"multiply\")\\nuseless_tools = [\\nFunctionTool.from_defaults(fn=useless, name=f\"useless_{str(idx)}\")\\nfor idx in range(28)\\n]\\nadd_tool = FunctionTool.from_defaults(fn=add, name=\"add\")\\n\\nall_tools = [multiply_tool] + [add_tool] + useless_tools\\nall_tools_map = {t.metadata.name: t for t in all_tools}\\n```', metadata={'Header 1': 'Retrieval-Augmented OpenAI Agent', 'Header 2': 'Initial Setup'}),\n",
      " Document(page_content='We have an `ObjectIndex` construct in LlamaIndex that allows the user to use our index data structures over arbitrary objects.\\nThe ObjectIndex will handle serialiation to/from the object, and use an underying index (e.g. VectorStoreIndex, SummaryIndex, KeywordTableIndex) as the storage mechanism.  \\nIn this case, we have a large collection of Tool objects, and we\\'d want to define an ObjectIndex over these Tools.  \\nThe index comes bundled with a retrieval mechanism, an `ObjectRetriever`.  \\nThis can be passed in to our agent so that it can\\nperform Tool retrieval during query-time.  \\n```python\\n# define an \"object\" index over these tools\\nfrom llama_index import VectorStoreIndex\\nfrom llama_index.objects import ObjectIndex, SimpleToolNodeMapping\\n\\ntool_mapping = SimpleToolNodeMapping.from_objects(all_tools)\\nobj_index = ObjectIndex.from_objects(\\nall_tools,\\ntool_mapping,\\nVectorStoreIndex,\\n)\\n```', metadata={'Header 1': 'Retrieval-Augmented OpenAI Agent', 'Header 2': 'Building an Object Index'}),\n",
      " Document(page_content='We provide a `FnRetrieverOpenAIAgent` implementation in LlamaIndex, which can take in an `ObjectRetriever` over a set of `BaseTool` objects.  \\nDuring query-time, we would first use the `ObjectRetriever` to retrieve a set of relevant Tools. These tools would then be passed into the agent; more specifically, their function signatures would be passed into the OpenAI Function calling API.  \\n```python\\nfrom llama_index.agent import FnRetrieverOpenAIAgent\\n```  \\n```python\\nagent = FnRetrieverOpenAIAgent.from_retriever(\\nobj_index.as_retriever(), verbose=True\\n)\\n```  \\n```python\\nagent.chat(\"What\\'s 212 multiplied by 122? Make sure to use Tools\")\\n```  \\n=== Calling Function ===\\nCalling function: multiply with args: {\\n\"a\": 212,\\n\"b\": 122\\n}\\nGot output: 25864\\n========================  \\nResponse(response=\\'212 multiplied by 122 is 25,864.\\', source_nodes=[], metadata=None)  \\n```python\\nagent.chat(\"What\\'s 212 added to 122 ? Make sure to use Tools\")\\n```  \\n=== Calling Function ===\\nCalling function: add with args: {\\n\"a\": 212,\\n\"b\": 122\\n}\\nGot output: 334\\n========================  \\nResponse(response=\\'212 added to 122 is 334.\\', source_nodes=[], metadata=None)', metadata={'Header 1': 'Retrieval-Augmented OpenAI Agent', 'Header 2': 'Our `FnRetrieverOpenAIAgent` Implementation'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/openai_agent_with_query_engine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>'),\n",
      " Document(page_content='If you\\'re opening this Notebook on colab, you will probably need to install LlamaIndex 🦙.  \\n```python\\n!pip install llama-index\\n```  \\n```python\\nfrom llama_index import (\\nSimpleDirectoryReader,\\nVectorStoreIndex,\\nStorageContext,\\nload_index_from_storage,\\n)\\n\\nfrom llama_index.tools import QueryEngineTool, ToolMetadata\\n```  \\n```python\\ntry:\\nstorage_context = StorageContext.from_defaults(\\npersist_dir=\"./storage/lyft\"\\n)\\nlyft_index = load_index_from_storage(storage_context)\\n\\nstorage_context = StorageContext.from_defaults(\\npersist_dir=\"./storage/uber\"\\n)\\nuber_index = load_index_from_storage(storage_context)\\n\\nindex_loaded = True\\nexcept:\\nindex_loaded = False\\n```  \\nDownload Data  \\n```python\\n!mkdir -p \\'data/10k/\\'\\n!wget \\'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10k/uber_2021.pdf\\' -O \\'data/10k/uber_2021.pdf\\'\\n!wget \\'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10k/lyft_2021.pdf\\' -O \\'data/10k/lyft_2021.pdf\\'\\n```  \\n```python\\nif not index_loaded:\\n# load data\\nlyft_docs = SimpleDirectoryReader(\\ninput_files=[\"./data/10k/lyft_2021.pdf\"]\\n).load_data()\\nuber_docs = SimpleDirectoryReader(\\ninput_files=[\"./data/10k/uber_2021.pdf\"]\\n).load_data()\\n\\n# build index\\nlyft_index = VectorStoreIndex.from_documents(lyft_docs)\\nuber_index = VectorStoreIndex.from_documents(uber_docs)\\n\\n# persist index\\nlyft_index.storage_context.persist(persist_dir=\"./storage/lyft\")\\nuber_index.storage_context.persist(persist_dir=\"./storage/uber\")\\n```  \\n```python\\nlyft_engine = lyft_index.as_query_engine(similarity_top_k=3)\\nuber_engine = uber_index.as_query_engine(similarity_top_k=3)\\n```  \\n```python\\nquery_engine_tools = [\\nQueryEngineTool(\\nquery_engine=lyft_engine,\\nmetadata=ToolMetadata(\\nname=\"lyft_10k\",\\ndescription=(\\n\"Provides information about Lyft financials for year 2021. \"\\n\"Use a detailed plain text question as input to the tool.\"\\n),\\n),\\n),\\nQueryEngineTool(\\nquery_engine=uber_engine,\\nmetadata=ToolMetadata(\\nname=\"uber_10k\",\\ndescription=(\\n\"Provides information about Uber financials for year 2021. \"\\n\"Use a detailed plain text question as input to the tool.\"\\n),\\n),\\n),\\n]\\n```', metadata={'Header 1': 'OpenAI Agent with Query Engine Tools', 'Header 2': 'Build Query Engine Tools'}),\n",
      " Document(page_content='```python\\nfrom llama_index.agent import OpenAIAgent\\n```  \\n```python\\nagent = OpenAIAgent.from_tools(query_engine_tools, verbose=True)\\n```', metadata={'Header 1': 'OpenAI Agent with Query Engine Tools', 'Header 2': 'Setup OpenAI Agent'}),\n",
      " Document(page_content='```python\\nagent.chat_repl()\\n```  \\n===== Entering Chat REPL =====\\nType \"exit\" to exit.  \\n=== Calling Function ===\\nCalling function: lyft_10k with args: {\\n\"input\": \"What was Lyft\\'s revenue growth in 2021?\"\\n}\\nGot output:\\nLyft\\'s revenue growth in 2021 was 36%.\\n========================\\n=== Calling Function ===\\nCalling function: uber_10k with args: {\\n\"input\": \"What was Uber\\'s revenue growth in 2021?\"\\n}\\nGot output:\\nUber\\'s revenue growth in 2021 was 57%.\\n========================\\nAssistant: Lyft\\'s revenue growth in 2021 was 36%, while Uber\\'s revenue growth in 2021 was 57%.', metadata={'Header 1': 'OpenAI Agent with Query Engine Tools', 'Header 2': \"Let's Try It Out!\"}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/openai_assistant_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>  \\nThis shows you how to use our agent abstractions built on top of the [OpenAI Assistant API](https://platform.openai.com/docs/assistants/overview).  \\n```python\\n!pip install llama-index\\n```', metadata={'Header 1': 'OpenAI Assistant Agent'}),\n",
      " Document(page_content='Here we show a simple example with the built-in code interpreter.  \\nLet\\'s start by importing some simple building blocks.  \\nIf you\\'re opening this Notebook on colab, you will probably need to install LlamaIndex 🦙.  \\n```python\\nfrom llama_index.agent import OpenAIAssistantAgent\\n```  \\n```python\\nagent = OpenAIAssistantAgent.from_new(\\nname=\"Math Tutor\",\\ninstructions=\"You are a personal math tutor. Write and run code to answer math questions.\",\\nopenai_tools=[{\"type\": \"code_interpreter\"}],\\ninstructions_prefix=\"Please address the user as Jane Doe. The user has a premium account.\",\\n)\\n```  \\n```python\\nagent.thread_id\\n```  \\n\\'thread_ctzN0ZY3JUWETHhYxI3DiFSo\\'  \\n```python\\nresponse = agent.chat(\\n\"I need to solve the equation `3x + 11 = 14`. Can you help me?\"\\n)\\n```  \\n```python\\nprint(str(response))\\n```  \\nThe solution to the equation \\\\(3x + 11 = 14\\\\) is \\\\(x = 1\\\\).', metadata={'Header 1': 'OpenAI Assistant Agent', 'Header 2': 'Simple Agent (no external tools)'}),\n",
      " Document(page_content='Let\\'s test the assistant by having it use the built-in OpenAI Retrieval tool over a user-uploaded file.  \\nHere, we upload and pass in the file during assistant-creation time.  \\nThe other option is you can upload/pass the file-id in for a message in a given thread with `upload_files` and `add_message`.  \\n```python\\nfrom llama_index.agent import OpenAIAssistantAgent\\n```  \\n```python\\nagent = OpenAIAssistantAgent.from_new(\\nname=\"SEC Analyst\",\\ninstructions=\"You are a QA assistant designed to analyze sec filings.\",\\nopenai_tools=[{\"type\": \"retrieval\"}],\\ninstructions_prefix=\"Please address the user as Jerry.\",\\nfiles=[\"data/10k/lyft_2021.pdf\"],\\nverbose=True,\\n)\\n```  \\n```python\\nresponse = agent.chat(\"What was Lyft\\'s revenue growth in 2021?\")\\n```  \\n```python\\nprint(str(response))\\n```  \\nLyft\\'s revenue increased by $843.6 million or 36% in 2021 as compared to the previous year【7†source】.', metadata={'Header 1': 'OpenAI Assistant Agent', 'Header 2': 'Assistant with Built-In Retrieval'}),\n",
      " Document(page_content='Here we showcase the function calling capabilities of the OpenAIAssistantAgent by integrating it with our query engine tools over different documents.', metadata={'Header 1': 'OpenAI Assistant Agent', 'Header 2': 'Assistant with Query Engine Tools'}),\n",
      " Document(page_content='```python\\nfrom llama_index.agent import OpenAIAssistantAgent\\nfrom llama_index import (\\nSimpleDirectoryReader,\\nVectorStoreIndex,\\nStorageContext,\\nload_index_from_storage,\\n)\\n\\nfrom llama_index.tools import QueryEngineTool, ToolMetadata\\n```  \\n```python\\ntry:\\nstorage_context = StorageContext.from_defaults(\\npersist_dir=\"./storage/lyft\"\\n)\\nlyft_index = load_index_from_storage(storage_context)\\n\\nstorage_context = StorageContext.from_defaults(\\npersist_dir=\"./storage/uber\"\\n)\\nuber_index = load_index_from_storage(storage_context)\\n\\nindex_loaded = True\\nexcept:\\nindex_loaded = False\\n```  \\n```python\\n!mkdir -p \\'data/10k/\\'\\n!wget \\'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10k/uber_2021.pdf\\' -O \\'data/10k/uber_2021.pdf\\'\\n!wget \\'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10k/lyft_2021.pdf\\' -O \\'data/10k/lyft_2021.pdf\\'\\n```  \\n--2023-11-07 00:20:08--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10k/uber_2021.pdf\\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8000::154, 2606:50c0:8001::154, 2606:50c0:8002::154, ...\\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8000::154|:443... connected.\\nHTTP request sent, awaiting response... 200 OK\\nLength: 1880483 (1.8M) [application/octet-stream]\\nSaving to: ‘data/10k/uber_2021.pdf’  \\ndata/10k/uber_2021. 100%[===================>]   1.79M  --.-KB/s    in 0.07s  \\n2023-11-07 00:20:08 (24.3 MB/s) - ‘data/10k/uber_2021.pdf’ saved [1880483/1880483]  \\n--2023-11-07 00:20:08--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10k/lyft_2021.pdf\\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8000::154, 2606:50c0:8001::154, 2606:50c0:8002::154, ...\\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8000::154|:443... connected.\\nHTTP request sent, awaiting response... 200 OK\\nLength: 1440303 (1.4M) [application/octet-stream]\\nSaving to: ‘data/10k/lyft_2021.pdf’  \\ndata/10k/lyft_2021. 100%[===================>]   1.37M  --.-KB/s    in 0.06s  \\n2023-11-07 00:20:09 (22.2 MB/s) - ‘data/10k/lyft_2021.pdf’ saved [1440303/1440303]  \\n```python\\nif not index_loaded:\\n# load data\\nlyft_docs = SimpleDirectoryReader(\\ninput_files=[\"./data/10k/lyft_2021.pdf\"]\\n).load_data()\\nuber_docs = SimpleDirectoryReader(\\ninput_files=[\"./data/10k/uber_2021.pdf\"]\\n).load_data()\\n\\n# build index\\nlyft_index = VectorStoreIndex.from_documents(lyft_docs)\\nuber_index = VectorStoreIndex.from_documents(uber_docs)\\n\\n# persist index\\nlyft_index.storage_context.persist(persist_dir=\"./storage/lyft\")\\nuber_index.storage_context.persist(persist_dir=\"./storage/uber\")\\n```  \\n```python\\nlyft_engine = lyft_index.as_query_engine(similarity_top_k=3)\\nuber_engine = uber_index.as_query_engine(similarity_top_k=3)\\n```  \\n```python\\nquery_engine_tools = [\\nQueryEngineTool(\\nquery_engine=lyft_engine,\\nmetadata=ToolMetadata(\\nname=\"lyft_10k\",\\ndescription=(\\n\"Provides information about Lyft financials for year 2021. \"\\n\"Use a detailed plain text question as input to the tool.\"\\n),\\n),\\n),\\nQueryEngineTool(\\nquery_engine=uber_engine,\\nmetadata=ToolMetadata(\\nname=\"uber_10k\",\\ndescription=(\\n\"Provides information about Uber financials for year 2021. \"\\n\"Use a detailed plain text question as input to the tool.\"\\n),\\n),\\n),\\n]\\n```', metadata={'Header 1': 'OpenAI Assistant Agent', 'Header 2': 'Assistant with Query Engine Tools', 'Header 3': '1. Setup: Load Data'}),\n",
      " Document(page_content='```python\\nagent = OpenAIAssistantAgent.from_new(\\nname=\"SEC Analyst\",\\ninstructions=\"You are a QA assistant designed to analyze sec filings.\",\\ntools=query_engine_tools,\\ninstructions_prefix=\"Please address the user as Jerry.\",\\nverbose=True,\\nrun_retrieve_sleep_time=1.0,\\n)\\n```  \\n```python\\nresponse = agent.chat(\"What was Lyft\\'s revenue growth in 2021?\")\\n```  \\n=== Calling Function ===\\nCalling function: lyft_10k with args: {\"input\":\"What was Lyft\\'s revenue growth in 2021?\"}\\nGot output: Lyft\\'s revenue growth in 2021 was 36%.\\n========================', metadata={'Header 1': 'OpenAI Assistant Agent', 'Header 2': 'Assistant with Query Engine Tools', 'Header 3': \"2. Let's Try it Out\"}),\n",
      " Document(page_content='LlamaIndex has 35+ vector database integrations. Instead of using the in-house Retrieval API, you can use our assistant agent over any vector store.  \\nHere is our full [list of vector store integrations](https://docs.llamaindex.ai/en/stable/module_guides/storing/vector_stores.html). We picked one vector store (Supabase) using a random number generator.  \\n```python\\nfrom llama_index.agent import OpenAIAssistantAgent\\nfrom llama_index import (\\nSimpleDirectoryReader,\\nVectorStoreIndex,\\nStorageContext,\\n)\\nfrom llama_index.vector_stores import SupabaseVectorStore\\n\\nfrom llama_index.tools import QueryEngineTool, ToolMetadata\\n```  \\n```python\\n!mkdir -p \\'data/10k/\\'\\n!wget \\'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10k/uber_2021.pdf\\' -O \\'data/10k/uber_2021.pdf\\'\\n!wget \\'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10k/lyft_2021.pdf\\' -O \\'data/10k/lyft_2021.pdf\\'\\n```  \\n```python\\n# load data\\nreader = SimpleDirectoryReader(input_files=[\"./data/10k/lyft_2021.pdf\"])\\ndocs = reader.load_data()\\nfor doc in docs:\\ndoc.id_ = \"lyft_docs\"\\n```  \\n```python\\nvector_store = SupabaseVectorStore(\\npostgres_connection_string=(\\n\"postgresql://<user>:<password>@<host>:<port>/<db_name>\"\\n),\\ncollection_name=\"base_demo\",\\n)\\nstorage_context = StorageContext.from_defaults(vector_store=vector_store)\\nindex = VectorStoreIndex.from_documents(docs, storage_context=storage_context)\\n```  \\n```python\\n# sanity check that the docs are in the vector store\\nnum_docs = vector_store.get_by_id(\"lyft_docs\", limit=1000)\\nprint(len(num_docs))\\n```  \\n/Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages/vecs/collection.py:445: UserWarning: Query does not have a covering index for cosine_distance. See Collection.create_index\\nwarnings.warn(  \\n357  \\n```python\\nlyft_tool = QueryEngineTool(\\nquery_engine=index.as_query_engine(similarity_top_k=3),\\nmetadata=ToolMetadata(\\nname=\"lyft_10k\",\\ndescription=(\\n\"Provides information about Lyft financials for year 2021. \"\\n\"Use a detailed plain text question as input to the tool.\"\\n),\\n),\\n)\\n```  \\n```python\\nagent = OpenAIAssistantAgent.from_new(\\nname=\"SEC Analyst\",\\ninstructions=\"You are a QA assistant designed to analyze SEC filings.\",\\ntools=[lyft_tool],\\nverbose=True,\\nrun_retrieve_sleep_time=1.0,\\n)\\n```  \\n```python\\nresponse = agent.chat(\\n\"Tell me about Lyft\\'s risk factors, as well as response to COVID-19\"\\n)\\n```  \\n=== Calling Function ===\\nCalling function: lyft_10k with args: {\"input\": \"What are Lyft\\'s risk factors?\"}  \\n/Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages/vecs/collection.py:445: UserWarning: Query does not have a covering index for cosine_distance. See Collection.create_index\\nwarnings.warn(  \\nGot output: Lyft\\'s risk factors include general economic factors, such as the impact of the COVID-19 pandemic and responsive measures, natural disasters, economic downturns, public health crises, or political crises. Operational factors, such as their limited operating history, financial performance, competition, unpredictability of results, uncertainty regarding market growth, ability to attract and retain qualified drivers and riders, insurance coverage, autonomous vehicle technology, reputation and brand, illegal or improper activity on the platform, accuracy of background checks, changes to pricing practices, growth and development of their network, ability to manage growth, security or privacy breaches, reliance on third parties, and ability to operate various programs and services.\\n========================\\n=== Calling Function ===\\nCalling function: lyft_10k with args: {\"input\": \"How did Lyft respond to COVID-19?\"}  \\n/Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages/vecs/collection.py:445: UserWarning: Query does not have a covering index for cosine_distance. See Collection.create_index\\nwarnings.warn(  \\nGot output: Lyft responded to COVID-19 by adopting multiple measures, including establishing new health and safety requirements for ridesharing and updating workplace policies. They also made adjustments to their expenses and cash flow to correlate with declines in revenues, which included headcount reductions in 2020. Additionally, Lyft temporarily reduced pricing for Flexdrive rentals in cities most affected by COVID-19 and waived rental fees for drivers who tested positive for COVID-19 or were requested to quarantine by a medical professional. These measures were implemented to mitigate the negative effects of the pandemic on their business.\\n========================  \\n```python\\nprint(str(response))\\n```  \\nLyft\\'s 2021 10-K filing outlines a multifaceted risk landscape for the company, encapsulating both operational and environmental challenges that could impact its business model:  \\n- **Economic Factors**: Risks include the ramifications of the COVID-19 pandemic, susceptibility to natural disasters, the volatility of economic downturns, and geopolitical tensions.  \\n- **Operational Dynamics**: The company is cognizant of its limited operating history, the uncertainties surrounding its financial performance, the intense competition in the ridesharing sector, the unpredictability in financial results, and the ambiguity tied to the expansion potential of the rideshare market.  \\n- **Human Capital**: A critical concern is the ability of Lyft to attract and maintain a robust network of both drivers and riders, which is essential for the platform\\'s vitality.  \\n- **Insurance and Safety**: Ensuring adequate insurance coverage for stakeholders and addressing autonomous vehicle technology risks are pivotal.  \\n- **Reputation and Brand**: Lyft is attentive to the influence that illegal or unseemly activities on its platform can have on its public image.  \\n- **Pricing Structure**: Changing pricing models pose a risk to Lyft\\'s revenue streams, considering how essential pricing dynamics are to maintaining competitive service offerings.  \\n- **Systemic Integrity**: Lyft also acknowledges risks emanating from potential system failures which could disrupt service continuity.  \\nFurthermore, Lyft is vigilant about regulatory and legal risks that could lead to litigation and is conscious of the broader implications of climate change on its operations.  \\nIn terms of its response to COVID-19, Lyft has adopted strategic measures to secure the welfare of both its workforce and customer base:  \\n1. **Health and Safety Protocols**: Lyft has instituted health and safety mandates tailored specifically to the ridesharing experience in view of the pandemic.  \\n2. **Workplace Adjustments**: The company revised its workplace policies to accommodate the shifts in the work environment precipitated by the pandemic.  \\n3. **Financial Adaptations**: To synchronize with the revenue contraction experienced during the pandemic, Lyft executed monetary realignments, which necessitated workforce reductions in 2020.  \\nThese initiatives reflect Lyft\\'s calculated approach to navigating the operational and financial hurdles enacted by the COVID-19 pandemic. By prioritizing health and safety, nimbly altering corporate practices, and recalibrating fiscal management, Lyft aimed to buttress its business against the storm of the pandemic while setting a foundation for post-pandemic recovery.', metadata={'Header 1': 'OpenAI Assistant Agent', 'Header 2': 'Assistant Agent with your own Vector Store / Retrieval API'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/openai_assistant_query_cookbook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>'),\n",
      " Document(page_content='In this notebook, we try out OpenAI Assistant API for advanced retrieval tasks, by plugging in a variety of query engine tools and datasets. The wrapper abstraction we use is our `OpenAIAssistantAgent` class, which allows us to plug in custom tools. We explore how `OpenAIAssistant` can complement/replace existing workflows solved by our retrievers/query engines through its agent execution + function calling loop.  \\n- Joint QA + Summarization\\n- Auto retrieval\\n- Joint SQL and vector search  \\n```python\\n!pip install llama-index\\n```  \\n```python\\nimport nest_asyncio\\n\\nnest_asyncio.apply()\\n```', metadata={'Header 1': 'OpenAI Assistant Advanced Retrieval Cookbook'}),\n",
      " Document(page_content='In this section we show how we can get the Assistant agent to both answer fact-based questions and summarization questions. This is something that the in-house retrieval tool struggles to accomplish.', metadata={'Header 1': 'OpenAI Assistant Advanced Retrieval Cookbook', 'Header 2': 'Joint QA and Summarization'}),\n",
      " Document(page_content='```python\\n!mkdir -p \\'data/paul_graham/\\'\\n!wget \\'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt\\' -O \\'data/paul_graham/paul_graham_essay.txt\\'\\n```  \\n--2023-11-11 09:40:13--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt\\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8002::154, 2606:50c0:8003::154, 2606:50c0:8000::154, ...\\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8002::154|:443... connected.\\nHTTP request sent, awaiting response... 200 OK\\nLength: 75042 (73K) [text/plain]\\nSaving to: ‘data/paul_graham/paul_graham_essay.txt’  \\ndata/paul_graham/pa 100%[===================>]  73.28K  --.-KB/s    in 0.009s  \\n2023-11-11 09:40:14 (8.24 MB/s) - ‘data/paul_graham/paul_graham_essay.txt’ saved [75042/75042]  \\n```python\\nfrom llama_index import SimpleDirectoryReader\\n\\n# load documents\\ndocuments = SimpleDirectoryReader(\"./data/paul_graham/\").load_data()\\n```', metadata={'Header 1': 'OpenAI Assistant Advanced Retrieval Cookbook', 'Header 2': 'Joint QA and Summarization', 'Header 3': 'Load Data'}),\n",
      " Document(page_content='```python\\nfrom llama_index.llms import OpenAI\\nfrom llama_index import (\\nServiceContext,\\nStorageContext,\\nSummaryIndex,\\nVectorStoreIndex,\\n)\\n\\n# initialize service context (set chunk size)\\nllm = OpenAI()\\nservice_context = ServiceContext.from_defaults(chunk_size=1024, llm=llm)\\nnodes = service_context.node_parser.get_nodes_from_documents(documents)\\n\\n# initialize storage context (by default it\\'s in-memory)\\nstorage_context = StorageContext.from_defaults()\\nstorage_context.docstore.add_documents(nodes)\\n\\n# Define Summary Index and Vector Index over Same Data\\nsummary_index = SummaryIndex(nodes, storage_context=storage_context)\\nvector_index = VectorStoreIndex(nodes, storage_context=storage_context)\\n\\n# define query engines\\nsummary_query_engine = summary_index.as_query_engine(\\nresponse_mode=\"tree_summarize\",\\nuse_async=True,\\n)\\nvector_query_engine = vector_index.as_query_engine()\\n```  \\n```python\\nfrom llama_index.tools.query_engine import QueryEngineTool\\n\\nsummary_tool = QueryEngineTool.from_defaults(\\nquery_engine=summary_query_engine,\\nname=\"summary_tool\",\\ndescription=(\\n\"Useful for summarization questions related to the author\\'s life\"\\n),\\n)\\n\\nvector_tool = QueryEngineTool.from_defaults(\\nquery_engine=vector_query_engine,\\nname=\"vector_tool\",\\ndescription=(\\n\"Useful for retrieving specific context to answer specific questions about the author\\'s life\"\\n),\\n)\\n```', metadata={'Header 1': 'OpenAI Assistant Advanced Retrieval Cookbook', 'Header 2': 'Joint QA and Summarization', 'Header 3': 'Setup Vector + Summary Indexes/Query Engines/Tools'}),\n",
      " Document(page_content='```python\\nfrom llama_index.agent import OpenAIAssistantAgent\\n\\nagent = OpenAIAssistantAgent.from_new(\\nname=\"QA bot\",\\ninstructions=\"You are a bot designed to answer questions about the author\",\\nopenai_tools=[],\\ntools=[summary_tool, vector_tool],\\nverbose=True,\\nrun_retrieve_sleep_time=1.0,\\n)\\n```  \\n#### Results: A bit flaky  \\n```python\\nresponse = agent.chat(\"Can you give me a summary about the author\\'s life?\")\\nprint(str(response))\\n```  \\n=== Calling Function ===\\nCalling function: summary_tool with args: {\"input\":\"Can you give me a summary about the author\\'s life?\"}\\nGot output: The author, Paul Graham, had a strong interest in writing and programming from a young age. They started writing short stories and experimenting with programming in high school. In college, they initially studied philosophy but switched to studying artificial intelligence. However, they realized that the AI being practiced at the time was not going to lead to true understanding of natural language. This led them to focus on Lisp programming and eventually write a book about Lisp hacking. Despite being in a PhD program in computer science, the author also developed a passion for art and decided to pursue it further. They attended the Accademia di Belli Arti in Florence but found that it did not teach them much. They then returned to the US and got a job at a software company. Afterward, they attended the Rhode Island School of Design but dropped out due to the focus on developing a signature style rather than teaching the fundamentals of art. They then moved to New York City and became interested in the World Wide Web, eventually starting a company called Viaweb. They later founded Y Combinator, an investment firm, and created Hacker News.\\n========================\\nPaul Graham is an author with eclectic interests and a varied career path. He began with interests in writing and programming, engaged in philosophy and artificial intelligence during college, and authored a book on Lisp programming. With an equally strong passion for art, he studied at the Accademia di Belli Arti in Florence and briefly at the Rhode Island School of Design before immersing himself in the tech industry by starting Viaweb and later founding the influential startup accelerator Y Combinator. He also created Hacker News, a social news website focused on computer science and entrepreneurship. Graham\\'s life reflects a blend of technology, entrepreneurship, and the arts.  \\n```python\\nresponse = agent.query(\"What did the author do after RICS?\")\\nprint(str(response))\\n```  \\n=== Calling Function ===\\nCalling function: vector_tool with args: {\"input\":\"After RICS\"}\\nGot output: After RICS, the author moved back to Providence to continue at RISD. However, it became clear that art school, specifically the painting department, did not have the same relationship to art as medical school had to medicine. Painting students were expected to express themselves and develop a distinctive signature style.\\n========================\\nAfter the author\\'s time at the Royal Institution of Chartered Surveyors (RICS), they moved back to Providence to continue their studies at the Rhode Island School of Design (RISD). There, the author noted a significant difference in the educational approaches between RISD and medical school, specifically in the painting department. At RISD, students were encouraged to express themselves and to develop a unique and distinctive signature style in their artwork.', metadata={'Header 1': 'OpenAI Assistant Advanced Retrieval Cookbook', 'Header 2': 'Joint QA and Summarization', 'Header 3': 'Define Assistant Agent'}),\n",
      " Document(page_content='Our existing \"auto-retrieval\" capabilities (in `VectorIndexAutoRetriever`) allow an LLM to infer the right query parameters for a vector database - including both the query string and metadata filter.  \\nSince the Assistant API can call functions + infer function parameters, we explore its capabilities in performing auto-retrieval here.  \\nIf you\\'re opening this Notebook on colab, you will probably need to install LlamaIndex 🦙.  \\n```python\\nimport pinecone\\nimport os\\n\\napi_key = os.environ[\"PINECONE_API_KEY\"]\\npinecone.init(api_key=api_key, environment=\"us-west1-gcp\")\\n```  \\n/Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\\nfrom tqdm.autonotebook import tqdm  \\n```python\\n# dimensions are for text-embedding-ada-002\\ntry:\\npinecone.create_index(\\n\"quickstart\", dimension=1536, metric=\"euclidean\", pod_type=\"p1\"\\n)\\nexcept Exception:\\n# most likely index already exists\\npass\\n```  \\n```python\\npinecone_index = pinecone.Index(\"quickstart\")\\n```  \\n```python\\n# Optional: delete data in your pinecone index\\npinecone_index.delete(deleteAll=True, namespace=\"test\")\\n```  \\n{}  \\n```python\\nfrom llama_index import VectorStoreIndex, StorageContext\\nfrom llama_index.vector_stores import PineconeVectorStore\\n```  \\n```python\\nfrom llama_index.schema import TextNode\\n\\nnodes = [\\nTextNode(\\ntext=(\\n\"Michael Jordan is a retired professional basketball player,\"\\n\" widely regarded as one of the greatest basketball players of all\"\\n\" time.\"\\n),\\nmetadata={\\n\"category\": \"Sports\",\\n\"country\": \"United States\",\\n},\\n),\\nTextNode(\\ntext=(\\n\"Angelina Jolie is an American actress, filmmaker, and\"\\n\" humanitarian. She has received numerous awards for her acting\"\\n\" and is known for her philanthropic work.\"\\n),\\nmetadata={\\n\"category\": \"Entertainment\",\\n\"country\": \"United States\",\\n},\\n),\\nTextNode(\\ntext=(\\n\"Elon Musk is a business magnate, industrial designer, and\"\\n\" engineer. He is the founder, CEO, and lead designer of SpaceX,\"\\n\" Tesla, Inc., Neuralink, and The Boring Company.\"\\n),\\nmetadata={\\n\"category\": \"Business\",\\n\"country\": \"United States\",\\n},\\n),\\nTextNode(\\ntext=(\\n\"Rihanna is a Barbadian singer, actress, and businesswoman. She\"\\n\" has achieved significant success in the music industry and is\"\\n\" known for her versatile musical style.\"\\n),\\nmetadata={\\n\"category\": \"Music\",\\n\"country\": \"Barbados\",\\n},\\n),\\nTextNode(\\ntext=(\\n\"Cristiano Ronaldo is a Portuguese professional footballer who is\"\\n\" considered one of the greatest football players of all time. He\"\\n\" has won numerous awards and set multiple records during his\"\\n\" career.\"\\n),\\nmetadata={\\n\"category\": \"Sports\",\\n\"country\": \"Portugal\",\\n},\\n),\\n]\\n```  \\n```python\\nvector_store = PineconeVectorStore(\\npinecone_index=pinecone_index, namespace=\"test\"\\n)\\nstorage_context = StorageContext.from_defaults(vector_store=vector_store)\\n```  \\n```python\\nindex = VectorStoreIndex(nodes, storage_context=storage_context)\\n```  \\nUpserted vectors:   0%|          | 0/5 [00:00<?, ?it/s]  \\n#### Define Function Tool  \\nHere we define the function interface, which is passed to OpenAI to perform auto-retrieval.  \\nWe were not able to get OpenAI to work with nested pydantic objects or tuples as arguments,\\nso we converted the metadata filter keys and values into lists for the function API to work with.  \\n```python\\n# define function tool\\nfrom llama_index.tools import FunctionTool\\nfrom llama_index.vector_stores.types import (\\nVectorStoreInfo,\\nMetadataInfo,\\nExactMatchFilter,\\nMetadataFilters,\\n)\\nfrom llama_index.retrievers import VectorIndexRetriever\\nfrom llama_index.query_engine import RetrieverQueryEngine\\n\\nfrom typing import List, Tuple, Any\\nfrom pydantic import BaseModel, Field\\n\\n# hardcode top k for now\\ntop_k = 3\\n\\n# define vector store info describing schema of vector store\\nvector_store_info = VectorStoreInfo(\\ncontent_info=\"brief biography of celebrities\",\\nmetadata_info=[\\nMetadataInfo(\\nname=\"category\",\\ntype=\"str\",\\ndescription=(\\n\"Category of the celebrity, one of [Sports, Entertainment,\"\\n\" Business, Music]\"\\n),\\n),\\nMetadataInfo(\\nname=\"country\",\\ntype=\"str\",\\ndescription=(\\n\"Country of the celebrity, one of [United States, Barbados,\"\\n\" Portugal]\"\\n),\\n),\\n],\\n)\\n\\n\\n# define pydantic model for auto-retrieval function\\nclass AutoRetrieveModel(BaseModel):\\nquery: str = Field(..., description=\"natural language query string\")\\nfilter_key_list: List[str] = Field(\\n..., description=\"List of metadata filter field names\"\\n)\\nfilter_value_list: List[str] = Field(\\n...,\\ndescription=(\\n\"List of metadata filter field values (corresponding to names\"\\n\" specified in filter_key_list)\"\\n),\\n)\\n\\n\\ndef auto_retrieve_fn(\\nquery: str, filter_key_list: List[str], filter_value_list: List[str]\\n):\\n\"\"\"Auto retrieval function.\\n\\nPerforms auto-retrieval from a vector database, and then applies a set of filters.\\n\\n\"\"\"\\nquery = query or \"Query\"\\n\\nexact_match_filters = [\\nExactMatchFilter(key=k, value=v)\\nfor k, v in zip(filter_key_list, filter_value_list)\\n]\\nretriever = VectorIndexRetriever(\\nindex,\\nfilters=MetadataFilters(filters=exact_match_filters),\\ntop_k=top_k,\\n)\\nresults = retriever.retrieve(query)\\nreturn [r.get_content() for r in results]\\n\\n\\ndescription = f\"\"\"\\\\\\nUse this tool to look up biographical information about celebrities.\\nThe vector database schema is given below:\\n{vector_store_info.json()}\\n\"\"\"\\n\\nauto_retrieve_tool = FunctionTool.from_defaults(\\nfn=auto_retrieve_fn,\\nname=\"celebrity_bios\",\\ndescription=description,\\nfn_schema=AutoRetrieveModel,\\n)\\n```  \\n```python\\nauto_retrieve_fn(\\n\"celebrity from the United States\",\\nfilter_key_list=[\"country\"],\\nfilter_value_list=[\"United States\"],\\n)\\n```  \\n[\\'Angelina Jolie is an American actress, filmmaker, and humanitarian. She has received numerous awards for her acting and is known for her philanthropic work.\\',\\n\\'Michael Jordan is a retired professional basketball player, widely regarded as one of the greatest basketball players of all time.\\']  \\n#### Initialize Agent  \\n```python\\nfrom llama_index.agent import OpenAIAssistantAgent\\n\\nagent = OpenAIAssistantAgent.from_new(\\nname=\"Celebrity bot\",\\ninstructions=\"You are a bot designed to answer questions about celebrities.\",\\ntools=[auto_retrieve_tool],\\nverbose=True,\\n)\\n```  \\n```python\\nresponse = agent.chat(\"Tell me about two celebrities from the United States. \")\\nprint(str(response))\\n```  \\n=== Calling Function ===\\nCalling function: celebrity_bios with args: {\"query\": \"celebrity from United States\", \"filter_key_list\": [\"country\"], \"filter_value_list\": [\"United States\"]}\\nGot output: [\\'Angelina Jolie is an American actress, filmmaker, and humanitarian. She has received numerous awards for her acting and is known for her philanthropic work.\\', \\'Michael Jordan is a retired professional basketball player, widely regarded as one of the greatest basketball players of all time.\\']\\n========================\\n=== Calling Function ===\\nCalling function: celebrity_bios with args: {\"query\": \"celebrity from United States\", \"filter_key_list\": [\"country\"], \"filter_value_list\": [\"United States\"]}\\nGot output: [\\'Angelina Jolie is an American actress, filmmaker, and humanitarian. She has received numerous awards for her acting and is known for her philanthropic work.\\', \\'Michael Jordan is a retired professional basketball player, widely regarded as one of the greatest basketball players of all time.\\']\\n========================\\nHere is some information about two celebrities from the United States:  \\n1. Angelina Jolie - Angelina Jolie is an American actress, filmmaker, and humanitarian. She has received numerous awards for her acting and is known for her philanthropic work. Over the years, Jolie has starred in several critically acclaimed and commercially successful films, and she has also been involved in various humanitarian causes, advocating for refugees and children\\'s education, among other things.  \\n2. Michael Jordan - Michael Jordan is a retired professional basketball player, widely regarded as one of the greatest basketball players of all time. During his career, Jordan dominated the NBA with his scoring ability, athleticism, and competitiveness. He won six NBA championships with the Chicago Bulls and earned the NBA Most Valuable Player Award five times. Jordan has also been a successful businessman and the principal owner of the Charlotte Hornets basketball team.  \\nBoth figures have made significant impacts in their respective fields and continue to be influential even after reaching the peaks of their careers.', metadata={'Header 1': 'OpenAI Assistant Advanced Retrieval Cookbook', 'Header 2': 'AutoRetrieval from a Vector Database'}),\n",
      " Document(page_content='This is currenty handled by our `SQLAutoVectorQueryEngine`.  \\nLet\\'s try implementing this by giving our `OpenAIAssistantAgent` access to two query tools: SQL and Vector search.  \\n#### Load and Index Structured Data  \\nWe load sample structured datapoints into a SQL db and index it.  \\n```python\\nfrom sqlalchemy import (\\ncreate_engine,\\nMetaData,\\nTable,\\nColumn,\\nString,\\nInteger,\\nselect,\\ncolumn,\\n)\\nfrom llama_index import SQLDatabase, SQLStructStoreIndex\\n\\nengine = create_engine(\"sqlite:///:memory:\", future=True)\\nmetadata_obj = MetaData()\\n```  \\n```python\\n# create city SQL table\\ntable_name = \"city_stats\"\\ncity_stats_table = Table(\\ntable_name,\\nmetadata_obj,\\nColumn(\"city_name\", String(16), primary_key=True),\\nColumn(\"population\", Integer),\\nColumn(\"country\", String(16), nullable=False),\\n)\\n\\nmetadata_obj.create_all(engine)\\n```  \\n```python\\n# print tables\\nmetadata_obj.tables.keys()\\n```  \\ndict_keys([\\'city_stats\\'])  \\n```python\\nfrom sqlalchemy import insert\\n\\nrows = [\\n{\"city_name\": \"Toronto\", \"population\": 2930000, \"country\": \"Canada\"},\\n{\"city_name\": \"Tokyo\", \"population\": 13960000, \"country\": \"Japan\"},\\n{\"city_name\": \"Berlin\", \"population\": 3645000, \"country\": \"Germany\"},\\n]\\nfor row in rows:\\nstmt = insert(city_stats_table).values(**row)\\nwith engine.begin() as connection:\\ncursor = connection.execute(stmt)\\n```  \\n```python\\nwith engine.connect() as connection:\\ncursor = connection.exec_driver_sql(\"SELECT * FROM city_stats\")\\nprint(cursor.fetchall())\\n```  \\n[(\\'Toronto\\', 2930000, \\'Canada\\'), (\\'Tokyo\\', 13960000, \\'Japan\\'), (\\'Berlin\\', 3645000, \\'Germany\\')]  \\n```python\\nsql_database = SQLDatabase(engine, include_tables=[\"city_stats\"])\\n```  \\n```python\\nfrom llama_index.indices.struct_store.sql_query import NLSQLTableQueryEngine\\n```  \\n```python\\nquery_engine = NLSQLTableQueryEngine(\\nsql_database=sql_database,\\ntables=[\"city_stats\"],\\n)\\n```  \\n#### Load and Index Unstructured Data  \\nWe load unstructured data into a vector index backed by Pinecone  \\n```python\\n# install wikipedia python package\\n!pip install wikipedia\\n```  \\nRequirement already satisfied: wikipedia in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (1.4.0)\\nRequirement already satisfied: requests<3.0.0,>=2.0.0 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from wikipedia) (2.28.2)\\nRequirement already satisfied: beautifulsoup4 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from wikipedia) (4.12.2)\\nRequirement already satisfied: charset-normalizer<4,>=2 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.1.0)\\nRequirement already satisfied: idna<4,>=2.5 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4)\\nRequirement already satisfied: certifi>=2017.4.17 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2022.12.7)\\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.26.15)\\nRequirement already satisfied: soupsieve>1.2 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from beautifulsoup4->wikipedia) (2.4.1)  \\n\\x1b[1m[\\x1b[0m\\x1b[34;49mnotice\\x1b[0m\\x1b[1;39;49m]\\x1b[0m\\x1b[39;49m A new release of pip available: \\x1b[0m\\x1b[31;49m22.3.1\\x1b[0m\\x1b[39;49m -> \\x1b[0m\\x1b[32;49m23.1.2\\x1b[0m\\n\\x1b[1m[\\x1b[0m\\x1b[34;49mnotice\\x1b[0m\\x1b[1;39;49m]\\x1b[0m\\x1b[39;49m To update, run: \\x1b[0m\\x1b[32;49mpip install --upgrade pip\\x1b[0m  \\n```python\\nfrom llama_index import (\\nWikipediaReader,\\nSimpleDirectoryReader,\\nVectorStoreIndex,\\n)\\n```  \\n```python\\ncities = [\"Toronto\", \"Berlin\", \"Tokyo\"]\\nwiki_docs = WikipediaReader().load_data(pages=cities)\\n```  \\n```python\\nfrom llama_index.node_parser import SimpleNodeParser\\nfrom llama_index import ServiceContext\\nfrom llama_index.storage import StorageContext\\nfrom llama_index.text_splitter import TokenTextSplitter\\nfrom llama_index.llms import OpenAI\\n\\n# define node parser and LLM\\nchunk_size = 1024\\nllm = OpenAI(temperature=0, model=\"gpt-4\")\\nservice_context = ServiceContext.from_defaults(chunk_size=chunk_size, llm=llm)\\ntext_splitter = TokenTextSplitter(chunk_size=chunk_size)\\nnode_parser = SimpleNodeParser.from_defaults(text_splitter=text_splitter)\\n\\n# use default in-memory store\\nstorage_context = StorageContext.from_defaults()\\nvector_index = VectorStoreIndex([], storage_context=storage_context)\\n```  \\n```python\\n# Insert documents into vector index\\n# Each document has metadata of the city attached\\nfor city, wiki_doc in zip(cities, wiki_docs):\\nnodes = node_parser.get_nodes_from_documents([wiki_doc])\\n# add metadata to each node\\nfor node in nodes:\\nnode.metadata = {\"title\": city}\\nvector_index.insert_nodes(nodes)\\n```  \\n#### Define Query Engines / Tools  \\n```python\\nfrom llama_index.tools.query_engine import QueryEngineTool\\n```  \\n```python\\nsql_tool = QueryEngineTool.from_defaults(\\nquery_engine=query_engine,\\nname=\"sql_tool\",\\ndescription=(\\n\"Useful for translating a natural language query into a SQL query over\"\\n\" a table containing: city_stats, containing the population/country of\"\\n\" each city\"\\n),\\n)\\nvector_tool = QueryEngineTool.from_defaults(\\nquery_engine=vector_index.as_query_engine(similarity_top_k=2),\\nname=\"vector_tool\",\\ndescription=(\\nf\"Useful for answering semantic questions about different cities\"\\n),\\n)\\n```  \\n#### Initialize Agent  \\n```python\\nfrom llama_index.agent import OpenAIAssistantAgent\\n\\nagent = OpenAIAssistantAgent.from_new(\\nname=\"City bot\",\\ninstructions=\"You are a bot designed to answer questions about cities (both unstructured and structured data)\",\\ntools=[sql_tool, vector_tool],\\nverbose=True,\\n)\\n```  \\n```python\\nresponse = agent.chat(\\n\"Tell me about the arts and culture of the city with the highest\"\\n\" population\"\\n)\\nprint(str(response))\\n```  \\n=== Calling Function ===\\nCalling function: sql_tool with args: {\"input\":\"SELECT name, country FROM city_stats ORDER BY population DESC LIMIT 1\"}\\nGot output: The city with the highest population is Tokyo, Japan.\\n========================\\n=== Calling Function ===\\nCalling function: vector_tool with args: {\"input\":\"What are the arts and culture like in Tokyo, Japan?\"}\\nGot output: Tokyo has a vibrant arts and culture scene. The city is home to many museums, including the Tokyo National Museum, which specializes in traditional Japanese art, the National Museum of Western Art, and the Edo-Tokyo Museum. There are also theaters for traditional forms of Japanese drama, such as the National Noh Theatre and the Kabuki-za. Tokyo hosts modern Japanese and international pop and rock music concerts, and the New National Theater Tokyo is a hub for opera, ballet, contemporary dance, and drama. The city also celebrates various festivals throughout the year, including the Sannō, Sanja, and Kanda Festivals. Additionally, Tokyo is known for its youth style, fashion, and cosplay in the Harajuku neighborhood.\\n========================\\nTokyo, Japan, which has the highest population of any city, boasts a rich and diverse arts and culture landscape. The city is a hub for traditional Japanese art as showcased in prominent institutions like the Tokyo National Museum, and it also features artwork from different parts of the world at the National Museum of Western Art. Tokyo has a deep appreciation for its historical roots, with the Edo-Tokyo Museum presenting the past in a detailed and engaging manner.  \\nThe traditional performing arts have a significant presence in Tokyo, with theaters such as the National Noh Theatre presenting classical Noh dramas and the iconic Kabuki-za offering enchanting Kabuki performances. For enthusiasts of modern entertainment, Tokyo is a prime spot for contemporary music, including both Japanese pop and rock as well as international acts.  \\nOpera, ballet, contemporary dance, and drama find a prestigious platform at the New National Theater Tokyo. Tokyo\\'s calendar is filled with a variety of festivals that reflect the city\\'s vibrant cultural heritage, including the Sannō, Sanja, and Kanda Festivals. Additionally, Tokyo is at the forefront of fashion and youth culture, particularly in the Harajuku district, which is famous for its unique fashion, style, and cosplay.  \\nThis mix of traditional and modern, local and international arts and culture makes Tokyo a dynamic and culturally rich city.  \\n```python\\nresponse = agent.chat(\"Tell me about the history of Berlin\")\\nprint(str(response))\\n```  \\n=== Calling Function ===\\nCalling function: vector_tool with args: {\"input\":\"What is the history of Berlin, Germany?\"}\\nGot output: Berlin has a rich and diverse history. It was first documented in the 13th century and has served as the capital of various entities throughout history, including the Margraviate of Brandenburg, the Kingdom of Prussia, the German Empire, the Weimar Republic, and Nazi Germany. After World War II, the city was divided, with West Berlin becoming a part of West Germany and East Berlin becoming the capital of East Germany. Following German reunification in 1990, Berlin once again became the capital of all of Germany. Throughout its history, Berlin has been a center of scientific, artistic, and philosophical activity, and has experienced periods of economic growth and cultural flourishing. Today, it is a world city of culture, politics, media, and science, known for its vibrant arts scene, diverse architecture, and high quality of life.\\n========================\\nBerlin, the capital city of Germany, has a rich and complex history that stretches back to its first documentation in the 13th century. Throughout the centuries, Berlin has been at the heart of numerous important historical movements and events.  \\nInitially a small town, Berlin grew in significance as the capital of the Margraviate of Brandenburg. Later on, it ascended in prominence as the capital of the Kingdom of Prussia. With the unification of Germany, Berlin became the imperial capital of the German Empire, a position it retained until the end of World War I.  \\nThe interwar period saw Berlin as the capital of the Weimar Republic, and it was during this time that the city became known for its vibrant cultural scene. However, the rise of the Nazi regime in the 1930s led to a dark period in Berlin\\'s history, and the city was heavily damaged during World War II.  \\nFollowing the war\\'s end, Berlin became a divided city. The division was physical, represented by the Berlin Wall, and ideological, with West Berlin aligning with democratic West Germany while East Berlin became the capital of the socialist East Germany.  \\nThe fall of the Berlin Wall in November 1989 was a historic moment, leading to German reunification in 1990. Berlin was once again chosen as the capital of a united Germany. Since reunification, Berlin has undergone massive reconstruction and has become a hub of contemporary culture, politics, media, and science.  \\nToday, Berlin celebrates its diverse heritage, from its grand historical landmarks like the Brandenburg Gate and the Reichstag, to its remembrance of the past with monuments such as the Berlin Wall Memorial and the Holocaust Memorial. It is a city known for its cultural dynamism, thriving arts and music scenes, and a high quality of life. Berlin\\'s history has shaped it into a unique world city that continues to play a significant role on the global stage.  \\n```python\\nresponse = agent.chat(\\n\"Can you give me the country corresponding to each city?\"\\n)\\nprint(str(response))\\n```  \\n=== Calling Function ===\\nCalling function: sql_tool with args: {\"input\":\"SELECT name, country FROM city_stats\"}\\nGot output: The cities in the city_stats table are Toronto from Canada, Tokyo from Japan, and Berlin from Germany.\\n========================\\nHere are the countries corresponding to each city:  \\n- Toronto: Canada\\n- Tokyo: Japan\\n- Berlin: Germany', metadata={'Header 1': 'OpenAI Assistant Advanced Retrieval Cookbook', 'Header 2': 'Joint Text-to-SQL and Semantic Search'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/openai_forced_function_call.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>'),\n",
      " Document(page_content='If you\\'re opening this Notebook on colab, you will probably need to install LlamaIndex 🦙.  \\n```python\\n!pip install llama-index\\n```  \\n```python\\nimport json\\nfrom typing import Sequence, List\\n\\nfrom llama_index.llms import OpenAI, ChatMessage\\nfrom llama_index.tools import BaseTool, FunctionTool\\nfrom llama_index.agent import OpenAIAgent\\n```  \\n```python\\ndef add(a: int, b: int) -> int:\\n\"\"\"Add two integers and returns the result integer\"\"\"\\nreturn a + b\\n\\n\\nadd_tool = FunctionTool.from_defaults(fn=add)\\n\\n\\ndef useless_tool() -> int:\\n\"\"\"This is a uselss tool.\"\"\"\\nreturn \"This is a uselss output.\"\\n\\n\\nuseless_tool = FunctionTool.from_defaults(fn=useless_tool)\\n```  \\n```python\\nllm = OpenAI(model=\"gpt-3.5-turbo-0613\")\\nagent = OpenAIAgent.from_tools([useless_tool, add_tool], llm=llm, verbose=True)\\n```', metadata={'Header 1': 'OpenAI agent: specifying a forced function call'}),\n",
      " Document(page_content='The agent automatically selects the useful \"add\" tool  \\n```python\\nresponse = agent.chat(\\n\"What is 5 + 2?\", tool_choice=\"auto\"\\n)  # note function_call param is deprecated\\n# use tool_choice instead\\n```  \\nSTARTING TURN 1\\n---------------  \\n=== Calling Function ===\\nCalling function: add with args: {\\n\"a\": 5,\\n\"b\": 2\\n}\\nGot output: 7\\n========================  \\nSTARTING TURN 2\\n---------------  \\n```python\\nprint(response)\\n```  \\nThe sum of 5 and 2 is 7.', metadata={'Header 1': 'OpenAI agent: specifying a forced function call', 'Header 3': '\"Auto\" function call'}),\n",
      " Document(page_content='The agent is forced to call the \"useless_tool\" before selecting the \"add\" tool  \\n```python\\nresponse = agent.chat(\"What is 5 * 2?\", tool_choice=\"useless_tool\")\\n```  \\nSTARTING TURN 1\\n---------------  \\n=== Calling Function ===\\nCalling function: useless_tool with args: {}\\nGot output: This is a uselss output.\\n========================  \\nSTARTING TURN 2\\n---------------  \\n=== Calling Function ===\\nCalling function: add with args: {\\n\"a\": 5,\\n\"b\": 2\\n}\\nGot output: 7\\n========================  \\nSTARTING TURN 3\\n---------------  \\n```python\\nprint(response)\\n```  \\nThe product of 5 and 2 is 10.', metadata={'Header 1': 'OpenAI agent: specifying a forced function call', 'Header 3': 'Forced function call'}),\n",
      " Document(page_content='The agent is forced to not use a tool  \\n```python\\nresponse = agent.chat(\"What is 5 * 2?\", tool_choice=\"none\")\\n```  \\nSTARTING TURN 1\\n---------------  \\n```python\\nprint(response)\\n```  \\nThe product of 5 and 2 is 10.', metadata={'Header 1': 'OpenAI agent: specifying a forced function call', 'Header 3': '\"None\" function call'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/openai_retrieval_benchmark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>  \\nThis guide benchmarks the Retrieval Tool from the [OpenAI Assistant API](https://platform.openai.com/docs/assistants/overview), by using our `OpenAIAssistantAgent`. We run over the Llama 2 paper, and compare generation quality against a naive RAG pipeline.  \\n```python\\n!pip install llama-index\\n```  \\n```python\\nimport nest_asyncio\\n\\nnest_asyncio.apply()\\n```', metadata={'Header 1': 'Benchmarking OpenAI Retrieval API (through Assistant Agent)'}),\n",
      " Document(page_content='Here we load the Llama 2 paper and chunk it.  \\n```python\\n!mkdir -p \\'data/\\'\\n!wget --user-agent \"Mozilla\" \"https://arxiv.org/pdf/2307.09288.pdf\" -O \"data/llama2.pdf\"\\n```  \\n--2023-11-08 21:53:52--  https://arxiv.org/pdf/2307.09288.pdf\\nResolving arxiv.org (arxiv.org)... 128.84.21.199\\nConnecting to arxiv.org (arxiv.org)|128.84.21.199|:443... connected.\\nHTTP request sent, awaiting response... 200 OK\\nLength: 13661300 (13M) [application/pdf]\\nSaving to: ‘data/llama2.pdf’  \\ndata/llama2.pdf     100%[===================>]  13.03M   141KB/s    in 1m 48s  \\n2023-11-08 21:55:42 (123 KB/s) - ‘data/llama2.pdf’ saved [13661300/13661300]  \\n```python\\nfrom pathlib import Path\\nfrom llama_index import Document, ServiceContext, VectorStoreIndex\\nfrom llama_hub.file.pymu_pdf.base import PyMuPDFReader\\nfrom llama_index.node_parser import SimpleNodeParser\\nfrom llama_index.llms import OpenAI\\n```  \\n```python\\nloader = PyMuPDFReader()\\ndocs0 = loader.load(file_path=Path(\"./data/llama2.pdf\"))\\n\\ndoc_text = \"\\\\n\\\\n\".join([d.get_content() for d in docs0])\\ndocs = [Document(text=doc_text)]\\n```  \\n```python\\nnode_parser = SimpleNodeParser.from_defaults()\\nnodes = node_parser.get_nodes_from_documents(docs)\\n```  \\n```python\\nlen(nodes)\\n```  \\n89', metadata={'Header 1': 'Benchmarking OpenAI Retrieval API (through Assistant Agent)', 'Header 2': 'Setup Data'}),\n",
      " Document(page_content='We setup evaluation modules, including the dataset and evaluators.', metadata={'Header 1': 'Benchmarking OpenAI Retrieval API (through Assistant Agent)', 'Header 2': 'Define Eval Modules'}),\n",
      " Document(page_content='Here we load in a \"golden\" dataset.  \\n#### Option 1: Pull Existing Dataset  \\n**NOTE**: We pull this in from Dropbox. For details on how to generate a dataset please see our `DatasetGenerator` module.  \\n```python\\n!wget \"https://www.dropbox.com/scl/fi/fh9vsmmm8vu0j50l3ss38/llama2_eval_qr_dataset.json?rlkey=kkoaez7aqeb4z25gzc06ak6kb&dl=1\" -O data/llama2_eval_qr_dataset.json\\n```  \\n--2023-11-08 22:20:10--  https://www.dropbox.com/scl/fi/fh9vsmmm8vu0j50l3ss38/llama2_eval_qr_dataset.json?rlkey=kkoaez7aqeb4z25gzc06ak6kb&dl=1\\nResolving www.dropbox.com (www.dropbox.com)... 2620:100:6057:18::a27d:d12, 162.125.13.18\\nConnecting to www.dropbox.com (www.dropbox.com)|2620:100:6057:18::a27d:d12|:443... connected.\\nHTTP request sent, awaiting response... 302 Found\\nLocation: https://uc63170224c66fda29da619e304b.dl.dropboxusercontent.com/cd/0/inline/CHOj1FEf2Dd6npmREaKmwUEIJ4S5QcrgeISKh55BE27i9tqrcE94Oym_0_z0EL9mBTmF9udNCxWwnFSHlio3ib6G_f_j3xiUzn5AVvQsKDPROYjazkJz_ChUVv3xkT-Pzuk/file?dl=1# [following]\\n--2023-11-08 22:20:11--  https://uc63170224c66fda29da619e304b.dl.dropboxusercontent.com/cd/0/inline/CHOj1FEf2Dd6npmREaKmwUEIJ4S5QcrgeISKh55BE27i9tqrcE94Oym_0_z0EL9mBTmF9udNCxWwnFSHlio3ib6G_f_j3xiUzn5AVvQsKDPROYjazkJz_ChUVv3xkT-Pzuk/file?dl=1\\nResolving uc63170224c66fda29da619e304b.dl.dropboxusercontent.com (uc63170224c66fda29da619e304b.dl.dropboxusercontent.com)... 2620:100:6057:15::a27d:d0f, 162.125.13.15\\nConnecting to uc63170224c66fda29da619e304b.dl.dropboxusercontent.com (uc63170224c66fda29da619e304b.dl.dropboxusercontent.com)|2620:100:6057:15::a27d:d0f|:443... connected.\\nHTTP request sent, awaiting response... 200 OK\\nLength: 60656 (59K) [application/binary]\\nSaving to: ‘data/llama2_eval_qr_dataset.json’  \\ndata/llama2_eval_qr 100%[===================>]  59.23K  --.-KB/s    in 0.02s  \\n2023-11-08 22:20:12 (2.87 MB/s) - ‘data/llama2_eval_qr_dataset.json’ saved [60656/60656]  \\n```python\\nfrom llama_index.evaluation import QueryResponseDataset\\n\\n# optional\\neval_dataset = QueryResponseDataset.from_json(\\n\"data/llama2_eval_qr_dataset.json\"\\n)\\n```  \\n#### Option 2: Generate New Dataset  \\nIf you choose this option, you can choose to generate a new dataset from scratch. This allows you to play around with our `DatasetGenerator` settings to make sure it suits your needs.  \\n```python\\nfrom llama_index.evaluation import (\\nDatasetGenerator,\\nQueryResponseDataset,\\n)\\nfrom llama_index import ServiceContext\\nfrom llama_index.llms import OpenAI\\n```  \\n```python\\n# NOTE: run this if the dataset isn\\'t already saved\\n# Note: we only generate from the first 20 nodes, since the rest are references\\neval_service_context = ServiceContext.from_defaults(\\nllm=OpenAI(model=\"gpt-4-1106-preview\")\\n)\\ndataset_generator = DatasetGenerator(\\nnodes[:20],\\nservice_context=eval_service_context,\\nshow_progress=True,\\nnum_questions_per_chunk=3,\\n)\\neval_dataset = await dataset_generator.agenerate_dataset_from_nodes(num=60)\\neval_dataset.save_json(\"data/llama2_eval_qr_dataset.json\")\\n```  \\n```python\\n# optional\\neval_dataset = QueryResponseDataset.from_json(\\n\"data/llama2_eval_qr_dataset.json\"\\n)\\n```', metadata={'Header 1': 'Benchmarking OpenAI Retrieval API (through Assistant Agent)', 'Header 2': 'Define Eval Modules', 'Header 3': 'Setup \"Golden Dataset\"'}),\n",
      " Document(page_content='We define two evaluation modules: correctness and semantic similarity - both comparing quality of predicted response with actual response.  \\n```python\\nfrom llama_index.evaluation.eval_utils import get_responses, get_results_df\\nfrom llama_index.evaluation import (\\nCorrectnessEvaluator,\\nSemanticSimilarityEvaluator,\\nBatchEvalRunner,\\n)\\nfrom llama_index.llms import OpenAI\\n```  \\n```python\\neval_llm = OpenAI(model=\"gpt-4-1106-preview\")\\neval_service_context = ServiceContext.from_defaults(llm=eval_llm)\\nevaluator_c = CorrectnessEvaluator(service_context=eval_service_context)\\nevaluator_s = SemanticSimilarityEvaluator(service_context=eval_service_context)\\nevaluator_dict = {\\n\"correctness\": evaluator_c,\\n\"semantic_similarity\": evaluator_s,\\n}\\nbatch_runner = BatchEvalRunner(evaluator_dict, workers=2, show_progress=True)\\n```  \\n```python\\nimport numpy as np\\nimport time\\nimport os\\nimport pickle\\nfrom tqdm import tqdm\\n\\n\\ndef get_responses_sync(\\neval_qs, query_engine, show_progress=True, save_path=None\\n):\\nif show_progress:\\neval_qs_iter = tqdm(eval_qs)\\nelse:\\neval_qs_iter = eval_qs\\npred_responses = []\\nstart_time = time.time()\\nfor eval_q in eval_qs_iter:\\nprint(f\"eval q: {eval_q}\")\\npred_response = agent.query(eval_q)\\nprint(f\"predicted response: {pred_response}\")\\npred_responses.append(pred_response)\\nif save_path is not None:\\n# save intermediate responses (to cache in case something breaks)\\navg_time = (time.time() - start_time) / len(pred_responses)\\npickle.dump(\\n{\"pred_responses\": pred_responses, \"avg_time\": avg_time},\\nopen(save_path, \"wb\"),\\n)\\nreturn pred_responses\\n\\n\\nasync def run_evals(\\nquery_engine,\\neval_qa_pairs,\\nbatch_runner,\\ndisable_async_for_preds=False,\\nsave_path=None,\\n):\\n# then evaluate\\n# TODO: evaluate a sample of generated results\\neval_qs = [q for q, _ in eval_qa_pairs]\\neval_answers = [a for _, a in eval_qa_pairs]\\n\\nif save_path is not None:\\nif not os.path.exists(save_path):\\nstart_time = time.time()\\nif disable_async_for_preds:\\npred_responses = get_responses_sync(\\neval_qs,\\nquery_engine,\\nshow_progress=True,\\nsave_path=save_path,\\n)\\nelse:\\npred_responses = get_responses(\\neval_qs, query_engine, show_progress=True\\n)\\navg_time = (time.time() - start_time) / len(eval_qs)\\npickle.dump(\\n{\"pred_responses\": pred_responses, \"avg_time\": avg_time},\\nopen(save_path, \"wb\"),\\n)\\nelse:\\n# [optional] load\\npickled_dict = pickle.load(open(save_path, \"rb\"))\\npred_responses = pickled_dict[\"pred_responses\"]\\navg_time = pickled_dict[\"avg_time\"]\\nelse:\\nstart_time = time.time()\\npred_responses = get_responses(\\neval_qs, query_engine, show_progress=True\\n)\\navg_time = (time.time() - start_time) / len(eval_qs)\\n\\neval_results = await batch_runner.aevaluate_responses(\\neval_qs, responses=pred_responses, reference=eval_answers\\n)\\nreturn eval_results, {\"avg_time\": avg_time}\\n```', metadata={'Header 1': 'Benchmarking OpenAI Retrieval API (through Assistant Agent)', 'Header 2': 'Define Eval Modules', 'Header 3': 'Eval Modules'}),\n",
      " Document(page_content='Let\\'s construct the assistant by also passing it the built-in OpenAI Retrieval tool.  \\nHere, we upload and pass in the file during assistant-creation time.  \\n```python\\nfrom llama_index.agent import OpenAIAssistantAgent\\n```  \\n```python\\nagent = OpenAIAssistantAgent.from_new(\\nname=\"SEC Analyst\",\\ninstructions=\"You are a QA assistant designed to analyze sec filings.\",\\nopenai_tools=[{\"type\": \"retrieval\"}],\\ninstructions_prefix=\"Please address the user as Jerry.\",\\nfiles=[\"data/llama2.pdf\"],\\nverbose=True,\\n)\\n```  \\n```python\\nresponse = agent.query(\\n\"What are the key differences between Llama 2 and Llama 2-Chat?\"\\n)\\n```  \\n```python\\nprint(str(response))\\n```  \\nThe key differences between Llama 2 and Llama 2-Chat, as indicated by the document, focus on their performance in safety evaluations, particularly when tested with adversarial prompts. Here are some of the differences highlighted within the safety evaluation section of Llama 2-Chat:  \\n1. Safety Human Evaluation: Llama 2-Chat was assessed with roughly 2000 adversarial prompts, among which 1351 were single-turn and 623 were multi-turn. The responses were judged for safety violations on a five-point Likert scale, where a rating of 1 or 2 indicated a violation. The evaluation aimed to gauge the model’s safety by its rate of generating responses with safety violations and its helpfulness to users.  \\n2. Violation Percentage and Mean Rating: Llama 2-Chat exhibited a low overall violation percentage across different model sizes and a high mean rating for safety and helpfulness, which suggests a strong performance in safety evaluations.  \\n3. Inter-Rater Reliability: The reliability of the safety assessments was measured using Gwet’s AC1/2 statistic, showing a high degree of agreement among annotators with an average inter-rater reliability score of 0.92 for Llama 2-Chat annotations.  \\n4. Single-turn and Multi-turn Conversations: The evaluation revealed that multi-turn conversations generally lead to more safety violations across models, but Llama 2-Chat performed well compared to baselines, particularly in multi-turn scenarios.  \\n5. Violation Percentage Per Risk Category: Llama 2-Chat had a relatively higher number of violations in the unqualified advice category, possibly due to a lack of appropriate disclaimers in its responses.  \\n6. Improvements in Fine-Tuned Llama 2-Chat: The document also mentions that the fine-tuned Llama 2-Chat showed significant improvement over the pre-trained Llama 2 in terms of truthfulness and toxicity. The percentage of toxic generations dropped to effectively 0% for Llama 2-Chat of all sizes, which was the lowest among all compared models, indicating a notable enhancement in safety.  \\nThese points detail the evaluations and improvements emphasizing safety that distinguish Llama 2-Chat from Llama 2【9†source】.', metadata={'Header 1': 'Benchmarking OpenAI Retrieval API (through Assistant Agent)', 'Header 2': 'Construct Assistant with Built-In Retrieval'}),\n",
      " Document(page_content='We run the agent over our evaluation dataset. We benchmark against a standard top-k RAG pipeline (k=2) with gpt-4-turbo.  \\n**NOTE**: During our time of testing (November 2023), the Assistant API is heavily rate-limited, and can take ~1-2 hours to generate responses over 60 datapoints.  \\n#### Define Baseline Index + RAG Pipeline  \\n```python\\nbase_sc = ServiceContext.from_defaults(llm=OpenAI(model=\"gpt-4-1106-preview\"))\\nbase_index = VectorStoreIndex(nodes, service_context=base_sc)\\nbase_query_engine = base_index.as_query_engine(similarity_top_k=2)\\n```  \\n#### Run Evals over Baseline  \\n```python\\nbase_eval_results, base_extra_info = await run_evals(\\nbase_query_engine,\\neval_dataset.qr_pairs,\\nbatch_runner,\\nsave_path=\"data/llama2_preds_base.pkl\",\\n)\\n```  \\n```python\\nresults_df = get_results_df(\\n[base_eval_results],\\n[\"Base Query Engine\"],\\n[\"correctness\", \"semantic_similarity\"],\\n)\\ndisplay(results_df)\\n```  \\n<div>\\n<style scoped>\\n.dataframe tbody tr th:only-of-type {\\nvertical-align: middle;\\n}  \\n.dataframe tbody tr th {\\nvertical-align: top;\\n}  \\n.dataframe thead th {\\ntext-align: right;\\n}\\n</style>\\n<table border=\"1\" class=\"dataframe\">\\n<thead>\\n<tr style=\"text-align: right;\">\\n<th></th>\\n<th>names</th>\\n<th>correctness</th>\\n<th>semantic_similarity</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<th>0</th>\\n<td>Base Query Engine</td>\\n<td>4.05</td>\\n<td>0.964245</td>\\n</tr>\\n</tbody>\\n</table>\\n</div>  \\n#### Run Evals over Assistant API  \\n```python\\nassistant_eval_results, assistant_extra_info = await run_evals(\\nagent,\\neval_dataset.qr_pairs[:55],\\nbatch_runner,\\nsave_path=\"data/llama2_preds_assistant.pkl\",\\ndisable_async_for_preds=True,\\n)\\n```  \\n#### Get Results  \\nHere we see...that our basic RAG pipeline does better.  \\nTake these numbers with a grain of salt. The goal here is to give you a script so you can run this on your own data.  \\nThat said it\\'s surprising the Retrieval API doesn\\'t give immediately better out of the box performance.  \\n```python\\nresults_df = get_results_df(\\n[assistant_eval_results, base_eval_results],\\n[\"Retrieval API\", \"Base Query Engine\"],\\n[\"correctness\", \"semantic_similarity\"],\\n)\\ndisplay(results_df)\\nprint(f\"Base Avg Time: {base_extra_info[\\'avg_time\\']}\")\\nprint(f\"Assistant Avg Time: {assistant_extra_info[\\'avg_time\\']}\")\\n```  \\n<div>\\n<style scoped>\\n.dataframe tbody tr th:only-of-type {\\nvertical-align: middle;\\n}  \\n.dataframe tbody tr th {\\nvertical-align: top;\\n}  \\n.dataframe thead th {\\ntext-align: right;\\n}\\n</style>\\n<table border=\"1\" class=\"dataframe\">\\n<thead>\\n<tr style=\"text-align: right;\">\\n<th></th>\\n<th>names</th>\\n<th>correctness</th>\\n<th>semantic_similarity</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<th>0</th>\\n<td>Retrieval API</td>\\n<td>3.536364</td>\\n<td>0.952647</td>\\n</tr>\\n<tr>\\n<th>1</th>\\n<td>Base Query Engine</td>\\n<td>4.050000</td>\\n<td>0.964245</td>\\n</tr>\\n</tbody>\\n</table>\\n</div>  \\nBase Avg Time: 0.25683316787083943\\nAssistant Avg Time: 75.43605598536405', metadata={'Header 1': 'Benchmarking OpenAI Retrieval API (through Assistant Agent)', 'Header 2': 'Benchmark'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/react_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>'),\n",
      " Document(page_content=\"This is a notebook that showcases the ReAct agent over very simple calculator tools (no fancy RAG pipelines or API calls).  \\nWe show how it can reason step-by-step over different tools to achieve the end goal.  \\nIf you're opening this Notebook on colab, you will probably need to install LlamaIndex 🦙.  \\n```python\\n!pip install llama-index\\n```  \\n```python\\nfrom llama_index.agent import ReActAgent\\nfrom llama_index.llms import OpenAI, ChatMessage\\nfrom llama_index.tools import BaseTool, FunctionTool\\n```\", metadata={'Header 1': 'ReAct Agent - A Simple Intro with Calculator Tools'}),\n",
      " Document(page_content='We setup some trivial `multiply` and `add` tools. Note that you can define arbitrary functions and pass it to the `FunctionTool` (which will process the docstring and parameter signature).  \\n```python\\ndef multiply(a: int, b: int) -> int:\\n\"\"\"Multiply two integers and returns the result integer\"\"\"\\nreturn a * b\\n\\n\\nmultiply_tool = FunctionTool.from_defaults(fn=multiply)\\n```  \\n```python\\ndef add(a: int, b: int) -> int:\\n\"\"\"Add two integers and returns the result integer\"\"\"\\nreturn a + b\\n\\n\\nadd_tool = FunctionTool.from_defaults(fn=add)\\n```', metadata={'Header 1': 'ReAct Agent - A Simple Intro with Calculator Tools', 'Header 2': 'Define Function Tools'}),\n",
      " Document(page_content='```python\\nllm = OpenAI(model=\"gpt-3.5-turbo-instruct\")\\nagent = ReActAgent.from_tools([multiply_tool, add_tool], llm=llm, verbose=True)\\n```  \\n```python\\nresponse = agent.chat(\"What is 20+(2*4)? Calculate step by step \")\\n```  \\n\\x1b[1;3;38;5;200mThought: I need to use a tool to help me answer the question.\\nassistant: Action: multiply\\nassistant: Action Input: {\"a\": 2, \"b\": 4}\\nObservation: 8\\nassistant: Thought: I need to use a tool to help me answer the question.\\nassistant: Action: add\\nassistant: Action Input: {\"a\": 20, \"b\": 8}\\nObservation: 28\\nThought: I can answer without using any more tools.\\nAnswer: 28\\n\\x1b[0m  \\n```python\\nresponse_gen = agent.stream_chat(\"What is 20+2*4? Calculate step by step\")\\nresponse_gen.print_response_stream()\\n```  \\n28', metadata={'Header 1': 'ReAct Agent - A Simple Intro with Calculator Tools', 'Header 2': 'Run Some Queries', 'Header 3': 'gpt-3.5-turbo'}),\n",
      " Document(page_content='```python\\nllm = OpenAI(model=\"gpt-4\")\\nagent = ReActAgent.from_tools([multiply_tool, add_tool], llm=llm, verbose=True)\\n```  \\n```python\\nresponse = agent.chat(\"What is 2+2*4\")\\nprint(response)\\n```  \\n\\x1b[1;3;38;5;200mThought: I need to use the tools to help me answer the question. According to the order of operations in mathematics (BIDMAS/BODMAS), multiplication should be done before addition. So, I will first multiply 2 and 4, then add the result to 2.\\nAction: multiply\\nAction Input: {\\'a\\': 2, \\'b\\': 4}\\n\\x1b[0m\\x1b[1;3;34mObservation: 8\\n\\x1b[0m\\x1b[1;3;38;5;200mThought: Now that I have the result of the multiplication, I need to add this to 2.\\nAction: add\\nAction Input: {\\'a\\': 2, \\'b\\': 8}\\n\\x1b[0m\\x1b[1;3;34mObservation: 10\\n\\x1b[0m\\x1b[1;3;38;5;200mThought: I can answer without using any more tools.\\nAnswer: 10\\n\\x1b[0m10', metadata={'Header 1': 'ReAct Agent - A Simple Intro with Calculator Tools', 'Header 2': 'Run Some Queries', 'Header 3': 'gpt-4'}),\n",
      " Document(page_content='Let\\'s take a look at the core system prompt powering the ReAct agent!  \\nWithin the agent, the current conversation history is dumped below this line.  \\n```python\\nllm = OpenAI(model=\"gpt-4\")\\nagent = ReActAgent.from_tools([multiply_tool, add_tool], llm=llm, verbose=True)\\n```  \\n```python\\nprompt_dict = agent.get_prompts()\\nfor k, v in prompt_dict.items():\\nprint(f\"Prompt: {k}\\\\n\\\\nValue: {v.template}\")\\n```  \\nPrompt: agent_worker:system_prompt  \\nValue:\\nYou are designed to help with a variety of tasks, from answering questions     to providing summaries to other types of analyses.', metadata={'Header 1': 'ReAct Agent - A Simple Intro with Calculator Tools', 'Header 2': 'View Prompts'}),\n",
      " Document(page_content='You have access to a wide variety of tools. You are responsible for using\\nthe tools in any sequence you deem appropriate to complete the task at hand.\\nThis may require breaking the task into subtasks and using different tools\\nto complete each subtask.  \\nYou have access to the following tools:\\n{tool_desc}', metadata={'Header 1': 'ReAct Agent - A Simple Intro with Calculator Tools', 'Header 2': 'Tools'}),\n",
      " Document(page_content='To answer the question, please use the following format.  \\n```\\nThought: I need to use a tool to help me answer the question.\\nAction: tool name (one of {tool_names}) if using a tool.\\nAction Input: the input to the tool, in a JSON format representing the kwargs (e.g. {{\"input\": \"hello world\", \"num_beams\": 5}})\\n```  \\nPlease ALWAYS start with a Thought.  \\nPlease use a valid JSON format for the Action Input. Do NOT do this {{\\'input\\': \\'hello world\\', \\'num_beams\\': 5}}.  \\nIf this format is used, the user will respond in the following format:  \\n```\\nObservation: tool response\\n```  \\nYou should keep repeating the above format until you have enough information\\nto answer the question without using any more tools. At that point, you MUST respond\\nin the one of the following two formats:  \\n```\\nThought: I can answer without using any more tools.\\nAnswer: [your answer here]\\n```  \\n```\\nThought: I cannot answer the question with the provided tools.\\nAnswer: Sorry, I cannot answer your query.\\n```', metadata={'Header 1': 'ReAct Agent - A Simple Intro with Calculator Tools', 'Header 2': 'Output Format'}),\n",
      " Document(page_content='Below is the current conversation consisting of interleaving human and assistant messages.', metadata={'Header 1': 'ReAct Agent - A Simple Intro with Calculator Tools', 'Header 2': 'Current Conversation'}),\n",
      " Document(page_content='For fun, let\\'s try instructing the agent to output the answer along with reasoning in bullet points. See \"## Additional Rules\" section.  \\n```python\\nfrom llama_index.prompts import PromptTemplate\\n\\nreact_system_header_str = \"\"\"\\\\\\n\\nYou are designed to help with a variety of tasks, from answering questions \\\\\\nto providing summaries to other types of analyses.\\n\\n## Tools\\nYou have access to a wide variety of tools. You are responsible for using\\nthe tools in any sequence you deem appropriate to complete the task at hand.\\nThis may require breaking the task into subtasks and using different tools\\nto complete each subtask.\\n\\nYou have access to the following tools:\\n{tool_desc}\\n\\n## Output Format\\nTo answer the question, please use the following format.\\n\\n```\\nThought: I need to use a tool to help me answer the question.\\nAction: tool name (one of {tool_names}) if using a tool.\\nAction Input: the input to the tool, in a JSON format representing the kwargs (e.g. {{\"input\": \"hello world\", \"num_beams\": 5}})\\n```\\n\\nPlease ALWAYS start with a Thought.\\n\\nPlease use a valid JSON format for the Action Input. Do NOT do this {{\\'input\\': \\'hello world\\', \\'num_beams\\': 5}}.\\n\\nIf this format is used, the user will respond in the following format:\\n\\n```\\nObservation: tool response\\n```\\n\\nYou should keep repeating the above format until you have enough information\\nto answer the question without using any more tools. At that point, you MUST respond\\nin the one of the following two formats:\\n\\n```\\nThought: I can answer without using any more tools.\\nAnswer: [your answer here]\\n```\\n\\n```\\nThought: I cannot answer the question with the provided tools.\\nAnswer: Sorry, I cannot answer your query.\\n```\\n\\n## Additional Rules\\n- The answer MUST contain a sequence of bullet points that explain how you arrived at the answer. This can include aspects of the previous conversation history.\\n- You MUST obey the function signature of each tool. Do NOT pass in no arguments if the function expects arguments.\\n\\n## Current Conversation\\nBelow is the current conversation consisting of interleaving human and assistant messages.\\n\\n\"\"\"\\nreact_system_prompt = PromptTemplate(react_system_header_str)\\n```  \\n```python\\nagent.update_prompts({\"agent_worker:system_prompt\": react_system_prompt})\\n```  \\n```python\\nagent.reset()\\nresponse = agent.chat(\"What is 5+3+2\")\\nprint(response)\\n```  \\n\\x1b[1;3;38;5;200mThought: I need to use the add tool to help me answer the question.\\nAction: add\\nAction Input: {\\'a\\': 5, \\'b\\': 3}\\n\\x1b[0m\\x1b[1;3;34mObservation: 8\\n\\x1b[0m\\x1b[1;3;38;5;200mThought: Now I need to add the result from the previous operation with 2.\\nAction: add\\nAction Input: {\\'a\\': 8, \\'b\\': 2}\\n\\x1b[0m\\x1b[1;3;34mObservation: 10\\n\\x1b[0m\\x1b[1;3;38;5;200mThought: I can answer without using any more tools.\\nAnswer: The result of 5+3+2 is 10.\\n- First, I added 5 and 3 using the add tool, which resulted in 8.\\n- Then, I added the result (8) to 2 using the add tool, which resulted in 10.\\n\\x1b[0mThe result of 5+3+2 is 10.\\n- First, I added 5 and 3 using the add tool, which resulted in 8.\\n- Then, I added the result (8) to 2 using the add tool, which resulted in 10.', metadata={'Header 1': 'ReAct Agent - A Simple Intro with Calculator Tools', 'Header 2': 'Current Conversation', 'Header 3': 'Customizing the Prompt'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/react_agent_with_query_engine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>'),\n",
      " Document(page_content='In this section, we show how to setup an agent powered by the ReAct loop for financial analysis.  \\nThe agent has access to two \"tools\": one to query the 2021 Lyft 10-K and the other to query the 2021 Uber 10-K.  \\nWe try two different LLMs:  \\n- gpt-3.5-turbo\\n- gpt-3.5-turbo-instruct  \\nNote that you can plug in any LLM that exposes a text completion endpoint.', metadata={'Header 1': 'ReAct Agent with Query Engine (RAG) Tools'}),\n",
      " Document(page_content='```python\\nfrom llama_index import (\\nSimpleDirectoryReader,\\nVectorStoreIndex,\\nStorageContext,\\nload_index_from_storage,\\n)\\n\\nfrom llama_index.tools import QueryEngineTool, ToolMetadata\\n```  \\n```python\\ntry:\\nstorage_context = StorageContext.from_defaults(\\npersist_dir=\"./storage/lyft\"\\n)\\nlyft_index = load_index_from_storage(storage_context)\\n\\nstorage_context = StorageContext.from_defaults(\\npersist_dir=\"./storage/uber\"\\n)\\nuber_index = load_index_from_storage(storage_context)\\n\\nindex_loaded = True\\nexcept:\\nindex_loaded = False\\n```  \\nDownload Data  \\n```python\\n!mkdir -p \\'data/10k/\\'\\n!wget \\'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10k/uber_2021.pdf\\' -O \\'data/10k/uber_2021.pdf\\'\\n!wget \\'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10k/lyft_2021.pdf\\' -O \\'data/10k/lyft_2021.pdf\\'\\n```  \\n```python\\nif not index_loaded:\\n# load data\\nlyft_docs = SimpleDirectoryReader(\\ninput_files=[\"./data/10k/lyft_2021.pdf\"]\\n).load_data()\\nuber_docs = SimpleDirectoryReader(\\ninput_files=[\"./data/10k/uber_2021.pdf\"]\\n).load_data()\\n\\n# build index\\nlyft_index = VectorStoreIndex.from_documents(lyft_docs)\\nuber_index = VectorStoreIndex.from_documents(uber_docs)\\n\\n# persist index\\nlyft_index.storage_context.persist(persist_dir=\"./storage/lyft\")\\nuber_index.storage_context.persist(persist_dir=\"./storage/uber\")\\n```  \\n```python\\nlyft_engine = lyft_index.as_query_engine(similarity_top_k=3)\\nuber_engine = uber_index.as_query_engine(similarity_top_k=3)\\n```  \\n```python\\nquery_engine_tools = [\\nQueryEngineTool(\\nquery_engine=lyft_engine,\\nmetadata=ToolMetadata(\\nname=\"lyft_10k\",\\ndescription=(\\n\"Provides information about Lyft financials for year 2021. \"\\n\"Use a detailed plain text question as input to the tool.\"\\n),\\n),\\n),\\nQueryEngineTool(\\nquery_engine=uber_engine,\\nmetadata=ToolMetadata(\\nname=\"uber_10k\",\\ndescription=(\\n\"Provides information about Uber financials for year 2021. \"\\n\"Use a detailed plain text question as input to the tool.\"\\n),\\n),\\n),\\n]\\n```', metadata={'Header 1': 'ReAct Agent with Query Engine (RAG) Tools', 'Header 2': 'Build Query Engine Tools'}),\n",
      " Document(page_content='Here we setup two ReAct agents: one powered by standard gpt-3.5-turbo, and the other powered by gpt-3.5-turbo-instruct.  \\nYou can **optionally** specify context which will be added to the core ReAct system prompt.  \\n```python\\nfrom llama_index.agent import ReActAgent\\nfrom llama_index.llms import OpenAI\\n```  \\n```python\\n# [Optional] Add Context\\n# context = \"\"\"\\\\\\n# You are a stock market sorcerer who is an expert on the companies Lyft and Uber.\\\\\\n#     You will answer questions about Uber and Lyft as in the persona of a sorcerer \\\\\\n#     and veteran stock market investor.\\n# \"\"\"\\nllm = OpenAI(model=\"gpt-3.5-turbo-0613\")\\n\\nagent = ReActAgent.from_tools(\\nquery_engine_tools,\\nllm=llm,\\nverbose=True,\\n# context=context\\n)\\n```  \\n```python\\nresponse = agent.chat(\"What was Lyft\\'s revenue growth in 2021?\")\\nprint(str(response))\\n```  \\n\\x1b[38;5;200m\\x1b[1;3mThought: I need to use a tool to help me answer the question.\\nAction: lyft_10k\\nAction Input: {\\'input\\': \"What was Lyft\\'s revenue growth in 2021?\"}\\n\\x1b[0m\\x1b[36;1m\\x1b[1;3mObservation: Lyft\\'s revenue growth in 2021 was 36%.\\n\\x1b[0m\\x1b[38;5;200m\\x1b[1;3mResponse: Lyft\\'s revenue growth in 2021 was 36%.\\n\\x1b[0mLyft\\'s revenue growth in 2021 was 36%.', metadata={'Header 1': 'ReAct Agent with Query Engine (RAG) Tools', 'Header 2': 'Setup ReAct Agent'}),\n",
      " Document(page_content='We run some example queries using the agent, showcasing some of the agent\\'s abilities to do chain-of-thought-reasoning and tool use to synthesize the right answer.  \\nWe also show queries.  \\n```python\\nresponse = agent.chat(\\n\"Compare and contrast the revenue growth of Uber and Lyft in 2021, then\"\\n\" give an analysis\"\\n)\\nprint(str(response))\\n```  \\n\\x1b[38;5;200m\\x1b[1;3mThought: I need to use a tool to help me compare the revenue growth of Uber and Lyft in 2021.\\nAction: lyft_10k\\nAction Input: {\\'input\\': \"What was Lyft\\'s revenue growth in 2021?\"}\\n\\x1b[0m\\x1b[36;1m\\x1b[1;3mObservation: Lyft\\'s revenue growth in 2021 was 36%.\\n\\x1b[0m\\x1b[38;5;200m\\x1b[1;3mThought: I need to use a tool to help me compare the revenue growth of Uber and Lyft in 2021.\\nAction: uber_10k\\nAction Input: {\\'input\\': \"What was Uber\\'s revenue growth in 2021?\"}\\n\\x1b[0m\\x1b[36;1m\\x1b[1;3mObservation: Uber\\'s revenue growth in 2021 was 57%.\\n\\x1b[0m\\x1b[38;5;200m\\x1b[1;3mResponse: In 2021, Lyft\\'s revenue growth was 36% while Uber\\'s revenue growth was 57%. This indicates that Uber experienced a higher revenue growth compared to Lyft in 2021.\\n\\x1b[0mIn 2021, Lyft\\'s revenue growth was 36% while Uber\\'s revenue growth was 57%. This indicates that Uber experienced a higher revenue growth compared to Lyft in 2021.  \\n**Async execution**: Here we try another query with async execution  \\n```python\\n# Try another query with async execution\\n\\nimport nest_asyncio\\n\\nnest_asyncio.apply()\\n\\nresponse = await agent.achat(\\n\"Compare and contrast the risks of Uber and Lyft in 2021, then give an\"\\n\" analysis\"\\n)\\nprint(str(response))\\n```', metadata={'Header 1': 'ReAct Agent with Query Engine (RAG) Tools', 'Header 2': 'Run Some Example Queries'}),\n",
      " Document(page_content='We compare the performance of the two agents in being able to answer some complex queries.  \\n#### Taking a look at a turbo-instruct agent  \\n```python\\nllm_instruct = OpenAI(model=\"gpt-3.5-turbo-instruct\")\\nagent_instruct = ReActAgent.from_tools(\\nquery_engine_tools, llm=llm_instruct, verbose=True\\n)\\n```  \\n```python\\nresponse = agent_instruct.chat(\"What was Lyft\\'s revenue growth in 2021?\")\\nprint(str(response))\\n```  \\n\\x1b[38;5;200m\\x1b[1;3mThought: I need to use a tool to help me answer the question.\\nAction: lyft_10k\\nAction Input: {\\'input\\': \"What was Lyft\\'s revenue growth in 2021?\"}\\n\\x1b[0m\\x1b[36;1m\\x1b[1;3mObservation: Lyft\\'s revenue growth in 2021 was 36%.\\n\\x1b[0m\\x1b[38;5;200m\\x1b[1;3mResponse: Lyft\\'s revenue growth in 2021 was 36%.\\n\\x1b[0mLyft\\'s revenue growth in 2021 was 36%.  \\n#### Try more complex queries  \\nWe compare gpt-3.5-turbo with gpt-3.5-turbo-instruct agents on more complex queries.  \\n```python\\nresponse = agent.chat(\\n\"Compare and contrast the revenue growth of Uber and Lyft in 2021, then\"\\n\" give an analysis\"\\n)\\nprint(str(response))\\n```  \\n\\x1b[38;5;200m\\x1b[1;3mThought: I need to use a tool to help me compare the revenue growth of Uber and Lyft in 2021.\\nAction: uber_10k\\nAction Input: {\\'input\\': \"Please provide information about Uber\\'s revenue growth in 2021.\"}\\n\\x1b[0m\\x1b[36;1m\\x1b[1;3mObservation: Uber\\'s revenue grew by 57% in 2021 compared to the previous year. This growth was primarily driven by an increase in Gross Bookings, with Delivery Gross Bookings increasing by 71% and Mobility Gross Bookings growing by 38%. The increase in Delivery Gross Bookings was due to higher demand for food delivery orders and expansion across U.S. and international markets. The growth in Mobility Gross Bookings was a result of increased Trip volumes as the business recovered from the impacts of COVID-19.\\n\\x1b[0m\\x1b[38;5;200m\\x1b[1;3mThought: I have information about Uber\\'s revenue growth in 2021. Now I need to use a tool to get information about Lyft\\'s revenue growth in 2021.\\nAction: lyft_10k\\nAction Input: {\\'input\\': \"Please provide information about Lyft\\'s revenue growth in 2021.\"}\\n\\x1b[0m\\x1b[36;1m\\x1b[1;3mObservation: Lyft\\'s revenue increased by 36% in 2021 compared to the prior year.\\n\\x1b[0m\\x1b[38;5;200m\\x1b[1;3mResponse: In 2021, Uber experienced a higher revenue growth rate of 57% compared to Lyft\\'s growth rate of 36%. This indicates that Uber had a stronger performance in terms of revenue growth during that period. The growth in Uber\\'s revenue was primarily driven by an increase in Gross Bookings, with both Delivery and Mobility segments contributing to the growth. The increase in Delivery Gross Bookings was due to higher demand for food delivery services, while the growth in Mobility Gross Bookings was a result of increased trip volumes as the business recovered from the impacts of COVID-19.\\n\\x1b[0mIn 2021, Uber experienced a higher revenue growth rate of 57% compared to Lyft\\'s growth rate of 36%. This indicates that Uber had a stronger performance in terms of revenue growth during that period. The growth in Uber\\'s revenue was primarily driven by an increase in Gross Bookings, with both Delivery and Mobility segments contributing to the growth. The increase in Delivery Gross Bookings was due to higher demand for food delivery services, while the growth in Mobility Gross Bookings was a result of increased trip volumes as the business recovered from the impacts of COVID-19.  \\n```python\\nresponse = agent_instruct.chat(\\n\"Compare and contrast the revenue growth of Uber and Lyft in 2021, then\"\\n\" give an analysis\"\\n)\\nprint(str(response))\\n```  \\n\\x1b[38;5;200m\\x1b[1;3mResponse: The revenue growth of Uber was higher than Lyft in 2021, with Uber experiencing a 74% growth compared to Lyft\\'s 48%. This indicates that Uber may have had a stronger financial performance in 2021. However, further analysis is needed to fully understand the factors contributing to this difference.\\n\\x1b[0mThe revenue growth of Uber was higher than Lyft in 2021, with Uber experiencing a 74% growth compared to Lyft\\'s 48%. This indicates that Uber may have had a stronger financial performance in 2021. However, further analysis is needed to fully understand the factors contributing to this difference.  \\n```python\\nresponse = agent.chat(\\n\"Can you tell me about the risk factors of the company with the higher\"\\n\" revenue?\"\\n)\\nprint(str(response))\\n```  \\n\\x1b[38;5;200m\\x1b[1;3mThought: I need to find out which company has higher revenue before I can provide information about its risk factors.\\nAction: lyft_10k\\nAction Input: {\\'input\\': \\'What is the revenue of Lyft in 2021?\\'}\\n\\x1b[0m\\x1b[36;1m\\x1b[1;3mObservation: The revenue of Lyft in 2021 is $3,208,323,000.\\n\\x1b[0m\\x1b[38;5;200m\\x1b[1;3mThought: Now that I know Lyft has higher revenue, I can find information about its risk factors.\\nAction: lyft_10k\\nAction Input: {\\'input\\': \\'What are the risk factors of Lyft?\\'}\\n\\x1b[0m\\x1b[36;1m\\x1b[1;3mObservation: Lyft faces numerous risk factors that could potentially harm its business, financial condition, and results of operations. These risk factors include general economic factors such as the impact of the COVID-19 pandemic, natural disasters, economic downturns, and political crises. Operational factors such as limited operating history, financial performance, competition, unpredictability of results, uncertainty regarding market growth, ability to attract and retain drivers and riders, insurance coverage, autonomous vehicle technology, reputation and brand, illegal or improper activity on the platform, accuracy of background checks, changes to pricing practices, growth management, security and privacy breaches, reliance on third parties, and ability to operate various programs and services. Additionally, Lyft faces risks related to its evolving business, including forecasting revenue and managing expenses, complying with laws and regulations, managing assets and expenses during the COVID-19 pandemic, capital expenditures, asset development and utilization, macroeconomic changes, reputation and brand management, growth and business operations, geographic expansion, talent acquisition and retention, platform development, and real estate portfolio management. Furthermore, Lyft\\'s financial performance in recent periods may not be indicative of future performance, and achieving or maintaining profitability in the future is not guaranteed. The Express Drive program and Lyft Rentals program also expose Lyft to risks related to vehicle rental partners, residual value of vehicles, and payment processing.\\n\\x1b[0m\\x1b[38;5;200m\\x1b[1;3mResponse: Lyft faces numerous risk factors that could potentially harm its business, financial condition, and results of operations. These risk factors include general economic factors such as the impact of the COVID-19 pandemic, natural disasters, economic downturns, and political crises. Operational factors such as limited operating history, financial performance, competition, unpredictability of results, uncertainty regarding market growth, ability to attract and retain drivers and riders, insurance coverage, autonomous vehicle technology, reputation and brand, illegal or improper activity on the platform, accuracy of background checks, changes to pricing practices, growth management, security and privacy breaches, reliance on third parties, and ability to operate various programs and services. Additionally, Lyft faces risks related to its evolving business, including forecasting revenue and managing expenses, complying with laws and regulations, managing assets and expenses during the COVID-19 pandemic, capital expenditures, asset development and utilization, macroeconomic changes, reputation and brand management, growth and business operations, geographic expansion, talent acquisition and retention, platform development, and real estate portfolio management. Furthermore, Lyft\\'s financial performance in recent periods may not be indicative of future performance, and achieving or maintaining profitability in the future is not guaranteed. The Express Drive program and Lyft Rentals program also expose Lyft to risks related to vehicle rental partners, residual value of vehicles, and payment processing.\\n\\x1b[0mLyft faces numerous risk factors that could potentially harm its business, financial condition, and results of operations. These risk factors include general economic factors such as the impact of the COVID-19 pandemic, natural disasters, economic downturns, and political crises. Operational factors such as limited operating history, financial performance, competition, unpredictability of results, uncertainty regarding market growth, ability to attract and retain drivers and riders, insurance coverage, autonomous vehicle technology, reputation and brand, illegal or improper activity on the platform, accuracy of background checks, changes to pricing practices, growth management, security and privacy breaches, reliance on third parties, and ability to operate various programs and services. Additionally, Lyft faces risks related to its evolving business, including forecasting revenue and managing expenses, complying with laws and regulations, managing assets and expenses during the COVID-19 pandemic, capital expenditures, asset development and utilization, macroeconomic changes, reputation and brand management, growth and business operations, geographic expansion, talent acquisition and retention, platform development, and real estate portfolio management. Furthermore, Lyft\\'s financial performance in recent periods may not be indicative of future performance, and achieving or maintaining profitability in the future is not guaranteed. The Express Drive program and Lyft Rentals program also expose Lyft to risks related to vehicle rental partners, residual value of vehicles, and payment processing.  \\n```python\\nresponse = agent_instruct.query(\\n\"Can you tell me about the risk factors of the company with the higher\"\\n\" revenue?\"\\n)\\nprint(str(response))\\n```  \\n\\x1b[38;5;200m\\x1b[1;3mResponse: The risk factors for the company with the higher revenue include competition, regulatory changes, and dependence on drivers.\\n\\x1b[0mThe risk factors for the company with the higher revenue include competition, regulatory changes, and dependence on drivers.  \\n**Observation**: The turbo-instruct agent seems to do worse on agent reasoning compared to the regular turbo model. Of course, this is subject to further observation!', metadata={'Header 1': 'ReAct Agent with Query Engine (RAG) Tools', 'Header 2': 'Run Some Example Queries', 'Header 3': 'Compare gpt-3.5-turbo vs. gpt-3.5-turbo-instruct'})]\n"
     ]
    }
   ],
   "source": [
    "# Now we have a list of Documents, each representing a chunk of Markdown content\n",
    "# under a specific header level\n",
    "pprint(all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, for each chunk, check if further splitting is needed\n",
    "chunk_size = 8000  # Or whatever size is appropriate for GPT-4\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=100,  # Some overlap to maintain context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply further splitting if necessary\n",
    "final_splits = []\n",
    "for md_chunk in all_splits:\n",
    "    # Check if the chunk is too large\n",
    "    if len(md_chunk.page_content) > chunk_size:\n",
    "        # Split further\n",
    "        smaller_chunks = text_splitter.split_documents([md_chunk])\n",
    "        final_splits.extend(smaller_chunks)\n",
    "    else:\n",
    "        final_splits.append(md_chunk)\n",
    "\n",
    "# final_splits now contains the optimally chunked documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/agent_builder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>  \\nInspired by GPTs interface, presented at OpenAI Dev Day 2023. Construct an agent with natural language.  \\nHere you can build your own agent...with another agent!  \\n```python\\nfrom llama_index.tools import BaseTool, FunctionTool\\n```  \\n```python\\nfrom llama_index.agent import OpenAIAgent\\nfrom llama_index.prompts import PromptTemplate\\nfrom llama_index.llms import ChatMessage, OpenAI\\nfrom llama_index import ServiceContext\\n```  \\n```python\\nllm = OpenAI(model=\"gpt-4\")\\nservice_context = ServiceContext.from_defaults(llm=llm)\\n```', metadata={'Header 1': 'GPT Builder Demo'}),\n",
      " Document(page_content='We also define a tool retriever to retrieve candidate tools.  \\nIn this setting we define tools as different Wikipedia pages.  \\n```python\\nfrom llama_index import SimpleDirectoryReader\\n```  \\n```python\\nwiki_titles = [\"Toronto\", \"Seattle\", \"Chicago\", \"Boston\", \"Houston\"]\\n```  \\n```python\\nfrom pathlib import Path\\n\\nimport requests\\n\\nfor title in wiki_titles:\\nresponse = requests.get(\\n\"https://en.wikipedia.org/w/api.php\",\\nparams={\\n\"action\": \"query\",\\n\"format\": \"json\",\\n\"titles\": title,\\n\"prop\": \"extracts\",\\n# \\'exintro\\': True,\\n\"explaintext\": True,\\n},\\n).json()\\npage = next(iter(response[\"query\"][\"pages\"].values()))\\nwiki_text = page[\"extract\"]\\n\\ndata_path = Path(\"data\")\\nif not data_path.exists():\\nPath.mkdir(data_path)\\n\\nwith open(data_path / f\"{title}.txt\", \"w\") as fp:\\nfp.write(wiki_text)\\n```  \\n```python\\n# Load all wiki documents\\ncity_docs = {}\\nfor wiki_title in wiki_titles:\\ncity_docs[wiki_title] = SimpleDirectoryReader(\\ninput_files=[f\"data/{wiki_title}.txt\"]\\n).load_data()\\n```', metadata={'Header 1': 'GPT Builder Demo', 'Header 2': 'Define Candidate Tools'}),\n",
      " Document(page_content='```python\\nfrom llama_index.agent import OpenAIAgent\\nfrom llama_index.tools import QueryEngineTool, ToolMetadata\\n\\n# Build tool dictionary\\ntool_dict = {}\\n\\nfor wiki_title in wiki_titles:\\n# build vector index\\nvector_index = VectorStoreIndex.from_documents(\\ncity_docs[wiki_title], service_context=service_context\\n)\\n# define query engines\\nvector_query_engine = vector_index.as_query_engine()\\n\\n# define tools\\nvector_tool = QueryEngineTool(\\nquery_engine=vector_query_engine,\\nmetadata=ToolMetadata(\\nname=wiki_title,\\ndescription=(\"Useful for questions related to\" f\" {wiki_title}\"),\\n),\\n)\\ntool_dict[wiki_title] = vector_tool\\n```', metadata={'Header 1': 'GPT Builder Demo', 'Header 2': 'Define Candidate Tools', 'Header 3': 'Build Query Tool for Each Document'}),\n",
      " Document(page_content='```python\\n# define an \"object\" index and retriever over these tools\\nfrom llama_index import VectorStoreIndex\\nfrom llama_index.objects import ObjectIndex, SimpleToolNodeMapping\\n\\ntool_mapping = SimpleToolNodeMapping.from_objects(list(tool_dict.values()))\\ntool_index = ObjectIndex.from_objects(\\nlist(tool_dict.values()),\\ntool_mapping,\\nVectorStoreIndex,\\n)\\ntool_retriever = tool_index.as_retriever(similarity_top_k=1)\\n```', metadata={'Header 1': 'GPT Builder Demo', 'Header 2': 'Define Candidate Tools', 'Header 3': 'Define Tool Retriever'}),\n",
      " Document(page_content='Here we load wikipedia pages from different cities.', metadata={'Header 1': 'GPT Builder Demo', 'Header 2': 'Define Candidate Tools', 'Header 3': 'Load Data'}),\n",
      " Document(page_content='```python\\nfrom llama_index.prompts import ChatPromptTemplate\\nfrom typing import List\\n\\nGEN_SYS_PROMPT_STR = \"\"\"\\\\\\nTask information is given below.\\n\\nGiven the task, please generate a system prompt for an OpenAI-powered bot to solve this task:\\n{task} \\\\\\n\"\"\"\\n\\ngen_sys_prompt_messages = [\\nChatMessage(\\nrole=\"system\",\\ncontent=\"You are helping to build a system prompt for another bot.\",\\n),\\nChatMessage(role=\"user\", content=GEN_SYS_PROMPT_STR),\\n]\\n\\nGEN_SYS_PROMPT_TMPL = ChatPromptTemplate(gen_sys_prompt_messages)\\n\\n\\nagent_cache = {}\\n\\n\\ndef create_system_prompt(task: str):\\n\"\"\"Create system prompt for another agent given an input task.\"\"\"\\nllm = OpenAI(llm=\"gpt-4\")\\nfmt_messages = GEN_SYS_PROMPT_TMPL.format_messages(task=task)\\nresponse = llm.chat(fmt_messages)\\nreturn response.message.content\\n\\n\\ndef get_tools(task: str):\\n\"\"\"Get the set of relevant tools to use given an input task.\"\"\"\\nsubset_tools = tool_retriever.retrieve(task)\\nreturn [t.metadata.name for t in subset_tools]\\n\\n\\ndef create_agent(system_prompt: str, tool_names: List[str]):\\n\"\"\"Create an agent given a system prompt and an input set of tools.\"\"\"\\nllm = OpenAI(model=\"gpt-4\")\\ntry:\\n# get the list of tools\\ninput_tools = [tool_dict[tn] for tn in tool_names]\\n\\nagent = OpenAIAgent.from_tools(input_tools, llm=llm, verbose=True)\\nagent_cache[\"agent\"] = agent\\nreturn_msg = \"Agent created successfully.\"\\nexcept Exception as e:\\nreturn_msg = f\"An error occurred when building an agent. Here is the error: {repr(e)}\"\\nreturn return_msg\\n```  \\n```python\\nsystem_prompt_tool = FunctionTool.from_defaults(fn=create_system_prompt)\\nget_tools_tool = FunctionTool.from_defaults(fn=get_tools)\\ncreate_agent_tool = FunctionTool.from_defaults(fn=create_agent)\\n```  \\n```python\\nGPT_BUILDER_SYS_STR = \"\"\"\\\\\\nYou are helping to construct an agent given a user-specified task. You should generally use the tools in this order to build the agent.\\n\\n1) Create system prompt tool: to create the system prompt for the agent.\\n2) Get tools tool: to fetch the candidate set of tools to use.\\n3) Create agent tool: to create the final agent.\\n\"\"\"\\n\\nprefix_msgs = [ChatMessage(role=\"system\", content=GPT_BUILDER_SYS_STR)]', metadata={'Header 1': 'GPT Builder Demo', 'Header 2': 'Define Meta-Tools for GPT Builder'}),\n",
      " Document(page_content='prefix_msgs = [ChatMessage(role=\"system\", content=GPT_BUILDER_SYS_STR)]\\n\\n\\nbuilder_agent = OpenAIAgent.from_tools(\\ntools=[system_prompt_tool, get_tools_tool, create_agent_tool],\\nllm=llm,\\nprefix_messages=prefix_msgs,\\nverbose=True,\\n)\\n```  \\n```python\\nbuilder_agent.query(\"Build an agent that can tell me about Toronto.\")\\n```  \\n=== Calling Function ===\\nCalling function: create_system_prompt with args: {\\n\"task\": \"tell me about Toronto\"\\n}\\nGot output: System Prompt:  \\n\"Sure, I can provide you with information about Toronto. Toronto is the capital city of the province of Ontario, Canada. It is the largest city in Canada and one of the most multicultural cities in the world. Known for its diverse population, vibrant arts scene, and thriving business community, Toronto offers a wide range of attractions and experiences.  \\nToronto is home to iconic landmarks such as the CN Tower, which offers breathtaking views of the city, and the Royal Ontario Museum, which houses an extensive collection of art, culture, and natural history. The city also boasts beautiful waterfront areas, including the Harbourfront Centre and the Toronto Islands, where visitors can enjoy outdoor activities and scenic views.  \\nIn terms of culture, Toronto hosts numerous festivals throughout the year, including the Toronto International Film Festival, Caribana, and Nuit Blanche. The city is also known for its world-class dining scene, offering a diverse range of cuisines from around the globe.  \\nToronto is a major economic hub, with a strong presence in industries such as finance, technology, and healthcare. It is home to the Toronto Stock Exchange and several multinational corporations. The city\\'s robust public transportation system, including the TTC subway and streetcar network, makes it easy to navigate and explore.  \\nWhether you\\'re interested in exploring its cultural attractions, enjoying its culinary delights, or experiencing its vibrant nightlife, Toronto has something to offer for everyone. How can I assist you further in discovering more about Toronto?\"\\n========================\\n=== Calling Function ===\\nCalling function: get_tools with args: {\\n\"task\": \"tell me about Toronto\"\\n}\\nGot output: [\\'Toronto\\']\\n========================\\n=== Calling Function ===\\nCalling function: create_agent with args: {\\n\"system_prompt\": \"Sure, I can provide you with information about Toronto. Toronto is the capital city of the province of Ontario, Canada. It is the largest city in Canada and one of the most multicultural cities in the world. Known for its diverse population, vibrant arts scene, and thriving business community, Toronto offers a wide range of attractions and experiences.\\\\n\\\\nToronto is home to iconic landmarks such as the CN Tower, which offers breathtaking views of the city, and the Royal Ontario Museum, which houses an extensive collection of art, culture, and natural history. The city also boasts beautiful waterfront areas, including the Harbourfront Centre and the Toronto Islands, where visitors can enjoy outdoor activities and scenic views.\\\\n\\\\nIn terms of culture, Toronto hosts numerous festivals throughout the year, including the Toronto International Film Festival, Caribana, and Nuit Blanche. The city is also known for its world-class dining scene, offering a diverse range of cuisines from around the globe.\\\\n\\\\nToronto is a major economic hub, with a strong presence in industries such as finance, technology, and healthcare. It is home to the Toronto Stock Exchange and several multinational corporations. The city\\'s robust public transportation system, including the TTC subway and streetcar network, makes it easy to navigate and explore.\\\\n\\\\nWhether you\\'re interested in exploring its cultural attractions, enjoying its culinary delights, or experiencing its vibrant nightlife, Toronto has something to offer for everyone. How can I assist you further in discovering more about Toronto?\",\\n\"tool_names\": [\"Toronto\"]\\n}\\nGot output: Agent created successfully.\\n========================  \\nResponse(response=\\'The agent has been successfully created. It can provide detailed information about Toronto, including its landmarks, culture, economy, and transportation.\\', source_nodes=[], metadata=None)  \\n```python\\ncity_agent = agent_cache[\"agent\"]\\n```  \\n```python\\nresponse = city_agent.query(\"Tell me about the parks in Toronto\")\\nprint(str(response))\\n```  \\n=== Calling Function ===\\nCalling function: Toronto with args: {\\n\"input\": \"parks in Toronto\"\\n}\\nGot output: Toronto has a wide variety of public parks and spaces. Some of the downtown parks include Allan Gardens, Christie Pits, Grange Park, Little Norway Park, Moss Park, Queen\\'s Park, Riverdale Park and Trinity Bellwoods Park. There are also two large parks on the waterfront south of downtown: Tommy Thompson Park and the Toronto Islands. Other large parks managed by the city in the outer areas include High Park, Humber Bay Park, Centennial Park, Downsview Park, Guild Park and Gardens, Sunnybrook Park and Morningside Park. Toronto also has parts of Rouge National Urban Park, the largest urban park in North America, which is managed by Parks Canada.\\n========================\\nToronto is home to a variety of parks, offering a mix of natural beauty, recreational activities, and cultural experiences. Here are some of the notable parks in Toronto:  \\n1. **Allan Gardens**: Located downtown, this park features a conservatory with six greenhouses showcasing rare botanical plants.  \\n2. **Christie Pits**: Known for its outdoor pool and artificial ice rink, this park is a popular spot for sports and leisure.  \\n3. **Grange Park**: This park is located in the heart of the city and offers a playground, a splash pad, and a dog off-leash area.  \\n4. **Little Norway Park**: Overlooking the waterfront, this park features a playground, a wading pool, and a baseball diamond.  \\n5. **Moss Park**: This downtown park has a large sports field, a playground, and a splash pad.  \\n6. **Queen\\'s Park**: This urban park is home to the Ontario Legislative Building and several monuments.  \\n7. **Riverdale Park**: Offering panoramic views of downtown Toronto, this park has sports fields, a swimming pool, and a large off-leash dog area.  \\n8. **Trinity Bellwoods Park**: This popular park features a variety of recreational facilities, including sports fields, a wading pool, and a children\\'s playground.  \\n9. **Tommy Thompson Park**: Located on the waterfront, this park is a popular spot for bird watching and nature walks.  \\n10. **Toronto Islands**: This group of small islands offers beaches, picnic areas, and canoe rentals.  \\n11. **High Park**: Toronto\\'s largest public park, featuring hiking trails, sports facilities, a beautiful lakefront, a dog park, a zoo, and several playgrounds.  \\n12. **Humber Bay Park**: This waterfront park offers stunning views of the Toronto skyline, a butterfly habitat, and a network of trails.  \\n13. **Centennial Park**: One of Toronto\\'s busiest parks, featuring a conservatory, a ski hill, a golf centre, and a multipurpose sports field.  \\n14. **Downsview Park**: Once a military base, now a dynamic urban park with sports fields, a pond, and a forested area.  \\n15. **Guild Park and Gardens**: Known for its collection of salvaged architectural pieces, this park offers a unique blend of nature and culture.  \\n16. **Sunnybrook Park**: This park offers a variety of sports fields, horse stables, and a dog off-leash area.  \\n17. **Morningside Park**: One of Toronto\\'s largest parks, featuring picnic areas, walking trails, and a creek.  \\n18. **Rouge National Urban Park**: Managed by Parks Canada, this is the largest urban park in North America, offering a mix of wilderness, farmland, and historical sites.', metadata={'Header 1': 'GPT Builder Demo', 'Header 2': 'Define Meta-Tools for GPT Builder'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/Chatbot_SEC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>'),\n",
      " Document(page_content=\"LlamaIndex serves as a bridge between your data and Language Learning Models (LLMs), providing a toolkit that enables you to establish a query interface around your data for a variety of tasks, such as question-answering and summarization.  \\nIn this tutorial, we'll walk you through building a context-augmented chatbot using a [Data Agent](https://gpt-index.readthedocs.io/en/stable/core_modules/agent_modules/agents/root.html). This agent, powered by LLMs, is capable of intelligently executing tasks over your data. The end result is a chatbot agent equipped with a robust set of data interface tools provided by LlamaIndex to answer queries about your data.  \\n**Note**: This tutorial builds upon initial work on creating a query interface over SEC 10-K filings - [check it out here](https://medium.com/@jerryjliu98/how-unstructured-and-llamaindex-can-help-bring-the-power-of-llms-to-your-own-data-3657d063e30d).\", metadata={'Header 1': '💬🤖 How to Build a Chatbot'}),\n",
      " Document(page_content='In this guide, we’ll build a \"10-K Chatbot\" that uses raw UBER 10-K HTML filings from Dropbox. Users can interact with the chatbot to ask questions related to the 10-K filings.', metadata={'Header 1': '💬🤖 How to Build a Chatbot', 'Header 3': 'Context'}),\n",
      " Document(page_content='```python\\nimport os\\nimport openai\\n\\nos.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\\nopenai.api_key = os.environ[\"OPENAI_API_KEY\"]\\n\\nimport nest_asyncio\\n\\nnest_asyncio.apply()\\n```  \\n```python\\n# set text wrapping\\nfrom IPython.display import HTML, display\\n\\n\\ndef set_css():\\ndisplay(\\nHTML(\\n\"\"\"\\n<style>\\npre {\\nwhite-space: pre-wrap;\\n}\\n</style>\\n\"\"\"\\n)\\n)\\n\\n\\nget_ipython().events.register(\"pre_run_cell\", set_css)\\n```', metadata={'Header 1': '💬🤖 How to Build a Chatbot', 'Header 3': 'Preparation'}),\n",
      " Document(page_content='Let\\'s first download the raw 10-k files, from 2019-2022.  \\n```python\\n# NOTE: the code examples assume you\\'re operating within a Jupyter notebook.\\n# download files\\n!mkdir data\\n!wget \"https://www.dropbox.com/s/948jr9cfs7fgj99/UBER.zip?dl=1\" -O data/UBER.zip\\n!unzip data/UBER.zip -d data\\n```  \\n<style>\\npre {\\nwhite-space: pre-wrap;\\n}\\n</style>  \\n--2023-09-22 11:13:42--  https://www.dropbox.com/s/948jr9cfs7fgj99/UBER.zip?dl=1\\nResolving www.dropbox.com (www.dropbox.com)... 2620:100:601f:18::a27d:912, 162.125.5.18\\nConnecting to www.dropbox.com (www.dropbox.com)|2620:100:601f:18::a27d:912|:443... connected.\\nHTTP request sent, awaiting response... 302 Found\\nLocation: /s/dl/948jr9cfs7fgj99/UBER.zip [following]\\n--2023-09-22 11:13:43--  https://www.dropbox.com/s/dl/948jr9cfs7fgj99/UBER.zip\\nReusing existing connection to [www.dropbox.com]:443.\\nHTTP request sent, awaiting response... 302 Found\\nLocation: https://uc5e96fc71f5bcad342d7ef5261b.dl.dropboxusercontent.com/cd/0/get/CEMPMHdxNS2yZDvMeO8IVhjAHBo1ExUFCUxxR3rUUAuuAn2VBlNyyyzCCERRU4Uj9cVyRgHADCluk4Kqqe1NWdxiC1Uh1u85EJEPIlVuW1gK9-KC3EcD0tD7u21w14I6d80gfspvvfKJCFzc15556zTV/file?dl=1# [following]\\n--2023-09-22 11:13:43--  https://uc5e96fc71f5bcad342d7ef5261b.dl.dropboxusercontent.com/cd/0/get/CEMPMHdxNS2yZDvMeO8IVhjAHBo1ExUFCUxxR3rUUAuuAn2VBlNyyyzCCERRU4Uj9cVyRgHADCluk4Kqqe1NWdxiC1Uh1u85EJEPIlVuW1gK9-KC3EcD0tD7u21w14I6d80gfspvvfKJCFzc15556zTV/file?dl=1\\nResolving uc5e96fc71f5bcad342d7ef5261b.dl.dropboxusercontent.com (uc5e96fc71f5bcad342d7ef5261b.dl.dropboxusercontent.com)... 2620:100:601f:15::a27d:90f, 162.125.5.15\\nConnecting to uc5e96fc71f5bcad342d7ef5261b.dl.dropboxusercontent.com (uc5e96fc71f5bcad342d7ef5261b.dl.dropboxusercontent.com)|2620:100:601f:15::a27d:90f|:443... connected.\\nHTTP request sent, awaiting response... 200 OK\\nLength: 1820227 (1,7M) [application/binary]\\nSaving to: ‘data/UBER.zip’  \\ndata/UBER.zip       100%[===================>]   1,74M  3,12MB/s    in 0,6s  \\n2023-09-22 11:13:45 (3,12 MB/s) - ‘data/UBER.zip’ saved [1820227/1820227]  \\nArchive:  data/UBER.zip\\ncreating: data/UBER/\\ninflating: data/UBER/UBER_2021.html\\ninflating: data/__MACOSX/UBER/._UBER_2021.html\\ninflating: data/UBER/UBER_2020.html\\ninflating: data/__MACOSX/UBER/._UBER_2020.html\\ninflating: data/UBER/UBER_2019.html\\ninflating: data/__MACOSX/UBER/._UBER_2019.html\\ninflating: data/UBER/UBER_2022.html\\ninflating: data/__MACOSX/UBER/._UBER_2022.html  \\nTo parse the HTML files into formatted text, we use the [Unstructured](https://github.com/Unstructured-IO/unstructured) library. Thanks to [LlamaHub](https://llamahub.ai/), we can directly integrate with Unstructured, allowing conversion of any text into a Document format that LlamaIndex can ingest.  \\nFirst we install the necessary packages:  \\n```python\\n!pip install llama-hub unstructured\\n```  \\n<style>\\npre {\\nwhite-space: pre-wrap;\\n}\\n</style>  \\nCollecting llama-hub\\nObtaining dependency information for llama-hub from https://files.pythonhosted.org/packages/3f/af/3bc30c2b7ca1bdd7a193f67443539f6667a6b77dd62e54f2c5c8464ad4cb/llama_hub-0.0.31-py3-none-any.whl.metadata\\nDownloading llama_hub-0.0.31-py3-none-any.whl.metadata (8.8 kB)\\nRequirement already satisfied: unstructured in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (0.10.15)\\nCollecting atlassian-python-api (from llama-hub)\\nObtaining dependency information for atlassian-python-api from https://files.pythonhosted.org/packages/ca/ed/3577ccec639736c8e4660423be68cf1a4a7040bf543b3144793760792949/atlassian_python_api-3.41.2-py3-none-any.whl.metadata\\nDownloading atlassian_python_api-3.41.2-py3-none-any.whl.metadata (8.7 kB)\\nCollecting html2text (from llama-hub)\\nDownloading html2text-2020.1.16-py3-none-any.whl (32 kB)\\nRequirement already satisfied: llama-index>=0.6.9 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from llama-hub) (0.8.29.post1)\\nRequirement already satisfied: psutil in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from llama-hub) (5.9.5)\\nCollecting retrying (from llama-hub)\\nDownloading retrying-1.3.4-py3-none-any.whl (11 kB)\\nRequirement already satisfied: chardet in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from unstructured) (5.2.0)\\nRequirement already satisfied: filetype in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from unstructured) (1.2.0)\\nRequirement already satisfied: python-magic in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from unstructured) (0.4.27)\\nRequirement already satisfied: lxml in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from unstructured) (4.9.3)\\nRequirement already satisfied: nltk in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from unstructured) (3.8.1)\\nRequirement already satisfied: tabulate in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from unstructured) (0.9.0)\\nRequirement already satisfied: requests in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from unstructured) (2.31.0)\\nRequirement already satisfied: beautifulsoup4 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from unstructured) (4.12.2)\\nRequirement already satisfied: emoji in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from unstructured) (2.8.0)\\nRequirement already satisfied: dataclasses-json in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from unstructured) (0.5.14)\\nRequirement already satisfied: tiktoken in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from llama-index>=0.6.9->llama-hub) (0.5.1)\\nRequirement already satisfied: langchain>=0.0.293 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from llama-index>=0.6.9->llama-hub) (0.0.295)\\nRequirement already satisfied: sqlalchemy>=2.0.15 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from llama-index>=0.6.9->llama-hub) (2.0.21)\\nRequirement already satisfied: numpy in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from llama-index>=0.6.9->llama-hub) (1.26.0)\\nRequirement already satisfied: tenacity<9.0.0,>=8.2.0 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from llama-index>=0.6.9->llama-hub) (8.2.3)\\nRequirement already satisfied: openai>=0.26.4 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from llama-index>=0.6.9->llama-hub) (0.28.0)\\nRequirement already satisfied: pandas in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from llama-index>=0.6.9->llama-hub) (2.1.0)\\nRequirement already satisfied: urllib3<2 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from llama-index>=0.6.9->llama-hub) (1.26.16)\\nRequirement already satisfied: fsspec>=2023.5.0 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from llama-index>=0.6.9->llama-hub) (2023.9.1)\\nRequirement already satisfied: typing-inspect>=0.8.0 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from llama-index>=0.6.9->llama-hub) (0.9.0)\\nRequirement already satisfied: typing-extensions>=4.5.0 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from llama-index>=0.6.9->llama-hub) (4.8.0)\\nRequirement already satisfied: nest-asyncio in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from llama-index>=0.6.9->llama-hub) (1.5.8)\\nCollecting deprecated (from atlassian-python-api->llama-hub)\\nObtaining dependency information for deprecated from https://files.pythonhosted.org/packages/20/8d/778b7d51b981a96554f29136cd59ca7880bf58094338085bcf2a979a0e6a/Deprecated-1.2.14-py2.py3-none-any.whl.metadata\\nDownloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\\nRequirement already satisfied: six in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from atlassian-python-api->llama-hub) (1.16.0)\\nRequirement already satisfied: oauthlib in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from atlassian-python-api->llama-hub) (3.2.2)', metadata={'Header 1': '💬🤖 How to Build a Chatbot', 'Header 3': 'Ingest Data'}),\n",
      " Document(page_content='Requirement already satisfied: requests-oauthlib in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from atlassian-python-api->llama-hub) (1.3.1)\\nRequirement already satisfied: soupsieve>1.2 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from beautifulsoup4->unstructured) (2.5)\\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from dataclasses-json->unstructured) (3.20.1)\\nRequirement already satisfied: click in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from nltk->unstructured) (8.1.7)\\nRequirement already satisfied: joblib in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from nltk->unstructured) (1.3.2)\\nRequirement already satisfied: regex>=2021.8.3 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from nltk->unstructured) (2023.8.8)\\nRequirement already satisfied: tqdm in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from nltk->unstructured) (4.66.1)\\nRequirement already satisfied: charset-normalizer<4,>=2 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from requests->unstructured) (3.2.0)\\nRequirement already satisfied: idna<4,>=2.5 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from requests->unstructured) (3.4)\\nRequirement already satisfied: certifi>=2017.4.17 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from requests->unstructured) (2023.7.22)\\nRequirement already satisfied: PyYAML>=5.3 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from langchain>=0.0.293->llama-index>=0.6.9->llama-hub) (6.0.1)\\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from langchain>=0.0.293->llama-index>=0.6.9->llama-hub) (3.8.5)\\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from langchain>=0.0.293->llama-index>=0.6.9->llama-hub) (4.0.3)\\nRequirement already satisfied: langsmith<0.1.0,>=0.0.38 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from langchain>=0.0.293->llama-index>=0.6.9->llama-hub) (0.0.38)\\nRequirement already satisfied: numexpr<3.0.0,>=2.8.4 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from langchain>=0.0.293->llama-index>=0.6.9->llama-hub) (2.8.6)\\nRequirement already satisfied: pydantic<3,>=1 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from langchain>=0.0.293->llama-index>=0.6.9->llama-hub) (1.10.12)\\nRequirement already satisfied: packaging>=17.0 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured) (23.1)\\nRequirement already satisfied: greenlet!=0.4.17 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from sqlalchemy>=2.0.15->llama-index>=0.6.9->llama-hub) (2.0.2)\\nRequirement already satisfied: mypy-extensions>=0.3.0 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index>=0.6.9->llama-hub) (1.0.0)\\nRequirement already satisfied: wrapt<2,>=1.10 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from deprecated->atlassian-python-api->llama-hub) (1.15.0)\\nRequirement already satisfied: python-dateutil>=2.8.2 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from pandas->llama-index>=0.6.9->llama-hub) (2.8.2)\\nRequirement already satisfied: pytz>=2020.1 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from pandas->llama-index>=0.6.9->llama-hub) (2023.3.post1)\\nRequirement already satisfied: tzdata>=2022.1 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from pandas->llama-index>=0.6.9->llama-hub) (2023.3)\\nRequirement already satisfied: attrs>=17.3.0 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.293->llama-index>=0.6.9->llama-hub) (23.1.0)\\nRequirement already satisfied: multidict<7.0,>=4.5 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.293->llama-index>=0.6.9->llama-hub) (6.0.4)\\nRequirement already satisfied: yarl<2.0,>=1.0 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.293->llama-index>=0.6.9->llama-hub) (1.9.2)\\nRequirement already satisfied: frozenlist>=1.1.1 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.293->llama-index>=0.6.9->llama-hub) (1.4.0)\\nRequirement already satisfied: aiosignal>=1.1.2 in /home/jtorres/llama_index/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.293->llama-index>=0.6.9->llama-hub) (1.3.1)\\nDownloading llama_hub-0.0.31-py3-none-any.whl (9.8 MB)\\n\\x1b[2K   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m9.8/9.8 MB\\x1b[0m \\x1b[31m16.4 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m00:01\\x1b[0m00:01\\x1b[0m\\n\\x1b[?25hDownloading atlassian_python_api-3.41.2-py3-none-any.whl (167 kB)\\n\\x1b[2K   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m167.2/167.2 kB\\x1b[0m \\x1b[31m20.8 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m\\n\\x1b[?25hDownloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\\nInstalling collected packages: retrying, html2text, deprecated, atlassian-python-api, llama-hub\\nSuccessfully installed atlassian-python-api-3.41.2 deprecated-1.2.14 html2text-2020.1.16 llama-hub-0.0.31 retrying-1.3.4  \\nThen we can use the `UnstructuredReader` to parse the HTML files into a list of `Document` objects.  \\n```python\\nfrom llama_hub.file.unstructured.base import UnstructuredReader\\nfrom pathlib import Path', metadata={'Header 1': '💬🤖 How to Build a Chatbot', 'Header 3': 'Ingest Data'}),\n",
      " Document(page_content='years = [2022, 2021, 2020, 2019]\\n\\nloader = UnstructuredReader()\\ndoc_set = {}\\nall_docs = []\\nfor year in years:\\nyear_docs = loader.load_data(\\nfile=Path(f\"./data/UBER/UBER_{year}.html\"), split_documents=False\\n)\\n# insert year metadata into each year\\nfor d in year_docs:\\nd.metadata = {\"year\": year}\\ndoc_set[year] = year_docs\\nall_docs.extend(year_docs)\\n```  \\n<style>\\npre {\\nwhite-space: pre-wrap;\\n}\\n</style>  \\n[nltk_data] Downloading package punkt to /home/jtorres/nltk_data...\\n[nltk_data]   Package punkt is already up-to-date!\\n[nltk_data] Downloading package averaged_perceptron_tagger to\\n[nltk_data]     /home/jtorres/nltk_data...\\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\\n[nltk_data]       date!', metadata={'Header 1': '💬🤖 How to Build a Chatbot', 'Header 3': 'Ingest Data'}),\n",
      " Document(page_content='We first setup a vector index for each year. Each vector index allows us\\nto ask questions about the 10-K filing of a given year.  \\nWe build each index and save it to disk.  \\n```python\\n# initialize simple vector indices\\n# NOTE: don\\'t run this cell if the indices are already loaded!\\nfrom llama_index import VectorStoreIndex, ServiceContext, StorageContext\\n\\nindex_set = {}\\nservice_context = ServiceContext.from_defaults(chunk_size=512)\\nfor year in years:\\nstorage_context = StorageContext.from_defaults()\\ncur_index = VectorStoreIndex.from_documents(\\ndoc_set[year],\\nservice_context=service_context,\\nstorage_context=storage_context,\\n)\\nindex_set[year] = cur_index\\nstorage_context.persist(persist_dir=f\"./storage/{year}\")\\n```  \\n<style>\\npre {\\nwhite-space: pre-wrap;\\n}\\n</style>  \\nTo load an index from disk, do the following  \\n```python\\n# Load indices from disk\\nfrom llama_index import load_index_from_storage\\n\\nindex_set = {}\\nfor year in years:\\nstorage_context = StorageContext.from_defaults(\\npersist_dir=f\"./storage/{year}\"\\n)\\ncur_index = load_index_from_storage(\\nstorage_context, service_context=service_context\\n)\\nindex_set[year] = cur_index\\n```  \\n<style>\\npre {\\nwhite-space: pre-wrap;\\n}\\n</style>', metadata={'Header 1': '💬🤖 How to Build a Chatbot', 'Header 3': 'Setting up Vector Indices for each year'}),\n",
      " Document(page_content='Since we have access to documents of 4 years, we may not only want to ask questions regarding the 10-K document of a given year, but ask questions that require analysis over all 10-K filings.  \\nTo address this, we can use a [Sub Question Query Engine](https://gpt-index.readthedocs.io/en/stable/examples/query_engine/sub_question_query_engine.html). It decomposes a query into subqueries, each answered by an individual vector index, and synthesizes the results to answer the overall query.  \\nLlamaIndex provides some wrappers around indices (and query engines) so that they can be used by query engines and agents. First we define a `QueryEngineTool` for each vector index.\\nEach tool has a name and a description; these are what the LLM agent sees to decide which tool to choose.  \\n```python\\nfrom llama_index.tools import QueryEngineTool, ToolMetadata\\n\\nindividual_query_engine_tools = [\\nQueryEngineTool(\\nquery_engine=index_set[year].as_query_engine(),\\nmetadata=ToolMetadata(\\nname=f\"vector_index_{year}\",\\ndescription=(\\n\"useful for when you want to answer queries about the\"\\nf\" {year} SEC 10-K for Uber\"\\n),\\n),\\n)\\nfor year in years\\n]\\n```  \\n<style>\\npre {\\nwhite-space: pre-wrap;\\n}\\n</style>  \\nNow we can create the Sub Question Query Engine, which will allow us to synthesize answers across the 10-K filings. We pass in the `individual_query_engine_tools` we defined above, as well as a `service_context` that will be used to run the subqueries.  \\n```python\\nfrom llama_index.query_engine import SubQuestionQueryEngine\\n\\nquery_engine = SubQuestionQueryEngine.from_defaults(\\nquery_engine_tools=individual_query_engine_tools,\\nservice_context=service_context,\\n)\\n```  \\n<style>\\npre {\\nwhite-space: pre-wrap;\\n}\\n</style>', metadata={'Header 1': '💬🤖 How to Build a Chatbot', 'Header 3': 'Setting up a Sub Question Query Engine to Synthesize Answers Across 10-K Filings'}),\n",
      " Document(page_content='We use a LlamaIndex Data Agent to setup the outer chatbot agent, which has access to a set of Tools. Specifically, we will use an OpenAIAgent, that takes advantage of OpenAI API function calling. We want to use the separate Tools we defined previously for each index (corresponding to a given year), as well as a tool for the sub question query engine we defined above.  \\nFirst we define a `QueryEngineTool` for the sub question query engine:  \\n```python\\nquery_engine_tool = QueryEngineTool(\\nquery_engine=query_engine,\\nmetadata=ToolMetadata(\\nname=\"sub_question_query_engine\",\\ndescription=(\\n\"useful for when you want to answer queries that require analyzing\"\\n\" multiple SEC 10-K documents for Uber\"\\n),\\n),\\n)\\n```  \\n<style>\\npre {\\nwhite-space: pre-wrap;\\n}\\n</style>  \\nThen, we combine the Tools we defined above into a single list of tools for the agent:  \\n```python\\ntools = individual_query_engine_tools + [query_engine_tool]\\n```  \\n<style>\\npre {\\nwhite-space: pre-wrap;\\n}\\n</style>  \\nFinally, we call `OpenAIAgent.from_tools` to create the agent, passing in the list of tools we defined above.  \\n```python\\nfrom llama_index.agent import OpenAIAgent\\n\\nagent = OpenAIAgent.from_tools(tools, verbose=True)\\n```  \\n<style>\\npre {\\nwhite-space: pre-wrap;\\n}\\n</style>', metadata={'Header 1': '💬🤖 How to Build a Chatbot', 'Header 3': 'Setting up the Chatbot Agent'}),\n",
      " Document(page_content='We can now test the agent with various queries.  \\nIf we test it with a simple \"hello\" query, the agent does not use any Tools.  \\n```python\\nresponse = agent.chat(\"hi, i am bob\")\\nprint(str(response))\\n```  \\n<style>\\npre {\\nwhite-space: pre-wrap;\\n}\\n</style>  \\nHello Bob! How can I assist you today?  \\nIf we test it with a query regarding the 10-k of a given year, the agent will use\\nthe relevant vector index Tool.  \\n```python\\nresponse = agent.chat(\\n\"What were some of the biggest risk factors in 2020 for Uber?\"\\n)\\nprint(str(response))\\n```  \\n<style>\\npre {\\nwhite-space: pre-wrap;\\n}\\n</style>  \\n=== Calling Function ===\\nCalling function: vector_index_2020 with args: {\\n\"input\": \"biggest risk factors\"\\n}\\nGot output: The biggest risk factors mentioned in the context are:\\n1. The adverse impact of the COVID-19 pandemic and actions taken to mitigate it on the business.\\n2. The potential reclassification of drivers as employees, workers, or quasi-employees instead of independent contractors.\\n3. Intense competition in the mobility, delivery, and logistics industries, with low barriers to entry and well-capitalized competitors.\\n4. The need to lower fares or service fees and offer driver incentives and consumer discounts to remain competitive.\\n5. Significant losses incurred and the uncertainty of achieving profitability.\\n6. The risk of not attracting or maintaining a critical mass of platform users.\\n7. Operational, compliance, and cultural challenges related to the workplace culture and forward-leaning approach.\\n8. The potential negative impact of international investments and the challenges of conducting business in foreign countries, including operational and compliance challenges, localization requirements, restrictive laws and regulations, competition from local companies, social acceptance, technological compatibility, improper business practices, legal uncertainty, difficulties in managing international operations, currency exchange rate fluctuations, and regulations governing local currencies.\\n========================\\nIn 2020, some of the biggest risk factors for Uber were:  \\n1. The adverse impact of the COVID-19 pandemic and the measures taken to mitigate it on the business.\\n2. The potential reclassification of drivers as employees, workers, or quasi-employees instead of independent contractors.\\n3. Intense competition in the mobility, delivery, and logistics industries, with low barriers to entry and well-capitalized competitors.\\n4. The need to lower fares or service fees and offer driver incentives and consumer discounts to remain competitive.\\n5. Significant losses incurred and uncertainty about achieving profitability.\\n6. The risk of not attracting or maintaining a critical mass of platform users.\\n7. Operational, compliance, and cultural challenges related to the workplace culture and forward-leaning approach.\\n8. The potential negative impact of international investments and the challenges of conducting business in foreign countries, including operational and compliance challenges, localization requirements, restrictive laws and regulations, competition from local companies, social acceptance, technological compatibility, improper business practices, legal uncertainty, difficulties in managing international operations, currency exchange rate fluctuations, and regulations governing local currencies.  \\nThese risk factors highlight the challenges and uncertainties faced by Uber in 2020.  \\nFinally, if we test it with a query to compare/contrast risk factors across years, the agent will use the Sub Question Query Engine Tool.  \\n```python\\ncross_query_str = (\\n\"Compare/contrast the risk factors described in the Uber 10-K across\"\\n\" years. Give answer in bullet points.\"\\n)', metadata={'Header 1': '💬🤖 How to Build a Chatbot', 'Header 3': 'Testing the Agent'}),\n",
      " Document(page_content='response = agent.chat(cross_query_str)\\nprint(str(response))\\n```  \\n<style>\\npre {\\nwhite-space: pre-wrap;\\n}\\n</style>  \\n=== Calling Function ===\\nCalling function: sub_question_query_engine with args: {\\n\"input\": \"Compare/contrast the risk factors described in the Uber 10-K across years\"\\n}\\nGenerated 4 sub questions.\\n\\x1b[36;1m\\x1b[1;3m[vector_index_2022] Q: What are the risk factors described in the 2022 SEC 10-K for Uber?\\n\\x1b[0m\\x1b[33;1m\\x1b[1;3m[vector_index_2021] Q: What are the risk factors described in the 2021 SEC 10-K for Uber?\\n\\x1b[0m\\x1b[38;5;200m\\x1b[1;3m[vector_index_2020] Q: What are the risk factors described in the 2020 SEC 10-K for Uber?\\n\\x1b[0m\\x1b[32;1m\\x1b[1;3m[vector_index_2019] Q: What are the risk factors described in the 2019 SEC 10-K for Uber?\\n\\x1b[0m\\x1b[36;1m\\x1b[1;3m[vector_index_2022] A: The risk factors described in the 2022 SEC 10-K for Uber include the potential adverse effect on their business if drivers were classified as employees instead of independent contractors, the highly competitive nature of the mobility, delivery, and logistics industries, the need to lower fares or service fees to remain competitive in certain markets, the company\\'s history of significant losses and the expectation of increased operating expenses in the future, and the potential impact on their platform if they are unable to attract or maintain a critical mass of drivers, consumers, merchants, shippers, and carriers.\\n\\x1b[0m\\x1b[32;1m\\x1b[1;3m[vector_index_2019] A: The risk factors described in the 2019 SEC 10-K for Uber include the loss of their license to operate in London, the complexity of their business and operating model due to regulatory uncertainties, the potential for additional regulations for their other products in the Other Bets segment, the evolving laws and regulations regarding the development and deployment of autonomous vehicles, and the increasing number of data protection and privacy laws around the world. Additionally, there are legal proceedings, litigation, claims, and government investigations that Uber is involved in, including those related to the classification of drivers and compliance with applicable laws, which could impose a significant burden on the company.\\n\\x1b[0m\\x1b[33;1m\\x1b[1;3m[vector_index_2021] A: The risk factors described in the 2021 SEC 10-K for Uber include the adverse impact of the COVID-19 pandemic and actions taken to mitigate it on their business, the potential reclassification of drivers as employees instead of independent contractors, intense competition in the mobility, delivery, and logistics industries, the need to lower fares and offer incentives to remain competitive, significant losses incurred and the expectation of increased operating expenses, the importance of attracting and maintaining a critical mass of drivers, consumers, merchants, shippers, and carriers, and the uncertainty surrounding the impact of COVID-19 on their business and financial position. Additionally, the classification of drivers is being challenged in courts and by government agencies, which could have legal and financial implications for the company.\\n\\x1b[0m\\x1b[38;5;200m\\x1b[1;3m[vector_index_2020] A: The risk factors described in the 2020 SEC 10-K for Uber include the adverse impact of the COVID-19 pandemic on their business, the potential reclassification of drivers as employees instead of independent contractors, intense competition in the mobility, delivery, and logistics industries, the need to lower fares and offer incentives to remain competitive, significant losses and the uncertainty of achieving profitability, the importance of attracting and maintaining a critical mass of platform users, operational and compliance challenges, inquiries and investigations from government agencies, risks related to data security breaches, the need to introduce new or upgraded products and features, and the need to invest in the development of new offerings to retain and attract users.\\n\\x1b[0mGot output: The risk factors described in the Uber 10-K reports across the years include the potential reclassification of drivers as employees instead of independent contractors, intense competition in the mobility, delivery, and logistics industries, the need to lower fares and offer incentives to remain competitive, significant losses incurred and the expectation of increased operating expenses, the importance of attracting and maintaining a critical mass of drivers, consumers, merchants, shippers, and carriers, and the impact of the COVID-19 pandemic on their business. Additionally, there are legal and regulatory uncertainties, such as the evolving laws and regulations regarding autonomous vehicles, data protection and privacy laws, and the potential for additional regulations for their other products. The reports also mention the operational and compliance challenges, inquiries and investigations from government agencies, and the risks associated with data security breaches. It is worth noting that specific risk factors may vary from year to year based on the prevailing circumstances and developments in the industry and regulatory environment.\\n========================\\nHere are the key points comparing and contrasting the risk factors described in the Uber 10-K reports across years:  \\n2022:\\n- Potential reclassification of drivers as employees instead of independent contractors.\\n- Intense competition in the mobility, delivery, and logistics industries.\\n- Need to lower fares and offer incentives to remain competitive.\\n- Significant losses incurred and expectation of increased operating expenses.\\n- Importance of attracting and maintaining a critical mass of drivers, consumers, merchants, shippers, and carriers.\\n- Impact of the COVID-19 pandemic on their business.\\n- Legal and regulatory uncertainties, including evolving laws and regulations regarding autonomous vehicles and data protection and privacy laws.\\n- Operational and compliance challenges.\\n- Inquiries and investigations from government agencies.\\n- Risks associated with data security breaches.  \\n2021:\\n- Similar risk factors as in 2022, including potential reclassification of drivers, intense competition, need to lower fares, significant losses, and the impact of the COVID-19 pandemic.\\n- Emphasis on the importance of maintaining a critical mass of drivers, consumers, merchants, shippers, and carriers.\\n- Mention of legal and regulatory uncertainties, such as evolving laws and regulations regarding autonomous vehicles and data protection and privacy laws.\\n- Operational and compliance challenges.\\n- Inquiries and investigations from government agencies.\\n- Risks associated with data security breaches.  \\n2020:\\n- Similar risk factors as in 2021, including potential reclassification of drivers, intense competition, need to lower fares, significant losses, and the impact of the COVID-19 pandemic.\\n- Emphasis on the importance of maintaining a critical mass of drivers, consumers, merchants, shippers, and carriers.\\n- Mention of legal and regulatory uncertainties, such as evolving laws and regulations regarding autonomous vehicles and data protection and privacy laws.\\n- Operational and compliance challenges.\\n- Inquiries and investigations from government agencies.\\n- Risks associated with data security breaches.  \\n2019:\\n- Similar risk factors as in 2020, including potential reclassification of drivers, intense competition, need to lower fares, significant losses, and the impact of the COVID-19 pandemic.\\n- Emphasis on the importance of maintaining a critical mass of drivers, consumers, merchants, shippers, and carriers.\\n- Mention of legal and regulatory uncertainties, such as evolving laws and regulations regarding autonomous vehicles and data protection and privacy laws.\\n- Operational and compliance challenges.\\n- Inquiries and investigations from government agencies.\\n- Risks associated with data security breaches.  \\nPlease note that these are just the key points, and there may be additional risk factors mentioned in each year\\'s 10-K report.', metadata={'Header 1': '💬🤖 How to Build a Chatbot', 'Header 3': 'Testing the Agent'}),\n",
      " Document(page_content='Now that we have the chatbot setup, it only takes a few more steps to setup a basic interactive loop to chat with our SEC-augmented chatbot!  \\n```python\\nagent = OpenAIAgent.from_tools(tools)  # verbose=False by default\\n\\nwhile True:\\ntext_input = input(\"User: \")\\nif text_input == \"exit\":\\nbreak\\nresponse = agent.chat(text_input)\\nprint(f\"Agent: {response}\")\\n\\n# User: What were some of the legal proceedings against Uber in 2022?\\n```  \\n<style>\\npre {\\nwhite-space: pre-wrap;\\n}\\n</style>  \\nAgent: In 2022, Uber is facing several legal proceedings. Here are some of them:  \\n1. California: The state Attorney General and city attorneys filed a complaint against Uber and Lyft, alleging that drivers are misclassified as independent contractors. A preliminary injunction was issued but stayed pending appeal. The Court of Appeal affirmed the lower court\\'s ruling, and Uber filed a petition for review with the California Supreme Court. However, the Supreme Court declined the petition for review. The lawsuit is ongoing, focusing on claims by the California Attorney General for periods prior to the enactment of Proposition 22.  \\n2. Massachusetts: The Attorney General of Massachusetts filed a complaint against Uber, alleging that drivers are employees entitled to wage and labor law protections. Uber\\'s motion to dismiss the complaint was denied, and a summary judgment motion is pending.  \\n3. New York: Uber is facing allegations of misclassification and employment violations by the state Attorney General. The resolution of this matter is uncertain.  \\n4. Switzerland: Several administrative bodies in Switzerland have issued rulings classifying Uber drivers as employees for social security or labor purposes. Uber is challenging these rulings before the Social Security and Administrative Tribunals.  \\nThese are some of the legal proceedings against Uber in 2022. The outcomes and potential losses in these cases are uncertain.', metadata={'Header 1': '💬🤖 How to Build a Chatbot', 'Header 3': 'Setting up the Chatbot Loop'}),\n",
      " Document(page_content='In this cookbook we show you how to build a custom agent using LlamaIndex.  \\nThe easiest way to build a custom agent is to simply subclass `CustomSimpleAgentWorker` and implement a few required functions. You have complete flexibility in defining the agent step-wise logic.  \\nThis lets you add arbitrarily complex reasoning logic on top of your RAG pipeline.  \\nWe show you how to build a simple agent that adds a retry layer on top of a RouterQueryEngine, allowing it to retry queries until the task is complete. We build this on top of both a SQL tool and a vector index query tool. Even if the tool makes an error or only answers part of the question, the agent can continue retrying the question until the task is complete.', metadata={'Header 1': 'Building a Custom Agent'}),\n",
      " Document(page_content='Here we setup the custom agent.', metadata={'Header 1': 'Building a Custom Agent', 'Header 2': 'Setup the Custom Agent'}),\n",
      " Document(page_content=\"An agent in LlamaIndex consists of both an agent runner + agent worker. An agent runner is an orchestrator that stores state like memory, whereas an agent worker controls the step-wise execution of a Task. Agent runners include sequential, parallel execution. More details can be found in our [lower level API guide](https://docs.llamaindex.ai/en/latest/module_guides/deploying/agents/agent_runner.html).  \\nMost core agent logic (e.g. ReAct, function calling loops), can be executed in the agent worker. Therefore we've made it easy to subclass an agent worker, letting you plug it into any agent runner.\", metadata={'Header 1': 'Building a Custom Agent', 'Header 2': 'Setup the Custom Agent', 'Header 3': 'Refresher'}),\n",
      " Document(page_content='As mentioned above we subclass `CustomSimpleAgentWorker`. This is a class that already sets up some scaffolding for you. This includes being able to take in tools, callbacks, LLM, and also ensures that the state/steps are properly formatted. In the meantime you mostly have to implement the following functions:  \\n- `_initialize_state`\\n- `_run_step`\\n- `_finalize_task`  \\nSome additional notes:\\n- You can implement `_arun_step` as well if you want to support async chat in the agent.\\n- You can choose to override `__init__` as long as you pass all remaining args, kwargs to `super()`\\n- `CustomSimpleAgentWorker` is implemented as a Pydantic `BaseModel` meaning that you can define your own custom properties as well.  \\nHere are the full set of base properties on each `CustomSimpleAgentWorker` (that you need to/can pass in when constructing your custom agent):\\n- `tools: Sequence[BaseTool]`\\n- `tool_retriever: Optional[ObjectRetriever[BaseTool]]`\\n- `llm: LLM`\\n- `callback_manager: CallbackManager`\\n- `verbose: bool`  \\nNote that `tools` and `tool_retriever` are mutually exclusive, you can only pass in one or the either (e.g. define a static list of tools or define a callable function that returns relevant tools given a user message). You can call `get_tools(message: str)` to return relevant tools given a message.  \\nAll of these properties are accessible via `self` when defining your custom agent.  \\n```python\\nfrom llama_index.agent import CustomSimpleAgentWorker, Task, AgentChatResponse\\nfrom typing import Dict, Any, List, Tuple\\nfrom llama_index.tools import BaseTool, QueryEngineTool\\nfrom llama_index.program import LLMTextCompletionProgram\\nfrom llama_index.output_parsers import PydanticOutputParser\\nfrom llama_index.query_engine import RouterQueryEngine\\nfrom llama_index.prompts import ChatPromptTemplate, PromptTemplate\\nfrom llama_index.selectors import PydanticSingleSelector\\nfrom pydantic import Field, BaseModel\\n```  \\nHere we define some helper variables and methods. E.g. the prompt template to use to detect errors as well as the response format in Pydantic.  \\n```python\\nfrom llama_index.llms import ChatMessage, MessageRole\\n\\nDEFAULT_PROMPT_STR = \"\"\"\\nGiven previous question/response pairs, please determine if an error has occurred in the response, and suggest \\\\\\na modified question that will not trigger the error.\\n\\nExamples of modified questions:\\n- The question itself is modified to elicit a non-erroneous response\\n- The question is augmented with context that will help the downstream system better answer the question.\\n- The question is augmented with examples of negative responses, or other negative questions.\\n\\nAn error means that either an exception has triggered, or the response is completely irrelevant to the question.\\n\\nPlease return the evaluation of the response in the following JSON format.\\n\\n\"\"\"\\n\\n\\ndef get_chat_prompt_template(\\nsystem_prompt: str, current_reasoning: Tuple[str, str]\\n) -> ChatPromptTemplate:\\nsystem_msg = ChatMessage(role=MessageRole.SYSTEM, content=system_prompt)\\nmessages = [system_msg]\\nfor raw_msg in current_reasoning:\\nif raw_msg[0] == \"user\":\\nmessages.append(\\nChatMessage(role=MessageRole.USER, content=raw_msg[1])\\n)\\nelse:\\nmessages.append(\\nChatMessage(role=MessageRole.ASSISTANT, content=raw_msg[1])\\n)\\nreturn ChatPromptTemplate(message_templates=messages)\\n\\n\\nclass ResponseEval(BaseModel):\\n\"\"\"Evaluation of whether the response has an error.\"\"\"\\n\\nhas_error: bool = Field(\\n..., description=\"Whether the response has an error.\"\\n)\\nnew_question: str = Field(..., description=\"The suggested new question.\")\\nexplanation: str = Field(\\n...,\\ndescription=(\\n\"The explanation for the error as well as for the new question.\"\\n\"Can include the direct stack trace as well.\"\\n),\\n)\\n```  \\n```python\\nfrom pydantic import PrivateAttr\\n\\n\\nclass RetryAgentWorker(CustomSimpleAgentWorker):\\n\"\"\"Agent worker that adds a retry layer on top of a router.\\n\\nContinues iterating until there\\'s no errors / task is done.\\n\\n\"\"\"\\n\\nprompt_str: str = Field(default=DEFAULT_PROMPT_STR)\\nmax_iterations: int = Field(default=10)\\n\\n_router_query_engine: RouterQueryEngine = PrivateAttr()\\n\\ndef __init__(self, tools: List[BaseTool], **kwargs: Any) -> None:\\n\"\"\"Init params.\"\"\"\\n# validate that all tools are query engine tools\\nfor tool in tools:\\nif not isinstance(tool, QueryEngineTool):\\nraise ValueError(\\nf\"Tool {tool.metadata.name} is not a query engine tool.\"\\n)\\nself._router_query_engine = RouterQueryEngine(\\nselector=PydanticSingleSelector.from_defaults(),\\nquery_engine_tools=tools,\\nverbose=kwargs.get(\"verbose\", False),\\n)\\nsuper().__init__(\\ntools=tools,\\n**kwargs,\\n)\\n\\ndef _initialize_state(self, task: Task, **kwargs: Any) -> Dict[str, Any]:\\n\"\"\"Initialize state.\"\"\"\\nreturn {\"count\": 0, \"current_reasoning\": []}\\n\\ndef _run_step(\\nself, state: Dict[str, Any], task: Task\\n) -> Tuple[AgentChatResponse, bool]:\\n\"\"\"Run step.\\n\\nReturns:\\nTuple of (agent_response, is_done)\\n\\n\"\"\"\\nif \"new_input\" not in state:\\nnew_input = task.input\\nelse:\\nnew_input = state[\"new_input\"]\\n\\n# first run router query engine\\nresponse = self._router_query_engine.query(new_input)\\n\\n# append to current reasoning\\nstate[\"current_reasoning\"].extend(\\n[(\"user\", new_input), (\"assistant\", str(response))]\\n)\\n\\n# Then, check for errors\\n# dynamically create pydantic program for structured output extraction based on template\\nchat_prompt_tmpl = get_chat_prompt_template(\\nself.prompt_str, state[\"current_reasoning\"]\\n)\\nllm_program = LLMTextCompletionProgram.from_defaults(\\noutput_parser=PydanticOutputParser(output_cls=ResponseEval),\\nprompt=chat_prompt_tmpl,\\nllm=self.llm,\\n)\\n# run program, look at the result\\nresponse_eval = llm_program(\\nquery_str=new_input, response_str=str(response)\\n)\\nif not response_eval.has_error:\\nis_done = True\\nelse:\\nis_done = False\\nstate[\"new_input\"] = response_eval.new_question\\n\\nif self.verbose:\\nprint(f\"> Question: {new_input}\")\\nprint(f\"> Response: {response}\")\\nprint(f\"> Response eval: {response_eval.dict()}\")\\n\\n# return response\\nreturn AgentChatResponse(response=str(response)), is_done\\n\\ndef _finalize_task(self, state: Dict[str, Any], **kwargs) -> None:\\n\"\"\"Finalize task.\"\"\"\\n# nothing to finalize here\\n# this is usually if you want to modify any sort of\\n# internal state beyond what is set in `_initialize_state`\\npass\\n```', metadata={'Header 1': 'Building a Custom Agent', 'Header 2': 'Setup the Custom Agent', 'Header 3': 'Creating a Custom Agent Worker Subclass'}),\n",
      " Document(page_content='We setup both a SQL Tool as well as vector index tools for each city.  \\n```python\\nfrom llama_index.tools.query_engine import QueryEngineTool\\n```', metadata={'Header 1': 'Building a Custom Agent', 'Header 2': 'Setup Data and Tools'}),\n",
      " Document(page_content='```python\\nfrom sqlalchemy import (\\ncreate_engine,\\nMetaData,\\nTable,\\nColumn,\\nString,\\nInteger,\\nselect,\\ncolumn,\\n)\\nfrom llama_index import SQLDatabase\\n\\nengine = create_engine(\"sqlite:///:memory:\", future=True)\\nmetadata_obj = MetaData()\\n# create city SQL table\\ntable_name = \"city_stats\"\\ncity_stats_table = Table(\\ntable_name,\\nmetadata_obj,\\nColumn(\"city_name\", String(16), primary_key=True),\\nColumn(\"population\", Integer),\\nColumn(\"country\", String(16), nullable=False),\\n)\\n\\nmetadata_obj.create_all(engine)\\n```  \\n```python\\nfrom sqlalchemy import insert\\n\\nrows = [\\n{\"city_name\": \"Toronto\", \"population\": 2930000, \"country\": \"Canada\"},\\n{\"city_name\": \"Tokyo\", \"population\": 13960000, \"country\": \"Japan\"},\\n{\"city_name\": \"Berlin\", \"population\": 3645000, \"country\": \"Germany\"},\\n]\\nfor row in rows:\\nstmt = insert(city_stats_table).values(**row)\\nwith engine.begin() as connection:\\ncursor = connection.execute(stmt)\\n```  \\n```python\\nfrom llama_index.indices.struct_store.sql_query import NLSQLTableQueryEngine\\n\\nsql_database = SQLDatabase(engine, include_tables=[\"city_stats\"])\\nsql_query_engine = NLSQLTableQueryEngine(\\nsql_database=sql_database, tables=[\"city_stats\"], verbose=True\\n)\\nsql_tool = QueryEngineTool.from_defaults(\\nquery_engine=sql_query_engine,\\ndescription=(\\n\"Useful for translating a natural language query into a SQL query over\"\\n\" a table containing: city_stats, containing the population/country of\"\\n\" each city\"\\n),\\n)\\n```', metadata={'Header 1': 'Building a Custom Agent', 'Header 2': 'Setup Data and Tools', 'Header 3': 'Setup SQL DB + Tool'}),\n",
      " Document(page_content='```python\\nfrom llama_index.readers import WikipediaReader\\nfrom llama_index import VectorStoreIndex\\n```  \\n```python\\ncities = [\"Toronto\", \"Berlin\", \"Tokyo\"]\\nwiki_docs = WikipediaReader().load_data(pages=cities)\\n```  \\n```python\\n# build a separate vector index per city\\n# You could also choose to define a single vector index across all docs, and annotate each chunk by metadata\\nvector_tools = []\\nfor city, wiki_doc in zip(cities, wiki_docs):\\nvector_index = VectorStoreIndex.from_documents([wiki_doc])\\nvector_query_engine = vector_index.as_query_engine()\\nvector_tool = QueryEngineTool.from_defaults(\\nquery_engine=vector_query_engine,\\ndescription=f\"Useful for answering semantic questions about {city}\",\\n)\\nvector_tools.append(vector_tool)\\n```', metadata={'Header 1': 'Building a Custom Agent', 'Header 2': 'Setup Data and Tools', 'Header 3': 'Setup Vector Tools'}),\n",
      " Document(page_content='```python\\nfrom llama_index.agent import AgentRunner\\nfrom llama_index.llms import OpenAI\\n```  \\n```python\\nllm = OpenAI(model=\"gpt-4\")\\ncallback_manager = llm.callback_manager\\n\\nquery_engine_tools = [sql_tool] + vector_tools\\nagent_worker = RetryAgentWorker.from_tools(\\nquery_engine_tools,\\nllm=llm,\\nverbose=True,\\ncallback_manager=callback_manager,\\n)\\nagent = AgentRunner(agent_worker, callback_manager=callback_manager)\\n```', metadata={'Header 1': 'Building a Custom Agent', 'Header 2': 'Build Custom Agent'}),\n",
      " Document(page_content='```python\\nresponse = agent.chat(\"Which countries are each city from?\")\\nprint(str(response))\\n```  \\n\\x1b[1;3;38;5;200mSelecting query engine 0: The choice is about translating a natural language query into a SQL query over a table containing city_stats, which likely includes information about the country of each city..\\n\\x1b[0m> Table desc str: Table \\'city_stats\\' has columns: city_name (VARCHAR(16)), population (INTEGER), country (VARCHAR(16)), and foreign keys: .\\n> Predicted SQL query: SELECT city_name, country FROM city_stats\\n> Question: Which countries are each city from?\\n> Response: The city of Toronto is from Canada, Tokyo is from Japan, and Berlin is from Germany.\\n> Response eval: {\\'has_error\\': True, \\'new_question\\': \\'Which country is each of the following cities from: Toronto, Tokyo, Berlin?\\', \\'explanation\\': \\'The original question was too vague as it did not specify which cities the question was referring to. The new question provides specific cities for which the country of origin is being asked.\\'}\\n\\x1b[1;3;38;5;200mSelecting query engine 0: This choice is relevant because it mentions a table containing city_stats, which likely includes information about the country of each city..\\n\\x1b[0m> Table desc str: Table \\'city_stats\\' has columns: city_name (VARCHAR(16)), population (INTEGER), country (VARCHAR(16)), and foreign keys: .\\n> Predicted SQL query: SELECT city_name, country\\nFROM city_stats\\nWHERE city_name IN (\\'Toronto\\', \\'Tokyo\\', \\'Berlin\\')\\n> Question: Which country is each of the following cities from: Toronto, Tokyo, Berlin?\\n> Response: Toronto is from Canada, Tokyo is from Japan, and Berlin is from Germany.\\n> Response eval: {\\'has_error\\': False, \\'new_question\\': \\'\\', \\'explanation\\': \\'\\'}\\nToronto is from Canada, Tokyo is from Japan, and Berlin is from Germany.  \\n```python\\nresponse = agent.chat(\\n\"What are the top modes of transporation fo the city with the higehest population?\"\\n)\\nprint(str(response))\\n```  \\n\\x1b[1;3;38;5;200mSelecting query engine 0: The question is asking about the top modes of transportation for the city with the highest population. Choice (1) is the most relevant because it mentions a table containing city_stats, which likely includes information about the population of each city..\\n\\x1b[0m> Table desc str: Table \\'city_stats\\' has columns: city_name (VARCHAR(16)), population (INTEGER), country (VARCHAR(16)), and foreign keys: .\\n> Predicted SQL query: SELECT city_name, population, mode_of_transportation\\nFROM city_stats\\nWHERE population = (SELECT MAX(population) FROM city_stats)\\nORDER BY mode_of_transportation ASC\\nLIMIT 5;\\n> Question: What are the top modes of transporation fo the city with the higehest population?\\n> Response: I\\'m sorry, but there was an error in retrieving the information. Please try again later.\\n> Response eval: {\\'has_error\\': True, \\'new_question\\': \\'What are the top modes of transportation for the city with the highest population?\\', \\'explanation\\': \\'The original question had spelling errors which might have caused the system to not understand the question correctly. The corrected question should now be clear and understandable for the system.\\'}\\n\\x1b[1;3;38;5;200mSelecting query engine 0: The first choice is the most relevant because it mentions translating a natural language query into a SQL query over a table containing city_stats, which likely includes information about the population of each city..\\n\\x1b[0m> Table desc str: Table \\'city_stats\\' has columns: city_name (VARCHAR(16)), population (INTEGER), country (VARCHAR(16)), and foreign keys: .\\n> Predicted SQL query: SELECT city_name, population, country\\nFROM city_stats\\nWHERE population = (SELECT MAX(population) FROM city_stats)\\n> Question: What are the top modes of transportation for the city with the highest population?\\n> Response: The city with the highest population is Tokyo, Japan with a population of 13,960,000.\\n> Response eval: {\\'has_error\\': True, \\'new_question\\': \\'What are the top modes of transportation for Tokyo, Japan?\\', \\'explanation\\': \\'The assistant failed to answer the original question correctly. The response was about the city with the highest population, but it did not mention anything about the top modes of transportation in that city. The new question directly asks about the top modes of transportation in Tokyo, Japan, which is the city with the highest population.\\'}\\n\\x1b[1;3;38;5;200mSelecting query engine 3: The question specifically asks about Tokyo, and choice (4) is about answering semantic questions about Tokyo..\\n\\x1b[0m> Question: What are the top modes of transportation for Tokyo, Japan?\\n> Response: The top modes of transportation for Tokyo, Japan are trains and subways, which are considered clean and efficient. Tokyo has an extensive network of electric train lines and over 900 train stations. Buses, monorails, and trams also play a secondary role in the public transportation system. Additionally, expressways connect Tokyo to other points in the Greater Tokyo Area and beyond. Taxis and long-distance ferries are also available for transportation within the city and to the surrounding islands.\\n> Response eval: {\\'has_error\\': True, \\'new_question\\': \\'What are the top modes of transportation for Tokyo, Japan?\\', \\'explanation\\': \\'The original question was not answered correctly because the assistant did not provide information on the top modes of transportation for the city with the highest population. The new question directly asks for the top modes of transportation for Tokyo, Japan, which is the city with the highest population.\\'}\\n\\x1b[1;3;38;5;200mSelecting query engine 3: Tokyo is mentioned in choice 4.\\n\\x1b[0m> Question: What are the top modes of transportation for Tokyo, Japan?\\n> Response: The top modes of transportation for Tokyo, Japan are trains and subways, which are considered clean and efficient. Tokyo has an extensive network of electric train lines and over 900 train stations. Buses, monorails, and trams also play a secondary role in public transportation within the city. Additionally, Tokyo has two major airports, Narita International Airport and Haneda Airport, which offer domestic and international flights. Expressways and taxis are also available for transportation within the city.\\n> Response eval: {\\'has_error\\': True, \\'new_question\\': \\'What are the top modes of transportation for Tokyo, Japan?\\', \\'explanation\\': \\'The response is erroneous because it does not answer the question asked. The question asks for the top modes of transportation in the city with the highest population, but the response only provides the population of the city. The new question directly asks for the top modes of transportation in Tokyo, Japan, which is the city with the highest population.\\'}\\n\\x1b[1;3;38;5;200mSelecting query engine 3: The question specifically asks about Tokyo, and choice 4 is about answering semantic questions about Tokyo..\\n\\x1b[0m> Question: What are the top modes of transportation for Tokyo, Japan?\\n> Response: The top modes of transportation for Tokyo, Japan are trains and subways, which are considered clean and efficient. Tokyo has an extensive network of electric train lines and over 900 train stations. Buses, monorails, and trams also play a secondary role in public transportation within the city. Additionally, Tokyo has two major airports, Narita International Airport and Haneda Airport, which offer domestic and international flights. Expressways and taxis are also available for transportation within the city.\\n> Response eval: {\\'has_error\\': False, \\'new_question\\': \\'\\', \\'explanation\\': \\'\\'}', metadata={'Header 1': 'Building a Custom Agent', 'Header 2': 'Try Out Some Queries'}),\n",
      " Document(page_content='> Response eval: {\\'has_error\\': False, \\'new_question\\': \\'\\', \\'explanation\\': \\'\\'}\\nThe top modes of transportation for Tokyo, Japan are trains and subways, which are considered clean and efficient. Tokyo has an extensive network of electric train lines and over 900 train stations. Buses, monorails, and trams also play a secondary role in public transportation within the city. Additionally, Tokyo has two major airports, Narita International Airport and Haneda Airport, which offer domestic and international flights. Expressways and taxis are also available for transportation within the city.  \\n```python\\nprint(str(response))\\n```  \\nThe top modes of transportation for Tokyo, Japan are trains and subways, which are considered clean and efficient. Tokyo has an extensive network of electric train lines and over 900 train stations. Buses, monorails, and trams also play a secondary role in public transportation within the city. Additionally, Tokyo has two major airports, Narita International Airport and Haneda Airport, which offer domestic and international flights. Expressways and taxis are also available for transportation within the city.  \\n```python\\nresponse = agent.chat(\"What are the sports teams of each city in Asia?\")\\nprint(str(response))\\n```  \\n\\x1b[1;3;38;5;200mSelecting query engine 3: The question is asking about sports teams in Asia, and Tokyo is located in Asia..\\n\\x1b[0m> Question: What are the sports teams of each city in Asia?\\n> Response: I\\'m sorry, but the context information does not provide a comprehensive list of sports teams in each city in Asia. It only mentions some sports teams in Tokyo, Japan. To get a complete list of sports teams in each city in Asia, you would need to consult a reliable source or conduct further research.\\n> Response eval: {\\'has_error\\': True, \\'new_question\\': \\'What are some popular sports teams in Tokyo, Japan?\\', \\'explanation\\': \\'The original question is too broad and requires extensive data that the system may not possess. The new question is more specific and focuses on a single city, making it more likely to receive a correct and comprehensive answer.\\'}\\n\\x1b[1;3;38;5;200mSelecting query engine 3: The question specifically asks about Tokyo, and choice 4 is about answering semantic questions about Tokyo..\\n\\x1b[0m> Question: What are some popular sports teams in Tokyo, Japan?\\n> Response: Some popular sports teams in Tokyo, Japan include the Yomiuri Giants and Tokyo Yakult Swallows in baseball, F.C. Tokyo and Tokyo Verdy 1969 in soccer, and Hitachi SunRockers, Toyota Alvark Tokyo, and Tokyo Excellence in basketball. Tokyo is also known for its sumo wrestling tournaments held at the Ryōgoku Kokugikan sumo arena.\\n> Response eval: {\\'has_error\\': False, \\'new_question\\': \\'\\', \\'explanation\\': \\'\\'}\\nSome popular sports teams in Tokyo, Japan include the Yomiuri Giants and Tokyo Yakult Swallows in baseball, F.C. Tokyo and Tokyo Verdy 1969 in soccer, and Hitachi SunRockers, Toyota Alvark Tokyo, and Tokyo Excellence in basketball. Tokyo is also known for its sumo wrestling tournaments held at the Ryōgoku Kokugikan sumo arena.', metadata={'Header 1': 'Building a Custom Agent', 'Header 2': 'Try Out Some Queries'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/multi_document_agents-v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>'),\n",
      " Document(page_content='In this guide, you learn towards setting up a multi-document agent over the LlamaIndex documentation.  \\nThis is an extension of V0 multi-document agents with the additional features:\\n- Reranking during document (tool) retrieval\\n- Query planning tool that the agent can use to plan  \\nWe do this with the following architecture:  \\n- setup a \"document agent\" over each Document: each doc agent can do QA/summarization within its doc\\n- setup a top-level agent over this set of document agents. Do tool retrieval and then do CoT over the set of tools to answer a question.  \\nIf you\\'re opening this Notebook on colab, you will probably need to install LlamaIndex 🦙.  \\n```python\\n!pip install llama-index\\n```  \\n```python\\n%load_ext autoreload\\n%autoreload 2\\n```', metadata={'Header 1': 'Multi-Document Agents (V1)'}),\n",
      " Document(page_content='In this section, we\\'ll load in the LlamaIndex documentation.  \\n```python\\ndomain = \"docs.llamaindex.ai\"\\ndocs_url = \"https://docs.llamaindex.ai/en/latest/\"\\n!wget -e robots=off --recursive --no-clobber --page-requisites --html-extension --convert-links --restrict-file-names=windows --domains {domain} --no-parent {docs_url}\\n```  \\n```python\\nfrom llama_hub.file.unstructured.base import UnstructuredReader\\nfrom pathlib import Path\\nfrom llama_index.llms import OpenAI\\nfrom llama_index import ServiceContext\\n```  \\n```python\\nreader = UnstructuredReader()\\n```  \\n[nltk_data] Downloading package punkt to /Users/jerryliu/nltk_data...\\n[nltk_data]   Package punkt is already up-to-date!\\n[nltk_data] Downloading package averaged_perceptron_tagger to\\n[nltk_data]     /Users/jerryliu/nltk_data...\\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\\n[nltk_data]       date!  \\n```python\\nall_files_gen = Path(\"./docs.llamaindex.ai/\").rglob(\"*\")\\nall_files = [f.resolve() for f in all_files_gen]\\n```  \\n```python\\nall_html_files = [f for f in all_files if f.suffix.lower() == \".html\"]\\n```  \\n```python\\nlen(all_html_files)\\n```  \\n418  \\n```python\\nfrom llama_index import Document\\n\\n# TODO: set to higher value if you want more docs\\ndoc_limit = 100\\n\\ndocs = []\\nfor idx, f in enumerate(all_html_files):\\nif idx > doc_limit:\\nbreak\\nprint(f\"Idx {idx}/{len(all_html_files)}\")\\nloaded_docs = reader.load_data(file=f, split_documents=True)\\n# Hardcoded Index. Everything before this is ToC for all pages\\nstart_idx = 72\\nloaded_doc = Document(\\ntext=\"\\\\n\\\\n\".join([d.get_content() for d in loaded_docs[72:]]),\\nmetadata={\"path\": str(f)},\\n)\\nprint(loaded_doc.metadata[\"path\"])\\ndocs.append(loaded_doc)\\n```  \\nDefine LLM + Service Context + Callback Manager  \\n```python\\nllm = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\\nservice_context = ServiceContext.from_defaults(llm=llm)\\n```', metadata={'Header 1': 'Multi-Document Agents (V1)', 'Header 2': 'Setup and Download Data'}),\n",
      " Document(page_content='In this section we show you how to construct the multi-document agent. We first build a document agent for each document, and then define the top-level parent agent with an object index.  \\n```python\\nfrom llama_index import VectorStoreIndex, SummaryIndex\\n```  \\n```python\\nimport nest_asyncio\\n\\nnest_asyncio.apply()\\n```', metadata={'Header 1': 'Multi-Document Agents (V1)', 'Header 2': 'Building Multi-Document Agents'}),\n",
      " Document(page_content='In this section we define \"document agents\" for each document.  \\nWe define both a vector index (for semantic search) and summary index (for summarization) for each document. The two query engines are then converted into tools that are passed to an OpenAI function calling agent.  \\nThis document agent can dynamically choose to perform semantic search or summarization within a given document.  \\nWe create a separate document agent for each city.  \\n```python\\nfrom llama_index.agent import OpenAIAgent\\nfrom llama_index import load_index_from_storage, StorageContext\\nfrom llama_index.tools import QueryEngineTool, ToolMetadata\\nfrom llama_index.node_parser import SentenceSplitter\\nimport os\\nfrom tqdm.notebook import tqdm\\nimport pickle\\n\\n\\nasync def build_agent_per_doc(nodes, file_base):\\nprint(file_base)\\n\\nvi_out_path = f\"./data/llamaindex_docs/{file_base}\"\\nsummary_out_path = f\"./data/llamaindex_docs/{file_base}_summary.pkl\"\\nif not os.path.exists(vi_out_path):\\nPath(\"./data/llamaindex_docs/\").mkdir(parents=True, exist_ok=True)\\n# build vector index\\nvector_index = VectorStoreIndex(nodes, service_context=service_context)\\nvector_index.storage_context.persist(persist_dir=vi_out_path)\\nelse:\\nvector_index = load_index_from_storage(\\nStorageContext.from_defaults(persist_dir=vi_out_path),\\nservice_context=service_context,\\n)\\n\\n# build summary index\\nsummary_index = SummaryIndex(nodes, service_context=service_context)\\n\\n# define query engines\\nvector_query_engine = vector_index.as_query_engine()\\nsummary_query_engine = summary_index.as_query_engine(\\nresponse_mode=\"tree_summarize\"\\n)\\n\\n# extract a summary\\nif not os.path.exists(summary_out_path):\\nPath(summary_out_path).parent.mkdir(parents=True, exist_ok=True)\\nsummary = str(\\nawait summary_query_engine.aquery(\\n\"Extract a concise 1-2 line summary of this document\"\\n)\\n)\\npickle.dump(summary, open(summary_out_path, \"wb\"))\\nelse:\\nsummary = pickle.load(open(summary_out_path, \"rb\"))\\n\\n# define tools\\nquery_engine_tools = [\\nQueryEngineTool(\\nquery_engine=vector_query_engine,\\nmetadata=ToolMetadata(\\nname=f\"vector_tool_{file_base}\",\\ndescription=f\"Useful for questions related to specific facts\",\\n),\\n),\\nQueryEngineTool(\\nquery_engine=summary_query_engine,\\nmetadata=ToolMetadata(\\nname=f\"summary_tool_{file_base}\",\\ndescription=f\"Useful for summarization questions\",\\n),\\n),\\n]\\n\\n# build agent\\nfunction_llm = OpenAI(model=\"gpt-4\")\\nagent = OpenAIAgent.from_tools(\\nquery_engine_tools,\\nllm=function_llm,\\nverbose=True,\\nsystem_prompt=f\"\"\"\\\\\\nYou are a specialized agent designed to answer queries about the `{file_base}.html` part of the LlamaIndex docs.\\nYou must ALWAYS use at least one of the tools provided when answering a question; do NOT rely on prior knowledge.\\\\\\n\"\"\",\\n)\\n\\nreturn agent, summary\\n\\n\\nasync def build_agents(docs):\\nnode_parser = SentenceSplitter()\\n\\n# Build agents dictionary\\nagents_dict = {}\\nextra_info_dict = {}\\n\\n# # this is for the baseline\\n# all_nodes = []\\n\\nfor idx, doc in enumerate(tqdm(docs)):\\nnodes = node_parser.get_nodes_from_documents([doc])\\n# all_nodes.extend(nodes)\\n\\n# ID will be base + parent\\nfile_path = Path(doc.metadata[\"path\"])\\nfile_base = str(file_path.parent.stem) + \"_\" + str(file_path.stem)\\nagent, summary = await build_agent_per_doc(nodes, file_base)\\n\\nagents_dict[file_base] = agent\\nextra_info_dict[file_base] = {\"summary\": summary, \"nodes\": nodes}\\n\\nreturn agents_dict, extra_info_dict\\n```  \\n```python\\nagents_dict, extra_info_dict = await build_agents(docs)\\n```', metadata={'Header 1': 'Multi-Document Agents (V1)', 'Header 2': 'Building Multi-Document Agents', 'Header 3': 'Build Document Agent for each Document'}),\n",
      " Document(page_content='We build a top-level agent that can orchestrate across the different document agents to answer any user query.  \\nThis `RetrieverOpenAIAgent` performs tool retrieval before tool use (unlike a default agent that tries to put all tools in the prompt).  \\n**Improvements from V0**: We make the following improvements compared to the \"base\" version in V0.  \\n- Adding in reranking: we use Cohere reranker to better filter the candidate set of documents.\\n- Adding in a query planning tool: we add an explicit query planning tool that\\'s dynamically created based on the set of retrieved tools.  \\n```python\\n# define tool for each document agent\\nall_tools = []\\nfor file_base, agent in agents_dict.items():\\nsummary = extra_info_dict[file_base][\"summary\"]\\ndoc_tool = QueryEngineTool(\\nquery_engine=agent,\\nmetadata=ToolMetadata(\\nname=f\"tool_{file_base}\",\\ndescription=summary,\\n),\\n)\\nall_tools.append(doc_tool)\\n```  \\n```python\\nprint(all_tools[0].metadata)\\n```  \\nToolMetadata(description=\\'LlamaIndex is a data framework that allows LLM applications to ingest, structure, and access private or domain-specific data by providing tools such as data connectors, data indexes, engines, data agents, and application integrations. It is designed for beginners, advanced users, and everyone in between, and offers both high-level and lower-level APIs for customization. LlamaIndex can be installed using pip and has detailed documentation and tutorials available. It is available on GitHub and PyPi, and there is also a Typescript package available. The LlamaIndex community can be joined on Twitter and Discord.\\', name=\\'tool_latest_index\\', fn_schema=<class \\'llama_index.tools.types.DefaultToolFnSchema\\'>)  \\n```python\\n# define an \"object\" index and retriever over these tools\\nfrom llama_index import VectorStoreIndex\\nfrom llama_index.objects import (\\nObjectIndex,\\nSimpleToolNodeMapping,\\nObjectRetriever,\\n)\\nfrom llama_index.retrievers import BaseRetriever\\nfrom llama_index.postprocessor import CohereRerank\\nfrom llama_index.tools import QueryPlanTool\\nfrom llama_index.query_engine import SubQuestionQueryEngine\\nfrom llama_index.llms import OpenAI\\n\\nllm = OpenAI(model_name=\"gpt-4-0613\")\\n\\ntool_mapping = SimpleToolNodeMapping.from_objects(all_tools)\\nobj_index = ObjectIndex.from_objects(\\nall_tools,\\ntool_mapping,\\nVectorStoreIndex,\\n)\\nvector_node_retriever = obj_index.as_node_retriever(similarity_top_k=10)\\n\\n\\n# define a custom retriever with reranking\\nclass CustomRetriever(BaseRetriever):\\ndef __init__(self, vector_retriever, postprocessor=None):\\nself._vector_retriever = vector_retriever\\nself._postprocessor = postprocessor or CohereRerank(top_n=5)\\nsuper().__init__()\\n\\ndef _retrieve(self, query_bundle):\\nretrieved_nodes = self._vector_retriever.retrieve(query_bundle)\\nfiltered_nodes = self._postprocessor.postprocess_nodes(\\nretrieved_nodes, query_bundle=query_bundle\\n)\\n\\nreturn filtered_nodes\\n\\n\\n# define a custom object retriever that adds in a query planning tool\\nclass CustomObjectRetriever(ObjectRetriever):\\ndef __init__(self, retriever, object_node_mapping, all_tools, llm=None):\\nself._retriever = retriever\\nself._object_node_mapping = object_node_mapping\\nself._llm = llm or OpenAI(\"gpt-4-0613\")\\n\\ndef retrieve(self, query_bundle):\\nnodes = self._retriever.retrieve(query_bundle)\\ntools = [self._object_node_mapping.from_node(n.node) for n in nodes]\\n\\nsub_question_sc = ServiceContext.from_defaults(llm=self._llm)\\nsub_question_engine = SubQuestionQueryEngine.from_defaults(\\nquery_engine_tools=tools, service_context=sub_question_sc\\n)\\nsub_question_description = f\"\"\"\\\\\\nUseful for any queries that involve comparing multiple documents. ALWAYS use this tool for comparison queries - make sure to call this \\\\\\ntool with the original query. Do NOT use the other tools for any queries involving multiple documents.\\n\"\"\"\\nsub_question_tool = QueryEngineTool(\\nquery_engine=sub_question_engine,\\nmetadata=ToolMetadata(\\nname=\"compare_tool\", description=sub_question_description\\n),\\n)\\n\\nreturn tools + [sub_question_tool]\\n```  \\n```python\\ncustom_node_retriever = CustomRetriever(vector_node_retriever)\\n\\n# wrap it with ObjectRetriever to return objects\\ncustom_obj_retriever = CustomObjectRetriever(\\ncustom_node_retriever, tool_mapping, all_tools, llm=llm\\n)\\n```  \\n```python\\ntmps = custom_obj_retriever.retrieve(\"hello\")\\nprint(len(tmps))\\n```  \\n6  \\n```python\\nfrom llama_index.agent import FnRetrieverOpenAIAgent, ReActAgent\\n\\ntop_agent = FnRetrieverOpenAIAgent.from_retriever(\\ncustom_obj_retriever,\\nsystem_prompt=\"\"\" \\\\\\nYou are an agent designed to answer queries about the documentation.\\nPlease always use the tools provided to answer a question. Do not rely on prior knowledge.\\\\\\n\\n\"\"\",\\nllm=llm,\\nverbose=True,\\n)\\n\\n# top_agent = ReActAgent.from_tools(\\n#     tool_retriever=custom_obj_retriever,\\n#     system_prompt=\"\"\" \\\\\\n# You are an agent designed to answer queries about the documentation.\\n# Please always use the tools provided to answer a question. Do not rely on prior knowledge.\\\\\\n\\n# \"\"\",\\n#     llm=llm,\\n#     verbose=True,\\n# )\\n```', metadata={'Header 1': 'Multi-Document Agents (V1)', 'Header 2': 'Building Multi-Document Agents', 'Header 3': 'Build Retriever-Enabled OpenAI Agent'}),\n",
      " Document(page_content='As a point of comparison, we define a \"naive\" RAG pipeline which dumps all docs into a single vector index collection.  \\nWe set the top_k = 4  \\n```python\\nall_nodes = [\\nn for extra_info in extra_info_dict.values() for n in extra_info[\"nodes\"]\\n]\\n```  \\n```python\\nbase_index = VectorStoreIndex(all_nodes)\\nbase_query_engine = base_index.as_query_engine(similarity_top_k=4)\\n```', metadata={'Header 1': 'Multi-Document Agents (V1)', 'Header 2': 'Building Multi-Document Agents', 'Header 3': 'Define Baseline Vector Store Index'}),\n",
      " Document(page_content='Let\\'s run some example queries, ranging from QA / summaries over a single document to QA / summarization over multiple documents.  \\n```python\\nresponse = top_agent.query(\\n\"Tell me about the different types of evaluation in LlamaIndex\"\\n)\\n```  \\n=== Calling Function ===\\nCalling function: tool_api_reference_evaluation with args: {\\n\"input\": \"types of evaluation\"\\n}\\n=== Calling Function ===\\nCalling function: vector_tool_api_reference_evaluation with args: {\\n\"input\": \"types of evaluation\"\\n}\\nGot output: The types of evaluation can include correctness evaluation, faithfulness evaluation, guideline evaluation, hit rate evaluation, MRR (Mean Reciprocal Rank) evaluation, pairwise comparison evaluation, relevancy evaluation, and response evaluation.\\n========================\\nGot output: The types of evaluation mentioned in the `api_reference_evaluation.html` part of the LlamaIndex docs include:  \\n1. Correctness Evaluation\\n2. Faithfulness Evaluation\\n3. Guideline Evaluation\\n4. Hit Rate Evaluation\\n5. MRR (Mean Reciprocal Rank) Evaluation\\n6. Pairwise Comparison Evaluation\\n7. Relevancy Evaluation\\n8. Response Evaluation\\n========================  \\n```python\\nprint(response)\\n```  \\nThere are several types of evaluation in LlamaIndex:  \\n1. Correctness Evaluation: This type of evaluation measures the accuracy of the retrieval results. It checks if the retrieved documents are correct and relevant to the query.  \\n2. Faithfulness Evaluation: Faithfulness evaluation measures how faithfully the retrieved documents represent the original data. It checks if the retrieved documents accurately reflect the information in the original documents.  \\n3. Guideline Evaluation: Guideline evaluation involves comparing the retrieval results against a set of guidelines or ground truth. It checks if the retrieval results align with the expected or desired outcomes.  \\n4. Hit Rate Evaluation: Hit rate evaluation measures the percentage of queries that return at least one relevant document. It is a binary evaluation metric that indicates the effectiveness of the retrieval system in finding relevant documents.  \\n5. MRR (Mean Reciprocal Rank) Evaluation: MRR evaluation measures the average rank of the first relevant document in the retrieval results. It provides a single value that represents the effectiveness of the retrieval system in ranking relevant documents.  \\n6. Pairwise Comparison Evaluation: Pairwise comparison evaluation involves comparing the retrieval results of different systems or algorithms. It helps determine which system performs better in terms of retrieval accuracy and relevance.  \\n7. Relevancy Evaluation: Relevancy evaluation measures the relevance of the retrieved documents to the query. It can be done using various metrics such as precision, recall, and F1 score.  \\n8. Response Evaluation: Response evaluation measures the quality of the response generated by the retrieval system. It checks if the response is informative, accurate, and helpful to the user.  \\nThese evaluation types help assess the performance and effectiveness of the retrieval system in LlamaIndex.  \\n```python\\n# baseline\\nresponse = base_query_engine.query(\\n\"Tell me about the different types of evaluation in LlamaIndex\"\\n)\\nprint(str(response))\\n```  \\nLlamaIndex utilizes various types of evaluation methods to assess its performance and effectiveness. These evaluation methods include RelevancyEvaluator, RetrieverEvaluator, SemanticSimilarityEvaluator, PairwiseComparisonEvaluator, CorrectnessEvaluator, FaithfulnessEvaluator, and GuidelineEvaluator. Each of these evaluators serves a specific purpose in evaluating different aspects of the LlamaIndex system.  \\n```python\\nresponse = top_agent.query(\\n\"Compare the content in the contributions page vs. index page.\"\\n)\\n```  \\n=== Calling Function ===\\nCalling function: compare_tool with args: {\\n\"input\": \"content in the contributions page vs. index page\"\\n}\\nGenerated 2 sub questions.\\n\\x1b[1;3;38;2;237;90;200m[tool_development_contributing] Q: What is the content of the contributions page?\\n\\x1b[0m\\x1b[1;3;38;2;90;149;237m[tool_latest_index] Q: What is the content of the index page?\\n\\x1b[0m=== Calling Function ===\\nCalling function: summary_tool_development_contributing with args: {\\n\"input\": \"development_contributing.html\"\\n}\\n=== Calling Function ===\\nCalling function: vector_tool_latest_index with args: {\\n\"input\": \"content of the index page\"\\n}\\nGot output: The development_contributing.html file provides information on how to contribute to LlamaIndex. It includes guidelines on what to work on, such as extending core modules, fixing bugs, adding usage examples, adding experimental features, and improving code quality and documentation. The file also provides details on each module, including data loaders, node parsers, text splitters, document/index/KV stores, managed index, vector stores, retrievers, query engines, query transforms, token usage optimizers, node postprocessors, and output parsers. Additionally, the file includes a development guideline section that covers environment setup, validating changes, formatting/linting, testing, creating example notebooks, and creating a pull request.\\n========================\\nGot output: The content of the index page provides information about LlamaIndex, a data framework for LLM applications. It explains why LlamaIndex is useful for augmenting LLM models with private or domain-specific data that may be distributed across different applications and data stores. LlamaIndex offers tools such as data connectors, data indexes, engines, and data agents to ingest, structure, and access data. It is designed for beginners as well as advanced users who can customize and extend its modules. The page also provides installation instructions, tutorials, and links to the LlamaIndex ecosystem and associated projects.\\n========================\\n\\x1b[1;3;38;2;90;149;237m[tool_latest_index] A: The content of the `latest_index.html` page provides comprehensive information about LlamaIndex, a data framework for LLM applications. It explains the utility of LlamaIndex in augmenting LLM models with private or domain-specific data that may be distributed across different applications and data stores.  \\nThe page details the tools offered by LlamaIndex, such as data connectors, data indexes, engines, and data agents, which are used to ingest, structure, and access data. It is designed to cater to both beginners and advanced users, with the flexibility to customize and extend its modules.  \\nAdditionally, the page provides installation instructions and tutorials for users. It also includes links to the LlamaIndex ecosystem and associated projects for further exploration and understanding.\\n\\x1b[0m\\x1b[1;3;38;2;237;90;200m[tool_development_contributing] A: The `development_contributing.html` page of the LlamaIndex docs provides comprehensive information on how to contribute to the project. It includes guidelines on the areas to focus on, such as extending core modules, fixing bugs, adding usage examples, adding experimental features, and improving code quality and documentation.  \\nThe page also provides detailed information on each module, including data loaders, node parsers, text splitters, document/index/KV stores, managed index, vector stores, retrievers, query engines, query transforms, token usage optimizers, node postprocessors, and output parsers.  \\nIn addition, there is a development guideline section that covers various aspects of the development process, including environment setup, validating changes, formatting/linting, testing, creating example notebooks, and creating a pull request.\\n\\x1b[0mGot output: The content in the contributions page of the LlamaIndex documentation provides comprehensive information on how to contribute to the project, including guidelines on areas to focus on and detailed information on each module. It also covers various aspects of the development process.', metadata={'Header 1': 'Multi-Document Agents (V1)', 'Header 2': 'Running Example Queries'}),\n",
      " Document(page_content='On the other hand, the content in the index page of the LlamaIndex documentation provides comprehensive information about LlamaIndex itself, explaining its utility in augmenting LLM models with private or domain-specific data. It details the tools offered by LlamaIndex and provides installation instructions, tutorials, and links to the LlamaIndex ecosystem and associated projects.\\n========================  \\n```python\\nprint(response)\\n```  \\nThe contributions page of the LlamaIndex documentation provides guidelines for contributing to LlamaIndex, including extending core modules, fixing bugs, adding usage examples, adding experimental features, and improving code quality and documentation. It also includes information on the environment setup, validating changes, formatting and linting, testing, creating example notebooks, and creating a pull request.  \\nOn the other hand, the index page of the LlamaIndex documentation provides information about LlamaIndex itself. It explains that LlamaIndex is a data framework that allows LLM applications to ingest, structure, and access private or domain-specific data. It provides tools such as data connectors, data indexes, engines, data agents, and application integrations. The index page also mentions that LlamaIndex is designed for beginners, advanced users, and everyone in between, and offers both high-level and lower-level APIs for customization. It provides installation instructions, links to the GitHub and PyPi repositories, and information about the LlamaIndex community on Twitter and Discord.  \\nIn summary, the contributions page focuses on contributing to LlamaIndex, while the index page provides an overview of LlamaIndex and its features.  \\n```python\\nresponse = top_agent.query(\\n\"Can you compare the tree index and list index at a very high-level?\"\\n)\\n```  \\n```python\\nprint(str(response))\\n```  \\nAt a high level, the Tree Index and List Index are two different types of indexes used in the system.  \\nThe Tree Index is a tree-structured index that is built specifically for each query. It allows for the construction of a query-specific tree from leaf nodes to return a response. The Tree Index is designed to provide a more optimized and efficient way of retrieving nodes based on a query.  \\nOn the other hand, the List Index is a keyword table index that supports operations such as inserting and deleting documents, retrieving nodes based on a query, and refreshing the index with updated documents. The List Index is a simpler index that uses a keyword table approach for retrieval.  \\nBoth indexes have their own advantages and use cases. The choice between them depends on the specific requirements and constraints of the system.', metadata={'Header 1': 'Multi-Document Agents (V1)', 'Header 2': 'Running Example Queries'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/multi_document_agents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>'),\n",
      " Document(page_content='In this guide, you learn towards setting up an agent that can effectively answer different types of questions over a larger set of documents.  \\nThese questions include the following  \\n- QA over a specific doc\\n- QA comparing different docs\\n- Summaries over a specific doc\\n- Comparing summaries between different docs  \\nWe do this with the following architecture:  \\n- setup a \"document agent\" over each Document: each doc agent can do QA/summarization within its doc\\n- setup a top-level agent over this set of document agents. Do tool retrieval and then do CoT over the set of tools to answer a question.', metadata={'Header 1': 'Multi-Document Agents'}),\n",
      " Document(page_content='In this section, we\\'ll define imports and then download Wikipedia articles about different cities. Each article is stored separately.  \\nWe load in 18 cities - this is not quite at the level of \"hundreds\" of documents but its still large enough to warrant some top-level document retrieval!  \\nIf you\\'re opening this Notebook on colab, you will probably need to install LlamaIndex 🦙.  \\n```python\\n!pip install llama-index\\n```  \\n```python\\nfrom llama_index import (\\nVectorStoreIndex,\\nSummaryIndex,\\nSimpleKeywordTableIndex,\\nSimpleDirectoryReader,\\nServiceContext,\\n)\\nfrom llama_index.schema import IndexNode\\nfrom llama_index.tools import QueryEngineTool, ToolMetadata\\nfrom llama_index.llms import OpenAI\\n```  \\n```python\\nwiki_titles = [\\n\"Toronto\",\\n\"Seattle\",\\n\"Chicago\",\\n\"Boston\",\\n\"Houston\",\\n\"Tokyo\",\\n\"Berlin\",\\n\"Lisbon\",\\n\"Paris\",\\n\"London\",\\n\"Atlanta\",\\n\"Munich\",\\n\"Shanghai\",\\n\"Beijing\",\\n\"Copenhagen\",\\n\"Moscow\",\\n\"Cairo\",\\n\"Karachi\",\\n]\\n```  \\n```python\\nfrom pathlib import Path\\n\\nimport requests\\n\\nfor title in wiki_titles:\\nresponse = requests.get(\\n\"https://en.wikipedia.org/w/api.php\",\\nparams={\\n\"action\": \"query\",\\n\"format\": \"json\",\\n\"titles\": title,\\n\"prop\": \"extracts\",\\n# \\'exintro\\': True,\\n\"explaintext\": True,\\n},\\n).json()\\npage = next(iter(response[\"query\"][\"pages\"].values()))\\nwiki_text = page[\"extract\"]\\n\\ndata_path = Path(\"data\")\\nif not data_path.exists():\\nPath.mkdir(data_path)\\n\\nwith open(data_path / f\"{title}.txt\", \"w\") as fp:\\nfp.write(wiki_text)\\n```  \\n```python\\n# Load all wiki documents\\ncity_docs = {}\\nfor wiki_title in wiki_titles:\\ncity_docs[wiki_title] = SimpleDirectoryReader(\\ninput_files=[f\"data/{wiki_title}.txt\"]\\n).load_data()\\n```  \\nDefine LLM + Service Context + Callback Manager  \\n```python\\nllm = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\\nservice_context = ServiceContext.from_defaults(llm=llm)\\n```', metadata={'Header 1': 'Multi-Document Agents', 'Header 2': 'Setup and Download Data'}),\n",
      " Document(page_content='In this section we show you how to construct the multi-document agent. We first build a document agent for each document, and then define the top-level parent agent with an object index.', metadata={'Header 1': 'Multi-Document Agents', 'Header 2': 'Building Multi-Document Agents'}),\n",
      " Document(page_content='In this section we define \"document agents\" for each document.  \\nWe define both a vector index (for semantic search) and summary index (for summarization) for each document. The two query engines are then converted into tools that are passed to an OpenAI function calling agent.  \\nThis document agent can dynamically choose to perform semantic search or summarization within a given document.  \\nWe create a separate document agent for each city.  \\n```python\\nfrom llama_index.agent import OpenAIAgent\\nfrom llama_index import load_index_from_storage, StorageContext\\nfrom llama_index.node_parser import SentenceSplitter\\nimport os\\n\\nnode_parser = SentenceSplitter()\\n\\n# Build agents dictionary\\nagents = {}\\nquery_engines = {}\\n\\n# this is for the baseline\\nall_nodes = []\\n\\nfor idx, wiki_title in enumerate(wiki_titles):\\nnodes = node_parser.get_nodes_from_documents(city_docs[wiki_title])\\nall_nodes.extend(nodes)\\n\\nif not os.path.exists(f\"./data/{wiki_title}\"):\\n# build vector index\\nvector_index = VectorStoreIndex(nodes, service_context=service_context)\\nvector_index.storage_context.persist(\\npersist_dir=f\"./data/{wiki_title}\"\\n)\\nelse:\\nvector_index = load_index_from_storage(\\nStorageContext.from_defaults(persist_dir=f\"./data/{wiki_title}\"),\\nservice_context=service_context,\\n)\\n\\n# build summary index\\nsummary_index = SummaryIndex(nodes, service_context=service_context)\\n# define query engines\\nvector_query_engine = vector_index.as_query_engine()\\nsummary_query_engine = summary_index.as_query_engine()\\n\\n# define tools\\nquery_engine_tools = [\\nQueryEngineTool(\\nquery_engine=vector_query_engine,\\nmetadata=ToolMetadata(\\nname=\"vector_tool\",\\ndescription=(\\n\"Useful for questions related to specific aspects of\"\\nf\" {wiki_title} (e.g. the history, arts and culture,\"\\n\" sports, demographics, or more).\"\\n),\\n),\\n),\\nQueryEngineTool(\\nquery_engine=summary_query_engine,\\nmetadata=ToolMetadata(\\nname=\"summary_tool\",\\ndescription=(\\n\"Useful for any requests that require a holistic summary\"\\nf\" of EVERYTHING about {wiki_title}. For questions about\"\\n\" more specific sections, please use the vector_tool.\"\\n),\\n),\\n),\\n]\\n\\n# build agent\\nfunction_llm = OpenAI(model=\"gpt-4\")\\nagent = OpenAIAgent.from_tools(\\nquery_engine_tools,\\nllm=function_llm,\\nverbose=True,\\nsystem_prompt=f\"\"\"\\\\\\nYou are a specialized agent designed to answer queries about {wiki_title}.\\nYou must ALWAYS use at least one of the tools provided when answering a question; do NOT rely on prior knowledge.\\\\\\n\"\"\",\\n)\\n\\nagents[wiki_title] = agent\\nquery_engines[wiki_title] = vector_index.as_query_engine(\\nsimilarity_top_k=2\\n)\\n```', metadata={'Header 1': 'Multi-Document Agents', 'Header 2': 'Building Multi-Document Agents', 'Header 3': 'Build Document Agent for each Document'}),\n",
      " Document(page_content='We build a top-level agent that can orchestrate across the different document agents to answer any user query.  \\nThis agent takes in all document agents as tools. This specific agent `RetrieverOpenAIAgent` performs tool retrieval before tool use (unlike a default agent that tries to put all tools in the prompt).  \\nHere we use a top-k retriever, but we encourage you to customize the tool retriever method!  \\n```python\\n# define tool for each document agent\\nall_tools = []\\nfor wiki_title in wiki_titles:\\nwiki_summary = (\\nf\"This content contains Wikipedia articles about {wiki_title}. Use\"\\nf\" this tool if you want to answer any questions about {wiki_title}.\\\\n\"\\n)\\ndoc_tool = QueryEngineTool(\\nquery_engine=agents[wiki_title],\\nmetadata=ToolMetadata(\\nname=f\"tool_{wiki_title}\",\\ndescription=wiki_summary,\\n),\\n)\\nall_tools.append(doc_tool)\\n```  \\n```python\\n# define an \"object\" index and retriever over these tools\\nfrom llama_index import VectorStoreIndex\\nfrom llama_index.objects import ObjectIndex, SimpleToolNodeMapping\\n\\ntool_mapping = SimpleToolNodeMapping.from_objects(all_tools)\\nobj_index = ObjectIndex.from_objects(\\nall_tools,\\ntool_mapping,\\nVectorStoreIndex,\\n)\\n```  \\n```python\\nfrom llama_index.agent import FnRetrieverOpenAIAgent\\n\\ntop_agent = FnRetrieverOpenAIAgent.from_retriever(\\nobj_index.as_retriever(similarity_top_k=3),\\nsystem_prompt=\"\"\" \\\\\\nYou are an agent designed to answer queries about a set of given cities.\\nPlease always use the tools provided to answer a question. Do not rely on prior knowledge.\\\\\\n\\n\"\"\",\\nverbose=True,\\n)\\n```', metadata={'Header 1': 'Multi-Document Agents', 'Header 2': 'Building Multi-Document Agents', 'Header 3': 'Build Retriever-Enabled OpenAI Agent'}),\n",
      " Document(page_content='As a point of comparison, we define a \"naive\" RAG pipeline which dumps all docs into a single vector index collection.  \\nWe set the top_k = 4  \\n```python\\nbase_index = VectorStoreIndex(all_nodes)\\nbase_query_engine = base_index.as_query_engine(similarity_top_k=4)\\n```', metadata={'Header 1': 'Multi-Document Agents', 'Header 2': 'Building Multi-Document Agents', 'Header 3': 'Define Baseline Vector Store Index'}),\n",
      " Document(page_content='Let\\'s run some example queries, ranging from QA / summaries over a single document to QA / summarization over multiple documents.  \\n```python\\n# should use Boston agent -> vector tool\\nresponse = top_agent.query(\"Tell me about the arts and culture in Boston\")\\n```  \\n=== Calling Function ===\\nCalling function: tool_Boston with args: {\\n\"input\": \"arts and culture\"\\n}\\n=== Calling Function ===\\nCalling function: vector_tool with args: {\\n\"input\": \"arts and culture\"\\n}\\nGot output: Boston is known for its vibrant arts and culture scene. The city is home to a number of performing arts organizations, including the Boston Ballet, Boston Lyric Opera Company, Opera Boston, Boston Baroque, and the Handel and Haydn Society. There are also several theaters in or near the Theater District, such as the Cutler Majestic Theatre, Citi Performing Arts Center, the Colonial Theater, and the Orpheum Theatre. Boston is a center for contemporary classical music, with groups like the Boston Modern Orchestra Project and Boston Musica Viva. The city also hosts major annual events, such as First Night, the Boston Early Music Festival, and the Boston Arts Festival. In addition, Boston has several art museums and galleries, including the Museum of Fine Arts, the Isabella Stewart Gardner Museum, and the Institute of Contemporary Art.\\n========================\\nGot output: Boston is renowned for its vibrant arts and culture scene. It is home to numerous performing arts organizations, including the Boston Ballet, Boston Lyric Opera Company, Opera Boston, Boston Baroque, and the Handel and Haydn Society. The city\\'s Theater District houses several theaters, such as the Cutler Majestic Theatre, Citi Performing Arts Center, the Colonial Theater, and the Orpheum Theatre.  \\nBoston is also a hub for contemporary classical music, with groups like the Boston Modern Orchestra Project and Boston Musica Viva. The city hosts major annual events, such as First Night, the Boston Early Music Festival, and the Boston Arts Festival, which contribute to its cultural richness.  \\nIn terms of visual arts, Boston boasts several art museums and galleries. The Museum of Fine Arts, the Isabella Stewart Gardner Museum, and the Institute of Contemporary Art are among the most notable. These institutions offer a wide range of art collections, from ancient to contemporary, attracting art enthusiasts from around the world.\\n========================  \\n```python\\nprint(response)\\n```  \\nBoston has a rich arts and culture scene, with a variety of performing arts organizations and venues. The city is home to renowned institutions such as the Boston Ballet, Boston Lyric Opera Company, Opera Boston, Boston Baroque, and the Handel and Haydn Society. The Theater District in Boston is a hub for theatrical performances, with theaters like the Cutler Majestic Theatre, Citi Performing Arts Center, Colonial Theater, and Orpheum Theatre.  \\nIn addition to performing arts, Boston also has a thriving contemporary classical music scene, with groups like the Boston Modern Orchestra Project and Boston Musica Viva. The city hosts several annual events that celebrate the arts, including First Night, the Boston Early Music Festival, and the Boston Arts Festival.  \\nBoston is also known for its visual arts scene, with a number of art museums and galleries. The Museum of Fine Arts, the Isabella Stewart Gardner Museum, and the Institute of Contemporary Art are among the notable institutions in the city. These museums offer a diverse range of art collections, spanning from ancient to contemporary art, and attract art enthusiasts from around the world.  \\n```python\\n# baseline\\nresponse = base_query_engine.query(\\n\"Tell me about the arts and culture in Boston\"\\n)\\nprint(str(response))\\n```  \\nBoston has a rich arts and culture scene. The city is home to a variety of performing arts organizations, such as the Boston Ballet, Boston Lyric Opera Company, Opera Boston, Boston Baroque, and the Handel and Haydn Society. Additionally, there are numerous contemporary classical music groups associated with the city\\'s conservatories and universities, like the Boston Modern Orchestra Project and Boston Musica Viva. The Theater District in Boston is a hub for theater, with notable venues including the Cutler Majestic Theatre, Citi Performing Arts Center, the Colonial Theater, and the Orpheum Theatre. Boston also hosts several significant annual events, including First Night, the Boston Early Music Festival, the Boston Arts Festival, and the Boston gay pride parade and festival. The city is renowned for its historic sites connected to the American Revolution, as well as its art museums and galleries, such as the Museum of Fine Arts, Isabella Stewart Gardner Museum, and the Institute of Contemporary Art.  \\n```python\\n# should use Houston agent -> vector tool\\nresponse = top_agent.query(\\n\"Give me a summary of all the positive aspects of Houston\"\\n)\\n```  \\n=== Calling Function ===\\nCalling function: tool_Houston with args: {\\n\"input\": \"positive aspects\"\\n}\\n=== Calling Function ===\\nCalling function: summary_tool with args: {\\n\"input\": \"positive aspects\"\\n}\\nGot output: Houston has many positive aspects that make it an attractive place to live and visit. The city\\'s diverse population, with people from different ethnic and religious backgrounds, adds to its cultural richness and inclusiveness. Additionally, Houston is home to the Texas Medical Center, which is the largest concentration of healthcare and research institutions in the world. The presence of NASA\\'s Johnson Space Center also highlights Houston\\'s importance in the fields of medicine and space exploration. The city\\'s strong economy, supported by industries such as energy, manufacturing, aeronautics, and transportation, provides numerous economic opportunities for residents and visitors alike. Furthermore, Houston has a thriving visual and performing arts scene, including a theater district and a variety of museums and galleries. Overall, Houston\\'s diverse community, cultural attractions, and economic prospects make it an exceptionally appealing city.\\n========================\\nGot output: Houston has numerous positive aspects that make it a desirable place to live and visit. Some of these include:  \\n1. **Diversity**: Houston is known for its diverse population, with people from different ethnic and religious backgrounds. This diversity adds to the city\\'s cultural richness and inclusiveness.  \\n2. **Healthcare and Research Institutions**: The city is home to the Texas Medical Center, the largest concentration of healthcare and research institutions in the world. This makes Houston a hub for medical innovation and healthcare services.  \\n3. **Space Exploration**: Houston is also known for NASA\\'s Johnson Space Center, highlighting the city\\'s significant role in space exploration.  \\n4. **Strong Economy**: Houston\\'s economy is robust and diverse, supported by industries such as energy, manufacturing, aeronautics, and transportation. This provides numerous economic opportunities for its residents.  \\n5. **Arts and Culture**: The city has a thriving visual and performing arts scene, with a theater district and a variety of museums and galleries. This makes Houston a vibrant place for art lovers and creatives.  \\nOverall, these aspects contribute to making Houston an appealing and dynamic city.\\n========================  \\n```python\\nprint(response)\\n```  \\nHouston has numerous positive aspects that make it a desirable place to live and visit. Some of these include:  \\n1. Diversity: Houston is known for its diverse population, with people from different ethnic and religious backgrounds. This diversity adds to the city\\'s cultural richness and inclusiveness.  \\n2. Healthcare and Research Institutions: The city is home to the Texas Medical Center, the largest concentration of healthcare and research institutions in the world. This makes Houston a hub for medical innovation and healthcare services.', metadata={'Header 1': 'Multi-Document Agents', 'Header 2': 'Running Example Queries'}),\n",
      " Document(page_content='3. Space Exploration: Houston is also known for NASA\\'s Johnson Space Center, highlighting the city\\'s significant role in space exploration.  \\n4. Strong Economy: Houston\\'s economy is robust and diverse, supported by industries such as energy, manufacturing, aeronautics, and transportation. This provides numerous economic opportunities for its residents.  \\n5. Arts and Culture: The city has a thriving visual and performing arts scene, with a theater district and a variety of museums and galleries. This makes Houston a vibrant place for art lovers and creatives.  \\nOverall, these aspects contribute to making Houston an appealing and dynamic city.  \\n```python\\n# baseline\\nresponse = base_query_engine.query(\\n\"Give me a summary of all the positive aspects of Houston\"\\n)\\nprint(str(response))\\n```  \\nHouston has several positive aspects that contribute to its reputation as a thriving city. It is home to a diverse and growing international community, with a large number of foreign banks and consular offices representing 92 countries. The city has received numerous accolades, including being ranked as one of the best cities for employment, college graduates, and homebuyers. Houston has a strong economy, with a broad industrial base in sectors such as energy, manufacturing, aeronautics, and healthcare. It is also a major center for the oil and gas industry and has the second-most Fortune 500 headquarters in the United States. The city\\'s cultural scene is vibrant, with a variety of annual events celebrating different cultures, as well as a reputation for diverse and excellent food. Houston is known for its world-class museums and performing arts scene. Additionally, the city has made significant investments in renewable energy sources like wind and solar. Overall, Houston offers a high quality of life, reasonable living costs, and abundant employment opportunities.  \\n```python\\n# baseline: the response doesn\\'t quite match the sources...\\nresponse.source_nodes[1].get_content()\\n```  \\n```python\\nresponse = top_agent.query(\\n\"Tell the demographics of Houston, and then compare that with the\"\\n\" demographics of Chicago\"\\n)\\n```  \\n=== Calling Function ===\\nCalling function: tool_Houston with args: {\\n\"input\": \"demographics\"\\n}\\n=== Calling Function ===\\nCalling function: vector_tool with args: {\\n\"input\": \"demographics\"\\n}\\nGot output: Houston is a majority-minority city with a diverse population. According to the U.S. Census Bureau, in 2019, non-Hispanic whites made up 23.3% of the population, Hispanics and Latino Americans 45.8%, Blacks or African Americans 22.4%, and Asian Americans 6.5%. The largest Hispanic or Latino American ethnic group in the city is Mexican Americans, followed by Puerto Ricans and Cuban Americans. Houston is also home to the largest African American community west of the Mississippi River. Additionally, Houston has a growing Muslim population, with Muslims estimated to make up 1.2% of the city\\'s population. The city is known for its LGBT community and is home to one of the largest pride parades in the United States. The Hindu, Sikh, and Buddhist communities are also growing in Houston. Overall, Houston is considered one of the most ethnically and culturally diverse metropolitan areas in the country.\\n========================\\nGot output: Houston is a majority-minority city with a diverse population. According to the U.S. Census Bureau, in 2019, non-Hispanic whites made up 23.3% of the population, Hispanics and Latino Americans 45.8%, Blacks or African Americans 22.4%, and Asian Americans 6.5%. The largest Hispanic or Latino American ethnic group in the city is Mexican Americans, followed by Puerto Ricans and Cuban Americans.  \\nHouston is also home to the largest African American community west of the Mississippi River. Additionally, Houston has a growing Muslim population, with Muslims estimated to make up 1.2% of the city\\'s population. The city is known for its LGBT community and is home to one of the largest pride parades in the United States. The Hindu, Sikh, and Buddhist communities are also growing in Houston.  \\nOverall, Houston is considered one of the most ethnically and culturally diverse metropolitan areas in the country.\\n========================\\n=== Calling Function ===\\nCalling function: tool_Chicago with args: {\\n\"input\": \"demographics\"\\n}\\n=== Calling Function ===\\nCalling function: vector_tool with args: {\\n\"input\": \"demographics\"\\n}\\nGot output: Chicago has a diverse demographic makeup. It experienced rapid population growth during its early years, becoming one of the fastest-growing cities in the world. Waves of immigrants from various European countries, as well as African Americans from the American South, contributed to the city\\'s population growth. Over time, Chicago\\'s population has fluctuated, with a decline in the latter half of the 20th century followed by a rise in recent years. As of the latest census estimates, the largest racial or ethnic groups in Chicago are non-Hispanic White, Black, and Hispanic. Additionally, Chicago has a significant LGBT population and is known for its cultural diversity.\\n========================\\nGot output: Chicago is known for its diverse demographic makeup. The city experienced rapid population growth during its early years, with immigrants from various European countries and African Americans from the American South contributing significantly to this growth. Over time, the population has fluctuated, with a decline in the latter half of the 20th century followed by a rise in recent years.  \\nAs per the latest census estimates, the largest racial or ethnic groups in Chicago are non-Hispanic White, Black, and Hispanic. The city also has a significant LGBT population and is celebrated for its cultural diversity.\\n========================  \\n```python\\nprint(response)\\n```  \\nHouston has a diverse population with a demographic makeup that includes non-Hispanic whites (23.3%), Hispanics and Latino Americans (45.8%), Blacks or African Americans (22.4%), and Asian Americans (6.5%). The largest Hispanic or Latino American ethnic group in Houston is Mexican Americans. Houston is also home to the largest African American community west of the Mississippi River and has a growing Muslim population.  \\nOn the other hand, Chicago is also known for its diverse demographics. The city has a significant non-Hispanic White population, along with a substantial Black population and Hispanic population. Chicago is celebrated for its cultural diversity and has a significant LGBT population.  \\nBoth Houston and Chicago have diverse populations, with a mix of different racial and ethnic groups contributing to their vibrant communities.  \\n```python\\n# baseline\\nresponse = base_query_engine.query(\\n\"Tell the demographics of Houston, and then compare that with the\"\\n\" demographics of Chicago\"\\n)\\nprint(str(response))\\n```  \\nHouston is the most populous city in Texas and the fourth-most populous city in the United States. It has a population of 2,304,580 as of the 2020 U.S. census. The city is known for its diversity, with a significant proportion of minorities. In 2019, non-Hispanic whites made up 23.3% of the population, Hispanics and Latino Americans 45.8%, Blacks or African Americans 22.4%, and Asian Americans 6.5%. The largest Hispanic or Latino American ethnic group in Houston is Mexican Americans, comprising 31.6% of the population.  \\nIn comparison, Chicago is the third-most populous city in the United States. According to the 2020 U.S. census, Chicago has a population of 2,746,388. The demographics of Chicago are different from Houston, with non-Hispanic whites making up 32.7% of the population, Hispanics and Latino Americans 29.9%, Blacks or African Americans 29.8%, and Asian Americans 7.6%. The largest Hispanic or Latino American ethnic group in Chicago is Mexican Americans, comprising 21.6% of the population.  \\nOverall, both Houston and Chicago have diverse populations, but the specific demographic composition differs between the two cities.', metadata={'Header 1': 'Multi-Document Agents', 'Header 2': 'Running Example Queries'}),\n",
      " Document(page_content='```python\\n# baseline: the response tells you nothing about Chicago...\\nresponse.source_nodes[3].get_content()\\n```  \\n```python\\nresponse = top_agent.query(\\n\"Tell me the differences between Shanghai and Beijing in terms of history\"\\n\" and current economy\"\\n)\\n```  \\n=== Calling Function ===\\nCalling function: tool_Shanghai with args: {\\n\"input\": \"history\"\\n}\\n=== Calling Function ===\\nCalling function: vector_tool with args: {\\n\"input\": \"history\"\\n}\\nGot output: Shanghai has a rich history that dates back to ancient times. However, in the context provided, the history of Shanghai is mainly discussed in relation to its modern development. After the war, Shanghai\\'s economy experienced significant growth, with increased agricultural and industrial output. The city\\'s administrative divisions were rearranged, and it became a center for radical leftism during the 1950s and 1960s. The Cultural Revolution had a severe impact on Shanghai\\'s society, but the city maintained economic production with a positive growth rate. Shanghai also played a significant role in China\\'s Third Front campaign and has been a major contributor of tax revenue to the central government. Economic reforms were initiated in Shanghai in 1990, leading to the development of the Pudong district and its classification as an Alpha+ city.\\n========================\\nGot output: Shanghai\\'s history is rich and complex, dating back to ancient times. However, its modern development is particularly noteworthy. After the war, Shanghai experienced significant economic growth, with a boost in both agricultural and industrial output. The city\\'s administrative divisions were restructured, and it became a hub for radical leftism during the 1950s and 1960s.  \\nThe Cultural Revolution had a profound impact on Shanghai\\'s society, but despite this, the city managed to maintain economic production with a positive growth rate. Shanghai also played a significant role in China\\'s Third Front campaign and has been a major contributor of tax revenue to the central government.  \\nIn 1990, economic reforms were initiated in Shanghai, leading to the development of the Pudong district. This has helped Shanghai to be classified as an Alpha+ city, indicating its influence on the global economic stage.\\n========================\\n=== Calling Function ===\\nCalling function: tool_Beijing with args: {\\n\"input\": \"history\"\\n}\\n=== Calling Function ===\\nCalling function: vector_tool with args: {\\n\"input\": \"history\"\\n}\\nGot output: Beijing has a rich history that spans several dynasties. It was the capital of the Ming dynasty, during which the city took its current shape and many of its major attractions, such as the Forbidden City and the Temple of Heaven, were constructed. The Qing dynasty succeeded the Ming dynasty and made Beijing its sole capital. During this time, the Imperial residence and the general layout of the city remained largely unchanged. However, the city faced challenges during the Second Opium War and the Boxer Rebellion, resulting in the looting and destruction of important structures. In the early 20th century, Beijing saw the signing of a peace agreement between the Eight-Nation Alliance and the Chinese government, which led to the restoration of Qing dynasty rule. However, the dynasty eventually collapsed in 1911.\\n========================\\nGot output: Beijing has a rich and complex history that spans several dynasties. It served as the capital during the Ming dynasty, during which the city took its current shape and many of its major attractions, such as the Forbidden City and the Temple of Heaven, were constructed. The Qing dynasty succeeded the Ming dynasty and made Beijing its sole capital. During this time, the Imperial residence and the general layout of the city remained largely unchanged.  \\nHowever, the city faced significant challenges during the Second Opium War and the Boxer Rebellion, which resulted in the looting and destruction of important structures. In the early 20th century, Beijing saw the signing of a peace agreement between the Eight-Nation Alliance and the Chinese government, leading to the restoration of Qing dynasty rule. However, the dynasty eventually collapsed in 1911. Despite these tumultuous events, Beijing has managed to preserve its historical heritage while also evolving into a modern metropolis.\\n========================\\n=== Calling Function ===\\nCalling function: tool_Shanghai with args: {\\n\"input\": \"current economy\"\\n}\\n=== Calling Function ===\\nCalling function: vector_tool with args: {\\n\"input\": \"current economy\"\\n}\\nGot output: The current economy of Shanghai is strong and thriving. It is a global center for finance and innovation, and a national center for commerce, trade, and transportation. The city has a diverse economy, with its six largest industries comprising about half of its GDP. Shanghai has experienced rapid development and has been one of the fastest-developing cities in the world. It has recorded double-digit GDP growth in almost every year between 1992 and 2008. As of 2021, Shanghai had a GDP of CN¥4.46 trillion ($1.106 trillion in PPP), making it one of the wealthiest cities in China. It is also the most expensive city in mainland China to live in. Shanghai is a major player in the global financial industry, ranking first in Asia and third globally in the Global Financial Centres Index. It is home to the Shanghai Stock Exchange, the largest stock exchange in China and the fourth-largest in the world. The city has attracted significant foreign investment and has been a hub for the technology industry and startups. Overall, the current economy of Shanghai is robust and continues to grow.\\n========================\\nGot output: The current economy of Shanghai is robust and thriving. It is a global center for finance and innovation, and a national center for commerce, trade, and transportation. The city has a diverse economy, with its six largest industries comprising about half of its GDP.  \\nShanghai has experienced rapid development and has been one of the fastest-developing cities in the world. It has recorded double-digit GDP growth in almost every year between 1992 and 2008. As of 2021, Shanghai had a GDP of CN¥4.46 trillion ($1.106 trillion in PPP), making it one of the wealthiest cities in China.  \\nShanghai is also the most expensive city in mainland China to live in. It is a major player in the global financial industry, ranking first in Asia and third globally in the Global Financial Centres Index. The city is home to the Shanghai Stock Exchange, the largest stock exchange in China and the fourth-largest in the world.  \\nThe city has attracted significant foreign investment and has been a hub for the technology industry and startups. Overall, the current economy of Shanghai is robust and continues to grow.\\n========================\\n=== Calling Function ===\\nCalling function: tool_Beijing with args: {\\n\"input\": \"current economy\"\\n}\\n=== Calling Function ===\\nCalling function: vector_tool with args: {\\n\"input\": \"current economy\"\\n}', metadata={'Header 1': 'Multi-Document Agents', 'Header 2': 'Running Example Queries'}),\n",
      " Document(page_content='}\\n=== Calling Function ===\\nCalling function: vector_tool with args: {\\n\"input\": \"current economy\"\\n}\\nGot output: The current economy of Beijing is dominated by the tertiary sector, which includes services such as professional services, wholesale and retail, information technology, commercial real estate, scientific research, and residential real estate. This sector generated 83.8% of the city\\'s output in 2022. The secondary sector, which includes manufacturing and construction, accounted for 15.8% of output, while the primary sector, which includes agriculture and mining, contributed only 0.26%. The city has also identified six high-end economic output zones that are driving local economic growth, including Zhongguancun, Beijing Financial Street, Beijing Central Business District (CBD), Beijing Economic and Technological Development Area (Yizhuang), Beijing Airport Economic Zone, and Beijing Olympic Center Zone. These zones are home to various industries and sectors, such as technology companies, financial institutions, office buildings, industrial parks, and entertainment and sports centers.\\n========================\\nGot output: The current economy of Beijing is primarily driven by the tertiary sector, which includes services such as professional services, wholesale and retail, information technology, commercial real estate, scientific research, and residential real estate. This sector generated 83.8% of the city\\'s output in 2022. The secondary sector, which includes manufacturing and construction, accounted for 15.8% of output, while the primary sector, which includes agriculture and mining, contributed only 0.26%.  \\nBeijing has also identified six high-end economic output zones that are driving local economic growth. These include Zhongguancun, Beijing Financial Street, Beijing Central Business District (CBD), Beijing Economic and Technological Development Area (Yizhuang), Beijing Airport Economic Zone, and Beijing Olympic Center Zone. These zones are home to various industries and sectors, such as technology companies, financial institutions, office buildings, industrial parks, and entertainment and sports centers.\\n========================  \\n```python\\nprint(str(response))\\n```  \\nIn terms of history, both Shanghai and Beijing have rich and complex pasts. Shanghai\\'s history dates back to ancient times, but its modern development is particularly noteworthy. It experienced significant economic growth after the war and played a major role in China\\'s economic reforms. Beijing, on the other hand, has a history that spans several dynasties and served as the capital during the Ming and Qing dynasties. It has preserved its historical heritage while evolving into a modern metropolis.  \\nIn terms of current economy, Shanghai is a global center for finance and innovation. It has a diverse economy and has experienced rapid development, with a high GDP and significant foreign investment. It is a major player in the global financial industry and is home to the Shanghai Stock Exchange. Beijing\\'s economy is primarily driven by the tertiary sector, with a focus on services such as professional services, information technology, and commercial real estate. It has identified high-end economic output zones that are driving local economic growth.  \\nOverall, both cities have thriving economies, but Shanghai has a stronger focus on finance and global influence, while Beijing has a diverse economy with a focus on services and high-end economic zones.  \\n```python\\n# baseline\\nresponse = base_query_engine.query(\\n\"Tell me the differences between Shanghai and Beijing in terms of history\"\\n\" and current economy\"\\n)\\nprint(str(response))\\n```  \\nShanghai and Beijing have distinct differences in terms of history and current economy. Historically, Shanghai was the largest and most prosperous city in East Asia during the 1930s, while Beijing served as the capital of the Republic of China and later the People\\'s Republic of China. Shanghai experienced significant growth and redevelopment in the 1990s, while Beijing expanded its urban area and underwent rapid development in the last two decades.  \\nIn terms of the current economy, Shanghai is considered the \"showpiece\" of China\\'s booming economy. It is a global center for finance and innovation, with a strong focus on industries such as retail, finance, IT, real estate, machine manufacturing, and automotive manufacturing. Shanghai is also home to the world\\'s busiest container port, the Port of Shanghai. The city has a high GDP and is classified as an Alpha+ city by the Globalization and World Cities Research Network.  \\nOn the other hand, Beijing is a global financial center and ranks third globally in the Global Financial Centres Index. It is also a hub for the Chinese and global technology industry, with a large startup ecosystem. Beijing has a strong presence in industries such as finance, technology, and pharmaceuticals. The city is home to the headquarters of large state banks and insurance companies, as well as the country\\'s financial regulatory agencies.  \\nOverall, while both Shanghai and Beijing are important economic centers in China, Shanghai has a stronger focus on industries such as finance, retail, and manufacturing, while Beijing has a strong presence in finance, technology, and pharmaceuticals.', metadata={'Header 1': 'Multi-Document Agents', 'Header 2': 'Running Example Queries'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/openai_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>'),\n",
      " Document(page_content=\"With the [new OpenAI API](https://openai.com/blog/function-calling-and-other-api-updates) that supports function calling, it's never been easier to build your own agent!  \\nIn this notebook tutorial, we showcase how to write your own OpenAI agent in **under 50 lines of code**! It is minimal, yet feature complete (with ability to carry on a conversation and use tools).\", metadata={'Header 1': 'Build your own OpenAI Agent'}),\n",
      " Document(page_content='Let\\'s start by importing some simple building blocks.  \\nThe main thing we need is:\\n1. the OpenAI API (using our own `llama_index` LLM class)\\n2. a place to keep conversation history\\n3. a definition for tools that our agent can use.  \\nIf you\\'re opening this Notebook on colab, you will probably need to install LlamaIndex 🦙.  \\n```python\\n!pip install llama-index\\n```  \\n```python\\nimport json\\nfrom typing import Sequence, List\\n\\nfrom llama_index.llms import OpenAI, ChatMessage\\nfrom llama_index.tools import BaseTool, FunctionTool\\n\\nimport nest_asyncio\\n\\nnest_asyncio.apply()\\n```  \\nLet\\'s define some very simple calculator tools for our agent.  \\n```python\\ndef multiply(a: int, b: int) -> int:\\n\"\"\"Multiple two integers and returns the result integer\"\"\"\\nreturn a * b\\n\\n\\nmultiply_tool = FunctionTool.from_defaults(fn=multiply)\\n```  \\n```python\\ndef add(a: int, b: int) -> int:\\n\"\"\"Add two integers and returns the result integer\"\"\"\\nreturn a + b\\n\\n\\nadd_tool = FunctionTool.from_defaults(fn=add)\\n```', metadata={'Header 1': 'Build your own OpenAI Agent', 'Header 2': 'Initial Setup'}),\n",
      " Document(page_content='Now, we define our agent that\\'s capable of holding a conversation and calling tools in **under 50 lines of code**.  \\nThe meat of the agent logic is in the `chat` method. At a high-level, there are 3 steps:\\n1. Call OpenAI to decide which tool (if any) to call and with what arguments.\\n2. Call the tool with the arguments to obtain an output\\n3. Call OpenAI to synthesize a response from the conversation context and the tool output.  \\nThe `reset` method simply resets the conversation context, so we can start another conversation.  \\n```python\\nclass YourOpenAIAgent:\\ndef __init__(\\nself,\\ntools: Sequence[BaseTool] = [],\\nllm: OpenAI = OpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\"),\\nchat_history: List[ChatMessage] = [],\\n) -> None:\\nself._llm = llm\\nself._tools = {tool.metadata.name: tool for tool in tools}\\nself._chat_history = chat_history\\n\\ndef reset(self) -> None:\\nself._chat_history = []\\n\\ndef chat(self, message: str) -> str:\\nchat_history = self._chat_history\\nchat_history.append(ChatMessage(role=\"user\", content=message))\\ntools = [\\ntool.metadata.to_openai_tool() for _, tool in self._tools.items()\\n]\\n\\nai_message = self._llm.chat(chat_history, tools=tools).message\\nadditional_kwargs = ai_message.additional_kwargs\\nchat_history.append(ai_message)\\n\\ntool_calls = ai_message.additional_kwargs.get(\"tool_calls\", None)\\n# parallel function calling is now supported\\nif tool_calls is not None:\\nfor tool_call in tool_calls:\\nfunction_message = self._call_function(tool_call)\\nchat_history.append(function_message)\\nai_message = self._llm.chat(chat_history).message\\nchat_history.append(ai_message)\\n\\nreturn ai_message.content\\n\\ndef _call_function(self, tool_call: dict) -> ChatMessage:\\nid_ = tool_call[\"id\"]\\nfunction_call = tool_call[\"function\"]\\ntool = self._tools[function_call[\"name\"]]\\noutput = tool(**json.loads(function_call[\"arguments\"]))\\nreturn ChatMessage(\\nname=function_call[\"name\"],\\ncontent=str(output),\\nrole=\"tool\",\\nadditional_kwargs={\\n\"tool_call_id\": id_,\\n\"name\": function_call[\"name\"],\\n},\\n)\\n```', metadata={'Header 1': 'Build your own OpenAI Agent', 'Header 2': 'Agent Definition'}),\n",
      " Document(page_content='```python\\nagent = YourOpenAIAgent(tools=[multiply_tool, add_tool])\\n```  \\n```python\\nagent.chat(\"Hi\")\\n```  \\n\\'Hello! How can I assist you today?\\'  \\n```python\\nagent.chat(\"What is 2123 * 215123\")\\n```  \\n\\'The product of 2123 multiplied by 215123 is 456,706,129.\\'', metadata={'Header 1': 'Build your own OpenAI Agent', 'Header 2': \"Let's Try It Out!\"}),\n",
      " Document(page_content='We provide a (slightly better) `OpenAIAgent` implementation in LlamaIndex, which you can directly use as follows.  \\nIn comparison to the simplified version above:\\n* it implements the `BaseChatEngine` and `BaseQueryEngine` interface, so you can more seamlessly use it in the LlamaIndex framework.\\n* it supports multiple function calls per conversation turn\\n* it supports streaming\\n* it supports async endpoints\\n* it supports callback and tracing  \\n```python\\nfrom llama_index.agent import OpenAIAgent\\nfrom llama_index.llms import OpenAI\\n```  \\n```python\\nllm = OpenAI(model=\"gpt-3.5-turbo-0613\")\\nagent = OpenAIAgent.from_tools(\\n[multiply_tool, add_tool], llm=llm, verbose=True\\n)\\n```', metadata={'Header 1': 'Build your own OpenAI Agent', 'Header 2': 'Our (Slightly Better) `OpenAIAgent` Implementation'}),\n",
      " Document(page_content='```python\\nresponse = agent.chat(\"What is (121 * 3) + 42?\")\\nprint(str(response))\\n```  \\nSTARTING TURN 1\\n---------------  \\n=== Calling Function ===\\nCalling function: multiply with args: {\\n\"a\": 121,\\n\"b\": 3\\n}\\nGot output: 363\\n========================  \\nSTARTING TURN 2\\n---------------  \\n=== Calling Function ===\\nCalling function: add with args: {\\n\"a\": 363,\\n\"b\": 42\\n}\\nGot output: 405\\n========================  \\nSTARTING TURN 3\\n---------------  \\n(121 * 3) + 42 is equal to 405.  \\n```python\\n# inspect sources\\nprint(response.sources)\\n```  \\n[ToolOutput(content=\\'363\\', tool_name=\\'multiply\\', raw_input={\\'args\\': (), \\'kwargs\\': {\\'a\\': 121, \\'b\\': 3}}, raw_output=363), ToolOutput(content=\\'405\\', tool_name=\\'add\\', raw_input={\\'args\\': (), \\'kwargs\\': {\\'a\\': 363, \\'b\\': 42}}, raw_output=405)]', metadata={'Header 1': 'Build your own OpenAI Agent', 'Header 2': 'Our (Slightly Better) `OpenAIAgent` Implementation', 'Header 3': 'Chat'}),\n",
      " Document(page_content='```python\\nresponse = await agent.achat(\"What is 121 * 3?\")\\nprint(str(response))\\n```  \\nSTARTING TURN 1\\n---------------  \\n=== Calling Function ===\\nCalling function: multiply with args: {\\n\"a\": 121,\\n\"b\": 3\\n}\\nGot output: 363\\n========================  \\nSTARTING TURN 2\\n---------------  \\n121 multiplied by 3 is equal to 363.', metadata={'Header 1': 'Build your own OpenAI Agent', 'Header 2': 'Our (Slightly Better) `OpenAIAgent` Implementation', 'Header 3': 'Async Chat'}),\n",
      " Document(page_content='Here, every LLM response is returned as a generator. You can stream every incremental step, or only the last response.  \\n```python\\nresponse = agent.stream_chat(\\n\"What is 121 * 2? Once you have the answer, use that number to write a\"\\n\" story about a group of mice.\"\\n)\\n\\nresponse_gen = response.response_gen\\n\\nfor token in response_gen:\\nprint(token, end=\"\")\\n```  \\nSTARTING TURN 1\\n---------------  \\n=== Calling Function ===\\nCalling function: multiply with args: {\\n\"a\": 121,\\n\"b\": 2\\n}\\nGot output: 242\\n========================  \\nSTARTING TURN 2\\n---------------  \\n121 multiplied by 2 is equal to 242.  \\nOnce upon a time, in a small village, there was a group of mice who lived in a cozy little burrow. The mice were known for their intelligence and resourcefulness. They had built a tight-knit community and worked together to overcome any challenges they faced.  \\nOne sunny day, as the mice were going about their daily activities, they stumbled upon a bountiful field of ripe corn. The field was filled with tall stalks of golden corn, swaying gently in the breeze. The mice couldn\\'t believe their luck! They knew they had to gather as much corn as possible to sustain themselves through the upcoming winter.  \\nWith their tiny paws and sharp teeth, the mice began to harvest the corn. They worked tirelessly, carrying one ear of corn at a time back to their burrow. The mice were determined to make the most of this opportunity and ensure they had enough food for everyone.  \\nAs the days turned into weeks, the mice\\'s hard work paid off. They had collected an impressive stash of corn, thanks to their diligent efforts and the abundance of the field. The mice celebrated their success, knowing that they had secured their survival for the winter.  \\nBut the mice didn\\'t stop there. They realized that they had more corn than they needed just for themselves. They decided to share their abundance with the other animals in the village who were struggling to find food. The mice knew the importance of community and believed in helping others in need.  \\nWord spread quickly about the generous mice and their corn. Animals from all around the village came to the mice\\'s burrow, grateful for the assistance. The mice happily distributed the corn, ensuring that everyone had enough to eat.  \\nThe mice\\'s act of kindness and their ability to multiply their resources had a profound impact on the village. The animals learned the value of working together and supporting one another. The mice became a symbol of unity and compassion, inspiring others to follow their example.  \\nAnd so, the mice\\'s story of multiplying their resources and spreading kindness became a legend in the village. The mice continued to thrive, not just because of their intelligence and resourcefulness, but also because of their big hearts and willingness to help others.  \\nThe end.', metadata={'Header 1': 'Build your own OpenAI Agent', 'Header 2': 'Our (Slightly Better) `OpenAIAgent` Implementation', 'Header 3': 'Streaming Chat'}),\n",
      " Document(page_content='```python\\nresponse = await agent.astream_chat(\\n\"What is 121 + 8? Once you have the answer, use that number to write a\"\\n\" story about a group of mice.\"\\n)\\n\\nresponse_gen = response.response_gen\\n\\nasync for token in response.async_response_gen():\\nprint(token, end=\"\")\\n```  \\nSTARTING TURN 1\\n---------------  \\n=== Calling Function ===\\nCalling function: add with args: {\\n\"a\": 121,\\n\"b\": 8\\n}\\nGot output: 129\\n========================  \\nSTARTING TURN 2\\n---------------  \\n121 plus 8 is equal to 129.  \\nOnce upon a time, in a peaceful meadow, there lived a group of mice. These mice were known for their bravery and adventurous spirit. They loved exploring the meadow and discovering new places.  \\nOne sunny day, as the mice were scurrying through the tall grass, they stumbled upon a hidden treasure. It was a small, sparkling gemstone that radiated with a mesmerizing glow. The mice were amazed by its beauty and knew that it was something special.  \\nExcitedly, the mice decided to take the gemstone back to their burrow. They carefully carried it, taking turns to ensure its safety. As they reached their cozy home, they marveled at the gemstone\\'s brilliance. Little did they know, this gemstone held a magical power.  \\nAs the mice gathered around the gemstone, a soft, enchanting light began to emanate from it. Suddenly, the mice felt a surge of energy and realized that they had been granted a special ability - the power to communicate with other animals.  \\nWith their newfound power, the mice embarked on a mission to bring harmony and understanding among the creatures of the meadow. They started by reaching out to the birds, sharing their wisdom and learning about the secrets of the sky. The mice and birds formed a strong bond, exchanging stories and songs.  \\nNext, the mice approached the rabbits, teaching them about the importance of unity and cooperation. The rabbits, known for their agility, shared their knowledge of navigating the meadow and avoiding danger. Together, the mice and rabbits created a safe haven for all the animals.  \\nThe mice\\'s journey continued as they connected with the squirrels, teaching them the value of saving and planning for the future. The squirrels, in return, shared their knowledge of gathering food and surviving the harsh winters. The meadow became a place of abundance and security for all its inhabitants.  \\nAs the seasons changed, the mice\\'s influence spread throughout the meadow. Animals from all walks of life came together, forming a diverse and harmonious community. The mice\\'s ability to bring different species together was a testament to their leadership and compassion.  \\nThe gemstone, a symbol of unity and understanding, remained at the center of the mice\\'s burrow. It served as a reminder of the power of collaboration and the importance of embracing diversity.  \\nAnd so, the mice\\'s story of adding their strengths and bringing animals together became a legend in the meadow. The mice continued to explore, learn, and spread their message of unity, leaving a lasting impact on the meadow and its inhabitants.  \\nThe end.', metadata={'Header 1': 'Build your own OpenAI Agent', 'Header 2': 'Our (Slightly Better) `OpenAIAgent` Implementation', 'Header 3': 'Async Streaming Chat'}),\n",
      " Document(page_content='You can specify a system prompt to give the agent additional instruction or personality.  \\n```python\\nfrom llama_index.agent import OpenAIAgent\\nfrom llama_index.llms import OpenAI\\nfrom llama_index.prompts.system import SHAKESPEARE_WRITING_ASSISTANT\\n```  \\n```python\\nllm = OpenAI(model=\"gpt-3.5-turbo-0613\")\\n\\nagent = OpenAIAgent.from_tools(\\n[multiply_tool, add_tool],\\nllm=llm,\\nverbose=True,\\nsystem_prompt=SHAKESPEARE_WRITING_ASSISTANT,\\n)\\n```  \\n```python\\nresponse = agent.chat(\"Hi\")\\nprint(response)\\n```  \\nSTARTING TURN 1\\n---------------  \\nGreetings, fair traveler! How may I assist thee on this fine day?  \\n```python\\nresponse = agent.chat(\"Tell me a story\")\\nprint(response)\\n```  \\nSTARTING TURN 1\\n---------------  \\nOf course, dear friend! Allow me to weave a tale for thee in the style of Shakespeare.  \\nOnce upon a time, in a land far away, there lived a noble knight named Sir William. He was known throughout the kingdom for his bravery and chivalry. One fateful day, as Sir William rode through the enchanted forest, he stumbled upon a hidden glade.  \\nIn the glade, he discovered a beautiful maiden named Lady Rosalind. She was fair of face and gentle of heart, and Sir William was instantly captivated by her beauty. They spent hours conversing, sharing stories, and laughing together.  \\nAs the days turned into weeks, Sir William and Lady Rosalind\\'s bond grew stronger. They found solace in each other\\'s company and realized that they had fallen deeply in love. However, their love was not without obstacles.  \\nLady Rosalind\\'s father, Lord Reginald, was a stern and overprotective man. He had already arranged a marriage for his daughter with a wealthy nobleman, Lord Percival. When Lady Rosalind confessed her love for Sir William, Lord Reginald was furious.  \\nDetermined to be together, Sir William and Lady Rosalind devised a plan. They decided to elope under the cover of darkness, seeking refuge in a distant land where their love could flourish without hindrance. With heavy hearts, they bid farewell to their families and set off on their journey.  \\nTheir path was treacherous, filled with perils and hardships. They faced raging storms, dangerous bandits, and even a fearsome dragon. But through it all, their love remained steadfast and unwavering.  \\nAfter many trials and tribulations, Sir William and Lady Rosalind finally reached their destination—a peaceful village nestled by the sea. They settled there, vowing to live a life of love and happiness.  \\nYears passed, and their love only grew stronger. They were blessed with children, who inherited their parents\\' noble qualities. Sir William and Lady Rosalind lived a long and fulfilling life, surrounded by the love of their family and the admiration of the villagers.  \\nAnd so, the tale of Sir William and Lady Rosalind serves as a reminder that true love can conquer all obstacles, even in the face of adversity. May their story inspire thee to follow thy heart and pursue love with unwavering determination.', metadata={'Header 1': 'Build your own OpenAI Agent', 'Header 2': 'Our (Slightly Better) `OpenAIAgent` Implementation', 'Header 3': 'Agent with Personality'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/openai_agent_context_retrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>'),\n",
      " Document(page_content=\"In this tutorial, we show you how to use our `ContextRetrieverOpenAIAgent` implementation\\nto build an agent on top of OpenAI's function API and store/index an arbitrary number of tools. Our indexing/retrieval modules help to remove the complexity of having too many functions to fit in the prompt.\", metadata={'Header 1': 'Context-Augmented OpenAI Agent'}),\n",
      " Document(page_content='Here we setup a ContextRetrieverOpenAIAgent. This agent will perform retrieval first before calling any tools. This can help ground the agent\\'s tool picking and answering capabilities in context.  \\nIf you\\'re opening this Notebook on colab, you will probably need to install LlamaIndex 🦙.  \\n```python\\n!pip install llama-index\\n```  \\n```python\\nimport json\\nfrom typing import Sequence\\n\\nfrom llama_index import (\\nSimpleDirectoryReader,\\nVectorStoreIndex,\\nStorageContext,\\nload_index_from_storage,\\n)\\nfrom llama_index.tools import QueryEngineTool, ToolMetadata\\n```  \\n```python\\ntry:\\nstorage_context = StorageContext.from_defaults(\\npersist_dir=\"./storage/march\"\\n)\\nmarch_index = load_index_from_storage(storage_context)\\n\\nstorage_context = StorageContext.from_defaults(\\npersist_dir=\"./storage/june\"\\n)\\njune_index = load_index_from_storage(storage_context)\\n\\nstorage_context = StorageContext.from_defaults(\\npersist_dir=\"./storage/sept\"\\n)\\nsept_index = load_index_from_storage(storage_context)\\n\\nindex_loaded = True\\nexcept:\\nindex_loaded = False\\n```  \\nDownload Data  \\n```python\\n!mkdir -p \\'data/10q/\\'\\n!wget \\'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10q/uber_10q_march_2022.pdf\\' -O \\'data/10q/uber_10q_march_2022.pdf\\'\\n!wget \\'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10q/uber_10q_june_2022.pdf\\' -O \\'data/10q/uber_10q_june_2022.pdf\\'\\n!wget \\'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10q/uber_10q_sept_2022.pdf\\' -O \\'data/10q/uber_10q_sept_2022.pdf\\'\\n```  \\n```python\\n# build indexes across the three data sources\\n\\nif not index_loaded:\\n# load data\\nmarch_docs = SimpleDirectoryReader(\\ninput_files=[\"./data/10q/uber_10q_march_2022.pdf\"]\\n).load_data()\\njune_docs = SimpleDirectoryReader(\\ninput_files=[\"./data/10q/uber_10q_june_2022.pdf\"]\\n).load_data()\\nsept_docs = SimpleDirectoryReader(\\ninput_files=[\"./data/10q/uber_10q_sept_2022.pdf\"]\\n).load_data()\\n\\n# build index\\nmarch_index = VectorStoreIndex.from_documents(march_docs)\\njune_index = VectorStoreIndex.from_documents(june_docs)\\nsept_index = VectorStoreIndex.from_documents(sept_docs)\\n\\n# persist index\\nmarch_index.storage_context.persist(persist_dir=\"./storage/march\")\\njune_index.storage_context.persist(persist_dir=\"./storage/june\")\\nsept_index.storage_context.persist(persist_dir=\"./storage/sept\")\\n```  \\n```python\\nmarch_engine = march_index.as_query_engine(similarity_top_k=3)\\njune_engine = june_index.as_query_engine(similarity_top_k=3)\\nsept_engine = sept_index.as_query_engine(similarity_top_k=3)\\n```  \\n```python\\nquery_engine_tools = [\\nQueryEngineTool(\\nquery_engine=march_engine,\\nmetadata=ToolMetadata(\\nname=\"uber_march_10q\",\\ndescription=(\\n\"Provides information about Uber 10Q filings for March 2022. \"\\n\"Use a detailed plain text question as input to the tool.\"\\n),\\n),\\n),\\nQueryEngineTool(\\nquery_engine=june_engine,\\nmetadata=ToolMetadata(\\nname=\"uber_june_10q\",\\ndescription=(\\n\"Provides information about Uber financials for June 2021. \"\\n\"Use a detailed plain text question as input to the tool.\"\\n),\\n),\\n),\\nQueryEngineTool(\\nquery_engine=sept_engine,\\nmetadata=ToolMetadata(\\nname=\"uber_sept_10q\",\\ndescription=(\\n\"Provides information about Uber financials for Sept 2021. \"\\n\"Use a detailed plain text question as input to the tool.\"\\n),\\n),\\n),\\n]\\n```', metadata={'Header 1': 'Context-Augmented OpenAI Agent', 'Header 2': 'Initial Setup'}),\n",
      " Document(page_content='Here we augment our agent with context in different settings:\\n- toy context: we define some abbreviations that map to financial terms (e.g. R=Revenue). We supply this as context to the agent  \\n```python\\nfrom llama_index.schema import Document\\nfrom llama_index.agent import ContextRetrieverOpenAIAgent\\n```  \\n```python\\n# toy index - stores a list of abbreviations\\ntexts = [\\n\"Abbreviation: X = Revenue\",\\n\"Abbreviation: YZ = Risk Factors\",\\n\"Abbreviation: Z = Costs\",\\n]\\ndocs = [Document(text=t) for t in texts]\\ncontext_index = VectorStoreIndex.from_documents(docs)\\n```  \\n```python\\ncontext_agent = ContextRetrieverOpenAIAgent.from_tools_and_retriever(\\nquery_engine_tools,\\ncontext_index.as_retriever(similarity_top_k=1),\\nverbose=True,\\n)\\n```  \\n```python\\nresponse = context_agent.chat(\"What is the YZ of March 2022?\")\\n```  \\n\\x1b[33;1m\\x1b[1;3mContext information is below.\\n---------------------\\nAbbreviation: YZ = Risk Factors\\n---------------------\\nGiven the context information and not prior knowledge, either pick the corresponding tool or answer the function: What is the YZ of March 2022?  \\n\\x1b[0m=== Calling Function ===\\nCalling function: uber_march_10q with args: {\\n\"input\": \"Risk Factors\"\\n}\\nGot output:\\n•The COVID-19 pandemic and the impact of actions to mitigate the pandemic have adversely affected and may continue to adversely affect parts of our business.\\n•Our business would be adversely affected if Drivers were classified as employees, workers or quasi-employees instead of independent contractors.\\n•The mobility, delivery, and logistics industries are highly competitive, with well-established and low-cost alternatives that have been available for decades, low barriers to entry, low switching costs, and well-capitalized competitors in nearly every major geographic region.\\n•To remain competitive in certain markets, we have in the past lowered, and may continue to lower, fares or service fees, and we have in the past offered, and may continue to offer, significant Driver incentives and consumer discounts and promotions.\\n•We have incurred significant losses since inception, including in the United States and other major markets. We expect our operating expenses to increase significantly in the foreseeable future, and we may not achieve or maintain profitability.\\n•If we are unable to attract or maintain a critical mass of Drivers, consumers, merchants, shippers, and carriers, whether as a result of competition or other factors, our platform will become less appealing to platform users.\\n•Maintaining and enhancing our brand and reputation is critical to our business prospects. We have previously received significant media coverage and negative publicity regarding our brand and reputation, and while we have taken significant steps to rehabilitate our brand and reputation, failure to maintain and enhance our brand and reputation could adversely affect our business.\\n•The impact of economic conditions, including the resulting effect on discretionary consumer spending, may harm our business and operating results.\\n•Increases in fuel, food, labor, energy, and other costs due to inflation and other factors could adversely affect our operating results.\\n•If we experience security or privacy breaches or other unauthorized or improper access to, use of, disclosure of, alteration of or destruction of our proprietary or confidential data, employee data, or platform user data.\\n•Cyberattacks, including computer malware, ransomware, viruses, spamming, and phishing attacks could harm our reputation, business, and operating results.\\n•We are subject to climate change risks, including physical and transitional risks, and if we are unable to manage such risks, our business may be adversely impacted.\\n•We have made climate related commitments that require us to invest significant effort, resources, and management time and circumstances may arise, including those beyond our control, that may require us to revise the contemplated timeframes for implementing these commitments.\\n•We rely on third parties maintaining open marketplaces to distribute our platform and to provide the software we use in certain of our products and offerings. If such third parties interfere with the distribution of our products or offerings or with our use of such software, our business would be adversely affected.\\n•We will require additional capital to support the growth of our business, and this capital might not be available on reasonable terms or at all.\\n•If we are unable to successfully identify, acquire and integrate suitable businesses, our operating results and prospects could be harmed, and any businesses we acquire may not perform as expected or be effectively integrated.\\n•We may continue to be blocked from or limited in providing or operating our products and offerings in certain jurisdictions, and may be required to modify our business model in those jurisdictions as a result.\\n•Our business is subject to numerous legal and regulatory risks that could have an adverse impact on our business and future prospects.\\n•Our business is subject to extensive government regulation and oversight relating to the provision of payment and financial services.\\n•We face risks related to our collection, use, transfer, disclosure, and other processing of data, which could result in investigations, inquiries, litigation, fines, legislative and regulatory action, and negative press about our privacy and data protection practices.\\n•If we are unable to protect our intellectual property, or if third parties are successful in claiming that we are misappropriating the intellectual property of others, we may incur significant expense and our business may be adversely affected.\\n•The market price of our common stock has been, and may continue to be, volatile or may decline steeply or suddenly regardless of our operating performance, and we may not be able to meet investor or analyst expectations. You may not be able to resell your shares at or above the price you paid and may lose all or part of your investment.\\n========================  \\n```python\\nprint(str(response))\\n```  \\nThe risk factors for Uber in March 2022 include:  \\n1. The adverse impact of the COVID-19 pandemic and actions taken to mitigate it on Uber\\'s business.\\n2. The potential adverse effect on Uber\\'s business if drivers are classified as employees instead of independent contractors.\\n3. Intense competition in the mobility, delivery, and logistics industries, with low-cost alternatives and well-capitalized competitors.\\n4. The need to lower fares, offer driver incentives, and provide consumer discounts and promotions to remain competitive in certain markets.\\n5. Uber\\'s history of significant losses and the expectation of increased operating expenses in the future, which may affect profitability.\\n6. The importance of attracting and maintaining a critical mass of drivers, consumers, merchants, shippers, and carriers to keep the platform appealing.\\n7. The significance of maintaining and enhancing Uber\\'s brand and reputation, as negative publicity could harm the business.\\n8. The potential impact of economic conditions and discretionary consumer spending on Uber\\'s business.\\n9. The adverse effect of increasing costs, such as fuel, food, labor, energy, and inflation, on Uber\\'s operating results.\\n10. The risk of security or privacy breaches and unauthorized access to Uber\\'s proprietary or confidential data.\\n11. The potential harm to Uber\\'s reputation, business, and operating results from cyberattacks.\\n12. The impact of climate change risks, including physical and transitional risks, on Uber\\'s business.\\n13. The commitment to climate-related initiatives that require significant effort, resources, and management time.\\n14. The reliance on third parties for distributing Uber\\'s platform and providing software, with the risk of interference or limitations.\\n15. The need for additional capital to support Uber\\'s business growth, with uncertainty about its availability on reasonable terms.', metadata={'Header 1': 'Context-Augmented OpenAI Agent', 'Header 2': 'Initial Setup', 'Header 3': 'Try Context-Augmented Agent'}),\n",
      " Document(page_content='16. The risks associated with identifying, acquiring, and integrating suitable businesses.\\n17. The potential limitations and modifications to Uber\\'s business model in certain jurisdictions.\\n18. The legal and regulatory risks that could adversely impact Uber\\'s business and future prospects.\\n19. The extensive government regulation and oversight related to payment and financial services provided by Uber.\\n20. The risks associated with data collection, use, transfer, disclosure, and processing, including investigations, litigation, and fines.\\n21. The importance of protecting Uber\\'s intellectual property and the risk of claims of misappropriation.\\n22. The volatility and potential decline in the market price of Uber\\'s common stock, which may not reflect operating performance.  \\nPlease note that this is a summary of the risk factors mentioned in Uber\\'s March 2022 10Q filing. For more detailed information, please refer to the official filing.  \\n```python\\ncontext_agent.chat(\"What is the X and Z in September 2022?\")\\n```', metadata={'Header 1': 'Context-Augmented OpenAI Agent', 'Header 2': 'Initial Setup', 'Header 3': 'Try Context-Augmented Agent'}),\n",
      " Document(page_content='```python\\nfrom llama_index.tools import BaseTool, FunctionTool\\n\\n\\ndef magic_formula(revenue: int, cost: int) -> int:\\n\"\"\"Runs MAGIC_FORMULA on revenue and cost.\"\"\"\\nreturn revenue - cost', metadata={'Header 1': 'Context-Augmented OpenAI Agent', 'Header 2': 'Initial Setup', 'Header 3': 'Use Uber 10-Q as context, use Calculator as Tool'}),\n",
      " Document(page_content='magic_tool = FunctionTool.from_defaults(fn=magic_formula, name=\"magic_formula\")\\n```  \\n```python\\ncontext_agent = ContextRetrieverOpenAIAgent.from_tools_and_retriever(\\n[magic_tool], sept_index.as_retriever(similarity_top_k=3), verbose=True\\n)\\n```  \\n```python\\nresponse = context_agent.chat(\\n\"Can you run MAGIC_FORMULA on Uber\\'s revenue and cost?\"\\n)\\n```  \\n\\x1b[33;1m\\x1b[1;3mContext information is below.\\n---------------------\\nThree Months Ended September 30, Nine Months Ended September 30,\\n2021 2022 2021 2022\\nRevenue 100 % 100 % 100 % 100 %\\nCosts and expenses\\nCost of revenue, exclusive of depreciation and amortization shown separately\\nbelow 50 % 62 % 53 % 62 %\\nOperations and support 10 % 7 % 11 % 8 %\\nSales and marketing 24 % 14 % 30 % 16 %\\nResearch and development 10 % 9 % 13 % 9 %\\nGeneral and administrative 13 % 11 % 15 % 10 %\\nDepreciation and amortization 4 % 3 % 6 % 3 %\\nTotal costs and expenses 112 % 106 % 128 % 107 %\\nLoss from operations (12)% (6)% (28)% (7)%\\nInterest expense (3)% (2)% (3)% (2)%\\nOther income (expense), net (38)% (6)% 16 % (34)%\\nLoss before income taxes and income (loss) from equity method\\ninvestments (52)% (14)% (16)% (43)%\\nProvision for (benefit from) income taxes (2)% 1 % (3)% — %\\nIncome (loss) from equity method investments — % — % — % — %\\nNet loss including non-controlling interests (50)% (14)% (12)% (42)%\\nLess: net income (loss) attributable to non-controlling interests,\\nnet of tax — % — % (1)% — %\\nNet loss attributable to Uber Technologies, Inc. (50)% (14)% (12)% (42)%\\nTotals of percentage of revenues may not foot due to rounding.\\nThe following discussion and analysis is for the three and nine months ended September 30, 2022 compared to same period in 2021.\\nRevenue\\nThree Months Ended September 30, Nine Months Ended September 30,\\n(In millions, except per centages) 2021 2022 % Change 2021 2022 % Change\\nRevenue $ 4,845 $ 8,343 72 %$ 11,677 $ 23,270 99 %\\nThree Months Ended September 30, 2022 Compared with the Same Period in 2021\\nRevenue increased $3.5 billion, or 72%, primarily attributable to an increase in Gross Bookings of 26%, or 32% on a constant currency basis. The increase in\\nGross Bookings was primarily driven by increases in Mobility Trip volumes as the business recovers from the impacts of COVID-19 and a $1.3 billion increase in\\nFreight Gross Bookings resulting primarily from the acquisition of Transplace in the fourth quarter of 2021. Additionally, during the third quarter of 2022, we saw a\\n$1.1 billion increase in Mobility revenue as a result of business model changes in the UK. We also saw a $164 million increase in Delivery revenue resulting from\\nan increase in certain Courier payments and incentives that are recorded in cost of revenue, exclusive of depreciation and amortization, for certain markets where\\nwe are primarily responsible for Delivery services and pay Couriers for services provided.\\nNine Months Ended September 30, 2022 Compared with the Same Period in 2021\\nRevenue increased $11.6 billion, or 99%, primarily attributable to an increase in Gross Bookings of 31%, or 36% on a constant currency basis. The increase in\\nGross Bookings was primarily driven by increases in Mobility Trip volumes as the business recovers from the impacts of COVID-19 and a $4.4 billion increase in\\nFreight Gross Bookings resulting primarily from the acquisition of Transplace in the fourth quarter of 2021. Additionally, during the first nine months of 2022, we\\nsaw a $2.2 billion net increase in Mobility revenue as a result of business model changes in the UK and an accrual made for the resolution of historical claims in\\nthe UK relating to the classification of drivers. We also saw a $751 million increase in Delivery revenue resulting from an increase in certain Courier payments and\\nincentives that are recorded in cost of revenue, exclusive of depreciation and amortization, for certain markets where we are primarily responsible for\\nUBER TECHNOLOGIES, INC.\\nCONDENSED CONSOLIDATED STATEMENTS OF OPERATIONS\\n(In millions, except share amounts which are reflected in thousands, and per share amounts)\\n(Unaudited)\\nThree Months Ended September  30, Nine Months Ended September  30,\\n2021 2022 2021 2022\\nRevenue $ 4,845 $ 8,343 $ 11,677 $ 23,270\\nCosts and expenses\\nCost of revenue, exclusive of depreciation and amortization shown separately\\nbelow 2,438 5,173 6,247 14,352\\nOperations and support 475 617 1,330 1,808\\nSales and marketing 1,168 1,153 3,527 3,634\\nResearch and development 493 760 1,496 2,051\\nGeneral and administrative 625 908 1,705 2,391\\nDepreciation and amortization 218 227 656 724\\nTotal costs and expenses 5,417 8,838 14,961 24,960\\nLoss from operations (572) (495) (3,284) (1,690)\\nInterest expense (123) (146) (353) (414)\\nOther income (expense), net (1,832) (535) 1,821 (7,796)\\nLoss before income taxes and income (loss) from equity method investments (2,527) (1,176) (1,816) (9,900)\\nProvision for (benefit from) income taxes (101) 58 (395) (97)\\nIncome (loss) from equity method investments (13) 30 (28) 65\\nNet loss including non-controlling interests (2,439) (1,204) (1,449) (9,738)\\nLess: net income (loss) attributable to non-controlling interests, net of\\ntax (15) 2 (61) (2)\\nNet loss attributable to Uber Technologies, Inc. $ (2,424)$ (1,206)$ (1,388)$ (9,736)\\nNet loss per share attributable to Uber Technologies, Inc. common\\nstockholders:\\nBasic $ (1.28)$ (0.61)$ (0.74)$ (4.96)\\nDiluted $ (1.28)$ (0.61)$ (0.75)$ (4.97)\\nWeighted-average shares used to compute net loss per share attributable to\\ncommon stockholders:\\nBasic 1,898,954 1,979,299 1,877,655 1,964,483\\nDiluted 1,898,954 1,979,299 1,878,997 1,968,228\\nThe accompanying notes are an integral part of these condensed consolidated financial statements.\\n5\\nComponents of Results of Operations\\nRevenue\\nWe generate substantially all of our revenue from fees paid by Drivers and Merchants for use of our platform. We have concluded that we are an agent in these\\narrangements as we arrange for other parties to provide the service to the end-user. Under this model, revenue is net of Driver and Merchant earnings and Driver\\nincentives. We act as an agent in these transactions by connecting consumers to Drivers and Merchants to facilitate a Trip, meal or grocery delivery service.\\nDuring the first quarter of 2022, we modified our arrangements in certain markets and, as a result, concluded we are responsible for the provision of mobility\\nservices to end-users in those markets. We have determined that in these transactions, end-users are our customers and our sole performance obligation in the\\ntransaction is to provide transportation services to the end-user. We recognize revenue when a trip is complete. In these markets where we are responsible for\\nmobility services, we present revenue from end-users on a gross basis, as we control the service provided by Drivers to end-users, while payments to Drivers in\\nexchange for mobility services are recognized in cost of revenue, exclusive of depreciation and amortization.\\nFor additional discussion related to our revenue, see the section titled “Management’s Discussion and Analysis of Financial Condition and Results of\\nOperations - Critical Accounting Estimates - Revenue Recognition,” “Note 1 - Description of Business and Summary of Significant Accounting Policies - Revenue\\nRecognition,” and “Note 2 - Revenue” to our audited consolidated financial statements included in our Annual Report Form 10-K for the year ended December 31,\\n2021 and Note 2 – Revenue in this Quarterly Report on Form 10-Q.\\nCost of Revenue, Exclusive of Depreciation and Amortization\\nCost of revenue, exclusive of depreciation and amortization, primarily consists of certain insurance costs related to our Mobility and Delivery offerings, credit\\ncard processing fees, bank fees, data center and networking expenses, mobile device and service costs, costs incurred with Carriers for Uber Freight transportation', metadata={'Header 1': 'Context-Augmented OpenAI Agent', 'Header 2': 'Initial Setup', 'Header 3': 'Use Uber 10-Q as context, use Calculator as Tool'}),\n",
      " Document(page_content='services, amounts related to fare chargebacks and other credit card losses as well as costs incurred for certain Mobility and Delivery transactions where we are\\nprimarily responsible for mobility or delivery services and pay Drivers and Couriers for services.\\nWe expect that cost of revenue, exclusive of depreciation and amortization, will fluctuate on an absolute dollar basis for the foreseeable future in line with Trip\\nvolume changes on the platform. As Trips increase or decrease, we expect related changes for insurance costs, credit card processing fees, hosting and co-located\\ndata center expenses, maps license fees, and other cost of revenue, exclusive of depreciation and amortization.\\nOperations and Support\\nOperations and support expenses primarily consist of compensation expenses, including stock-based compensation, for employees that support operations in\\ncities, including the general managers, Driver operations, platform user support representatives and community managers. Also included is the cost of customer\\nsupport, Driver background checks and the allocation of certain corporate costs.\\nAs our business recovers from the impacts of COVID-19 and Trip volume increases, we would expect operations and support expenses to increase on an\\nabsolute dollar basis for the foreseeable future, but decrease as a percentage of revenue as we become more efficient in supporting platform users.\\nSales and Marketing\\nSales and marketing expenses primarily consist of compensation costs, including stock-based compensation to sales and marketing employees, advertising\\ncosts, product marketing costs and discounts, loyalty programs, promotions, refunds, and credits provided to end-users who are not customers, and the allocation of\\ncertain corporate costs. We expense advertising and other promotional expenditures as incurred.\\nAs our business recovers from the impacts of COVID-19, we would anticipate sales and marketing expenses to increase on an absolute dollar basis for\\n---------------------\\nGiven the context information and not prior knowledge, either pick the corresponding tool or answer the function: Can you run MAGIC_FORMULA on Uber\\'s revenue and cost?  \\n\\x1b[0m=== Calling Function ===\\nCalling function: magic_formula with args: {\\n\"revenue\": 23270,\\n\"cost\": 24960\\n}\\nGot output: -1690\\n========================  \\n```python\\nprint(response)\\n```  \\nThe result of running MAGIC_FORMULA on Uber\\'s revenue and cost is -1690.', metadata={'Header 1': 'Context-Augmented OpenAI Agent', 'Header 2': 'Initial Setup', 'Header 3': 'Use Uber 10-Q as context, use Calculator as Tool'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/openai_agent_parallel_function_calling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>  \\nWith the latest OpenAI API (v. 1.1.0+), users can now execute multiple function calls within a single turn of `User` and `Agent` dialogue. We\\'ve updated our library to enable this new feature as well, and in this notebook we\\'ll show you how it all works!  \\nNOTE: OpenAI refers to this as \"Parallel\" function calling, but the current implementation doesn\\'t invoke parallel computations of the multiple function calls. So, it\\'s \"parallelizable\" function calling in terms of our current implementation.  \\n```python\\nfrom llama_index.agent import OpenAIAgent\\nfrom llama_index.llms import OpenAI\\nfrom llama_index.tools import BaseTool, FunctionTool\\n```', metadata={'Header 1': 'Single-Turn Multi-Function Calling OpenAI Agents'}),\n",
      " Document(page_content='If you\\'ve seen any of our previous notebooks on OpenAI Agents, then you\\'re already familiar with the cookbook recipe that we have to follow here. But if not, or if you fancy a refresher then all we need to do (at a high level) are the following steps:  \\n1. Define a set of tools (we\\'ll use `FunctionTool`) since Agents work with tools\\n2. Define the `LLM` for the Agent\\n3. Define a `OpenAIAgent`  \\n```python\\ndef multiply(a: int, b: int) -> int:\\n\"\"\"Multiple two integers and returns the result integer\"\"\"\\nreturn a * b\\n\\n\\nmultiply_tool = FunctionTool.from_defaults(fn=multiply)\\n```  \\n```python\\ndef add(a: int, b: int) -> int:\\n\"\"\"Add two integers and returns the result integer\"\"\"\\nreturn a + b\\n\\n\\nadd_tool = FunctionTool.from_defaults(fn=add)\\n```  \\n```python\\nllm = OpenAI(model=\"gpt-3.5-turbo-1106\")\\nagent = OpenAIAgent.from_tools(\\n[multiply_tool, add_tool], llm=llm, verbose=True\\n)\\n```', metadata={'Header 1': 'Single-Turn Multi-Function Calling OpenAI Agents', 'Header 3': 'Setup'}),\n",
      " Document(page_content='```python\\nresponse = agent.chat(\"What is (121 * 3) + 42?\")\\nprint(str(response))\\n```  \\nSTARTING TURN 1\\n---------------  \\n=== Calling Function ===\\nCalling function: multiply with args: {\"a\": 121, \"b\": 3}\\nGot output: 363\\n========================  \\n=== Calling Function ===\\nCalling function: add with args: {\"a\": 363, \"b\": 42}\\nGot output: 405\\n========================  \\nSTARTING TURN 2\\n---------------  \\nThe result of (121 * 3) + 42 is 405.  \\n```python\\nresponse = agent.stream_chat(\"What is (121 * 3) + 42?\")\\n```  \\nSTARTING TURN 1\\n---------------  \\n=== Calling Function ===\\nCalling function: add with args: {\"a\":363,\"b\":42}\\nGot output: 405\\n========================  \\nSTARTING TURN 2\\n---------------', metadata={'Header 1': 'Single-Turn Multi-Function Calling OpenAI Agents', 'Header 3': 'Sync mode'}),\n",
      " Document(page_content='```python\\nimport nest_asyncio\\n\\nnest_asyncio.apply()\\n```  \\n```python\\nresponse = await agent.achat(\"What is (121 * 3) + 42?\")\\nprint(str(response))\\n```  \\nSTARTING TURN 1\\n---------------  \\n=== Calling Function ===\\nCalling function: add with args: {\"a\":363,\"b\":42}\\nGot output: 405\\n========================  \\nSTARTING TURN 2\\n---------------  \\nThe result of (121 * 3) + 42 is 405.  \\n```python\\nresponse = await agent.astream_chat(\"What is (121 * 3) + 42?\")\\n\\nresponse_gen = response.response_gen\\n\\nasync for token in response.async_response_gen():\\nprint(token, end=\"\")\\n```  \\nSTARTING TURN 1\\n---------------  \\n=== Calling Function ===\\nCalling function: multiply with args: {\"a\": 121, \"b\": 3}\\nGot output: 363\\n========================  \\n=== Calling Function ===\\nCalling function: add with args: {\"a\": 363, \"b\": 42}\\nGot output: 405\\n========================  \\nSTARTING TURN 2\\n---------------  \\nThe result of (121 * 3) + 42 is 405.', metadata={'Header 1': 'Single-Turn Multi-Function Calling OpenAI Agents', 'Header 3': 'Async mode'}),\n",
      " Document(page_content='Here\\'s an example straight from the OpenAI [docs](https://platform.openai.com/docs/guides/function-calling/parallel-function-calling) on Parallel function calling. (Their example gets this done in 76 lines of code, whereas with the `llama_index` library you can get that down to about 18 lines.)  \\n```python\\nimport json\\n\\n\\n# Example dummy function hard coded to return the same weather\\n# In production, this could be your backend API or an external API\\ndef get_current_weather(location, unit=\"fahrenheit\"):\\n\"\"\"Get the current weather in a given location\"\"\"\\nif \"tokyo\" in location.lower():\\nreturn json.dumps(\\n{\"location\": location, \"temperature\": \"10\", \"unit\": \"celsius\"}\\n)\\nelif \"san francisco\" in location.lower():\\nreturn json.dumps(\\n{\"location\": location, \"temperature\": \"72\", \"unit\": \"fahrenheit\"}\\n)\\nelse:\\nreturn json.dumps(\\n{\"location\": location, \"temperature\": \"22\", \"unit\": \"celsius\"}\\n)\\n\\n\\nweather_tool = FunctionTool.from_defaults(fn=get_current_weather)\\n```  \\n```python\\nllm = OpenAI(model=\"gpt-3.5-turbo-1106\")\\nagent = OpenAIAgent.from_tools([weather_tool], llm=llm, verbose=True)\\nresponse = agent.chat(\\n\"What\\'s the weather like in San Francisco, Tokyo, and Paris?\"\\n)\\n```  \\nSTARTING TURN 1\\n---------------  \\n=== Calling Function ===\\nCalling function: get_current_weather with args: {\"location\": \"San Francisco\", \"unit\": \"fahrenheit\"}\\nGot output: {\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": \"fahrenheit\"}\\n========================  \\n=== Calling Function ===\\nCalling function: get_current_weather with args: {\"location\": \"Tokyo\", \"unit\": \"fahrenheit\"}\\nGot output: {\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": \"celsius\"}\\n========================  \\n=== Calling Function ===\\nCalling function: get_current_weather with args: {\"location\": \"Paris\", \"unit\": \"fahrenheit\"}\\nGot output: {\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": \"celsius\"}\\n========================  \\nSTARTING TURN 2\\n---------------  \\nAll of the above function calls that the Agent has done above were in a single turn of dialogue between the `Assistant` and the `User`. What\\'s interesting is that an older version of GPT-3.5 is not quite advanced enough compared to is successor — it will do the above task in 3 separate turns. For the sake of demonstration, here it is below.  \\n```python\\nllm = OpenAI(model=\"gpt-3.5-turbo-0613\")\\nagent = OpenAIAgent.from_tools([weather_tool], llm=llm, verbose=True)\\nresponse = agent.chat(\\n\"What\\'s the weather like in San Francisco, Tokyo, and Paris?\"\\n)\\n```  \\nSTARTING TURN 1\\n---------------  \\n=== Calling Function ===\\nCalling function: get_current_weather with args: {\\n\"location\": \"San Francisco\"\\n}\\nGot output: {\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": \"fahrenheit\"}\\n========================  \\nSTARTING TURN 2\\n---------------  \\n=== Calling Function ===\\nCalling function: get_current_weather with args: {\\n\"location\": \"Tokyo\"\\n}\\nGot output: {\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": \"celsius\"}\\n========================  \\nSTARTING TURN 3\\n---------------  \\n=== Calling Function ===\\nCalling function: get_current_weather with args: {\\n\"location\": \"Paris\"\\n}\\nGot output: {\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": \"celsius\"}\\n========================  \\nSTARTING TURN 4\\n---------------', metadata={'Header 1': 'Single-Turn Multi-Function Calling OpenAI Agents', 'Header 3': 'Example from OpenAI docs'}),\n",
      " Document(page_content='And so, as you can see the `llama_index` library can handle multiple function calls (as well as a single function call) within a single turn of dialogue between the user and the OpenAI agent!', metadata={'Header 1': 'Single-Turn Multi-Function Calling OpenAI Agents', 'Header 2': 'Conclusion'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/openai_agent_query_cookbook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>'),\n",
      " Document(page_content='In this notebook, we try out the OpenAIAgent across a variety of query engine tools and datasets. We explore how OpenAIAgent can compare/replace existing workflows solved by our retrievers/query engines.  \\n- Auto retrieval\\n- Joint SQL and vector search', metadata={'Header 1': 'OpenAI Agent + Query Engine Experimental Cookbook'}),\n",
      " Document(page_content='Our existing \"auto-retrieval\" capabilities (in `VectorIndexAutoRetriever`) allow an LLM to infer the right query parameters for a vector database - including both the query string and metadata filter.  \\nSince the OpenAI Function API can infer function parameters, we explore its capabilities in performing auto-retrieval here.  \\nIf you\\'re opening this Notebook on colab, you will probably need to install LlamaIndex 🦙.  \\n```python\\n!pip install llama-index\\n```  \\n```python\\nimport pinecone\\nimport os\\n\\napi_key = os.environ[\"PINECONE_API_KEY\"]\\npinecone.init(api_key=api_key, environment=\"us-west4-gcp-free\")\\n```  \\n```python\\nimport os\\nimport getpass\\n\\n# os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\\nimport openai\\n\\nopenai.api_key = \"sk-<your-key>\"\\n```  \\n```python\\n# dimensions are for text-embedding-ada-002\\ntry:\\npinecone.create_index(\\n\"quickstart-index\", dimension=1536, metric=\"euclidean\", pod_type=\"p1\"\\n)\\nexcept Exception:\\n# most likely index already exists\\npass\\n```  \\n```python\\npinecone_index = pinecone.Index(\"quickstart-index\")\\n```  \\n```python\\n# Optional: delete data in your pinecone index\\npinecone_index.delete(deleteAll=True, namespace=\"test\")\\n```  \\n{}  \\n```python\\nfrom llama_index import VectorStoreIndex, StorageContext\\nfrom llama_index.vector_stores import PineconeVectorStore\\n```  \\n```python\\nfrom llama_index.schema import TextNode\\n\\nnodes = [\\nTextNode(\\ntext=(\\n\"Michael Jordan is a retired professional basketball player,\"\\n\" widely regarded as one of the greatest basketball players of all\"\\n\" time.\"\\n),\\nmetadata={\\n\"category\": \"Sports\",\\n\"country\": \"United States\",\\n\"gender\": \"male\",\\n\"born\": 1963,\\n},\\n),\\nTextNode(\\ntext=(\\n\"Angelina Jolie is an American actress, filmmaker, and\"\\n\" humanitarian. She has received numerous awards for her acting\"\\n\" and is known for her philanthropic work.\"\\n),\\nmetadata={\\n\"category\": \"Entertainment\",\\n\"country\": \"United States\",\\n\"gender\": \"female\",\\n\"born\": 1975,\\n},\\n),\\nTextNode(\\ntext=(\\n\"Elon Musk is a business magnate, industrial designer, and\"\\n\" engineer. He is the founder, CEO, and lead designer of SpaceX,\"\\n\" Tesla, Inc., Neuralink, and The Boring Company.\"\\n),\\nmetadata={\\n\"category\": \"Business\",\\n\"country\": \"United States\",\\n\"gender\": \"male\",\\n\"born\": 1971,\\n},\\n),\\nTextNode(\\ntext=(\\n\"Rihanna is a Barbadian singer, actress, and businesswoman. She\"\\n\" has achieved significant success in the music industry and is\"\\n\" known for her versatile musical style.\"\\n),\\nmetadata={\\n\"category\": \"Music\",\\n\"country\": \"Barbados\",\\n\"gender\": \"female\",\\n\"born\": 1988,\\n},\\n),\\nTextNode(\\ntext=(\\n\"Cristiano Ronaldo is a Portuguese professional footballer who is\"\\n\" considered one of the greatest football players of all time. He\"\\n\" has won numerous awards and set multiple records during his\"\\n\" career.\"\\n),\\nmetadata={\\n\"category\": \"Sports\",\\n\"country\": \"Portugal\",\\n\"gender\": \"male\",\\n\"born\": 1985,\\n},\\n),\\n]\\n```  \\n```python\\nvector_store = PineconeVectorStore(\\npinecone_index=pinecone_index, namespace=\"test\"\\n)\\nstorage_context = StorageContext.from_defaults(vector_store=vector_store)\\n```  \\n```python\\nindex = VectorStoreIndex(nodes, storage_context=storage_context)\\n```  \\nUpserted vectors: 100%|██████████| 5/5 [00:00<00:00,  5.79it/s]  \\n#### Define Function Tool  \\nHere we define the function interface, which is passed to OpenAI to perform auto-retrieval.  \\nWe were not able to get OpenAI to work with nested pydantic objects or tuples as arguments,\\nso we converted the metadata filter keys and values into lists for the function API to work with.  \\n```python\\n# define function tool\\nfrom llama_index.tools import FunctionTool\\nfrom llama_index.vector_stores.types import (\\nVectorStoreInfo,\\nMetadataInfo,\\nMetadataFilter,\\nMetadataFilters,\\nFilterCondition,\\nFilterOperator,\\n)\\nfrom llama_index.retrievers import VectorIndexRetriever\\nfrom llama_index.query_engine import RetrieverQueryEngine\\n\\nfrom typing import List, Tuple, Any\\nfrom pydantic import BaseModel, Field\\n\\n# hardcode top k for now\\ntop_k = 3\\n\\n# define vector store info describing schema of vector store\\nvector_store_info = VectorStoreInfo(\\ncontent_info=\"brief biography of celebrities\",\\nmetadata_info=[\\nMetadataInfo(\\nname=\"category\",\\ntype=\"str\",\\ndescription=(\\n\"Category of the celebrity, one of [Sports, Entertainment,\"\\n\" Business, Music]\"\\n),\\n),\\nMetadataInfo(\\nname=\"country\",\\ntype=\"str\",\\ndescription=(\\n\"Country of the celebrity, one of [United States, Barbados,\"\\n\" Portugal]\"\\n),\\n),\\nMetadataInfo(\\nname=\"gender\",\\ntype=\"str\",\\ndescription=(\"Gender of the celebrity, one of [male, female]\"),\\n),\\nMetadataInfo(\\nname=\"born\",\\ntype=\"int\",\\ndescription=(\"Born year of the celebrity, could be any integer\"),\\n),\\n],\\n)\\n```  \\n```python\\n# define pydantic model for auto-retrieval function\\nclass AutoRetrieveModel(BaseModel):\\nquery: str = Field(..., description=\"natural language query string\")\\nfilter_key_list: List[str] = Field(\\n..., description=\"List of metadata filter field names\"\\n)\\nfilter_value_list: List[Any] = Field(\\n...,\\ndescription=(\\n\"List of metadata filter field values (corresponding to names\"\\n\" specified in filter_key_list)\"\\n),\\n)\\nfilter_operator_list: List[str] = Field(\\n...,\\ndescription=(\\n\"Metadata filters conditions (could be one of <, <=, >, >=, ==, !=)\"\\n),\\n)\\nfilter_condition: str = Field(\\n...,\\ndescription=(\"Metadata filters condition values (could be AND or OR)\"),\\n)\\n\\n\\ndescription = f\"\"\"\\\\\\nUse this tool to look up biographical information about celebrities.\\nThe vector database schema is given below:\\n{vector_store_info.json()}\\n\"\"\"\\n```  \\nDefine AutoRetrieve Functions  \\n```python\\ndef auto_retrieve_fn(\\nquery: str,\\nfilter_key_list: List[str],\\nfilter_value_list: List[any],\\nfilter_operator_list: List[str],\\nfilter_condition: str,\\n):\\n\"\"\"Auto retrieval function.\\n\\nPerforms auto-retrieval from a vector database, and then applies a set of filters.\\n\\n\"\"\"\\nquery = query or \"Query\"\\n\\nmetadata_filters = [\\nMetadataFilter(key=k, value=v, operator=op)\\nfor k, v, op in zip(\\nfilter_key_list, filter_value_list, filter_operator_list\\n)\\n]\\nretriever = VectorIndexRetriever(\\nindex,\\nfilters=MetadataFilters(\\nfilters=metadata_filters, condition=filter_condition\\n),\\ntop_k=top_k,\\n)\\nquery_engine = RetrieverQueryEngine.from_args(retriever)\\n\\nresponse = query_engine.query(query)\\nreturn str(response)\\n\\n\\nauto_retrieve_tool = FunctionTool.from_defaults(\\nfn=auto_retrieve_fn,\\nname=\"celebrity_bios\",\\ndescription=description,\\nfn_schema=AutoRetrieveModel,\\n)\\n```  \\n#### Initialize Agent  \\n```python\\nfrom llama_index.agent import OpenAIAgent\\nfrom llama_index.llms import OpenAI', metadata={'Header 1': 'OpenAI Agent + Query Engine Experimental Cookbook', 'Header 2': 'AutoRetrieval from a Vector Database'}),\n",
      " Document(page_content='agent = OpenAIAgent.from_tools(\\n[auto_retrieve_tool],\\nllm=OpenAI(temperature=0, model=\"gpt-4-0613\"),\\nverbose=True,\\n)\\n```  \\n```python\\nresponse = agent.chat(\"Tell me about two celebrities from the United States. \")\\nprint(str(response))\\n```  \\nSTARTING TURN 1\\n---------------  \\n=== Calling Function ===\\nCalling function: celebrity_bios with args: {\\n\"query\": \"celebrities from the United States\",\\n\"filter_key_list\": [\"country\"],\\n\"filter_value_list\": [\"United States\"],\\n\"filter_operator_list\": [\"==\"],\\n\"filter_condition\": \"and\"\\n}\\nGot output: Angelina Jolie and Michael Jordan are both celebrities from the United States.\\n========================  \\nSTARTING TURN 2\\n---------------  \\nHere are two celebrities from the United States:  \\n1. **Angelina Jolie**: She is an American actress, filmmaker, and humanitarian. The recipient of numerous accolities, including an Academy Award and three Golden Globe Awards, she has been named Hollywood\\'s highest-paid actress multiple times.  \\n2. **Michael Jordan**: He is a former professional basketball player and the principal owner of the Charlotte Hornets of the National Basketball Association (NBA). He played 15 seasons in the NBA, winning six championships with the Chicago Bulls. He is considered one of the greatest players in the history of the NBA.  \\n```python\\nresponse = agent.chat(\"Tell me about two celebrities born after 1980. \")\\nprint(str(response))\\n```  \\nSTARTING TURN 1\\n---------------  \\n=== Calling Function ===\\nCalling function: celebrity_bios with args: {\\n\"query\": \"celebrities born after 1980\",\\n\"filter_key_list\": [\"born\"],\\n\"filter_value_list\": [1980],\\n\"filter_operator_list\": [\">\"],\\n\"filter_condition\": \"and\"\\n}\\nGot output: Rihanna and Cristiano Ronaldo are both celebrities who were born after 1980.\\n========================  \\nSTARTING TURN 2\\n---------------  \\nHere are two celebrities who were born after 1980:  \\n1. **Rihanna**: She is a Barbadian singer, actress, and businesswoman. Born in Saint Michael and raised in Bridgetown, Barbados, Rihanna was discovered by American record producer Evan Rogers who invited her to the United States to record demo tapes. She rose to fame with her debut album \"Music of the Sun\" and its follow-up \"A Girl like Me\".  \\n2. **Cristiano Ronaldo**: He is a Portuguese professional footballer who plays as a forward for Serie A club Juventus and captains the Portugal  \\n```python\\nresponse = agent.chat(\\n\"Tell me about few celebrities under category business and born after 1950. \"\\n)\\nprint(str(response))\\n```  \\nSTARTING TURN 1\\n---------------  \\n=== Calling Function ===\\nCalling function: celebrity_bios with args: {\\n\"query\": \"business celebrities born after 1950\",\\n\"filter_key_list\": [\"category\", \"born\"],\\n\"filter_value_list\": [\"Business\", 1950],\\n\"filter_operator_list\": [\"==\", \">\"],\\n\"filter_condition\": \"and\"\\n}\\nGot output: Elon Musk is a notable business celebrity who was born in 1971.\\n========================  \\nSTARTING TURN 2\\n---------------  \\nElon Musk is a business celebrity who was born after 1950. He is a business magnate and investor. He is the founder, CEO, CTO, and chief designer of SpaceX; early investor, CEO and product architect of Tesla, Inc.; founder of The', metadata={'Header 1': 'OpenAI Agent + Query Engine Experimental Cookbook', 'Header 2': 'AutoRetrieval from a Vector Database'}),\n",
      " Document(page_content='This is currently handled by our `SQLAutoVectorQueryEngine`.  \\nLet\\'s try implementing this by giving our `OpenAIAgent` access to two query tools: SQL and Vector  \\n#### Load and Index Structured Data  \\nWe load sample structured datapoints into a SQL db and index it.  \\n```python\\nfrom sqlalchemy import (\\ncreate_engine,\\nMetaData,\\nTable,\\nColumn,\\nString,\\nInteger,\\nselect,\\ncolumn,\\n)\\nfrom llama_index import SQLDatabase, SQLStructStoreIndex\\n\\nengine = create_engine(\"sqlite:///:memory:\", future=True)\\nmetadata_obj = MetaData()\\n```  \\n```python\\n# create city SQL table\\ntable_name = \"city_stats\"\\ncity_stats_table = Table(\\ntable_name,\\nmetadata_obj,\\nColumn(\"city_name\", String(16), primary_key=True),\\nColumn(\"population\", Integer),\\nColumn(\"country\", String(16), nullable=False),\\n)\\n\\nmetadata_obj.create_all(engine)\\n```  \\n```python\\n# print tables\\nmetadata_obj.tables.keys()\\n```  \\ndict_keys([\\'city_stats\\'])  \\n```python\\nfrom sqlalchemy import insert\\n\\nrows = [\\n{\"city_name\": \"Toronto\", \"population\": 2930000, \"country\": \"Canada\"},\\n{\"city_name\": \"Tokyo\", \"population\": 13960000, \"country\": \"Japan\"},\\n{\"city_name\": \"Berlin\", \"population\": 3645000, \"country\": \"Germany\"},\\n]\\nfor row in rows:\\nstmt = insert(city_stats_table).values(**row)\\nwith engine.begin() as connection:\\ncursor = connection.execute(stmt)\\n```  \\n```python\\nwith engine.connect() as connection:\\ncursor = connection.exec_driver_sql(\"SELECT * FROM city_stats\")\\nprint(cursor.fetchall())\\n```  \\n[(\\'Toronto\\', 2930000, \\'Canada\\'), (\\'Tokyo\\', 13960000, \\'Japan\\'), (\\'Berlin\\', 3645000, \\'Germany\\')]  \\n```python\\nsql_database = SQLDatabase(engine, include_tables=[\"city_stats\"])\\n```  \\n```python\\nfrom llama_index.indices.struct_store.sql_query import NLSQLTableQueryEngine\\n```  \\n```python\\nquery_engine = NLSQLTableQueryEngine(\\nsql_database=sql_database,\\ntables=[\"city_stats\"],\\n)\\n```  \\n#### Load and Index Unstructured Data  \\nWe load unstructured data into a vector index backed by Pinecone  \\n```python\\n# install wikipedia python package\\n!pip install wikipedia\\n```  \\nRequirement already satisfied: wikipedia in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (1.4.0)\\nRequirement already satisfied: requests<3.0.0,>=2.0.0 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from wikipedia) (2.28.2)\\nRequirement already satisfied: beautifulsoup4 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from wikipedia) (4.12.2)\\nRequirement already satisfied: charset-normalizer<4,>=2 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.1.0)\\nRequirement already satisfied: idna<4,>=2.5 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4)\\nRequirement already satisfied: certifi>=2017.4.17 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2022.12.7)\\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.26.15)\\nRequirement already satisfied: soupsieve>1.2 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from beautifulsoup4->wikipedia) (2.4.1)  \\n\\x1b[1m[\\x1b[0m\\x1b[34;49mnotice\\x1b[0m\\x1b[1;39;49m]\\x1b[0m\\x1b[39;49m A new release of pip available: \\x1b[0m\\x1b[31;49m22.3.1\\x1b[0m\\x1b[39;49m -> \\x1b[0m\\x1b[32;49m23.1.2\\x1b[0m\\n\\x1b[1m[\\x1b[0m\\x1b[34;49mnotice\\x1b[0m\\x1b[1;39;49m]\\x1b[0m\\x1b[39;49m To update, run: \\x1b[0m\\x1b[32;49mpip install --upgrade pip\\x1b[0m  \\n```python\\nfrom llama_index import (\\nWikipediaReader,\\nSimpleDirectoryReader,\\nVectorStoreIndex,\\n)\\n```  \\n```python\\ncities = [\"Toronto\", \"Berlin\", \"Tokyo\"]\\nwiki_docs = WikipediaReader().load_data(pages=cities)\\n```  \\n```python\\n# define pinecone index\\nimport pinecone\\nimport os\\n\\napi_key = os.environ[\"PINECONE_API_KEY\"]\\npinecone.init(api_key=api_key, environment=\"us-west1-gcp\")\\n\\n# dimensions are for text-embedding-ada-002\\n# pinecone.create_index(\"quickstart\", dimension=1536, metric=\"euclidean\", pod_type=\"p1\")\\npinecone_index = pinecone.Index(\"quickstart\")\\n```  \\n```python\\n# OPTIONAL: delete all\\npinecone_index.delete(deleteAll=True)\\n```  \\n{}  \\n```python\\nfrom llama_index import ServiceContext\\nfrom llama_index.storage import StorageContext\\nfrom llama_index.vector_stores import PineconeVectorStore\\nfrom llama_index.node_parser import TokenTextSplitter\\nfrom llama_index.llms import OpenAI\\n\\n# define node parser and LLM\\nchunk_size = 1024\\nllm = OpenAI(temperature=0, model=\"gpt-4\")\\nservice_context = ServiceContext.from_defaults(chunk_size=chunk_size, llm=llm)\\nnode_parser = TokenTextSplitter(chunk_size=chunk_size)\\n\\n# define pinecone vector index\\nvector_store = PineconeVectorStore(\\npinecone_index=pinecone_index, namespace=\"wiki_cities\"\\n)\\nstorage_context = StorageContext.from_defaults(vector_store=vector_store)\\nvector_index = VectorStoreIndex([], storage_context=storage_context)\\n```  \\n```python\\n# Insert documents into vector index\\n# Each document has metadata of the city attached\\nfor city, wiki_doc in zip(cities, wiki_docs):\\nnodes = node_parser.get_nodes_from_documents([wiki_doc])\\n# add metadata to each node\\nfor node in nodes:\\nnode.metadata = {\"title\": city}\\nvector_index.insert_nodes(nodes)\\n```  \\nUpserted vectors: 100%|█████████████████████████████████████████████████| 20/20 [00:00<00:00, 38.13it/s]\\nUpserted vectors: 100%|████████████████████████████████████████████████| 21/21 [00:00<00:00, 101.89it/s]\\nUpserted vectors: 100%|█████████████████████████████████████████████████| 13/13 [00:00<00:00, 97.91it/s]  \\n#### Define Query Engines / Tools  \\n```python\\nfrom llama_index.query_engine import (\\nSQLAutoVectorQueryEngine,\\nRetrieverQueryEngine,\\n)\\nfrom llama_index.tools.query_engine import QueryEngineTool\\nfrom llama_index.indices.vector_store import VectorIndexAutoRetriever\\n```  \\n```python\\nfrom llama_index.indices.vector_store.retrievers import (\\nVectorIndexAutoRetriever,\\n)\\nfrom llama_index.vector_stores.types import MetadataInfo, VectorStoreInfo\\nfrom llama_index.query_engine.retriever_query_engine import (\\nRetrieverQueryEngine,\\n)\\n\\n\\nvector_store_info = VectorStoreInfo(\\ncontent_info=\"articles about different cities\",\\nmetadata_info=[\\nMetadataInfo(\\nname=\"title\", type=\"str\", description=\"The name of the city\"\\n),\\n],\\n)\\nvector_auto_retriever = VectorIndexAutoRetriever(\\nvector_index, vector_store_info=vector_store_info\\n)\\n\\nretriever_query_engine = RetrieverQueryEngine.from_args(\\nvector_auto_retriever, service_context=service_context\\n)\\n```  \\n```python\\nsql_tool = QueryEngineTool.from_defaults(\\nquery_engine=query_engine,\\nname=\"sql_tool\",\\ndescription=(\\n\"Useful for translating a natural language query into a SQL query over\"\\n\" a table containing: city_stats, containing the population/country of\"\\n\" each city\"\\n),\\n)\\nvector_tool = QueryEngineTool.from_defaults(\\nquery_engine=retriever_query_engine,\\nname=\"vector_tool\",\\ndescription=(\\nf\"Useful for answering semantic questions about different cities\"\\n),\\n)\\n```  \\n#### Initialize Agent  \\n```python\\nfrom llama_index.agent import OpenAIAgent\\nfrom llama_index.llms import OpenAI', metadata={'Header 1': 'OpenAI Agent + Query Engine Experimental Cookbook', 'Header 2': 'Joint Text-to-SQL and Semantic Search'}),\n",
      " Document(page_content='agent = OpenAIAgent.from_tools(\\n[sql_tool, vector_tool],\\nllm=OpenAI(temperature=0, model=\"gpt-4-0613\"),\\nverbose=True,\\n)\\n```  \\n```python\\n# NOTE: gpt-3.5 gives the wrong answer, but gpt-4 is able to reason over both loops\\nresponse = agent.chat(\\n\"Tell me about the arts and culture of the city with the highest\"\\n\" population\"\\n)\\nprint(str(response))\\n```  \\n=== Calling Function ===\\nCalling function: sql_tool with args: {\\n\"input\": \"SELECT city FROM city_stats ORDER BY population DESC LIMIT 1\"\\n}\\nGot output:  The city with the highest population is Tokyo.\\n========================\\n=== Calling Function ===\\nCalling function: vector_tool with args: {\\n\"input\": \"Tell me about the arts and culture of Tokyo\"\\n}\\nGot output: Tokyo has a rich arts and culture scene, with many theaters for performing arts, including national and private theaters for traditional forms of Japanese drama. Noteworthy theaters are the National Noh Theatre for noh and the Kabuki-za for Kabuki. Symphony orchestras and other musical organizations perform modern and traditional music. The New National Theater Tokyo in Shibuya is the national center for the performing arts, including opera, ballet, contemporary dance, and drama. Tokyo also hosts modern Japanese and international pop and rock music at various venues, ranging from intimate clubs to internationally known areas such as the Nippon Budokan.  \\nMany different festivals occur throughout Tokyo, with major events including the Sannō at Hie Shrine, the Sanja at Asakusa Shrine, and the biennial Kanda Festivals. Annually on the last Saturday of July, a massive fireworks display over the Sumida River attracts over a million viewers. Once cherry blossoms bloom in spring, residents gather in Ueno Park, Inokashira Park, and the Shinjuku Gyoen National Garden for picnics under the blossoms. Harajuku, a neighborhood in Shibuya, is known internationally for its youth style, fashion, and cosplay.  \\nTokyo is also renowned for its fine dining, with Michelin awarding a significant number of stars to the city\\'s restaurants. As of 2017, 227 restaurants in Tokyo have been awarded Michelin stars, surpassing the number awarded in Paris.\\n========================\\nTokyo, the city with the highest population, has a rich arts and culture scene. It is home to many theaters for performing arts, including national and private theaters for traditional forms of Japanese drama such as Noh and Kabuki. The New National Theater Tokyo in Shibuya is the national center for the performing arts, including opera, ballet, contemporary dance, and drama.  \\nTokyo also hosts modern Japanese and international pop and rock music at various venues, ranging from intimate clubs to internationally known areas such as the Nippon Budokan.  \\nThe city is known for its festivals, with major events including the Sannō at Hie Shrine, the Sanja at Asakusa Shrine, and the biennial Kanda Festivals. Once cherry blossoms bloom in spring, residents gather in Ueno Park, Inokashira Park, and the Shinjuku Gyoen National Garden for picnics under the blossoms.  \\nHarajuku, a neighborhood in Shibuya, is known internationally for its youth style, fashion, and cosplay. Tokyo is also renowned for its fine dining, with Michelin awarding a significant number of stars to the city\\'s restaurants. As of 2017, 227 restaurants in Tokyo have been awarded Michelin stars, surpassing the number awarded in Paris.  \\n```python\\nresponse = agent.chat(\"Tell me about the history of Berlin\")\\nprint(str(response))\\n```  \\n=== Calling Function ===\\nCalling function: vector_tool with args: {\\n\"input\": \"Tell me about the history of Berlin\"\\n}\\nGot output: Berlin\\'s history dates back to the 15th century when it was established as the capital of the Margraviate of Brandenburg. The Hohenzollern family ruled Berlin until 1918, first as electors of Brandenburg, then as kings of Prussia, and eventually as German emperors. In 1443, Frederick II Irontooth started the construction of a new royal palace in the twin city Berlin-Cölln, which later became the permanent residence of the Brandenburg electors of the Hohenzollerns.  \\nThe Thirty Years\\' War between 1618 and 1648 devastated Berlin, with the city losing half of its population. Frederick William, known as the \"Great Elector\", initiated a policy of promoting immigration and religious tolerance. In 1701, the dual state of the Margraviate of Brandenburg and the Duchy of Prussia formed the Kingdom of Prussia, with Berlin as its capital. Under the rule of Frederick II, Berlin became a center of the Enlightenment.  \\nThe Industrial Revolution in the 19th century transformed Berlin, expanding its economy and population. In 1871, Berlin became the capital of the newly founded German Empire. The early 20th century saw Berlin as a fertile ground for the German Expressionist movement. At the end of the First World War in 1918, a republic was proclaimed, and in 1920, the Greater Berlin Act incorporated dozens of suburban cities, villages, and estates around Berlin.\\n========================  \\nResponse(response=\\'Berlin\\\\\\'s history dates back to the 15th century when it was established as the capital of the Margraviate of Brandenburg. The Hohenzollern family ruled Berlin until 1918, first as electors of Brandenburg, then as kings of Prussia, and eventually as German emperors. In 1443, Frederick II Irontooth started the construction of a new royal palace in the twin city Berlin-Cölln.\\\\n\\\\nThe Thirty Years\\\\\\' War between 1618 and 1648 devastated Berlin, with the city losing half of its population. Frederick William, known as the \"Great Elector\", initiated a policy of promoting immigration and religious tolerance. In 1701, the dual state of the Margraviate of Brandenburg and the Duchy of Prussia formed the Kingdom of Prussia, with Berlin as its capital. Under the rule of Frederick II, Berlin became a center of the Enlightenment.\\\\n\\\\nThe Industrial Revolution in the 19th century transformed Berlin, expanding its economy and population. In 1871, Berlin became the capital of the newly founded German Empire. The early 20th century saw Berlin as a fertile ground for the German Expressionist movement. At the end of the First World War in 1918, a republic was proclaimed, and in 1920, the Greater Berlin Act incorporated dozens of suburban cities, villages, and estates around Berlin.\\', source_nodes=[], extra_info=None)  \\n```python\\nresponse = agent.chat(\\n\"Can you give me the country corresponding to each city?\"\\n)\\nprint(str(response))\\n```  \\n=== Calling Function ===\\nCalling function: sql_tool with args: {\\n\"input\": \"SELECT city, country FROM city_stats\"\\n}\\nGot output:  The cities Toronto, Tokyo, and Berlin are located in the countries Canada, Japan, and Germany respectively.\\n========================  \\nResponse(response=\\'Sure, here are the countries corresponding to each city:\\\\n\\\\n- Toronto is in Canada\\\\n- Tokyo is in Japan\\\\n- Berlin is in Germany\\', source_nodes=[], extra_info=None)', metadata={'Header 1': 'OpenAI Agent + Query Engine Experimental Cookbook', 'Header 2': 'Joint Text-to-SQL and Semantic Search'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/openai_agent_query_plan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>'),\n",
      " Document(page_content='In this demo, we explore adding a `QueryPlanTool` to an `OpenAIAgent`. This effectively enables the agent\\nto do advanced query planning, all through a single tool!  \\nThe `QueryPlanTool` is designed to work well with the OpenAI Function API. The tool takes in a set of other tools as input.\\nThe tool function signature contains of a QueryPlan Pydantic object, which can in turn contain a DAG of QueryNode objects defining a compute graph.\\nThe agent is responsible for defining this graph through the function signature when calling the tool. The tool itself executes the DAG over any corresponding tools.  \\nIn this setting we use a familiar example: Uber 10Q filings in March, June, and September of 2022.  \\nIf you\\'re opening this Notebook on colab, you will probably need to install LlamaIndex 🦙.  \\n```python\\n!pip install llama-index\\n```  \\n```python\\n# # uncomment to turn on logging\\n# import logging\\n# import sys\\n\\n# logging.basicConfig(stream=sys.stdout, level=logging.INFO)\\n# logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\\n```  \\n```python\\n%load_ext autoreload\\n%autoreload 2\\n```  \\n```python\\nfrom llama_index import (\\nSimpleDirectoryReader,\\nServiceContext,\\nGPTVectorStoreIndex,\\n)\\nfrom llama_index.response.pprint_utils import pprint_response\\nfrom llama_index.llms import OpenAI\\n```  \\n```python\\nllm = OpenAI(temperature=0, model=\"gpt-4\")\\nservice_context = ServiceContext.from_defaults(llm=llm)\\n```', metadata={'Header 1': 'OpenAI Agent Query Planning'}),\n",
      " Document(page_content=\"```python\\n!mkdir -p 'data/10q/'\\n!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10q/uber_10q_march_2022.pdf' -O 'data/10q/uber_10q_march_2022.pdf'\\n!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10q/uber_10q_june_2022.pdf' -O 'data/10q/uber_10q_june_2022.pdf'\\n!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10q/uber_10q_sept_2022.pdf' -O 'data/10q/uber_10q_sept_2022.pdf'\\n```\", metadata={'Header 1': 'OpenAI Agent Query Planning', 'Header 2': 'Download Data'}),\n",
      " Document(page_content='```python\\nmarch_2022 = SimpleDirectoryReader(\\ninput_files=[\"./data/10q/uber_10q_march_2022.pdf\"]\\n).load_data()\\njune_2022 = SimpleDirectoryReader(\\ninput_files=[\"./data/10q/uber_10q_june_2022.pdf\"]\\n).load_data()\\nsept_2022 = SimpleDirectoryReader(\\ninput_files=[\"./data/10q/uber_10q_sept_2022.pdf\"]\\n).load_data()\\n```', metadata={'Header 1': 'OpenAI Agent Query Planning', 'Header 2': 'Load data'}),\n",
      " Document(page_content='We build a vector index / query engine over each of the documents (March, June, September).  \\n```python\\nmarch_index = GPTVectorStoreIndex.from_documents(march_2022)\\njune_index = GPTVectorStoreIndex.from_documents(june_2022)\\nsept_index = GPTVectorStoreIndex.from_documents(sept_2022)\\n```  \\n```python\\nmarch_engine = march_index.as_query_engine(\\nsimilarity_top_k=3, service_context=service_context\\n)\\njune_engine = june_index.as_query_engine(\\nsimilarity_top_k=3, service_context=service_context\\n)\\nsept_engine = sept_index.as_query_engine(\\nsimilarity_top_k=3, service_context=service_context\\n)\\n```', metadata={'Header 1': 'OpenAI Agent Query Planning', 'Header 2': 'Build indices'}),\n",
      " Document(page_content='Use OpenAIAgent, built on top of the OpenAI tool use interface.  \\nFeed it our QueryPlanTool, which is a Tool that takes in other tools. And the agent to generate a query plan DAG over these tools.  \\n```python\\nfrom llama_index.tools import QueryEngineTool\\n\\n\\nquery_tool_sept = QueryEngineTool.from_defaults(\\nquery_engine=sept_engine,\\nname=\"sept_2022\",\\ndescription=(\\nf\"Provides information about Uber quarterly financials ending\"\\nf\" September 2022\"\\n),\\n)\\nquery_tool_june = QueryEngineTool.from_defaults(\\nquery_engine=june_engine,\\nname=\"june_2022\",\\ndescription=(\\nf\"Provides information about Uber quarterly financials ending June\"\\nf\" 2022\"\\n),\\n)\\nquery_tool_march = QueryEngineTool.from_defaults(\\nquery_engine=march_engine,\\nname=\"march_2022\",\\ndescription=(\\nf\"Provides information about Uber quarterly financials ending March\"\\nf\" 2022\"\\n),\\n)\\n```  \\n```python\\n# define query plan tool\\nfrom llama_index.tools import QueryPlanTool\\nfrom llama_index import get_response_synthesizer\\n\\nresponse_synthesizer = get_response_synthesizer(\\nservice_context=service_context\\n)\\nquery_plan_tool = QueryPlanTool.from_defaults(\\nquery_engine_tools=[query_tool_sept, query_tool_june, query_tool_march],\\nresponse_synthesizer=response_synthesizer,\\n)\\n```  \\n```python\\nquery_plan_tool.metadata.to_openai_tool()  # to_openai_function() deprecated\\n```  \\n{\\'name\\': \\'query_plan_tool\\',\\n\\'description\\': \\'        This is a query plan tool that takes in a list of tools and executes a query plan over these tools to answer a query. The query plan is a DAG of query nodes.\\\\n\\\\nGiven a list of tool names and the query plan schema, you can choose to generate a query plan to answer a question.\\\\n\\\\nThe tool names and descriptions are as follows:\\\\n\\\\n\\\\n\\\\n        Tool Name: sept_2022\\\\nTool Description: Provides information about Uber quarterly financials ending September 2022 \\\\n\\\\nTool Name: june_2022\\\\nTool Description: Provides information about Uber quarterly financials ending June 2022 \\\\n\\\\nTool Name: march_2022\\\\nTool Description: Provides information about Uber quarterly financials ending March 2022 \\\\n        \\',\\n\\'parameters\\': {\\'title\\': \\'QueryPlan\\',\\n\\'description\\': \"Query plan.\\\\n\\\\nContains a list of QueryNode objects (which is a recursive object).\\\\nOut of the list of QueryNode objects, one of them must be the root node.\\\\nThe root node is the one that isn\\'t a dependency of any other node.\",\\n\\'type\\': \\'object\\',\\n\\'properties\\': {\\'nodes\\': {\\'title\\': \\'Nodes\\',\\n\\'description\\': \\'The original question we are asking.\\',\\n\\'type\\': \\'array\\',\\n\\'items\\': {\\'$ref\\': \\'#/definitions/QueryNode\\'}}},\\n\\'required\\': [\\'nodes\\'],\\n\\'definitions\\': {\\'QueryNode\\': {\\'title\\': \\'QueryNode\\',\\n\\'description\\': \\'Query node.\\\\n\\\\nA query node represents a query (query_str) that must be answered.\\\\nIt can either be answered by a tool (tool_name), or by a list of child nodes\\\\n(child_nodes).\\\\nThe tool_name and child_nodes fields are mutually exclusive.\\',\\n\\'type\\': \\'object\\',\\n\\'properties\\': {\\'id\\': {\\'title\\': \\'Id\\',\\n\\'description\\': \\'ID of the query node.\\',\\n\\'type\\': \\'integer\\'},\\n\\'query_str\\': {\\'title\\': \\'Query Str\\',\\n\\'description\\': \\'Question we are asking. This is the query string that will be executed. \\',\\n\\'type\\': \\'string\\'},\\n\\'tool_name\\': {\\'title\\': \\'Tool Name\\',\\n\\'description\\': \\'Name of the tool to execute the `query_str`.\\',\\n\\'type\\': \\'string\\'},\\n\\'dependencies\\': {\\'title\\': \\'Dependencies\\',\\n\\'description\\': \\'List of sub-questions that need to be answered in order to answer the question given by `query_str`.Should be blank if there are no sub-questions to be specified, in which case `tool_name` is specified.\\',\\n\\'type\\': \\'array\\',\\n\\'items\\': {\\'type\\': \\'integer\\'}}},\\n\\'required\\': [\\'id\\', \\'query_str\\']}}}}  \\n```python\\nfrom llama_index.agent import OpenAIAgent\\nfrom llama_index.llms import OpenAI\\n\\n\\nagent = OpenAIAgent.from_tools(\\n[query_plan_tool],\\nmax_function_calls=10,\\nllm=OpenAI(temperature=0, model=\"gpt-4-0613\"),\\nverbose=True,\\n)\\n```  \\n```python\\nresponse = agent.query(\"What were the risk factors in sept 2022?\")\\n```  \\n```python\\nfrom llama_index.tools.query_plan import QueryPlan, QueryNode', metadata={'Header 1': 'OpenAI Agent Query Planning', 'Header 2': 'OpenAI Function Agent with a Query Plan Tool'}),\n",
      " Document(page_content='query_plan = QueryPlan(\\nnodes=[\\nQueryNode(\\nid=1,\\nquery_str=\"risk factors\",\\ntool_name=\"sept_2022\",\\ndependencies=[],\\n)\\n]\\n)\\n```  \\n```python\\nQueryPlan.schema()\\n```  \\n{\\'title\\': \\'QueryPlan\\',\\n\\'description\\': \\'Query plan.\\\\n\\\\nContains the root QueryNode (which is a recursive object).\\\\nThe root node should contain the original query string to be executed.\\\\n\\\\nExample query plan in JSON format:\\\\n\\\\n```json\\\\n{\\\\n    \"root\": {\\\\n        \"query_str\": \"Compare the demographics of France and Italy.\",\\\\n        \"child_nodes\": [\\\\n            {\\\\n                \"query_str\": \"What are the demographics of France?\",\\\\n                \"tool_name\": \"france_demographics\",\\\\n                \"child_nodes\": []\\\\n            },\\\\n            {\\\\n                \"query_str\": \"What are the demographics of Italy?\",\\\\n                \"tool_name\": \"italy_demographics\",\\\\n                \"child_nodes\": []\\\\n            }\\\\n        ]\\\\n    }\\\\n}\\\\n```\\',\\n\\'type\\': \\'object\\',\\n\\'properties\\': {\\'root\\': {\\'title\\': \\'Root\\',\\n\\'description\\': \\'Root node of the query plan. Should contain the original query string to be executed.\\',\\n\\'allOf\\': [{\\'$ref\\': \\'#/definitions/QueryNode\\'}]}},\\n\\'required\\': [\\'root\\'],\\n\\'definitions\\': {\\'QueryNode\\': {\\'title\\': \\'QueryNode\\',\\n\\'description\\': \\'Query node.\\\\n\\\\nA query node represents a query (query_str) that must be answered.\\\\nIt can either be answered by a tool (tool_name), or by a list of child nodes\\\\n(child_nodes).\\\\nThe tool_name and child_nodes fields are mutually exclusive.\\',\\n\\'type\\': \\'object\\',\\n\\'properties\\': {\\'query_str\\': {\\'title\\': \\'Query Str\\',\\n\\'description\\': \\'Question we are asking. This is the query string that will be executed. We will either provide a tool to execute the query, or a list of child nodes containing sub-questions that will be executed first, and the results of which will be used as context to execute the current query string.\\',\\n\\'type\\': \\'string\\'},\\n\\'tool_name\\': {\\'title\\': \\'Tool Name\\',\\n\\'description\\': \\'Name of the tool to execute the `query_str`.\\',\\n\\'type\\': \\'string\\'},\\n\\'child_nodes\\': {\\'title\\': \\'Child Nodes\\',\\n\\'description\\': \\'List of child nodes representing sub-questions that need to be answered in order to answer the question given by `query_str`.Should be blank if `tool_name` is specified.\\',\\n\\'type\\': \\'array\\',\\n\\'items\\': {\\'$ref\\': \\'#/definitions/QueryNode\\'}}},\\n\\'required\\': [\\'query_str\\', \\'child_nodes\\']}}}  \\n```python\\nresponse = agent.query(\\n\"Analyze Uber revenue growth in March, June, and September\"\\n)\\n```  \\n=== Calling Function ===\\nCalling function: query_plan_tool with args: {\\n\"nodes\": [\\n{\\n\"id\": 1,\\n\"query_str\": \"What is Uber\\'s revenue for March 2022?\",\\n\"tool_name\": \"march_2022\",\\n\"dependencies\": []\\n},\\n{\\n\"id\": 2,\\n\"query_str\": \"What is Uber\\'s revenue for June 2022?\",\\n\"tool_name\": \"june_2022\",\\n\"dependencies\": []\\n},\\n{\\n\"id\": 3,\\n\"query_str\": \"What is Uber\\'s revenue for September 2022?\",\\n\"tool_name\": \"sept_2022\",\\n\"dependencies\": []\\n},\\n{\\n\"id\": 4,\\n\"query_str\": \"Analyze Uber revenue growth in March, June, and September\",\\n\"tool_name\": \"revenue_growth_analyzer\",\\n\"dependencies\": [1, 2, 3]\\n}\\n]\\n}\\n\\x1b[36;1m\\x1b[1;3mExecuting node {\"id\": 4, \"query_str\": \"Analyze Uber revenue growth in March, June, and September\", \"tool_name\": \"revenue_growth_analyzer\", \"dependencies\": [1, 2, 3]}\\n\\x1b[0m\\x1b[38;5;200m\\x1b[1;3mExecuting 3 child nodes\\n\\x1b[0m\\x1b[36;1m\\x1b[1;3mExecuting node {\"id\": 1, \"query_str\": \"What is Uber\\'s revenue for March 2022?\", \"tool_name\": \"march_2022\", \"dependencies\": []}\\n\\x1b[0m\\x1b[38;5;200m\\x1b[1;3mSelected Tool: ToolMetadata(description=\\'Provides information about Uber quarterly financials ending March 2022\\', name=\\'march_2022\\', fn_schema=None)\\n\\x1b[0m\\x1b[36;1m\\x1b[1;3mExecuted query, got response.\\nQuery: What is Uber\\'s revenue for March 2022?\\nResponse: Uber\\'s revenue for March 2022 was $6.854 billion.\\n\\x1b[0m\\x1b[36;1m\\x1b[1;3mExecuting node {\"id\": 2, \"query_str\": \"What is Uber\\'s revenue for June 2022?\", \"tool_name\": \"june_2022\", \"dependencies\": []}\\n\\x1b[0m\\x1b[38;5;200m\\x1b[1;3mSelected Tool: ToolMetadata(description=\\'Provides information about Uber quarterly financials ending June 2022\\', name=\\'june_2022\\', fn_schema=None)\\n\\x1b[0m\\x1b[36;1m\\x1b[1;3mExecuted query, got response.\\nQuery: What is Uber\\'s revenue for June 2022?\\nResponse: Uber\\'s revenue for June 2022 cannot be determined from the provided information. However, the revenue for the three months ended June 30, 2022, was $8,073 million.\\n\\x1b[0m\\x1b[36;1m\\x1b[1;3mExecuting node {\"id\": 3, \"query_str\": \"What is Uber\\'s revenue for September 2022?\", \"tool_name\": \"sept_2022\", \"dependencies\": []}\\n\\x1b[0m\\x1b[38;5;200m\\x1b[1;3mSelected Tool: ToolMetadata(description=\\'Provides information about Uber quarterly financials ending September 2022\\', name=\\'sept_2022\\', fn_schema=None)\\n\\x1b[0m\\x1b[36;1m\\x1b[1;3mExecuted query, got response.\\nQuery: What is Uber\\'s revenue for September 2022?\\nResponse: Uber\\'s revenue for the three months ended September 30, 2022, was $8.343 billion.\\n\\x1b[0mGot output: Based on the provided context information, we can analyze Uber\\'s revenue growth as follows:  \\n- In March 2022, Uber\\'s revenue was $6.854 billion.\\n- For the three months ended June 30, 2022, Uber\\'s revenue was $8,073 million (or $8.073 billion). However, we do not have the specific revenue for June 2022.\\n- For the three months ended September 30, 2022, Uber\\'s revenue was $8.343 billion.  \\nFrom this information, we can observe that Uber\\'s revenue has been growing between the periods mentioned. The revenue increased from $6.854 billion in March 2022 to $8.073 billion for the three months ended June 2022, and further increased to $8.343 billion for the three months ended September 2022. However, we cannot provide a month-by-month analysis for June and September as the specific monthly revenue figures are not available.\\n========================  \\n```python\\nprint(str(response))\\n```  \\nBased on the provided context information, we can analyze Uber\\'s revenue growth for the three-month periods ending in March, June, and September.  \\n1. For the three months ended March 31, 2022, Uber\\'s revenue was $6.854 billion.\\n2. For the three months ended June 30, 2022, Uber\\'s revenue was $8.073 billion.\\n3. For the three months ended September 30, 2022, Uber\\'s revenue was $8.343 billion.  \\nTo analyze the growth, we can compare the revenue figures for each period:  \\n- From March to June, Uber\\'s revenue increased by $1.219 billion ($8.073 billion - $6.854 billion), which represents a growth of approximately 17.8% (($1.219 billion / $6.854 billion) * 100).\\n- From June to September, Uber\\'s revenue increased by $0.270 billion ($8.343 billion - $8.073 billion), which represents a growth of approximately 3.3% (($0.270 billion / $8.073 billion) * 100).  \\nIn summary, Uber experienced significant revenue growth of 17.8% between the three-month periods ending in March and June, followed by a smaller growth of 3.3% between the periods ending in June and September.  \\n```python\\nresponse = agent.query(\\n\"Analyze changes in risk factors in march, june, and september for Uber\"\\n)\\n```  \\n```python\\nprint(str(response))\\n```  \\n```python\\n# response = agent.query(\"Analyze both Uber revenue growth and risk factors over march, june, and september\")\\n```  \\n```python\\nprint(str(response))\\n```  \\nBased on the provided context information, we can analyze Uber\\'s revenue growth for the three-month periods ending in March, June, and September.  \\n1. For the three months ended March 31, 2022, Uber\\'s revenue was $6.854 billion.\\n2. For the three months ended June 30, 2022, Uber\\'s revenue was $8.073 billion.\\n3. For the three months ended September 30, 2022, Uber\\'s revenue was $8.343 billion.  \\nTo analyze the growth, we can compare the revenue figures for each period:  \\n- From March to June, Uber\\'s revenue increased by $1.219 billion ($8.073 billion - $6.854 billion), which represents a growth of approximately 17.8% (($1.219 billion / $6.854 billion) * 100).\\n- From June to September, Uber\\'s revenue increased by $0.270 billion ($8.343 billion - $8.073 billion), which represents a growth of approximately 3.3% (($0.270 billion / $8.073 billion) * 100).', metadata={'Header 1': 'OpenAI Agent Query Planning', 'Header 2': 'OpenAI Function Agent with a Query Plan Tool'}),\n",
      " Document(page_content='In summary, Uber experienced significant revenue growth of 17.8% between the three-month periods ending in March and June, followed by a smaller growth of 3.3% between the periods ending in June and September.  \\n```python\\nresponse = agent.query(\\n\"First look at Uber\\'s revenue growth and risk factors in March, \"\\n+ \"then revenue growth and risk factors in September, and then compare and\"\\n\" contrast the two documents?\"\\n)\\n```  \\n```python\\nresponse\\n```', metadata={'Header 1': 'OpenAI Agent Query Planning', 'Header 2': 'OpenAI Function Agent with a Query Plan Tool'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/openai_agent_retrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>'),\n",
      " Document(page_content=\"In this tutorial, we show you how to use our `FnRetrieverOpenAI` implementation\\nto build an agent on top of OpenAI's function API and store/index an arbitrary number of tools. Our indexing/retrieval modules help to remove the complexity of having too many functions to fit in the prompt.\", metadata={'Header 1': 'Retrieval-Augmented OpenAI Agent'}),\n",
      " Document(page_content='Let\\'s start by importing some simple building blocks.  \\nThe main thing we need is:\\n1. the OpenAI API\\n2. a place to keep conversation history\\n3. a definition for tools that our agent can use.  \\nIf you\\'re opening this Notebook on colab, you will probably need to install LlamaIndex 🦙.  \\n```python\\n!pip install llama-index\\n```  \\n```python\\nimport json\\nfrom typing import Sequence\\n\\nfrom llama_index.tools import BaseTool, FunctionTool\\n```  \\n/Users/suo/miniconda3/envs/llama/lib/python3.9/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.6.7) is available. It\\'s recommended that you update to the latest version using `pip install -U deeplake`.\\nwarnings.warn(  \\nLet\\'s define some very simple calculator tools for our agent.  \\n```python\\ndef multiply(a: int, b: int) -> int:\\n\"\"\"Multiply two integers and returns the result integer\"\"\"\\nreturn a * b\\n\\n\\ndef add(a: int, b: int) -> int:\\n\"\"\"Add two integers and returns the result integer\"\"\"\\nreturn a + b\\n\\n\\ndef useless(a: int, b: int) -> int:\\n\"\"\"Toy useless function.\"\"\"\\npass\\n\\n\\nmultiply_tool = FunctionTool.from_defaults(fn=multiply, name=\"multiply\")\\nuseless_tools = [\\nFunctionTool.from_defaults(fn=useless, name=f\"useless_{str(idx)}\")\\nfor idx in range(28)\\n]\\nadd_tool = FunctionTool.from_defaults(fn=add, name=\"add\")\\n\\nall_tools = [multiply_tool] + [add_tool] + useless_tools\\nall_tools_map = {t.metadata.name: t for t in all_tools}\\n```', metadata={'Header 1': 'Retrieval-Augmented OpenAI Agent', 'Header 2': 'Initial Setup'}),\n",
      " Document(page_content='We have an `ObjectIndex` construct in LlamaIndex that allows the user to use our index data structures over arbitrary objects.\\nThe ObjectIndex will handle serialiation to/from the object, and use an underying index (e.g. VectorStoreIndex, SummaryIndex, KeywordTableIndex) as the storage mechanism.  \\nIn this case, we have a large collection of Tool objects, and we\\'d want to define an ObjectIndex over these Tools.  \\nThe index comes bundled with a retrieval mechanism, an `ObjectRetriever`.  \\nThis can be passed in to our agent so that it can\\nperform Tool retrieval during query-time.  \\n```python\\n# define an \"object\" index over these tools\\nfrom llama_index import VectorStoreIndex\\nfrom llama_index.objects import ObjectIndex, SimpleToolNodeMapping\\n\\ntool_mapping = SimpleToolNodeMapping.from_objects(all_tools)\\nobj_index = ObjectIndex.from_objects(\\nall_tools,\\ntool_mapping,\\nVectorStoreIndex,\\n)\\n```', metadata={'Header 1': 'Retrieval-Augmented OpenAI Agent', 'Header 2': 'Building an Object Index'}),\n",
      " Document(page_content='We provide a `FnRetrieverOpenAIAgent` implementation in LlamaIndex, which can take in an `ObjectRetriever` over a set of `BaseTool` objects.  \\nDuring query-time, we would first use the `ObjectRetriever` to retrieve a set of relevant Tools. These tools would then be passed into the agent; more specifically, their function signatures would be passed into the OpenAI Function calling API.  \\n```python\\nfrom llama_index.agent import FnRetrieverOpenAIAgent\\n```  \\n```python\\nagent = FnRetrieverOpenAIAgent.from_retriever(\\nobj_index.as_retriever(), verbose=True\\n)\\n```  \\n```python\\nagent.chat(\"What\\'s 212 multiplied by 122? Make sure to use Tools\")\\n```  \\n=== Calling Function ===\\nCalling function: multiply with args: {\\n\"a\": 212,\\n\"b\": 122\\n}\\nGot output: 25864\\n========================  \\nResponse(response=\\'212 multiplied by 122 is 25,864.\\', source_nodes=[], metadata=None)  \\n```python\\nagent.chat(\"What\\'s 212 added to 122 ? Make sure to use Tools\")\\n```  \\n=== Calling Function ===\\nCalling function: add with args: {\\n\"a\": 212,\\n\"b\": 122\\n}\\nGot output: 334\\n========================  \\nResponse(response=\\'212 added to 122 is 334.\\', source_nodes=[], metadata=None)', metadata={'Header 1': 'Retrieval-Augmented OpenAI Agent', 'Header 2': 'Our `FnRetrieverOpenAIAgent` Implementation'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/openai_agent_with_query_engine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>'),\n",
      " Document(page_content='If you\\'re opening this Notebook on colab, you will probably need to install LlamaIndex 🦙.  \\n```python\\n!pip install llama-index\\n```  \\n```python\\nfrom llama_index import (\\nSimpleDirectoryReader,\\nVectorStoreIndex,\\nStorageContext,\\nload_index_from_storage,\\n)\\n\\nfrom llama_index.tools import QueryEngineTool, ToolMetadata\\n```  \\n```python\\ntry:\\nstorage_context = StorageContext.from_defaults(\\npersist_dir=\"./storage/lyft\"\\n)\\nlyft_index = load_index_from_storage(storage_context)\\n\\nstorage_context = StorageContext.from_defaults(\\npersist_dir=\"./storage/uber\"\\n)\\nuber_index = load_index_from_storage(storage_context)\\n\\nindex_loaded = True\\nexcept:\\nindex_loaded = False\\n```  \\nDownload Data  \\n```python\\n!mkdir -p \\'data/10k/\\'\\n!wget \\'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10k/uber_2021.pdf\\' -O \\'data/10k/uber_2021.pdf\\'\\n!wget \\'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10k/lyft_2021.pdf\\' -O \\'data/10k/lyft_2021.pdf\\'\\n```  \\n```python\\nif not index_loaded:\\n# load data\\nlyft_docs = SimpleDirectoryReader(\\ninput_files=[\"./data/10k/lyft_2021.pdf\"]\\n).load_data()\\nuber_docs = SimpleDirectoryReader(\\ninput_files=[\"./data/10k/uber_2021.pdf\"]\\n).load_data()\\n\\n# build index\\nlyft_index = VectorStoreIndex.from_documents(lyft_docs)\\nuber_index = VectorStoreIndex.from_documents(uber_docs)\\n\\n# persist index\\nlyft_index.storage_context.persist(persist_dir=\"./storage/lyft\")\\nuber_index.storage_context.persist(persist_dir=\"./storage/uber\")\\n```  \\n```python\\nlyft_engine = lyft_index.as_query_engine(similarity_top_k=3)\\nuber_engine = uber_index.as_query_engine(similarity_top_k=3)\\n```  \\n```python\\nquery_engine_tools = [\\nQueryEngineTool(\\nquery_engine=lyft_engine,\\nmetadata=ToolMetadata(\\nname=\"lyft_10k\",\\ndescription=(\\n\"Provides information about Lyft financials for year 2021. \"\\n\"Use a detailed plain text question as input to the tool.\"\\n),\\n),\\n),\\nQueryEngineTool(\\nquery_engine=uber_engine,\\nmetadata=ToolMetadata(\\nname=\"uber_10k\",\\ndescription=(\\n\"Provides information about Uber financials for year 2021. \"\\n\"Use a detailed plain text question as input to the tool.\"\\n),\\n),\\n),\\n]\\n```', metadata={'Header 1': 'OpenAI Agent with Query Engine Tools', 'Header 2': 'Build Query Engine Tools'}),\n",
      " Document(page_content='```python\\nfrom llama_index.agent import OpenAIAgent\\n```  \\n```python\\nagent = OpenAIAgent.from_tools(query_engine_tools, verbose=True)\\n```', metadata={'Header 1': 'OpenAI Agent with Query Engine Tools', 'Header 2': 'Setup OpenAI Agent'}),\n",
      " Document(page_content='```python\\nagent.chat_repl()\\n```  \\n===== Entering Chat REPL =====\\nType \"exit\" to exit.  \\n=== Calling Function ===\\nCalling function: lyft_10k with args: {\\n\"input\": \"What was Lyft\\'s revenue growth in 2021?\"\\n}\\nGot output:\\nLyft\\'s revenue growth in 2021 was 36%.\\n========================\\n=== Calling Function ===\\nCalling function: uber_10k with args: {\\n\"input\": \"What was Uber\\'s revenue growth in 2021?\"\\n}\\nGot output:\\nUber\\'s revenue growth in 2021 was 57%.\\n========================\\nAssistant: Lyft\\'s revenue growth in 2021 was 36%, while Uber\\'s revenue growth in 2021 was 57%.', metadata={'Header 1': 'OpenAI Agent with Query Engine Tools', 'Header 2': \"Let's Try It Out!\"}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/openai_assistant_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>  \\nThis shows you how to use our agent abstractions built on top of the [OpenAI Assistant API](https://platform.openai.com/docs/assistants/overview).  \\n```python\\n!pip install llama-index\\n```', metadata={'Header 1': 'OpenAI Assistant Agent'}),\n",
      " Document(page_content='Here we show a simple example with the built-in code interpreter.  \\nLet\\'s start by importing some simple building blocks.  \\nIf you\\'re opening this Notebook on colab, you will probably need to install LlamaIndex 🦙.  \\n```python\\nfrom llama_index.agent import OpenAIAssistantAgent\\n```  \\n```python\\nagent = OpenAIAssistantAgent.from_new(\\nname=\"Math Tutor\",\\ninstructions=\"You are a personal math tutor. Write and run code to answer math questions.\",\\nopenai_tools=[{\"type\": \"code_interpreter\"}],\\ninstructions_prefix=\"Please address the user as Jane Doe. The user has a premium account.\",\\n)\\n```  \\n```python\\nagent.thread_id\\n```  \\n\\'thread_ctzN0ZY3JUWETHhYxI3DiFSo\\'  \\n```python\\nresponse = agent.chat(\\n\"I need to solve the equation `3x + 11 = 14`. Can you help me?\"\\n)\\n```  \\n```python\\nprint(str(response))\\n```  \\nThe solution to the equation \\\\(3x + 11 = 14\\\\) is \\\\(x = 1\\\\).', metadata={'Header 1': 'OpenAI Assistant Agent', 'Header 2': 'Simple Agent (no external tools)'}),\n",
      " Document(page_content='Let\\'s test the assistant by having it use the built-in OpenAI Retrieval tool over a user-uploaded file.  \\nHere, we upload and pass in the file during assistant-creation time.  \\nThe other option is you can upload/pass the file-id in for a message in a given thread with `upload_files` and `add_message`.  \\n```python\\nfrom llama_index.agent import OpenAIAssistantAgent\\n```  \\n```python\\nagent = OpenAIAssistantAgent.from_new(\\nname=\"SEC Analyst\",\\ninstructions=\"You are a QA assistant designed to analyze sec filings.\",\\nopenai_tools=[{\"type\": \"retrieval\"}],\\ninstructions_prefix=\"Please address the user as Jerry.\",\\nfiles=[\"data/10k/lyft_2021.pdf\"],\\nverbose=True,\\n)\\n```  \\n```python\\nresponse = agent.chat(\"What was Lyft\\'s revenue growth in 2021?\")\\n```  \\n```python\\nprint(str(response))\\n```  \\nLyft\\'s revenue increased by $843.6 million or 36% in 2021 as compared to the previous year【7†source】.', metadata={'Header 1': 'OpenAI Assistant Agent', 'Header 2': 'Assistant with Built-In Retrieval'}),\n",
      " Document(page_content='Here we showcase the function calling capabilities of the OpenAIAssistantAgent by integrating it with our query engine tools over different documents.', metadata={'Header 1': 'OpenAI Assistant Agent', 'Header 2': 'Assistant with Query Engine Tools'}),\n",
      " Document(page_content='```python\\nfrom llama_index.agent import OpenAIAssistantAgent\\nfrom llama_index import (\\nSimpleDirectoryReader,\\nVectorStoreIndex,\\nStorageContext,\\nload_index_from_storage,\\n)\\n\\nfrom llama_index.tools import QueryEngineTool, ToolMetadata\\n```  \\n```python\\ntry:\\nstorage_context = StorageContext.from_defaults(\\npersist_dir=\"./storage/lyft\"\\n)\\nlyft_index = load_index_from_storage(storage_context)\\n\\nstorage_context = StorageContext.from_defaults(\\npersist_dir=\"./storage/uber\"\\n)\\nuber_index = load_index_from_storage(storage_context)\\n\\nindex_loaded = True\\nexcept:\\nindex_loaded = False\\n```  \\n```python\\n!mkdir -p \\'data/10k/\\'\\n!wget \\'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10k/uber_2021.pdf\\' -O \\'data/10k/uber_2021.pdf\\'\\n!wget \\'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10k/lyft_2021.pdf\\' -O \\'data/10k/lyft_2021.pdf\\'\\n```  \\n--2023-11-07 00:20:08--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10k/uber_2021.pdf\\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8000::154, 2606:50c0:8001::154, 2606:50c0:8002::154, ...\\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8000::154|:443... connected.\\nHTTP request sent, awaiting response... 200 OK\\nLength: 1880483 (1.8M) [application/octet-stream]\\nSaving to: ‘data/10k/uber_2021.pdf’  \\ndata/10k/uber_2021. 100%[===================>]   1.79M  --.-KB/s    in 0.07s  \\n2023-11-07 00:20:08 (24.3 MB/s) - ‘data/10k/uber_2021.pdf’ saved [1880483/1880483]  \\n--2023-11-07 00:20:08--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10k/lyft_2021.pdf\\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8000::154, 2606:50c0:8001::154, 2606:50c0:8002::154, ...\\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8000::154|:443... connected.\\nHTTP request sent, awaiting response... 200 OK\\nLength: 1440303 (1.4M) [application/octet-stream]\\nSaving to: ‘data/10k/lyft_2021.pdf’  \\ndata/10k/lyft_2021. 100%[===================>]   1.37M  --.-KB/s    in 0.06s  \\n2023-11-07 00:20:09 (22.2 MB/s) - ‘data/10k/lyft_2021.pdf’ saved [1440303/1440303]  \\n```python\\nif not index_loaded:\\n# load data\\nlyft_docs = SimpleDirectoryReader(\\ninput_files=[\"./data/10k/lyft_2021.pdf\"]\\n).load_data()\\nuber_docs = SimpleDirectoryReader(\\ninput_files=[\"./data/10k/uber_2021.pdf\"]\\n).load_data()\\n\\n# build index\\nlyft_index = VectorStoreIndex.from_documents(lyft_docs)\\nuber_index = VectorStoreIndex.from_documents(uber_docs)\\n\\n# persist index\\nlyft_index.storage_context.persist(persist_dir=\"./storage/lyft\")\\nuber_index.storage_context.persist(persist_dir=\"./storage/uber\")\\n```  \\n```python\\nlyft_engine = lyft_index.as_query_engine(similarity_top_k=3)\\nuber_engine = uber_index.as_query_engine(similarity_top_k=3)\\n```  \\n```python\\nquery_engine_tools = [\\nQueryEngineTool(\\nquery_engine=lyft_engine,\\nmetadata=ToolMetadata(\\nname=\"lyft_10k\",\\ndescription=(\\n\"Provides information about Lyft financials for year 2021. \"\\n\"Use a detailed plain text question as input to the tool.\"\\n),\\n),\\n),\\nQueryEngineTool(\\nquery_engine=uber_engine,\\nmetadata=ToolMetadata(\\nname=\"uber_10k\",\\ndescription=(\\n\"Provides information about Uber financials for year 2021. \"\\n\"Use a detailed plain text question as input to the tool.\"\\n),\\n),\\n),\\n]\\n```', metadata={'Header 1': 'OpenAI Assistant Agent', 'Header 2': 'Assistant with Query Engine Tools', 'Header 3': '1. Setup: Load Data'}),\n",
      " Document(page_content='```python\\nagent = OpenAIAssistantAgent.from_new(\\nname=\"SEC Analyst\",\\ninstructions=\"You are a QA assistant designed to analyze sec filings.\",\\ntools=query_engine_tools,\\ninstructions_prefix=\"Please address the user as Jerry.\",\\nverbose=True,\\nrun_retrieve_sleep_time=1.0,\\n)\\n```  \\n```python\\nresponse = agent.chat(\"What was Lyft\\'s revenue growth in 2021?\")\\n```  \\n=== Calling Function ===\\nCalling function: lyft_10k with args: {\"input\":\"What was Lyft\\'s revenue growth in 2021?\"}\\nGot output: Lyft\\'s revenue growth in 2021 was 36%.\\n========================', metadata={'Header 1': 'OpenAI Assistant Agent', 'Header 2': 'Assistant with Query Engine Tools', 'Header 3': \"2. Let's Try it Out\"}),\n",
      " Document(page_content='LlamaIndex has 35+ vector database integrations. Instead of using the in-house Retrieval API, you can use our assistant agent over any vector store.  \\nHere is our full [list of vector store integrations](https://docs.llamaindex.ai/en/stable/module_guides/storing/vector_stores.html). We picked one vector store (Supabase) using a random number generator.  \\n```python\\nfrom llama_index.agent import OpenAIAssistantAgent\\nfrom llama_index import (\\nSimpleDirectoryReader,\\nVectorStoreIndex,\\nStorageContext,\\n)\\nfrom llama_index.vector_stores import SupabaseVectorStore\\n\\nfrom llama_index.tools import QueryEngineTool, ToolMetadata\\n```  \\n```python\\n!mkdir -p \\'data/10k/\\'\\n!wget \\'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10k/uber_2021.pdf\\' -O \\'data/10k/uber_2021.pdf\\'\\n!wget \\'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10k/lyft_2021.pdf\\' -O \\'data/10k/lyft_2021.pdf\\'\\n```  \\n```python\\n# load data\\nreader = SimpleDirectoryReader(input_files=[\"./data/10k/lyft_2021.pdf\"])\\ndocs = reader.load_data()\\nfor doc in docs:\\ndoc.id_ = \"lyft_docs\"\\n```  \\n```python\\nvector_store = SupabaseVectorStore(\\npostgres_connection_string=(\\n\"postgresql://<user>:<password>@<host>:<port>/<db_name>\"\\n),\\ncollection_name=\"base_demo\",\\n)\\nstorage_context = StorageContext.from_defaults(vector_store=vector_store)\\nindex = VectorStoreIndex.from_documents(docs, storage_context=storage_context)\\n```  \\n```python\\n# sanity check that the docs are in the vector store\\nnum_docs = vector_store.get_by_id(\"lyft_docs\", limit=1000)\\nprint(len(num_docs))\\n```  \\n/Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages/vecs/collection.py:445: UserWarning: Query does not have a covering index for cosine_distance. See Collection.create_index\\nwarnings.warn(  \\n357  \\n```python\\nlyft_tool = QueryEngineTool(\\nquery_engine=index.as_query_engine(similarity_top_k=3),\\nmetadata=ToolMetadata(\\nname=\"lyft_10k\",\\ndescription=(\\n\"Provides information about Lyft financials for year 2021. \"\\n\"Use a detailed plain text question as input to the tool.\"\\n),\\n),\\n)\\n```  \\n```python\\nagent = OpenAIAssistantAgent.from_new(\\nname=\"SEC Analyst\",\\ninstructions=\"You are a QA assistant designed to analyze SEC filings.\",\\ntools=[lyft_tool],\\nverbose=True,\\nrun_retrieve_sleep_time=1.0,\\n)\\n```  \\n```python\\nresponse = agent.chat(\\n\"Tell me about Lyft\\'s risk factors, as well as response to COVID-19\"\\n)\\n```  \\n=== Calling Function ===\\nCalling function: lyft_10k with args: {\"input\": \"What are Lyft\\'s risk factors?\"}  \\n/Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages/vecs/collection.py:445: UserWarning: Query does not have a covering index for cosine_distance. See Collection.create_index\\nwarnings.warn(  \\nGot output: Lyft\\'s risk factors include general economic factors, such as the impact of the COVID-19 pandemic and responsive measures, natural disasters, economic downturns, public health crises, or political crises. Operational factors, such as their limited operating history, financial performance, competition, unpredictability of results, uncertainty regarding market growth, ability to attract and retain qualified drivers and riders, insurance coverage, autonomous vehicle technology, reputation and brand, illegal or improper activity on the platform, accuracy of background checks, changes to pricing practices, growth and development of their network, ability to manage growth, security or privacy breaches, reliance on third parties, and ability to operate various programs and services.\\n========================\\n=== Calling Function ===\\nCalling function: lyft_10k with args: {\"input\": \"How did Lyft respond to COVID-19?\"}  \\n/Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages/vecs/collection.py:445: UserWarning: Query does not have a covering index for cosine_distance. See Collection.create_index\\nwarnings.warn(  \\nGot output: Lyft responded to COVID-19 by adopting multiple measures, including establishing new health and safety requirements for ridesharing and updating workplace policies. They also made adjustments to their expenses and cash flow to correlate with declines in revenues, which included headcount reductions in 2020. Additionally, Lyft temporarily reduced pricing for Flexdrive rentals in cities most affected by COVID-19 and waived rental fees for drivers who tested positive for COVID-19 or were requested to quarantine by a medical professional. These measures were implemented to mitigate the negative effects of the pandemic on their business.\\n========================  \\n```python\\nprint(str(response))\\n```  \\nLyft\\'s 2021 10-K filing outlines a multifaceted risk landscape for the company, encapsulating both operational and environmental challenges that could impact its business model:  \\n- **Economic Factors**: Risks include the ramifications of the COVID-19 pandemic, susceptibility to natural disasters, the volatility of economic downturns, and geopolitical tensions.  \\n- **Operational Dynamics**: The company is cognizant of its limited operating history, the uncertainties surrounding its financial performance, the intense competition in the ridesharing sector, the unpredictability in financial results, and the ambiguity tied to the expansion potential of the rideshare market.  \\n- **Human Capital**: A critical concern is the ability of Lyft to attract and maintain a robust network of both drivers and riders, which is essential for the platform\\'s vitality.  \\n- **Insurance and Safety**: Ensuring adequate insurance coverage for stakeholders and addressing autonomous vehicle technology risks are pivotal.  \\n- **Reputation and Brand**: Lyft is attentive to the influence that illegal or unseemly activities on its platform can have on its public image.  \\n- **Pricing Structure**: Changing pricing models pose a risk to Lyft\\'s revenue streams, considering how essential pricing dynamics are to maintaining competitive service offerings.  \\n- **Systemic Integrity**: Lyft also acknowledges risks emanating from potential system failures which could disrupt service continuity.  \\nFurthermore, Lyft is vigilant about regulatory and legal risks that could lead to litigation and is conscious of the broader implications of climate change on its operations.  \\nIn terms of its response to COVID-19, Lyft has adopted strategic measures to secure the welfare of both its workforce and customer base:  \\n1. **Health and Safety Protocols**: Lyft has instituted health and safety mandates tailored specifically to the ridesharing experience in view of the pandemic.  \\n2. **Workplace Adjustments**: The company revised its workplace policies to accommodate the shifts in the work environment precipitated by the pandemic.  \\n3. **Financial Adaptations**: To synchronize with the revenue contraction experienced during the pandemic, Lyft executed monetary realignments, which necessitated workforce reductions in 2020.  \\nThese initiatives reflect Lyft\\'s calculated approach to navigating the operational and financial hurdles enacted by the COVID-19 pandemic. By prioritizing health and safety, nimbly altering corporate practices, and recalibrating fiscal management, Lyft aimed to buttress its business against the storm of the pandemic while setting a foundation for post-pandemic recovery.', metadata={'Header 1': 'OpenAI Assistant Agent', 'Header 2': 'Assistant Agent with your own Vector Store / Retrieval API'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/openai_assistant_query_cookbook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>'),\n",
      " Document(page_content='In this notebook, we try out OpenAI Assistant API for advanced retrieval tasks, by plugging in a variety of query engine tools and datasets. The wrapper abstraction we use is our `OpenAIAssistantAgent` class, which allows us to plug in custom tools. We explore how `OpenAIAssistant` can complement/replace existing workflows solved by our retrievers/query engines through its agent execution + function calling loop.  \\n- Joint QA + Summarization\\n- Auto retrieval\\n- Joint SQL and vector search  \\n```python\\n!pip install llama-index\\n```  \\n```python\\nimport nest_asyncio\\n\\nnest_asyncio.apply()\\n```', metadata={'Header 1': 'OpenAI Assistant Advanced Retrieval Cookbook'}),\n",
      " Document(page_content='In this section we show how we can get the Assistant agent to both answer fact-based questions and summarization questions. This is something that the in-house retrieval tool struggles to accomplish.', metadata={'Header 1': 'OpenAI Assistant Advanced Retrieval Cookbook', 'Header 2': 'Joint QA and Summarization'}),\n",
      " Document(page_content='```python\\n!mkdir -p \\'data/paul_graham/\\'\\n!wget \\'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt\\' -O \\'data/paul_graham/paul_graham_essay.txt\\'\\n```  \\n--2023-11-11 09:40:13--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt\\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8002::154, 2606:50c0:8003::154, 2606:50c0:8000::154, ...\\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8002::154|:443... connected.\\nHTTP request sent, awaiting response... 200 OK\\nLength: 75042 (73K) [text/plain]\\nSaving to: ‘data/paul_graham/paul_graham_essay.txt’  \\ndata/paul_graham/pa 100%[===================>]  73.28K  --.-KB/s    in 0.009s  \\n2023-11-11 09:40:14 (8.24 MB/s) - ‘data/paul_graham/paul_graham_essay.txt’ saved [75042/75042]  \\n```python\\nfrom llama_index import SimpleDirectoryReader\\n\\n# load documents\\ndocuments = SimpleDirectoryReader(\"./data/paul_graham/\").load_data()\\n```', metadata={'Header 1': 'OpenAI Assistant Advanced Retrieval Cookbook', 'Header 2': 'Joint QA and Summarization', 'Header 3': 'Load Data'}),\n",
      " Document(page_content='```python\\nfrom llama_index.llms import OpenAI\\nfrom llama_index import (\\nServiceContext,\\nStorageContext,\\nSummaryIndex,\\nVectorStoreIndex,\\n)\\n\\n# initialize service context (set chunk size)\\nllm = OpenAI()\\nservice_context = ServiceContext.from_defaults(chunk_size=1024, llm=llm)\\nnodes = service_context.node_parser.get_nodes_from_documents(documents)\\n\\n# initialize storage context (by default it\\'s in-memory)\\nstorage_context = StorageContext.from_defaults()\\nstorage_context.docstore.add_documents(nodes)\\n\\n# Define Summary Index and Vector Index over Same Data\\nsummary_index = SummaryIndex(nodes, storage_context=storage_context)\\nvector_index = VectorStoreIndex(nodes, storage_context=storage_context)\\n\\n# define query engines\\nsummary_query_engine = summary_index.as_query_engine(\\nresponse_mode=\"tree_summarize\",\\nuse_async=True,\\n)\\nvector_query_engine = vector_index.as_query_engine()\\n```  \\n```python\\nfrom llama_index.tools.query_engine import QueryEngineTool\\n\\nsummary_tool = QueryEngineTool.from_defaults(\\nquery_engine=summary_query_engine,\\nname=\"summary_tool\",\\ndescription=(\\n\"Useful for summarization questions related to the author\\'s life\"\\n),\\n)\\n\\nvector_tool = QueryEngineTool.from_defaults(\\nquery_engine=vector_query_engine,\\nname=\"vector_tool\",\\ndescription=(\\n\"Useful for retrieving specific context to answer specific questions about the author\\'s life\"\\n),\\n)\\n```', metadata={'Header 1': 'OpenAI Assistant Advanced Retrieval Cookbook', 'Header 2': 'Joint QA and Summarization', 'Header 3': 'Setup Vector + Summary Indexes/Query Engines/Tools'}),\n",
      " Document(page_content='```python\\nfrom llama_index.agent import OpenAIAssistantAgent\\n\\nagent = OpenAIAssistantAgent.from_new(\\nname=\"QA bot\",\\ninstructions=\"You are a bot designed to answer questions about the author\",\\nopenai_tools=[],\\ntools=[summary_tool, vector_tool],\\nverbose=True,\\nrun_retrieve_sleep_time=1.0,\\n)\\n```  \\n#### Results: A bit flaky  \\n```python\\nresponse = agent.chat(\"Can you give me a summary about the author\\'s life?\")\\nprint(str(response))\\n```  \\n=== Calling Function ===\\nCalling function: summary_tool with args: {\"input\":\"Can you give me a summary about the author\\'s life?\"}\\nGot output: The author, Paul Graham, had a strong interest in writing and programming from a young age. They started writing short stories and experimenting with programming in high school. In college, they initially studied philosophy but switched to studying artificial intelligence. However, they realized that the AI being practiced at the time was not going to lead to true understanding of natural language. This led them to focus on Lisp programming and eventually write a book about Lisp hacking. Despite being in a PhD program in computer science, the author also developed a passion for art and decided to pursue it further. They attended the Accademia di Belli Arti in Florence but found that it did not teach them much. They then returned to the US and got a job at a software company. Afterward, they attended the Rhode Island School of Design but dropped out due to the focus on developing a signature style rather than teaching the fundamentals of art. They then moved to New York City and became interested in the World Wide Web, eventually starting a company called Viaweb. They later founded Y Combinator, an investment firm, and created Hacker News.\\n========================\\nPaul Graham is an author with eclectic interests and a varied career path. He began with interests in writing and programming, engaged in philosophy and artificial intelligence during college, and authored a book on Lisp programming. With an equally strong passion for art, he studied at the Accademia di Belli Arti in Florence and briefly at the Rhode Island School of Design before immersing himself in the tech industry by starting Viaweb and later founding the influential startup accelerator Y Combinator. He also created Hacker News, a social news website focused on computer science and entrepreneurship. Graham\\'s life reflects a blend of technology, entrepreneurship, and the arts.  \\n```python\\nresponse = agent.query(\"What did the author do after RICS?\")\\nprint(str(response))\\n```  \\n=== Calling Function ===\\nCalling function: vector_tool with args: {\"input\":\"After RICS\"}\\nGot output: After RICS, the author moved back to Providence to continue at RISD. However, it became clear that art school, specifically the painting department, did not have the same relationship to art as medical school had to medicine. Painting students were expected to express themselves and develop a distinctive signature style.\\n========================\\nAfter the author\\'s time at the Royal Institution of Chartered Surveyors (RICS), they moved back to Providence to continue their studies at the Rhode Island School of Design (RISD). There, the author noted a significant difference in the educational approaches between RISD and medical school, specifically in the painting department. At RISD, students were encouraged to express themselves and to develop a unique and distinctive signature style in their artwork.', metadata={'Header 1': 'OpenAI Assistant Advanced Retrieval Cookbook', 'Header 2': 'Joint QA and Summarization', 'Header 3': 'Define Assistant Agent'}),\n",
      " Document(page_content='Our existing \"auto-retrieval\" capabilities (in `VectorIndexAutoRetriever`) allow an LLM to infer the right query parameters for a vector database - including both the query string and metadata filter.  \\nSince the Assistant API can call functions + infer function parameters, we explore its capabilities in performing auto-retrieval here.  \\nIf you\\'re opening this Notebook on colab, you will probably need to install LlamaIndex 🦙.  \\n```python\\nimport pinecone\\nimport os\\n\\napi_key = os.environ[\"PINECONE_API_KEY\"]\\npinecone.init(api_key=api_key, environment=\"us-west1-gcp\")\\n```  \\n/Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\\nfrom tqdm.autonotebook import tqdm  \\n```python\\n# dimensions are for text-embedding-ada-002\\ntry:\\npinecone.create_index(\\n\"quickstart\", dimension=1536, metric=\"euclidean\", pod_type=\"p1\"\\n)\\nexcept Exception:\\n# most likely index already exists\\npass\\n```  \\n```python\\npinecone_index = pinecone.Index(\"quickstart\")\\n```  \\n```python\\n# Optional: delete data in your pinecone index\\npinecone_index.delete(deleteAll=True, namespace=\"test\")\\n```  \\n{}  \\n```python\\nfrom llama_index import VectorStoreIndex, StorageContext\\nfrom llama_index.vector_stores import PineconeVectorStore\\n```  \\n```python\\nfrom llama_index.schema import TextNode\\n\\nnodes = [\\nTextNode(\\ntext=(\\n\"Michael Jordan is a retired professional basketball player,\"\\n\" widely regarded as one of the greatest basketball players of all\"\\n\" time.\"\\n),\\nmetadata={\\n\"category\": \"Sports\",\\n\"country\": \"United States\",\\n},\\n),\\nTextNode(\\ntext=(\\n\"Angelina Jolie is an American actress, filmmaker, and\"\\n\" humanitarian. She has received numerous awards for her acting\"\\n\" and is known for her philanthropic work.\"\\n),\\nmetadata={\\n\"category\": \"Entertainment\",\\n\"country\": \"United States\",\\n},\\n),\\nTextNode(\\ntext=(\\n\"Elon Musk is a business magnate, industrial designer, and\"\\n\" engineer. He is the founder, CEO, and lead designer of SpaceX,\"\\n\" Tesla, Inc., Neuralink, and The Boring Company.\"\\n),\\nmetadata={\\n\"category\": \"Business\",\\n\"country\": \"United States\",\\n},\\n),\\nTextNode(\\ntext=(\\n\"Rihanna is a Barbadian singer, actress, and businesswoman. She\"\\n\" has achieved significant success in the music industry and is\"\\n\" known for her versatile musical style.\"\\n),\\nmetadata={\\n\"category\": \"Music\",\\n\"country\": \"Barbados\",\\n},\\n),\\nTextNode(\\ntext=(\\n\"Cristiano Ronaldo is a Portuguese professional footballer who is\"\\n\" considered one of the greatest football players of all time. He\"\\n\" has won numerous awards and set multiple records during his\"\\n\" career.\"\\n),\\nmetadata={\\n\"category\": \"Sports\",\\n\"country\": \"Portugal\",\\n},\\n),\\n]\\n```  \\n```python\\nvector_store = PineconeVectorStore(\\npinecone_index=pinecone_index, namespace=\"test\"\\n)\\nstorage_context = StorageContext.from_defaults(vector_store=vector_store)\\n```  \\n```python\\nindex = VectorStoreIndex(nodes, storage_context=storage_context)\\n```  \\nUpserted vectors:   0%|          | 0/5 [00:00<?, ?it/s]  \\n#### Define Function Tool  \\nHere we define the function interface, which is passed to OpenAI to perform auto-retrieval.  \\nWe were not able to get OpenAI to work with nested pydantic objects or tuples as arguments,\\nso we converted the metadata filter keys and values into lists for the function API to work with.  \\n```python\\n# define function tool\\nfrom llama_index.tools import FunctionTool\\nfrom llama_index.vector_stores.types import (\\nVectorStoreInfo,\\nMetadataInfo,\\nExactMatchFilter,\\nMetadataFilters,\\n)\\nfrom llama_index.retrievers import VectorIndexRetriever\\nfrom llama_index.query_engine import RetrieverQueryEngine\\n\\nfrom typing import List, Tuple, Any\\nfrom pydantic import BaseModel, Field\\n\\n# hardcode top k for now\\ntop_k = 3\\n\\n# define vector store info describing schema of vector store\\nvector_store_info = VectorStoreInfo(\\ncontent_info=\"brief biography of celebrities\",\\nmetadata_info=[\\nMetadataInfo(\\nname=\"category\",\\ntype=\"str\",\\ndescription=(\\n\"Category of the celebrity, one of [Sports, Entertainment,\"\\n\" Business, Music]\"\\n),\\n),\\nMetadataInfo(\\nname=\"country\",\\ntype=\"str\",\\ndescription=(\\n\"Country of the celebrity, one of [United States, Barbados,\"\\n\" Portugal]\"\\n),\\n),\\n],\\n)\\n\\n\\n# define pydantic model for auto-retrieval function\\nclass AutoRetrieveModel(BaseModel):\\nquery: str = Field(..., description=\"natural language query string\")\\nfilter_key_list: List[str] = Field(\\n..., description=\"List of metadata filter field names\"\\n)\\nfilter_value_list: List[str] = Field(\\n...,\\ndescription=(\\n\"List of metadata filter field values (corresponding to names\"\\n\" specified in filter_key_list)\"\\n),\\n)\\n\\n\\ndef auto_retrieve_fn(\\nquery: str, filter_key_list: List[str], filter_value_list: List[str]\\n):\\n\"\"\"Auto retrieval function.\\n\\nPerforms auto-retrieval from a vector database, and then applies a set of filters.\\n\\n\"\"\"\\nquery = query or \"Query\"\\n\\nexact_match_filters = [\\nExactMatchFilter(key=k, value=v)\\nfor k, v in zip(filter_key_list, filter_value_list)\\n]\\nretriever = VectorIndexRetriever(\\nindex,\\nfilters=MetadataFilters(filters=exact_match_filters),\\ntop_k=top_k,\\n)\\nresults = retriever.retrieve(query)\\nreturn [r.get_content() for r in results]\\n\\n\\ndescription = f\"\"\"\\\\\\nUse this tool to look up biographical information about celebrities.\\nThe vector database schema is given below:\\n{vector_store_info.json()}\\n\"\"\"\\n\\nauto_retrieve_tool = FunctionTool.from_defaults(\\nfn=auto_retrieve_fn,\\nname=\"celebrity_bios\",\\ndescription=description,\\nfn_schema=AutoRetrieveModel,\\n)\\n```  \\n```python\\nauto_retrieve_fn(\\n\"celebrity from the United States\",\\nfilter_key_list=[\"country\"],\\nfilter_value_list=[\"United States\"],\\n)\\n```  \\n[\\'Angelina Jolie is an American actress, filmmaker, and humanitarian. She has received numerous awards for her acting and is known for her philanthropic work.\\',\\n\\'Michael Jordan is a retired professional basketball player, widely regarded as one of the greatest basketball players of all time.\\']  \\n#### Initialize Agent  \\n```python\\nfrom llama_index.agent import OpenAIAssistantAgent', metadata={'Header 1': 'OpenAI Assistant Advanced Retrieval Cookbook', 'Header 2': 'AutoRetrieval from a Vector Database'}),\n",
      " Document(page_content='agent = OpenAIAssistantAgent.from_new(\\nname=\"Celebrity bot\",\\ninstructions=\"You are a bot designed to answer questions about celebrities.\",\\ntools=[auto_retrieve_tool],\\nverbose=True,\\n)\\n```  \\n```python\\nresponse = agent.chat(\"Tell me about two celebrities from the United States. \")\\nprint(str(response))\\n```  \\n=== Calling Function ===\\nCalling function: celebrity_bios with args: {\"query\": \"celebrity from United States\", \"filter_key_list\": [\"country\"], \"filter_value_list\": [\"United States\"]}\\nGot output: [\\'Angelina Jolie is an American actress, filmmaker, and humanitarian. She has received numerous awards for her acting and is known for her philanthropic work.\\', \\'Michael Jordan is a retired professional basketball player, widely regarded as one of the greatest basketball players of all time.\\']\\n========================\\n=== Calling Function ===\\nCalling function: celebrity_bios with args: {\"query\": \"celebrity from United States\", \"filter_key_list\": [\"country\"], \"filter_value_list\": [\"United States\"]}\\nGot output: [\\'Angelina Jolie is an American actress, filmmaker, and humanitarian. She has received numerous awards for her acting and is known for her philanthropic work.\\', \\'Michael Jordan is a retired professional basketball player, widely regarded as one of the greatest basketball players of all time.\\']\\n========================\\nHere is some information about two celebrities from the United States:  \\n1. Angelina Jolie - Angelina Jolie is an American actress, filmmaker, and humanitarian. She has received numerous awards for her acting and is known for her philanthropic work. Over the years, Jolie has starred in several critically acclaimed and commercially successful films, and she has also been involved in various humanitarian causes, advocating for refugees and children\\'s education, among other things.  \\n2. Michael Jordan - Michael Jordan is a retired professional basketball player, widely regarded as one of the greatest basketball players of all time. During his career, Jordan dominated the NBA with his scoring ability, athleticism, and competitiveness. He won six NBA championships with the Chicago Bulls and earned the NBA Most Valuable Player Award five times. Jordan has also been a successful businessman and the principal owner of the Charlotte Hornets basketball team.  \\nBoth figures have made significant impacts in their respective fields and continue to be influential even after reaching the peaks of their careers.', metadata={'Header 1': 'OpenAI Assistant Advanced Retrieval Cookbook', 'Header 2': 'AutoRetrieval from a Vector Database'}),\n",
      " Document(page_content='This is currenty handled by our `SQLAutoVectorQueryEngine`.  \\nLet\\'s try implementing this by giving our `OpenAIAssistantAgent` access to two query tools: SQL and Vector search.  \\n#### Load and Index Structured Data  \\nWe load sample structured datapoints into a SQL db and index it.  \\n```python\\nfrom sqlalchemy import (\\ncreate_engine,\\nMetaData,\\nTable,\\nColumn,\\nString,\\nInteger,\\nselect,\\ncolumn,\\n)\\nfrom llama_index import SQLDatabase, SQLStructStoreIndex\\n\\nengine = create_engine(\"sqlite:///:memory:\", future=True)\\nmetadata_obj = MetaData()\\n```  \\n```python\\n# create city SQL table\\ntable_name = \"city_stats\"\\ncity_stats_table = Table(\\ntable_name,\\nmetadata_obj,\\nColumn(\"city_name\", String(16), primary_key=True),\\nColumn(\"population\", Integer),\\nColumn(\"country\", String(16), nullable=False),\\n)\\n\\nmetadata_obj.create_all(engine)\\n```  \\n```python\\n# print tables\\nmetadata_obj.tables.keys()\\n```  \\ndict_keys([\\'city_stats\\'])  \\n```python\\nfrom sqlalchemy import insert\\n\\nrows = [\\n{\"city_name\": \"Toronto\", \"population\": 2930000, \"country\": \"Canada\"},\\n{\"city_name\": \"Tokyo\", \"population\": 13960000, \"country\": \"Japan\"},\\n{\"city_name\": \"Berlin\", \"population\": 3645000, \"country\": \"Germany\"},\\n]\\nfor row in rows:\\nstmt = insert(city_stats_table).values(**row)\\nwith engine.begin() as connection:\\ncursor = connection.execute(stmt)\\n```  \\n```python\\nwith engine.connect() as connection:\\ncursor = connection.exec_driver_sql(\"SELECT * FROM city_stats\")\\nprint(cursor.fetchall())\\n```  \\n[(\\'Toronto\\', 2930000, \\'Canada\\'), (\\'Tokyo\\', 13960000, \\'Japan\\'), (\\'Berlin\\', 3645000, \\'Germany\\')]  \\n```python\\nsql_database = SQLDatabase(engine, include_tables=[\"city_stats\"])\\n```  \\n```python\\nfrom llama_index.indices.struct_store.sql_query import NLSQLTableQueryEngine\\n```  \\n```python\\nquery_engine = NLSQLTableQueryEngine(\\nsql_database=sql_database,\\ntables=[\"city_stats\"],\\n)\\n```  \\n#### Load and Index Unstructured Data  \\nWe load unstructured data into a vector index backed by Pinecone  \\n```python\\n# install wikipedia python package\\n!pip install wikipedia\\n```  \\nRequirement already satisfied: wikipedia in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (1.4.0)\\nRequirement already satisfied: requests<3.0.0,>=2.0.0 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from wikipedia) (2.28.2)\\nRequirement already satisfied: beautifulsoup4 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from wikipedia) (4.12.2)\\nRequirement already satisfied: charset-normalizer<4,>=2 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.1.0)\\nRequirement already satisfied: idna<4,>=2.5 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4)\\nRequirement already satisfied: certifi>=2017.4.17 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2022.12.7)\\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.26.15)\\nRequirement already satisfied: soupsieve>1.2 in /Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages (from beautifulsoup4->wikipedia) (2.4.1)  \\n\\x1b[1m[\\x1b[0m\\x1b[34;49mnotice\\x1b[0m\\x1b[1;39;49m]\\x1b[0m\\x1b[39;49m A new release of pip available: \\x1b[0m\\x1b[31;49m22.3.1\\x1b[0m\\x1b[39;49m -> \\x1b[0m\\x1b[32;49m23.1.2\\x1b[0m\\n\\x1b[1m[\\x1b[0m\\x1b[34;49mnotice\\x1b[0m\\x1b[1;39;49m]\\x1b[0m\\x1b[39;49m To update, run: \\x1b[0m\\x1b[32;49mpip install --upgrade pip\\x1b[0m  \\n```python\\nfrom llama_index import (\\nWikipediaReader,\\nSimpleDirectoryReader,\\nVectorStoreIndex,\\n)\\n```  \\n```python\\ncities = [\"Toronto\", \"Berlin\", \"Tokyo\"]\\nwiki_docs = WikipediaReader().load_data(pages=cities)\\n```  \\n```python\\nfrom llama_index.node_parser import SimpleNodeParser\\nfrom llama_index import ServiceContext\\nfrom llama_index.storage import StorageContext\\nfrom llama_index.text_splitter import TokenTextSplitter\\nfrom llama_index.llms import OpenAI\\n\\n# define node parser and LLM\\nchunk_size = 1024\\nllm = OpenAI(temperature=0, model=\"gpt-4\")\\nservice_context = ServiceContext.from_defaults(chunk_size=chunk_size, llm=llm)\\ntext_splitter = TokenTextSplitter(chunk_size=chunk_size)\\nnode_parser = SimpleNodeParser.from_defaults(text_splitter=text_splitter)\\n\\n# use default in-memory store\\nstorage_context = StorageContext.from_defaults()\\nvector_index = VectorStoreIndex([], storage_context=storage_context)\\n```  \\n```python\\n# Insert documents into vector index\\n# Each document has metadata of the city attached\\nfor city, wiki_doc in zip(cities, wiki_docs):\\nnodes = node_parser.get_nodes_from_documents([wiki_doc])\\n# add metadata to each node\\nfor node in nodes:\\nnode.metadata = {\"title\": city}\\nvector_index.insert_nodes(nodes)\\n```  \\n#### Define Query Engines / Tools  \\n```python\\nfrom llama_index.tools.query_engine import QueryEngineTool\\n```  \\n```python\\nsql_tool = QueryEngineTool.from_defaults(\\nquery_engine=query_engine,\\nname=\"sql_tool\",\\ndescription=(\\n\"Useful for translating a natural language query into a SQL query over\"\\n\" a table containing: city_stats, containing the population/country of\"\\n\" each city\"\\n),\\n)\\nvector_tool = QueryEngineTool.from_defaults(\\nquery_engine=vector_index.as_query_engine(similarity_top_k=2),\\nname=\"vector_tool\",\\ndescription=(\\nf\"Useful for answering semantic questions about different cities\"\\n),\\n)\\n```  \\n#### Initialize Agent  \\n```python\\nfrom llama_index.agent import OpenAIAssistantAgent', metadata={'Header 1': 'OpenAI Assistant Advanced Retrieval Cookbook', 'Header 2': 'Joint Text-to-SQL and Semantic Search'}),\n",
      " Document(page_content='agent = OpenAIAssistantAgent.from_new(\\nname=\"City bot\",\\ninstructions=\"You are a bot designed to answer questions about cities (both unstructured and structured data)\",\\ntools=[sql_tool, vector_tool],\\nverbose=True,\\n)\\n```  \\n```python\\nresponse = agent.chat(\\n\"Tell me about the arts and culture of the city with the highest\"\\n\" population\"\\n)\\nprint(str(response))\\n```  \\n=== Calling Function ===\\nCalling function: sql_tool with args: {\"input\":\"SELECT name, country FROM city_stats ORDER BY population DESC LIMIT 1\"}\\nGot output: The city with the highest population is Tokyo, Japan.\\n========================\\n=== Calling Function ===\\nCalling function: vector_tool with args: {\"input\":\"What are the arts and culture like in Tokyo, Japan?\"}\\nGot output: Tokyo has a vibrant arts and culture scene. The city is home to many museums, including the Tokyo National Museum, which specializes in traditional Japanese art, the National Museum of Western Art, and the Edo-Tokyo Museum. There are also theaters for traditional forms of Japanese drama, such as the National Noh Theatre and the Kabuki-za. Tokyo hosts modern Japanese and international pop and rock music concerts, and the New National Theater Tokyo is a hub for opera, ballet, contemporary dance, and drama. The city also celebrates various festivals throughout the year, including the Sannō, Sanja, and Kanda Festivals. Additionally, Tokyo is known for its youth style, fashion, and cosplay in the Harajuku neighborhood.\\n========================\\nTokyo, Japan, which has the highest population of any city, boasts a rich and diverse arts and culture landscape. The city is a hub for traditional Japanese art as showcased in prominent institutions like the Tokyo National Museum, and it also features artwork from different parts of the world at the National Museum of Western Art. Tokyo has a deep appreciation for its historical roots, with the Edo-Tokyo Museum presenting the past in a detailed and engaging manner.  \\nThe traditional performing arts have a significant presence in Tokyo, with theaters such as the National Noh Theatre presenting classical Noh dramas and the iconic Kabuki-za offering enchanting Kabuki performances. For enthusiasts of modern entertainment, Tokyo is a prime spot for contemporary music, including both Japanese pop and rock as well as international acts.  \\nOpera, ballet, contemporary dance, and drama find a prestigious platform at the New National Theater Tokyo. Tokyo\\'s calendar is filled with a variety of festivals that reflect the city\\'s vibrant cultural heritage, including the Sannō, Sanja, and Kanda Festivals. Additionally, Tokyo is at the forefront of fashion and youth culture, particularly in the Harajuku district, which is famous for its unique fashion, style, and cosplay.  \\nThis mix of traditional and modern, local and international arts and culture makes Tokyo a dynamic and culturally rich city.  \\n```python\\nresponse = agent.chat(\"Tell me about the history of Berlin\")\\nprint(str(response))\\n```  \\n=== Calling Function ===\\nCalling function: vector_tool with args: {\"input\":\"What is the history of Berlin, Germany?\"}\\nGot output: Berlin has a rich and diverse history. It was first documented in the 13th century and has served as the capital of various entities throughout history, including the Margraviate of Brandenburg, the Kingdom of Prussia, the German Empire, the Weimar Republic, and Nazi Germany. After World War II, the city was divided, with West Berlin becoming a part of West Germany and East Berlin becoming the capital of East Germany. Following German reunification in 1990, Berlin once again became the capital of all of Germany. Throughout its history, Berlin has been a center of scientific, artistic, and philosophical activity, and has experienced periods of economic growth and cultural flourishing. Today, it is a world city of culture, politics, media, and science, known for its vibrant arts scene, diverse architecture, and high quality of life.\\n========================\\nBerlin, the capital city of Germany, has a rich and complex history that stretches back to its first documentation in the 13th century. Throughout the centuries, Berlin has been at the heart of numerous important historical movements and events.  \\nInitially a small town, Berlin grew in significance as the capital of the Margraviate of Brandenburg. Later on, it ascended in prominence as the capital of the Kingdom of Prussia. With the unification of Germany, Berlin became the imperial capital of the German Empire, a position it retained until the end of World War I.  \\nThe interwar period saw Berlin as the capital of the Weimar Republic, and it was during this time that the city became known for its vibrant cultural scene. However, the rise of the Nazi regime in the 1930s led to a dark period in Berlin\\'s history, and the city was heavily damaged during World War II.  \\nFollowing the war\\'s end, Berlin became a divided city. The division was physical, represented by the Berlin Wall, and ideological, with West Berlin aligning with democratic West Germany while East Berlin became the capital of the socialist East Germany.  \\nThe fall of the Berlin Wall in November 1989 was a historic moment, leading to German reunification in 1990. Berlin was once again chosen as the capital of a united Germany. Since reunification, Berlin has undergone massive reconstruction and has become a hub of contemporary culture, politics, media, and science.  \\nToday, Berlin celebrates its diverse heritage, from its grand historical landmarks like the Brandenburg Gate and the Reichstag, to its remembrance of the past with monuments such as the Berlin Wall Memorial and the Holocaust Memorial. It is a city known for its cultural dynamism, thriving arts and music scenes, and a high quality of life. Berlin\\'s history has shaped it into a unique world city that continues to play a significant role on the global stage.  \\n```python\\nresponse = agent.chat(\\n\"Can you give me the country corresponding to each city?\"\\n)\\nprint(str(response))\\n```  \\n=== Calling Function ===\\nCalling function: sql_tool with args: {\"input\":\"SELECT name, country FROM city_stats\"}\\nGot output: The cities in the city_stats table are Toronto from Canada, Tokyo from Japan, and Berlin from Germany.\\n========================\\nHere are the countries corresponding to each city:  \\n- Toronto: Canada\\n- Tokyo: Japan\\n- Berlin: Germany', metadata={'Header 1': 'OpenAI Assistant Advanced Retrieval Cookbook', 'Header 2': 'Joint Text-to-SQL and Semantic Search'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/openai_forced_function_call.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>'),\n",
      " Document(page_content='If you\\'re opening this Notebook on colab, you will probably need to install LlamaIndex 🦙.  \\n```python\\n!pip install llama-index\\n```  \\n```python\\nimport json\\nfrom typing import Sequence, List\\n\\nfrom llama_index.llms import OpenAI, ChatMessage\\nfrom llama_index.tools import BaseTool, FunctionTool\\nfrom llama_index.agent import OpenAIAgent\\n```  \\n```python\\ndef add(a: int, b: int) -> int:\\n\"\"\"Add two integers and returns the result integer\"\"\"\\nreturn a + b\\n\\n\\nadd_tool = FunctionTool.from_defaults(fn=add)\\n\\n\\ndef useless_tool() -> int:\\n\"\"\"This is a uselss tool.\"\"\"\\nreturn \"This is a uselss output.\"\\n\\n\\nuseless_tool = FunctionTool.from_defaults(fn=useless_tool)\\n```  \\n```python\\nllm = OpenAI(model=\"gpt-3.5-turbo-0613\")\\nagent = OpenAIAgent.from_tools([useless_tool, add_tool], llm=llm, verbose=True)\\n```', metadata={'Header 1': 'OpenAI agent: specifying a forced function call'}),\n",
      " Document(page_content='The agent automatically selects the useful \"add\" tool  \\n```python\\nresponse = agent.chat(\\n\"What is 5 + 2?\", tool_choice=\"auto\"\\n)  # note function_call param is deprecated\\n# use tool_choice instead\\n```  \\nSTARTING TURN 1\\n---------------  \\n=== Calling Function ===\\nCalling function: add with args: {\\n\"a\": 5,\\n\"b\": 2\\n}\\nGot output: 7\\n========================  \\nSTARTING TURN 2\\n---------------  \\n```python\\nprint(response)\\n```  \\nThe sum of 5 and 2 is 7.', metadata={'Header 1': 'OpenAI agent: specifying a forced function call', 'Header 3': '\"Auto\" function call'}),\n",
      " Document(page_content='The agent is forced to call the \"useless_tool\" before selecting the \"add\" tool  \\n```python\\nresponse = agent.chat(\"What is 5 * 2?\", tool_choice=\"useless_tool\")\\n```  \\nSTARTING TURN 1\\n---------------  \\n=== Calling Function ===\\nCalling function: useless_tool with args: {}\\nGot output: This is a uselss output.\\n========================  \\nSTARTING TURN 2\\n---------------  \\n=== Calling Function ===\\nCalling function: add with args: {\\n\"a\": 5,\\n\"b\": 2\\n}\\nGot output: 7\\n========================  \\nSTARTING TURN 3\\n---------------  \\n```python\\nprint(response)\\n```  \\nThe product of 5 and 2 is 10.', metadata={'Header 1': 'OpenAI agent: specifying a forced function call', 'Header 3': 'Forced function call'}),\n",
      " Document(page_content='The agent is forced to not use a tool  \\n```python\\nresponse = agent.chat(\"What is 5 * 2?\", tool_choice=\"none\")\\n```  \\nSTARTING TURN 1\\n---------------  \\n```python\\nprint(response)\\n```  \\nThe product of 5 and 2 is 10.', metadata={'Header 1': 'OpenAI agent: specifying a forced function call', 'Header 3': '\"None\" function call'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/openai_retrieval_benchmark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>  \\nThis guide benchmarks the Retrieval Tool from the [OpenAI Assistant API](https://platform.openai.com/docs/assistants/overview), by using our `OpenAIAssistantAgent`. We run over the Llama 2 paper, and compare generation quality against a naive RAG pipeline.  \\n```python\\n!pip install llama-index\\n```  \\n```python\\nimport nest_asyncio\\n\\nnest_asyncio.apply()\\n```', metadata={'Header 1': 'Benchmarking OpenAI Retrieval API (through Assistant Agent)'}),\n",
      " Document(page_content='Here we load the Llama 2 paper and chunk it.  \\n```python\\n!mkdir -p \\'data/\\'\\n!wget --user-agent \"Mozilla\" \"https://arxiv.org/pdf/2307.09288.pdf\" -O \"data/llama2.pdf\"\\n```  \\n--2023-11-08 21:53:52--  https://arxiv.org/pdf/2307.09288.pdf\\nResolving arxiv.org (arxiv.org)... 128.84.21.199\\nConnecting to arxiv.org (arxiv.org)|128.84.21.199|:443... connected.\\nHTTP request sent, awaiting response... 200 OK\\nLength: 13661300 (13M) [application/pdf]\\nSaving to: ‘data/llama2.pdf’  \\ndata/llama2.pdf     100%[===================>]  13.03M   141KB/s    in 1m 48s  \\n2023-11-08 21:55:42 (123 KB/s) - ‘data/llama2.pdf’ saved [13661300/13661300]  \\n```python\\nfrom pathlib import Path\\nfrom llama_index import Document, ServiceContext, VectorStoreIndex\\nfrom llama_hub.file.pymu_pdf.base import PyMuPDFReader\\nfrom llama_index.node_parser import SimpleNodeParser\\nfrom llama_index.llms import OpenAI\\n```  \\n```python\\nloader = PyMuPDFReader()\\ndocs0 = loader.load(file_path=Path(\"./data/llama2.pdf\"))\\n\\ndoc_text = \"\\\\n\\\\n\".join([d.get_content() for d in docs0])\\ndocs = [Document(text=doc_text)]\\n```  \\n```python\\nnode_parser = SimpleNodeParser.from_defaults()\\nnodes = node_parser.get_nodes_from_documents(docs)\\n```  \\n```python\\nlen(nodes)\\n```  \\n89', metadata={'Header 1': 'Benchmarking OpenAI Retrieval API (through Assistant Agent)', 'Header 2': 'Setup Data'}),\n",
      " Document(page_content='We setup evaluation modules, including the dataset and evaluators.', metadata={'Header 1': 'Benchmarking OpenAI Retrieval API (through Assistant Agent)', 'Header 2': 'Define Eval Modules'}),\n",
      " Document(page_content='Here we load in a \"golden\" dataset.  \\n#### Option 1: Pull Existing Dataset  \\n**NOTE**: We pull this in from Dropbox. For details on how to generate a dataset please see our `DatasetGenerator` module.  \\n```python\\n!wget \"https://www.dropbox.com/scl/fi/fh9vsmmm8vu0j50l3ss38/llama2_eval_qr_dataset.json?rlkey=kkoaez7aqeb4z25gzc06ak6kb&dl=1\" -O data/llama2_eval_qr_dataset.json\\n```  \\n--2023-11-08 22:20:10--  https://www.dropbox.com/scl/fi/fh9vsmmm8vu0j50l3ss38/llama2_eval_qr_dataset.json?rlkey=kkoaez7aqeb4z25gzc06ak6kb&dl=1\\nResolving www.dropbox.com (www.dropbox.com)... 2620:100:6057:18::a27d:d12, 162.125.13.18\\nConnecting to www.dropbox.com (www.dropbox.com)|2620:100:6057:18::a27d:d12|:443... connected.\\nHTTP request sent, awaiting response... 302 Found\\nLocation: https://uc63170224c66fda29da619e304b.dl.dropboxusercontent.com/cd/0/inline/CHOj1FEf2Dd6npmREaKmwUEIJ4S5QcrgeISKh55BE27i9tqrcE94Oym_0_z0EL9mBTmF9udNCxWwnFSHlio3ib6G_f_j3xiUzn5AVvQsKDPROYjazkJz_ChUVv3xkT-Pzuk/file?dl=1# [following]\\n--2023-11-08 22:20:11--  https://uc63170224c66fda29da619e304b.dl.dropboxusercontent.com/cd/0/inline/CHOj1FEf2Dd6npmREaKmwUEIJ4S5QcrgeISKh55BE27i9tqrcE94Oym_0_z0EL9mBTmF9udNCxWwnFSHlio3ib6G_f_j3xiUzn5AVvQsKDPROYjazkJz_ChUVv3xkT-Pzuk/file?dl=1\\nResolving uc63170224c66fda29da619e304b.dl.dropboxusercontent.com (uc63170224c66fda29da619e304b.dl.dropboxusercontent.com)... 2620:100:6057:15::a27d:d0f, 162.125.13.15\\nConnecting to uc63170224c66fda29da619e304b.dl.dropboxusercontent.com (uc63170224c66fda29da619e304b.dl.dropboxusercontent.com)|2620:100:6057:15::a27d:d0f|:443... connected.\\nHTTP request sent, awaiting response... 200 OK\\nLength: 60656 (59K) [application/binary]\\nSaving to: ‘data/llama2_eval_qr_dataset.json’  \\ndata/llama2_eval_qr 100%[===================>]  59.23K  --.-KB/s    in 0.02s  \\n2023-11-08 22:20:12 (2.87 MB/s) - ‘data/llama2_eval_qr_dataset.json’ saved [60656/60656]  \\n```python\\nfrom llama_index.evaluation import QueryResponseDataset\\n\\n# optional\\neval_dataset = QueryResponseDataset.from_json(\\n\"data/llama2_eval_qr_dataset.json\"\\n)\\n```  \\n#### Option 2: Generate New Dataset  \\nIf you choose this option, you can choose to generate a new dataset from scratch. This allows you to play around with our `DatasetGenerator` settings to make sure it suits your needs.  \\n```python\\nfrom llama_index.evaluation import (\\nDatasetGenerator,\\nQueryResponseDataset,\\n)\\nfrom llama_index import ServiceContext\\nfrom llama_index.llms import OpenAI\\n```  \\n```python\\n# NOTE: run this if the dataset isn\\'t already saved\\n# Note: we only generate from the first 20 nodes, since the rest are references\\neval_service_context = ServiceContext.from_defaults(\\nllm=OpenAI(model=\"gpt-4-1106-preview\")\\n)\\ndataset_generator = DatasetGenerator(\\nnodes[:20],\\nservice_context=eval_service_context,\\nshow_progress=True,\\nnum_questions_per_chunk=3,\\n)\\neval_dataset = await dataset_generator.agenerate_dataset_from_nodes(num=60)\\neval_dataset.save_json(\"data/llama2_eval_qr_dataset.json\")\\n```  \\n```python\\n# optional\\neval_dataset = QueryResponseDataset.from_json(\\n\"data/llama2_eval_qr_dataset.json\"\\n)\\n```', metadata={'Header 1': 'Benchmarking OpenAI Retrieval API (through Assistant Agent)', 'Header 2': 'Define Eval Modules', 'Header 3': 'Setup \"Golden Dataset\"'}),\n",
      " Document(page_content='We define two evaluation modules: correctness and semantic similarity - both comparing quality of predicted response with actual response.  \\n```python\\nfrom llama_index.evaluation.eval_utils import get_responses, get_results_df\\nfrom llama_index.evaluation import (\\nCorrectnessEvaluator,\\nSemanticSimilarityEvaluator,\\nBatchEvalRunner,\\n)\\nfrom llama_index.llms import OpenAI\\n```  \\n```python\\neval_llm = OpenAI(model=\"gpt-4-1106-preview\")\\neval_service_context = ServiceContext.from_defaults(llm=eval_llm)\\nevaluator_c = CorrectnessEvaluator(service_context=eval_service_context)\\nevaluator_s = SemanticSimilarityEvaluator(service_context=eval_service_context)\\nevaluator_dict = {\\n\"correctness\": evaluator_c,\\n\"semantic_similarity\": evaluator_s,\\n}\\nbatch_runner = BatchEvalRunner(evaluator_dict, workers=2, show_progress=True)\\n```  \\n```python\\nimport numpy as np\\nimport time\\nimport os\\nimport pickle\\nfrom tqdm import tqdm\\n\\n\\ndef get_responses_sync(\\neval_qs, query_engine, show_progress=True, save_path=None\\n):\\nif show_progress:\\neval_qs_iter = tqdm(eval_qs)\\nelse:\\neval_qs_iter = eval_qs\\npred_responses = []\\nstart_time = time.time()\\nfor eval_q in eval_qs_iter:\\nprint(f\"eval q: {eval_q}\")\\npred_response = agent.query(eval_q)\\nprint(f\"predicted response: {pred_response}\")\\npred_responses.append(pred_response)\\nif save_path is not None:\\n# save intermediate responses (to cache in case something breaks)\\navg_time = (time.time() - start_time) / len(pred_responses)\\npickle.dump(\\n{\"pred_responses\": pred_responses, \"avg_time\": avg_time},\\nopen(save_path, \"wb\"),\\n)\\nreturn pred_responses\\n\\n\\nasync def run_evals(\\nquery_engine,\\neval_qa_pairs,\\nbatch_runner,\\ndisable_async_for_preds=False,\\nsave_path=None,\\n):\\n# then evaluate\\n# TODO: evaluate a sample of generated results\\neval_qs = [q for q, _ in eval_qa_pairs]\\neval_answers = [a for _, a in eval_qa_pairs]\\n\\nif save_path is not None:\\nif not os.path.exists(save_path):\\nstart_time = time.time()\\nif disable_async_for_preds:\\npred_responses = get_responses_sync(\\neval_qs,\\nquery_engine,\\nshow_progress=True,\\nsave_path=save_path,\\n)\\nelse:\\npred_responses = get_responses(\\neval_qs, query_engine, show_progress=True\\n)\\navg_time = (time.time() - start_time) / len(eval_qs)\\npickle.dump(\\n{\"pred_responses\": pred_responses, \"avg_time\": avg_time},\\nopen(save_path, \"wb\"),\\n)\\nelse:\\n# [optional] load\\npickled_dict = pickle.load(open(save_path, \"rb\"))\\npred_responses = pickled_dict[\"pred_responses\"]\\navg_time = pickled_dict[\"avg_time\"]\\nelse:\\nstart_time = time.time()\\npred_responses = get_responses(\\neval_qs, query_engine, show_progress=True\\n)\\navg_time = (time.time() - start_time) / len(eval_qs)\\n\\neval_results = await batch_runner.aevaluate_responses(\\neval_qs, responses=pred_responses, reference=eval_answers\\n)\\nreturn eval_results, {\"avg_time\": avg_time}\\n```', metadata={'Header 1': 'Benchmarking OpenAI Retrieval API (through Assistant Agent)', 'Header 2': 'Define Eval Modules', 'Header 3': 'Eval Modules'}),\n",
      " Document(page_content='Let\\'s construct the assistant by also passing it the built-in OpenAI Retrieval tool.  \\nHere, we upload and pass in the file during assistant-creation time.  \\n```python\\nfrom llama_index.agent import OpenAIAssistantAgent\\n```  \\n```python\\nagent = OpenAIAssistantAgent.from_new(\\nname=\"SEC Analyst\",\\ninstructions=\"You are a QA assistant designed to analyze sec filings.\",\\nopenai_tools=[{\"type\": \"retrieval\"}],\\ninstructions_prefix=\"Please address the user as Jerry.\",\\nfiles=[\"data/llama2.pdf\"],\\nverbose=True,\\n)\\n```  \\n```python\\nresponse = agent.query(\\n\"What are the key differences between Llama 2 and Llama 2-Chat?\"\\n)\\n```  \\n```python\\nprint(str(response))\\n```  \\nThe key differences between Llama 2 and Llama 2-Chat, as indicated by the document, focus on their performance in safety evaluations, particularly when tested with adversarial prompts. Here are some of the differences highlighted within the safety evaluation section of Llama 2-Chat:  \\n1. Safety Human Evaluation: Llama 2-Chat was assessed with roughly 2000 adversarial prompts, among which 1351 were single-turn and 623 were multi-turn. The responses were judged for safety violations on a five-point Likert scale, where a rating of 1 or 2 indicated a violation. The evaluation aimed to gauge the model’s safety by its rate of generating responses with safety violations and its helpfulness to users.  \\n2. Violation Percentage and Mean Rating: Llama 2-Chat exhibited a low overall violation percentage across different model sizes and a high mean rating for safety and helpfulness, which suggests a strong performance in safety evaluations.  \\n3. Inter-Rater Reliability: The reliability of the safety assessments was measured using Gwet’s AC1/2 statistic, showing a high degree of agreement among annotators with an average inter-rater reliability score of 0.92 for Llama 2-Chat annotations.  \\n4. Single-turn and Multi-turn Conversations: The evaluation revealed that multi-turn conversations generally lead to more safety violations across models, but Llama 2-Chat performed well compared to baselines, particularly in multi-turn scenarios.  \\n5. Violation Percentage Per Risk Category: Llama 2-Chat had a relatively higher number of violations in the unqualified advice category, possibly due to a lack of appropriate disclaimers in its responses.  \\n6. Improvements in Fine-Tuned Llama 2-Chat: The document also mentions that the fine-tuned Llama 2-Chat showed significant improvement over the pre-trained Llama 2 in terms of truthfulness and toxicity. The percentage of toxic generations dropped to effectively 0% for Llama 2-Chat of all sizes, which was the lowest among all compared models, indicating a notable enhancement in safety.  \\nThese points detail the evaluations and improvements emphasizing safety that distinguish Llama 2-Chat from Llama 2【9†source】.', metadata={'Header 1': 'Benchmarking OpenAI Retrieval API (through Assistant Agent)', 'Header 2': 'Construct Assistant with Built-In Retrieval'}),\n",
      " Document(page_content='We run the agent over our evaluation dataset. We benchmark against a standard top-k RAG pipeline (k=2) with gpt-4-turbo.  \\n**NOTE**: During our time of testing (November 2023), the Assistant API is heavily rate-limited, and can take ~1-2 hours to generate responses over 60 datapoints.  \\n#### Define Baseline Index + RAG Pipeline  \\n```python\\nbase_sc = ServiceContext.from_defaults(llm=OpenAI(model=\"gpt-4-1106-preview\"))\\nbase_index = VectorStoreIndex(nodes, service_context=base_sc)\\nbase_query_engine = base_index.as_query_engine(similarity_top_k=2)\\n```  \\n#### Run Evals over Baseline  \\n```python\\nbase_eval_results, base_extra_info = await run_evals(\\nbase_query_engine,\\neval_dataset.qr_pairs,\\nbatch_runner,\\nsave_path=\"data/llama2_preds_base.pkl\",\\n)\\n```  \\n```python\\nresults_df = get_results_df(\\n[base_eval_results],\\n[\"Base Query Engine\"],\\n[\"correctness\", \"semantic_similarity\"],\\n)\\ndisplay(results_df)\\n```  \\n<div>\\n<style scoped>\\n.dataframe tbody tr th:only-of-type {\\nvertical-align: middle;\\n}  \\n.dataframe tbody tr th {\\nvertical-align: top;\\n}  \\n.dataframe thead th {\\ntext-align: right;\\n}\\n</style>\\n<table border=\"1\" class=\"dataframe\">\\n<thead>\\n<tr style=\"text-align: right;\">\\n<th></th>\\n<th>names</th>\\n<th>correctness</th>\\n<th>semantic_similarity</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<th>0</th>\\n<td>Base Query Engine</td>\\n<td>4.05</td>\\n<td>0.964245</td>\\n</tr>\\n</tbody>\\n</table>\\n</div>  \\n#### Run Evals over Assistant API  \\n```python\\nassistant_eval_results, assistant_extra_info = await run_evals(\\nagent,\\neval_dataset.qr_pairs[:55],\\nbatch_runner,\\nsave_path=\"data/llama2_preds_assistant.pkl\",\\ndisable_async_for_preds=True,\\n)\\n```  \\n#### Get Results  \\nHere we see...that our basic RAG pipeline does better.  \\nTake these numbers with a grain of salt. The goal here is to give you a script so you can run this on your own data.  \\nThat said it\\'s surprising the Retrieval API doesn\\'t give immediately better out of the box performance.  \\n```python\\nresults_df = get_results_df(\\n[assistant_eval_results, base_eval_results],\\n[\"Retrieval API\", \"Base Query Engine\"],\\n[\"correctness\", \"semantic_similarity\"],\\n)\\ndisplay(results_df)\\nprint(f\"Base Avg Time: {base_extra_info[\\'avg_time\\']}\")\\nprint(f\"Assistant Avg Time: {assistant_extra_info[\\'avg_time\\']}\")\\n```  \\n<div>\\n<style scoped>\\n.dataframe tbody tr th:only-of-type {\\nvertical-align: middle;\\n}  \\n.dataframe tbody tr th {\\nvertical-align: top;\\n}  \\n.dataframe thead th {\\ntext-align: right;\\n}\\n</style>\\n<table border=\"1\" class=\"dataframe\">\\n<thead>\\n<tr style=\"text-align: right;\">\\n<th></th>\\n<th>names</th>\\n<th>correctness</th>\\n<th>semantic_similarity</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<th>0</th>\\n<td>Retrieval API</td>\\n<td>3.536364</td>\\n<td>0.952647</td>\\n</tr>\\n<tr>\\n<th>1</th>\\n<td>Base Query Engine</td>\\n<td>4.050000</td>\\n<td>0.964245</td>\\n</tr>\\n</tbody>\\n</table>\\n</div>  \\nBase Avg Time: 0.25683316787083943\\nAssistant Avg Time: 75.43605598536405', metadata={'Header 1': 'Benchmarking OpenAI Retrieval API (through Assistant Agent)', 'Header 2': 'Benchmark'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/react_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>'),\n",
      " Document(page_content=\"This is a notebook that showcases the ReAct agent over very simple calculator tools (no fancy RAG pipelines or API calls).  \\nWe show how it can reason step-by-step over different tools to achieve the end goal.  \\nIf you're opening this Notebook on colab, you will probably need to install LlamaIndex 🦙.  \\n```python\\n!pip install llama-index\\n```  \\n```python\\nfrom llama_index.agent import ReActAgent\\nfrom llama_index.llms import OpenAI, ChatMessage\\nfrom llama_index.tools import BaseTool, FunctionTool\\n```\", metadata={'Header 1': 'ReAct Agent - A Simple Intro with Calculator Tools'}),\n",
      " Document(page_content='We setup some trivial `multiply` and `add` tools. Note that you can define arbitrary functions and pass it to the `FunctionTool` (which will process the docstring and parameter signature).  \\n```python\\ndef multiply(a: int, b: int) -> int:\\n\"\"\"Multiply two integers and returns the result integer\"\"\"\\nreturn a * b\\n\\n\\nmultiply_tool = FunctionTool.from_defaults(fn=multiply)\\n```  \\n```python\\ndef add(a: int, b: int) -> int:\\n\"\"\"Add two integers and returns the result integer\"\"\"\\nreturn a + b\\n\\n\\nadd_tool = FunctionTool.from_defaults(fn=add)\\n```', metadata={'Header 1': 'ReAct Agent - A Simple Intro with Calculator Tools', 'Header 2': 'Define Function Tools'}),\n",
      " Document(page_content='```python\\nllm = OpenAI(model=\"gpt-3.5-turbo-instruct\")\\nagent = ReActAgent.from_tools([multiply_tool, add_tool], llm=llm, verbose=True)\\n```  \\n```python\\nresponse = agent.chat(\"What is 20+(2*4)? Calculate step by step \")\\n```  \\n\\x1b[1;3;38;5;200mThought: I need to use a tool to help me answer the question.\\nassistant: Action: multiply\\nassistant: Action Input: {\"a\": 2, \"b\": 4}\\nObservation: 8\\nassistant: Thought: I need to use a tool to help me answer the question.\\nassistant: Action: add\\nassistant: Action Input: {\"a\": 20, \"b\": 8}\\nObservation: 28\\nThought: I can answer without using any more tools.\\nAnswer: 28\\n\\x1b[0m  \\n```python\\nresponse_gen = agent.stream_chat(\"What is 20+2*4? Calculate step by step\")\\nresponse_gen.print_response_stream()\\n```  \\n28', metadata={'Header 1': 'ReAct Agent - A Simple Intro with Calculator Tools', 'Header 2': 'Run Some Queries', 'Header 3': 'gpt-3.5-turbo'}),\n",
      " Document(page_content='```python\\nllm = OpenAI(model=\"gpt-4\")\\nagent = ReActAgent.from_tools([multiply_tool, add_tool], llm=llm, verbose=True)\\n```  \\n```python\\nresponse = agent.chat(\"What is 2+2*4\")\\nprint(response)\\n```  \\n\\x1b[1;3;38;5;200mThought: I need to use the tools to help me answer the question. According to the order of operations in mathematics (BIDMAS/BODMAS), multiplication should be done before addition. So, I will first multiply 2 and 4, then add the result to 2.\\nAction: multiply\\nAction Input: {\\'a\\': 2, \\'b\\': 4}\\n\\x1b[0m\\x1b[1;3;34mObservation: 8\\n\\x1b[0m\\x1b[1;3;38;5;200mThought: Now that I have the result of the multiplication, I need to add this to 2.\\nAction: add\\nAction Input: {\\'a\\': 2, \\'b\\': 8}\\n\\x1b[0m\\x1b[1;3;34mObservation: 10\\n\\x1b[0m\\x1b[1;3;38;5;200mThought: I can answer without using any more tools.\\nAnswer: 10\\n\\x1b[0m10', metadata={'Header 1': 'ReAct Agent - A Simple Intro with Calculator Tools', 'Header 2': 'Run Some Queries', 'Header 3': 'gpt-4'}),\n",
      " Document(page_content='Let\\'s take a look at the core system prompt powering the ReAct agent!  \\nWithin the agent, the current conversation history is dumped below this line.  \\n```python\\nllm = OpenAI(model=\"gpt-4\")\\nagent = ReActAgent.from_tools([multiply_tool, add_tool], llm=llm, verbose=True)\\n```  \\n```python\\nprompt_dict = agent.get_prompts()\\nfor k, v in prompt_dict.items():\\nprint(f\"Prompt: {k}\\\\n\\\\nValue: {v.template}\")\\n```  \\nPrompt: agent_worker:system_prompt  \\nValue:\\nYou are designed to help with a variety of tasks, from answering questions     to providing summaries to other types of analyses.', metadata={'Header 1': 'ReAct Agent - A Simple Intro with Calculator Tools', 'Header 2': 'View Prompts'}),\n",
      " Document(page_content='You have access to a wide variety of tools. You are responsible for using\\nthe tools in any sequence you deem appropriate to complete the task at hand.\\nThis may require breaking the task into subtasks and using different tools\\nto complete each subtask.  \\nYou have access to the following tools:\\n{tool_desc}', metadata={'Header 1': 'ReAct Agent - A Simple Intro with Calculator Tools', 'Header 2': 'Tools'}),\n",
      " Document(page_content='To answer the question, please use the following format.  \\n```\\nThought: I need to use a tool to help me answer the question.\\nAction: tool name (one of {tool_names}) if using a tool.\\nAction Input: the input to the tool, in a JSON format representing the kwargs (e.g. {{\"input\": \"hello world\", \"num_beams\": 5}})\\n```  \\nPlease ALWAYS start with a Thought.  \\nPlease use a valid JSON format for the Action Input. Do NOT do this {{\\'input\\': \\'hello world\\', \\'num_beams\\': 5}}.  \\nIf this format is used, the user will respond in the following format:  \\n```\\nObservation: tool response\\n```  \\nYou should keep repeating the above format until you have enough information\\nto answer the question without using any more tools. At that point, you MUST respond\\nin the one of the following two formats:  \\n```\\nThought: I can answer without using any more tools.\\nAnswer: [your answer here]\\n```  \\n```\\nThought: I cannot answer the question with the provided tools.\\nAnswer: Sorry, I cannot answer your query.\\n```', metadata={'Header 1': 'ReAct Agent - A Simple Intro with Calculator Tools', 'Header 2': 'Output Format'}),\n",
      " Document(page_content='Below is the current conversation consisting of interleaving human and assistant messages.', metadata={'Header 1': 'ReAct Agent - A Simple Intro with Calculator Tools', 'Header 2': 'Current Conversation'}),\n",
      " Document(page_content='For fun, let\\'s try instructing the agent to output the answer along with reasoning in bullet points. See \"## Additional Rules\" section.  \\n```python\\nfrom llama_index.prompts import PromptTemplate\\n\\nreact_system_header_str = \"\"\"\\\\\\n\\nYou are designed to help with a variety of tasks, from answering questions \\\\\\nto providing summaries to other types of analyses.\\n\\n## Tools\\nYou have access to a wide variety of tools. You are responsible for using\\nthe tools in any sequence you deem appropriate to complete the task at hand.\\nThis may require breaking the task into subtasks and using different tools\\nto complete each subtask.\\n\\nYou have access to the following tools:\\n{tool_desc}\\n\\n## Output Format\\nTo answer the question, please use the following format.\\n\\n```\\nThought: I need to use a tool to help me answer the question.\\nAction: tool name (one of {tool_names}) if using a tool.\\nAction Input: the input to the tool, in a JSON format representing the kwargs (e.g. {{\"input\": \"hello world\", \"num_beams\": 5}})\\n```\\n\\nPlease ALWAYS start with a Thought.\\n\\nPlease use a valid JSON format for the Action Input. Do NOT do this {{\\'input\\': \\'hello world\\', \\'num_beams\\': 5}}.\\n\\nIf this format is used, the user will respond in the following format:\\n\\n```\\nObservation: tool response\\n```\\n\\nYou should keep repeating the above format until you have enough information\\nto answer the question without using any more tools. At that point, you MUST respond\\nin the one of the following two formats:\\n\\n```\\nThought: I can answer without using any more tools.\\nAnswer: [your answer here]\\n```\\n\\n```\\nThought: I cannot answer the question with the provided tools.\\nAnswer: Sorry, I cannot answer your query.\\n```\\n\\n## Additional Rules\\n- The answer MUST contain a sequence of bullet points that explain how you arrived at the answer. This can include aspects of the previous conversation history.\\n- You MUST obey the function signature of each tool. Do NOT pass in no arguments if the function expects arguments.\\n\\n## Current Conversation\\nBelow is the current conversation consisting of interleaving human and assistant messages.\\n\\n\"\"\"\\nreact_system_prompt = PromptTemplate(react_system_header_str)\\n```  \\n```python\\nagent.update_prompts({\"agent_worker:system_prompt\": react_system_prompt})\\n```  \\n```python\\nagent.reset()\\nresponse = agent.chat(\"What is 5+3+2\")\\nprint(response)\\n```  \\n\\x1b[1;3;38;5;200mThought: I need to use the add tool to help me answer the question.\\nAction: add\\nAction Input: {\\'a\\': 5, \\'b\\': 3}\\n\\x1b[0m\\x1b[1;3;34mObservation: 8\\n\\x1b[0m\\x1b[1;3;38;5;200mThought: Now I need to add the result from the previous operation with 2.\\nAction: add\\nAction Input: {\\'a\\': 8, \\'b\\': 2}\\n\\x1b[0m\\x1b[1;3;34mObservation: 10\\n\\x1b[0m\\x1b[1;3;38;5;200mThought: I can answer without using any more tools.\\nAnswer: The result of 5+3+2 is 10.\\n- First, I added 5 and 3 using the add tool, which resulted in 8.\\n- Then, I added the result (8) to 2 using the add tool, which resulted in 10.\\n\\x1b[0mThe result of 5+3+2 is 10.\\n- First, I added 5 and 3 using the add tool, which resulted in 8.\\n- Then, I added the result (8) to 2 using the add tool, which resulted in 10.', metadata={'Header 1': 'ReAct Agent - A Simple Intro with Calculator Tools', 'Header 2': 'Current Conversation', 'Header 3': 'Customizing the Prompt'}),\n",
      " Document(page_content='<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/react_agent_with_query_engine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>'),\n",
      " Document(page_content='In this section, we show how to setup an agent powered by the ReAct loop for financial analysis.  \\nThe agent has access to two \"tools\": one to query the 2021 Lyft 10-K and the other to query the 2021 Uber 10-K.  \\nWe try two different LLMs:  \\n- gpt-3.5-turbo\\n- gpt-3.5-turbo-instruct  \\nNote that you can plug in any LLM that exposes a text completion endpoint.', metadata={'Header 1': 'ReAct Agent with Query Engine (RAG) Tools'}),\n",
      " Document(page_content='```python\\nfrom llama_index import (\\nSimpleDirectoryReader,\\nVectorStoreIndex,\\nStorageContext,\\nload_index_from_storage,\\n)\\n\\nfrom llama_index.tools import QueryEngineTool, ToolMetadata\\n```  \\n```python\\ntry:\\nstorage_context = StorageContext.from_defaults(\\npersist_dir=\"./storage/lyft\"\\n)\\nlyft_index = load_index_from_storage(storage_context)\\n\\nstorage_context = StorageContext.from_defaults(\\npersist_dir=\"./storage/uber\"\\n)\\nuber_index = load_index_from_storage(storage_context)\\n\\nindex_loaded = True\\nexcept:\\nindex_loaded = False\\n```  \\nDownload Data  \\n```python\\n!mkdir -p \\'data/10k/\\'\\n!wget \\'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10k/uber_2021.pdf\\' -O \\'data/10k/uber_2021.pdf\\'\\n!wget \\'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10k/lyft_2021.pdf\\' -O \\'data/10k/lyft_2021.pdf\\'\\n```  \\n```python\\nif not index_loaded:\\n# load data\\nlyft_docs = SimpleDirectoryReader(\\ninput_files=[\"./data/10k/lyft_2021.pdf\"]\\n).load_data()\\nuber_docs = SimpleDirectoryReader(\\ninput_files=[\"./data/10k/uber_2021.pdf\"]\\n).load_data()\\n\\n# build index\\nlyft_index = VectorStoreIndex.from_documents(lyft_docs)\\nuber_index = VectorStoreIndex.from_documents(uber_docs)\\n\\n# persist index\\nlyft_index.storage_context.persist(persist_dir=\"./storage/lyft\")\\nuber_index.storage_context.persist(persist_dir=\"./storage/uber\")\\n```  \\n```python\\nlyft_engine = lyft_index.as_query_engine(similarity_top_k=3)\\nuber_engine = uber_index.as_query_engine(similarity_top_k=3)\\n```  \\n```python\\nquery_engine_tools = [\\nQueryEngineTool(\\nquery_engine=lyft_engine,\\nmetadata=ToolMetadata(\\nname=\"lyft_10k\",\\ndescription=(\\n\"Provides information about Lyft financials for year 2021. \"\\n\"Use a detailed plain text question as input to the tool.\"\\n),\\n),\\n),\\nQueryEngineTool(\\nquery_engine=uber_engine,\\nmetadata=ToolMetadata(\\nname=\"uber_10k\",\\ndescription=(\\n\"Provides information about Uber financials for year 2021. \"\\n\"Use a detailed plain text question as input to the tool.\"\\n),\\n),\\n),\\n]\\n```', metadata={'Header 1': 'ReAct Agent with Query Engine (RAG) Tools', 'Header 2': 'Build Query Engine Tools'}),\n",
      " Document(page_content='Here we setup two ReAct agents: one powered by standard gpt-3.5-turbo, and the other powered by gpt-3.5-turbo-instruct.  \\nYou can **optionally** specify context which will be added to the core ReAct system prompt.  \\n```python\\nfrom llama_index.agent import ReActAgent\\nfrom llama_index.llms import OpenAI\\n```  \\n```python\\n# [Optional] Add Context\\n# context = \"\"\"\\\\\\n# You are a stock market sorcerer who is an expert on the companies Lyft and Uber.\\\\\\n#     You will answer questions about Uber and Lyft as in the persona of a sorcerer \\\\\\n#     and veteran stock market investor.\\n# \"\"\"\\nllm = OpenAI(model=\"gpt-3.5-turbo-0613\")\\n\\nagent = ReActAgent.from_tools(\\nquery_engine_tools,\\nllm=llm,\\nverbose=True,\\n# context=context\\n)\\n```  \\n```python\\nresponse = agent.chat(\"What was Lyft\\'s revenue growth in 2021?\")\\nprint(str(response))\\n```  \\n\\x1b[38;5;200m\\x1b[1;3mThought: I need to use a tool to help me answer the question.\\nAction: lyft_10k\\nAction Input: {\\'input\\': \"What was Lyft\\'s revenue growth in 2021?\"}\\n\\x1b[0m\\x1b[36;1m\\x1b[1;3mObservation: Lyft\\'s revenue growth in 2021 was 36%.\\n\\x1b[0m\\x1b[38;5;200m\\x1b[1;3mResponse: Lyft\\'s revenue growth in 2021 was 36%.\\n\\x1b[0mLyft\\'s revenue growth in 2021 was 36%.', metadata={'Header 1': 'ReAct Agent with Query Engine (RAG) Tools', 'Header 2': 'Setup ReAct Agent'}),\n",
      " Document(page_content='We run some example queries using the agent, showcasing some of the agent\\'s abilities to do chain-of-thought-reasoning and tool use to synthesize the right answer.  \\nWe also show queries.  \\n```python\\nresponse = agent.chat(\\n\"Compare and contrast the revenue growth of Uber and Lyft in 2021, then\"\\n\" give an analysis\"\\n)\\nprint(str(response))\\n```  \\n\\x1b[38;5;200m\\x1b[1;3mThought: I need to use a tool to help me compare the revenue growth of Uber and Lyft in 2021.\\nAction: lyft_10k\\nAction Input: {\\'input\\': \"What was Lyft\\'s revenue growth in 2021?\"}\\n\\x1b[0m\\x1b[36;1m\\x1b[1;3mObservation: Lyft\\'s revenue growth in 2021 was 36%.\\n\\x1b[0m\\x1b[38;5;200m\\x1b[1;3mThought: I need to use a tool to help me compare the revenue growth of Uber and Lyft in 2021.\\nAction: uber_10k\\nAction Input: {\\'input\\': \"What was Uber\\'s revenue growth in 2021?\"}\\n\\x1b[0m\\x1b[36;1m\\x1b[1;3mObservation: Uber\\'s revenue growth in 2021 was 57%.\\n\\x1b[0m\\x1b[38;5;200m\\x1b[1;3mResponse: In 2021, Lyft\\'s revenue growth was 36% while Uber\\'s revenue growth was 57%. This indicates that Uber experienced a higher revenue growth compared to Lyft in 2021.\\n\\x1b[0mIn 2021, Lyft\\'s revenue growth was 36% while Uber\\'s revenue growth was 57%. This indicates that Uber experienced a higher revenue growth compared to Lyft in 2021.  \\n**Async execution**: Here we try another query with async execution  \\n```python\\n# Try another query with async execution\\n\\nimport nest_asyncio\\n\\nnest_asyncio.apply()\\n\\nresponse = await agent.achat(\\n\"Compare and contrast the risks of Uber and Lyft in 2021, then give an\"\\n\" analysis\"\\n)\\nprint(str(response))\\n```', metadata={'Header 1': 'ReAct Agent with Query Engine (RAG) Tools', 'Header 2': 'Run Some Example Queries'}),\n",
      " Document(page_content='We compare the performance of the two agents in being able to answer some complex queries.  \\n#### Taking a look at a turbo-instruct agent  \\n```python\\nllm_instruct = OpenAI(model=\"gpt-3.5-turbo-instruct\")\\nagent_instruct = ReActAgent.from_tools(\\nquery_engine_tools, llm=llm_instruct, verbose=True\\n)\\n```  \\n```python\\nresponse = agent_instruct.chat(\"What was Lyft\\'s revenue growth in 2021?\")\\nprint(str(response))\\n```  \\n\\x1b[38;5;200m\\x1b[1;3mThought: I need to use a tool to help me answer the question.\\nAction: lyft_10k\\nAction Input: {\\'input\\': \"What was Lyft\\'s revenue growth in 2021?\"}\\n\\x1b[0m\\x1b[36;1m\\x1b[1;3mObservation: Lyft\\'s revenue growth in 2021 was 36%.\\n\\x1b[0m\\x1b[38;5;200m\\x1b[1;3mResponse: Lyft\\'s revenue growth in 2021 was 36%.\\n\\x1b[0mLyft\\'s revenue growth in 2021 was 36%.  \\n#### Try more complex queries  \\nWe compare gpt-3.5-turbo with gpt-3.5-turbo-instruct agents on more complex queries.  \\n```python\\nresponse = agent.chat(\\n\"Compare and contrast the revenue growth of Uber and Lyft in 2021, then\"\\n\" give an analysis\"\\n)\\nprint(str(response))\\n```  \\n\\x1b[38;5;200m\\x1b[1;3mThought: I need to use a tool to help me compare the revenue growth of Uber and Lyft in 2021.\\nAction: uber_10k\\nAction Input: {\\'input\\': \"Please provide information about Uber\\'s revenue growth in 2021.\"}\\n\\x1b[0m\\x1b[36;1m\\x1b[1;3mObservation: Uber\\'s revenue grew by 57% in 2021 compared to the previous year. This growth was primarily driven by an increase in Gross Bookings, with Delivery Gross Bookings increasing by 71% and Mobility Gross Bookings growing by 38%. The increase in Delivery Gross Bookings was due to higher demand for food delivery orders and expansion across U.S. and international markets. The growth in Mobility Gross Bookings was a result of increased Trip volumes as the business recovered from the impacts of COVID-19.\\n\\x1b[0m\\x1b[38;5;200m\\x1b[1;3mThought: I have information about Uber\\'s revenue growth in 2021. Now I need to use a tool to get information about Lyft\\'s revenue growth in 2021.\\nAction: lyft_10k\\nAction Input: {\\'input\\': \"Please provide information about Lyft\\'s revenue growth in 2021.\"}\\n\\x1b[0m\\x1b[36;1m\\x1b[1;3mObservation: Lyft\\'s revenue increased by 36% in 2021 compared to the prior year.\\n\\x1b[0m\\x1b[38;5;200m\\x1b[1;3mResponse: In 2021, Uber experienced a higher revenue growth rate of 57% compared to Lyft\\'s growth rate of 36%. This indicates that Uber had a stronger performance in terms of revenue growth during that period. The growth in Uber\\'s revenue was primarily driven by an increase in Gross Bookings, with both Delivery and Mobility segments contributing to the growth. The increase in Delivery Gross Bookings was due to higher demand for food delivery services, while the growth in Mobility Gross Bookings was a result of increased trip volumes as the business recovered from the impacts of COVID-19.\\n\\x1b[0mIn 2021, Uber experienced a higher revenue growth rate of 57% compared to Lyft\\'s growth rate of 36%. This indicates that Uber had a stronger performance in terms of revenue growth during that period. The growth in Uber\\'s revenue was primarily driven by an increase in Gross Bookings, with both Delivery and Mobility segments contributing to the growth. The increase in Delivery Gross Bookings was due to higher demand for food delivery services, while the growth in Mobility Gross Bookings was a result of increased trip volumes as the business recovered from the impacts of COVID-19.  \\n```python\\nresponse = agent_instruct.chat(\\n\"Compare and contrast the revenue growth of Uber and Lyft in 2021, then\"\\n\" give an analysis\"\\n)\\nprint(str(response))\\n```  \\n\\x1b[38;5;200m\\x1b[1;3mResponse: The revenue growth of Uber was higher than Lyft in 2021, with Uber experiencing a 74% growth compared to Lyft\\'s 48%. This indicates that Uber may have had a stronger financial performance in 2021. However, further analysis is needed to fully understand the factors contributing to this difference.\\n\\x1b[0mThe revenue growth of Uber was higher than Lyft in 2021, with Uber experiencing a 74% growth compared to Lyft\\'s 48%. This indicates that Uber may have had a stronger financial performance in 2021. However, further analysis is needed to fully understand the factors contributing to this difference.  \\n```python\\nresponse = agent.chat(\\n\"Can you tell me about the risk factors of the company with the higher\"\\n\" revenue?\"\\n)\\nprint(str(response))\\n```  \\n\\x1b[38;5;200m\\x1b[1;3mThought: I need to find out which company has higher revenue before I can provide information about its risk factors.\\nAction: lyft_10k\\nAction Input: {\\'input\\': \\'What is the revenue of Lyft in 2021?\\'}\\n\\x1b[0m\\x1b[36;1m\\x1b[1;3mObservation: The revenue of Lyft in 2021 is $3,208,323,000.\\n\\x1b[0m\\x1b[38;5;200m\\x1b[1;3mThought: Now that I know Lyft has higher revenue, I can find information about its risk factors.\\nAction: lyft_10k\\nAction Input: {\\'input\\': \\'What are the risk factors of Lyft?\\'}\\n\\x1b[0m\\x1b[36;1m\\x1b[1;3mObservation: Lyft faces numerous risk factors that could potentially harm its business, financial condition, and results of operations. These risk factors include general economic factors such as the impact of the COVID-19 pandemic, natural disasters, economic downturns, and political crises. Operational factors such as limited operating history, financial performance, competition, unpredictability of results, uncertainty regarding market growth, ability to attract and retain drivers and riders, insurance coverage, autonomous vehicle technology, reputation and brand, illegal or improper activity on the platform, accuracy of background checks, changes to pricing practices, growth management, security and privacy breaches, reliance on third parties, and ability to operate various programs and services. Additionally, Lyft faces risks related to its evolving business, including forecasting revenue and managing expenses, complying with laws and regulations, managing assets and expenses during the COVID-19 pandemic, capital expenditures, asset development and utilization, macroeconomic changes, reputation and brand management, growth and business operations, geographic expansion, talent acquisition and retention, platform development, and real estate portfolio management. Furthermore, Lyft\\'s financial performance in recent periods may not be indicative of future performance, and achieving or maintaining profitability in the future is not guaranteed. The Express Drive program and Lyft Rentals program also expose Lyft to risks related to vehicle rental partners, residual value of vehicles, and payment processing.', metadata={'Header 1': 'ReAct Agent with Query Engine (RAG) Tools', 'Header 2': 'Run Some Example Queries', 'Header 3': 'Compare gpt-3.5-turbo vs. gpt-3.5-turbo-instruct'}),\n",
      " Document(page_content='\\x1b[0m\\x1b[38;5;200m\\x1b[1;3mResponse: Lyft faces numerous risk factors that could potentially harm its business, financial condition, and results of operations. These risk factors include general economic factors such as the impact of the COVID-19 pandemic, natural disasters, economic downturns, and political crises. Operational factors such as limited operating history, financial performance, competition, unpredictability of results, uncertainty regarding market growth, ability to attract and retain drivers and riders, insurance coverage, autonomous vehicle technology, reputation and brand, illegal or improper activity on the platform, accuracy of background checks, changes to pricing practices, growth management, security and privacy breaches, reliance on third parties, and ability to operate various programs and services. Additionally, Lyft faces risks related to its evolving business, including forecasting revenue and managing expenses, complying with laws and regulations, managing assets and expenses during the COVID-19 pandemic, capital expenditures, asset development and utilization, macroeconomic changes, reputation and brand management, growth and business operations, geographic expansion, talent acquisition and retention, platform development, and real estate portfolio management. Furthermore, Lyft\\'s financial performance in recent periods may not be indicative of future performance, and achieving or maintaining profitability in the future is not guaranteed. The Express Drive program and Lyft Rentals program also expose Lyft to risks related to vehicle rental partners, residual value of vehicles, and payment processing.\\n\\x1b[0mLyft faces numerous risk factors that could potentially harm its business, financial condition, and results of operations. These risk factors include general economic factors such as the impact of the COVID-19 pandemic, natural disasters, economic downturns, and political crises. Operational factors such as limited operating history, financial performance, competition, unpredictability of results, uncertainty regarding market growth, ability to attract and retain drivers and riders, insurance coverage, autonomous vehicle technology, reputation and brand, illegal or improper activity on the platform, accuracy of background checks, changes to pricing practices, growth management, security and privacy breaches, reliance on third parties, and ability to operate various programs and services. Additionally, Lyft faces risks related to its evolving business, including forecasting revenue and managing expenses, complying with laws and regulations, managing assets and expenses during the COVID-19 pandemic, capital expenditures, asset development and utilization, macroeconomic changes, reputation and brand management, growth and business operations, geographic expansion, talent acquisition and retention, platform development, and real estate portfolio management. Furthermore, Lyft\\'s financial performance in recent periods may not be indicative of future performance, and achieving or maintaining profitability in the future is not guaranteed. The Express Drive program and Lyft Rentals program also expose Lyft to risks related to vehicle rental partners, residual value of vehicles, and payment processing.  \\n```python\\nresponse = agent_instruct.query(\\n\"Can you tell me about the risk factors of the company with the higher\"\\n\" revenue?\"\\n)\\nprint(str(response))\\n```  \\n\\x1b[38;5;200m\\x1b[1;3mResponse: The risk factors for the company with the higher revenue include competition, regulatory changes, and dependence on drivers.\\n\\x1b[0mThe risk factors for the company with the higher revenue include competition, regulatory changes, and dependence on drivers.  \\n**Observation**: The turbo-instruct agent seems to do worse on agent reasoning compared to the regular turbo model. Of course, this is subject to further observation!', metadata={'Header 1': 'ReAct Agent with Query Engine (RAG) Tools', 'Header 2': 'Run Some Example Queries', 'Header 3': 'Compare gpt-3.5-turbo vs. gpt-3.5-turbo-instruct'})]\n"
     ]
    }
   ],
   "source": [
    "pprint(final_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
